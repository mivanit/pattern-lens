<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="pdoc 15.0.1"/>
    <title>pattern_lens.activations API documentation</title>
<link rel="stylesheet" href="../resources/css/bootstrap-reboot.min.css"><link rel="stylesheet" href="../resources/css/syntax-highlighting.css"><link rel="stylesheet" href="../resources/css/theme.css"><link rel="stylesheet" href="../resources/css/layout.css"><link rel="stylesheet" href="../resources/css/content.css"><link rel="stylesheet" href="../resources/css/custom.css"><script>
    window.MathJax = {
        tex: {
            inlineMath: [['$', '$'], ['\\(', '\\)']]
        }
    };
</script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<script>
    /* Re-invoke MathJax when DOM content changes, for example during search. */
    document.addEventListener("DOMContentLoaded", () => {
        new MutationObserver(() => MathJax.typeset()).observe(
            document.querySelector("main.pdoc").parentNode,
            {childList: true}
        );
    })
</script>
<style>
    mjx-container {
        overflow-x: auto;
        overflow-y: hidden;
    }
</style><style>
    .pdoc .mermaid-pre {
        border: none;
        background: none;
    }
</style>
<script type="module" defer>
    import mermaid from "https://cdn.jsdelivr.net/npm/mermaid@11/dist/mermaid.esm.min.mjs";

    /* Re-invoke Mermaid when DOM content changes, for example during search. */
    document.addEventListener("DOMContentLoaded", () => {
        new MutationObserver(() => mermaid.run()).observe(
            document.querySelector("main.pdoc").parentNode,
            {childList: true}
        );
    })
</script></head>
<body>
<div class="package-version">
    docs for <a href="https://github.com/mivanit/pattern-lens">pattern_lens</a> v0.4.0<br>
</div>
    <nav class="pdoc">
        <label id="navtoggle" for="togglestate" class="pdoc-button">
            <img src="../resources/svg/navtoggle.svg" alt="Toggle navigation"> 
        </label>
        <input id="togglestate" type="checkbox" aria-hidden="true" tabindex="-1">
        <div>            <a class="pdoc-button module-list-button" href="../pattern_lens.html">
                <img src="../resources/svg/box-arrow-in-left.svg" alt="Back to parent module"/>
                &nbsp;pattern_lens</a>


            <input type="search" placeholder="Search..." role="searchbox" aria-label="search"
                   pattern=".+" required>

            <h2>Contents</h2>
            <ul>
  <li><a href="#usage">Usage:</a></li>
</ul>



            <h2>API Documentation</h2>
                <ul class="memberlist">
            <li>
                    <a class="function" href="#compute_activations">compute_activations</a>
            </li>
            <li>
                    <a class="function" href="#get_activations">get_activations</a>
            </li>
            <li>
                    <a class="variable" href="#DEFAULT_DEVICE">DEFAULT_DEVICE</a>
            </li>
            <li>
                    <a class="function" href="#activations_main">activations_main</a>
            </li>
            <li>
                    <a class="function" href="#main">main</a>
            </li>
    </ul>


    <hr/>
    
    <div>
        <a href="../coverage/html/index.html" class="pdoc-button" title="View test coverage report">
            Coverage
        </a>
        <a href="../other/todo-inline.html" class="pdoc-button" title="Table of TODOs scraped from source code, with links to create issues from them">
            TODOs
        </a>
        <a href="../other/lmcat.txt" class="pdoc-button" title="a view of the repo contents made for LLMs, using https://miv.name/lmcat">
            lmcat
        </a>
    </div>


        <a class="attribution" title="pdoc: Python API documentation generator" href="https://pdoc.dev" target="_blank">
            built with <span class="visually-hidden">pdoc</span>
            <img src="../resources/svg/pdoc-logo.svg" alt="pdoc logo"/>
        </a>
</div>
    </nav>
    <main class="pdoc">
            <section class="module-info">
                        <a class="pdoc-button git-button" href="https://github.com/mivanit/pattern-lens/blob/0.4.0activations.py">View Source on GitHub</a>
                    <h1 class="modulename">
<a href="./../pattern_lens.html">pattern_lens</a><wbr>.activations    </h1>

                        <div class="docstring"><p>computing and saving activations given a model and prompts</p>

<h1 id="usage">Usage:</h1>

<p>from the command line:</p>

<div class="pdoc-code codehilite">
<pre><span></span><code>python<span class="w"> </span>-m<span class="w"> </span><a href="">pattern_lens.activations</a><span class="w"> </span>--model<span class="w"> </span>&lt;model_name&gt;<span class="w"> </span>--prompts<span class="w"> </span>&lt;prompts_path&gt;<span class="w"> </span>--save-path<span class="w"> </span>&lt;save_path&gt;<span class="w"> </span>--min-chars<span class="w"> </span>&lt;min_chars&gt;<span class="w"> </span>--max-chars<span class="w"> </span>&lt;max_chars&gt;<span class="w"> </span>--n-samples<span class="w"> </span>&lt;n_samples&gt;
</code></pre>
</div>

<p>from a script:</p>

<div class="pdoc-code codehilite">
<pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn"><a href="">pattern_lens.activations</a></span><span class="w"> </span><span class="kn">import</span> <span class="n">activations_main</span>
<span class="n">activations_main</span><span class="p">(</span>
        <span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;gpt2&quot;</span><span class="p">,</span>
        <span class="n">save_path</span><span class="o">=</span><span class="s2">&quot;demo/&quot;</span>
        <span class="n">prompts_path</span><span class="o">=</span><span class="s2">&quot;data/pile_1k.jsonl&quot;</span><span class="p">,</span>
<span class="p">)</span>
</code></pre>
</div>
</div>

                        <input id="mod-activations-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">

                        <div class="source-button-container">
            <label class="pdoc-button view-source-button" for="mod-activations-view-source"><span>View Source</span></label>
            <div class="github-button-wrapper">
                <a class="pdoc-button github-link-button" href="https://github.com/mivanit/pattern-lens/blob/0.4.0activations.py#L0-L656" target="_blank">
                    <span>View on GitHub</span>
                </a>
            </div>
        </div>

                <br/>
                        <div class="pdoc-code codehilite"><pre><span></span><span id="L-1"><a href="#L-1"><span class="linenos">  1</span></a><span class="sd">&quot;&quot;&quot;computing and saving activations given a model and prompts</span>
</span><span id="L-2"><a href="#L-2"><span class="linenos">  2</span></a>
</span><span id="L-3"><a href="#L-3"><span class="linenos">  3</span></a><span class="sd"># Usage:</span>
</span><span id="L-4"><a href="#L-4"><span class="linenos">  4</span></a>
</span><span id="L-5"><a href="#L-5"><span class="linenos">  5</span></a><span class="sd">from the command line:</span>
</span><span id="L-6"><a href="#L-6"><span class="linenos">  6</span></a>
</span><span id="L-7"><a href="#L-7"><span class="linenos">  7</span></a><span class="sd">```bash</span>
</span><span id="L-8"><a href="#L-8"><span class="linenos">  8</span></a><span class="sd">python -m pattern_lens.activations --model &lt;model_name&gt; --prompts &lt;prompts_path&gt; --save-path &lt;save_path&gt; --min-chars &lt;min_chars&gt; --max-chars &lt;max_chars&gt; --n-samples &lt;n_samples&gt;</span>
</span><span id="L-9"><a href="#L-9"><span class="linenos">  9</span></a><span class="sd">```</span>
</span><span id="L-10"><a href="#L-10"><span class="linenos"> 10</span></a>
</span><span id="L-11"><a href="#L-11"><span class="linenos"> 11</span></a><span class="sd">from a script:</span>
</span><span id="L-12"><a href="#L-12"><span class="linenos"> 12</span></a>
</span><span id="L-13"><a href="#L-13"><span class="linenos"> 13</span></a><span class="sd">```python</span>
</span><span id="L-14"><a href="#L-14"><span class="linenos"> 14</span></a><span class="sd">from pattern_lens.activations import activations_main</span>
</span><span id="L-15"><a href="#L-15"><span class="linenos"> 15</span></a><span class="sd">activations_main(</span>
</span><span id="L-16"><a href="#L-16"><span class="linenos"> 16</span></a><span class="sd">	model_name=&quot;gpt2&quot;,</span>
</span><span id="L-17"><a href="#L-17"><span class="linenos"> 17</span></a><span class="sd">	save_path=&quot;demo/&quot;</span>
</span><span id="L-18"><a href="#L-18"><span class="linenos"> 18</span></a><span class="sd">	prompts_path=&quot;data/pile_1k.jsonl&quot;,</span>
</span><span id="L-19"><a href="#L-19"><span class="linenos"> 19</span></a><span class="sd">)</span>
</span><span id="L-20"><a href="#L-20"><span class="linenos"> 20</span></a><span class="sd">```</span>
</span><span id="L-21"><a href="#L-21"><span class="linenos"> 21</span></a>
</span><span id="L-22"><a href="#L-22"><span class="linenos"> 22</span></a><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-23"><a href="#L-23"><span class="linenos"> 23</span></a>
</span><span id="L-24"><a href="#L-24"><span class="linenos"> 24</span></a><span class="kn">import</span><span class="w"> </span><span class="nn">argparse</span>
</span><span id="L-25"><a href="#L-25"><span class="linenos"> 25</span></a><span class="kn">import</span><span class="w"> </span><span class="nn">functools</span>
</span><span id="L-26"><a href="#L-26"><span class="linenos"> 26</span></a><span class="kn">import</span><span class="w"> </span><span class="nn">json</span>
</span><span id="L-27"><a href="#L-27"><span class="linenos"> 27</span></a><span class="kn">import</span><span class="w"> </span><span class="nn">re</span>
</span><span id="L-28"><a href="#L-28"><span class="linenos"> 28</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">collections.abc</span><span class="w"> </span><span class="kn">import</span> <span class="n">Callable</span>
</span><span id="L-29"><a href="#L-29"><span class="linenos"> 29</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">dataclasses</span><span class="w"> </span><span class="kn">import</span> <span class="n">asdict</span>
</span><span id="L-30"><a href="#L-30"><span class="linenos"> 30</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">pathlib</span><span class="w"> </span><span class="kn">import</span> <span class="n">Path</span>
</span><span id="L-31"><a href="#L-31"><span class="linenos"> 31</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Literal</span><span class="p">,</span> <span class="n">overload</span>
</span><span id="L-32"><a href="#L-32"><span class="linenos"> 32</span></a>
</span><span id="L-33"><a href="#L-33"><span class="linenos"> 33</span></a><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
</span><span id="L-34"><a href="#L-34"><span class="linenos"> 34</span></a><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
</span><span id="L-35"><a href="#L-35"><span class="linenos"> 35</span></a><span class="kn">import</span><span class="w"> </span><span class="nn">tqdm</span>
</span><span id="L-36"><a href="#L-36"><span class="linenos"> 36</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">jaxtyping</span><span class="w"> </span><span class="kn">import</span> <span class="n">Float</span>
</span><span id="L-37"><a href="#L-37"><span class="linenos"> 37</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">muutils.json_serialize</span><span class="w"> </span><span class="kn">import</span> <span class="n">json_serialize</span>
</span><span id="L-38"><a href="#L-38"><span class="linenos"> 38</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">muutils.misc.numerical</span><span class="w"> </span><span class="kn">import</span> <span class="n">shorten_numerical_to_str</span>
</span><span id="L-39"><a href="#L-39"><span class="linenos"> 39</span></a>
</span><span id="L-40"><a href="#L-40"><span class="linenos"> 40</span></a><span class="c1"># custom utils</span>
</span><span id="L-41"><a href="#L-41"><span class="linenos"> 41</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">muutils.spinner</span><span class="w"> </span><span class="kn">import</span> <span class="n">SpinnerContext</span>
</span><span id="L-42"><a href="#L-42"><span class="linenos"> 42</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">transformer_lens</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>  <span class="c1"># type: ignore[import-untyped]</span>
</span><span id="L-43"><a href="#L-43"><span class="linenos"> 43</span></a>	<span class="n">ActivationCache</span><span class="p">,</span>
</span><span id="L-44"><a href="#L-44"><span class="linenos"> 44</span></a>	<span class="n">HookedTransformer</span><span class="p">,</span>
</span><span id="L-45"><a href="#L-45"><span class="linenos"> 45</span></a>	<span class="n">HookedTransformerConfig</span><span class="p">,</span>
</span><span id="L-46"><a href="#L-46"><span class="linenos"> 46</span></a><span class="p">)</span>
</span><span id="L-47"><a href="#L-47"><span class="linenos"> 47</span></a>
</span><span id="L-48"><a href="#L-48"><span class="linenos"> 48</span></a><span class="c1"># pattern_lens</span>
</span><span id="L-49"><a href="#L-49"><span class="linenos"> 49</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">pattern_lens.consts</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
</span><span id="L-50"><a href="#L-50"><span class="linenos"> 50</span></a>	<span class="n">ATTN_PATTERN_REGEX</span><span class="p">,</span>
</span><span id="L-51"><a href="#L-51"><span class="linenos"> 51</span></a>	<span class="n">DATA_DIR</span><span class="p">,</span>
</span><span id="L-52"><a href="#L-52"><span class="linenos"> 52</span></a>	<span class="n">DIVIDER_S1</span><span class="p">,</span>
</span><span id="L-53"><a href="#L-53"><span class="linenos"> 53</span></a>	<span class="n">DIVIDER_S2</span><span class="p">,</span>
</span><span id="L-54"><a href="#L-54"><span class="linenos"> 54</span></a>	<span class="n">SPINNER_KWARGS</span><span class="p">,</span>
</span><span id="L-55"><a href="#L-55"><span class="linenos"> 55</span></a>	<span class="n">ActivationCacheNp</span><span class="p">,</span>
</span><span id="L-56"><a href="#L-56"><span class="linenos"> 56</span></a>	<span class="n">ReturnCache</span><span class="p">,</span>
</span><span id="L-57"><a href="#L-57"><span class="linenos"> 57</span></a><span class="p">)</span>
</span><span id="L-58"><a href="#L-58"><span class="linenos"> 58</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">pattern_lens.indexes</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
</span><span id="L-59"><a href="#L-59"><span class="linenos"> 59</span></a>	<span class="n">generate_models_jsonl</span><span class="p">,</span>
</span><span id="L-60"><a href="#L-60"><span class="linenos"> 60</span></a>	<span class="n">generate_prompts_jsonl</span><span class="p">,</span>
</span><span id="L-61"><a href="#L-61"><span class="linenos"> 61</span></a>	<span class="n">write_html_index</span><span class="p">,</span>
</span><span id="L-62"><a href="#L-62"><span class="linenos"> 62</span></a><span class="p">)</span>
</span><span id="L-63"><a href="#L-63"><span class="linenos"> 63</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">pattern_lens.load_activations</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
</span><span id="L-64"><a href="#L-64"><span class="linenos"> 64</span></a>	<span class="n">ActivationsMissingError</span><span class="p">,</span>
</span><span id="L-65"><a href="#L-65"><span class="linenos"> 65</span></a>	<span class="n">augment_prompt_with_hash</span><span class="p">,</span>
</span><span id="L-66"><a href="#L-66"><span class="linenos"> 66</span></a>	<span class="n">load_activations</span><span class="p">,</span>
</span><span id="L-67"><a href="#L-67"><span class="linenos"> 67</span></a><span class="p">)</span>
</span><span id="L-68"><a href="#L-68"><span class="linenos"> 68</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">pattern_lens.prompts</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_text_data</span>
</span><span id="L-69"><a href="#L-69"><span class="linenos"> 69</span></a>
</span><span id="L-70"><a href="#L-70"><span class="linenos"> 70</span></a>
</span><span id="L-71"><a href="#L-71"><span class="linenos"> 71</span></a><span class="c1"># return nothing, but `stack_heads` still affects how we save the activations</span>
</span><span id="L-72"><a href="#L-72"><span class="linenos"> 72</span></a><span class="nd">@overload</span>
</span><span id="L-73"><a href="#L-73"><span class="linenos"> 73</span></a><span class="k">def</span><span class="w"> </span><span class="nf">compute_activations</span><span class="p">(</span>
</span><span id="L-74"><a href="#L-74"><span class="linenos"> 74</span></a>	<span class="n">prompt</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>
</span><span id="L-75"><a href="#L-75"><span class="linenos"> 75</span></a>	<span class="n">model</span><span class="p">:</span> <span class="n">HookedTransformer</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="L-76"><a href="#L-76"><span class="linenos"> 76</span></a>	<span class="n">save_path</span><span class="p">:</span> <span class="n">Path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">DATA_DIR</span><span class="p">),</span>
</span><span id="L-77"><a href="#L-77"><span class="linenos"> 77</span></a>	<span class="n">names_filter</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="nb">str</span><span class="p">],</span> <span class="nb">bool</span><span class="p">]</span> <span class="o">|</span> <span class="n">re</span><span class="o">.</span><span class="n">Pattern</span> <span class="o">=</span> <span class="n">ATTN_PATTERN_REGEX</span><span class="p">,</span>
</span><span id="L-78"><a href="#L-78"><span class="linenos"> 78</span></a>	<span class="n">return_cache</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="L-79"><a href="#L-79"><span class="linenos"> 79</span></a>	<span class="n">stack_heads</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="L-80"><a href="#L-80"><span class="linenos"> 80</span></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Path</span><span class="p">,</span> <span class="kc">None</span><span class="p">]:</span> <span class="o">...</span>
</span><span id="L-81"><a href="#L-81"><span class="linenos"> 81</span></a><span class="c1"># return stacked heads in numpy or torch form</span>
</span><span id="L-82"><a href="#L-82"><span class="linenos"> 82</span></a><span class="nd">@overload</span>
</span><span id="L-83"><a href="#L-83"><span class="linenos"> 83</span></a><span class="k">def</span><span class="w"> </span><span class="nf">compute_activations</span><span class="p">(</span>
</span><span id="L-84"><a href="#L-84"><span class="linenos"> 84</span></a>	<span class="n">prompt</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>
</span><span id="L-85"><a href="#L-85"><span class="linenos"> 85</span></a>	<span class="n">model</span><span class="p">:</span> <span class="n">HookedTransformer</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="L-86"><a href="#L-86"><span class="linenos"> 86</span></a>	<span class="n">save_path</span><span class="p">:</span> <span class="n">Path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">DATA_DIR</span><span class="p">),</span>
</span><span id="L-87"><a href="#L-87"><span class="linenos"> 87</span></a>	<span class="n">names_filter</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="nb">str</span><span class="p">],</span> <span class="nb">bool</span><span class="p">]</span> <span class="o">|</span> <span class="n">re</span><span class="o">.</span><span class="n">Pattern</span> <span class="o">=</span> <span class="n">ATTN_PATTERN_REGEX</span><span class="p">,</span>
</span><span id="L-88"><a href="#L-88"><span class="linenos"> 88</span></a>	<span class="n">return_cache</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;torch&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;torch&quot;</span><span class="p">,</span>
</span><span id="L-89"><a href="#L-89"><span class="linenos"> 89</span></a>	<span class="n">stack_heads</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="kc">True</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="L-90"><a href="#L-90"><span class="linenos"> 90</span></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Path</span><span class="p">,</span> <span class="n">Float</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">&quot;n_layers n_heads n_ctx n_ctx&quot;</span><span class="p">]]:</span> <span class="o">...</span>
</span><span id="L-91"><a href="#L-91"><span class="linenos"> 91</span></a><span class="nd">@overload</span>
</span><span id="L-92"><a href="#L-92"><span class="linenos"> 92</span></a><span class="k">def</span><span class="w"> </span><span class="nf">compute_activations</span><span class="p">(</span>
</span><span id="L-93"><a href="#L-93"><span class="linenos"> 93</span></a>	<span class="n">prompt</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>
</span><span id="L-94"><a href="#L-94"><span class="linenos"> 94</span></a>	<span class="n">model</span><span class="p">:</span> <span class="n">HookedTransformer</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="L-95"><a href="#L-95"><span class="linenos"> 95</span></a>	<span class="n">save_path</span><span class="p">:</span> <span class="n">Path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">DATA_DIR</span><span class="p">),</span>
</span><span id="L-96"><a href="#L-96"><span class="linenos"> 96</span></a>	<span class="n">names_filter</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="nb">str</span><span class="p">],</span> <span class="nb">bool</span><span class="p">]</span> <span class="o">|</span> <span class="n">re</span><span class="o">.</span><span class="n">Pattern</span> <span class="o">=</span> <span class="n">ATTN_PATTERN_REGEX</span><span class="p">,</span>
</span><span id="L-97"><a href="#L-97"><span class="linenos"> 97</span></a>	<span class="n">return_cache</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;numpy&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;numpy&quot;</span><span class="p">,</span>
</span><span id="L-98"><a href="#L-98"><span class="linenos"> 98</span></a>	<span class="n">stack_heads</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="kc">True</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="L-99"><a href="#L-99"><span class="linenos"> 99</span></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Path</span><span class="p">,</span> <span class="n">Float</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="s2">&quot;n_layers n_heads n_ctx n_ctx&quot;</span><span class="p">]]:</span> <span class="o">...</span>
</span><span id="L-100"><a href="#L-100"><span class="linenos">100</span></a><span class="c1"># return dicts in numpy or torch form</span>
</span><span id="L-101"><a href="#L-101"><span class="linenos">101</span></a><span class="nd">@overload</span>
</span><span id="L-102"><a href="#L-102"><span class="linenos">102</span></a><span class="k">def</span><span class="w"> </span><span class="nf">compute_activations</span><span class="p">(</span>
</span><span id="L-103"><a href="#L-103"><span class="linenos">103</span></a>	<span class="n">prompt</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>
</span><span id="L-104"><a href="#L-104"><span class="linenos">104</span></a>	<span class="n">model</span><span class="p">:</span> <span class="n">HookedTransformer</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="L-105"><a href="#L-105"><span class="linenos">105</span></a>	<span class="n">save_path</span><span class="p">:</span> <span class="n">Path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">DATA_DIR</span><span class="p">),</span>
</span><span id="L-106"><a href="#L-106"><span class="linenos">106</span></a>	<span class="n">names_filter</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="nb">str</span><span class="p">],</span> <span class="nb">bool</span><span class="p">]</span> <span class="o">|</span> <span class="n">re</span><span class="o">.</span><span class="n">Pattern</span> <span class="o">=</span> <span class="n">ATTN_PATTERN_REGEX</span><span class="p">,</span>
</span><span id="L-107"><a href="#L-107"><span class="linenos">107</span></a>	<span class="n">return_cache</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;numpy&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;numpy&quot;</span><span class="p">,</span>
</span><span id="L-108"><a href="#L-108"><span class="linenos">108</span></a>	<span class="n">stack_heads</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="kc">False</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="L-109"><a href="#L-109"><span class="linenos">109</span></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Path</span><span class="p">,</span> <span class="n">ActivationCacheNp</span><span class="p">]:</span> <span class="o">...</span>
</span><span id="L-110"><a href="#L-110"><span class="linenos">110</span></a><span class="nd">@overload</span>
</span><span id="L-111"><a href="#L-111"><span class="linenos">111</span></a><span class="k">def</span><span class="w"> </span><span class="nf">compute_activations</span><span class="p">(</span>
</span><span id="L-112"><a href="#L-112"><span class="linenos">112</span></a>	<span class="n">prompt</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>
</span><span id="L-113"><a href="#L-113"><span class="linenos">113</span></a>	<span class="n">model</span><span class="p">:</span> <span class="n">HookedTransformer</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="L-114"><a href="#L-114"><span class="linenos">114</span></a>	<span class="n">save_path</span><span class="p">:</span> <span class="n">Path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">DATA_DIR</span><span class="p">),</span>
</span><span id="L-115"><a href="#L-115"><span class="linenos">115</span></a>	<span class="n">names_filter</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="nb">str</span><span class="p">],</span> <span class="nb">bool</span><span class="p">]</span> <span class="o">|</span> <span class="n">re</span><span class="o">.</span><span class="n">Pattern</span> <span class="o">=</span> <span class="n">ATTN_PATTERN_REGEX</span><span class="p">,</span>
</span><span id="L-116"><a href="#L-116"><span class="linenos">116</span></a>	<span class="n">return_cache</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;torch&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;torch&quot;</span><span class="p">,</span>
</span><span id="L-117"><a href="#L-117"><span class="linenos">117</span></a>	<span class="n">stack_heads</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="kc">False</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="L-118"><a href="#L-118"><span class="linenos">118</span></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Path</span><span class="p">,</span> <span class="n">ActivationCache</span><span class="p">]:</span> <span class="o">...</span>
</span><span id="L-119"><a href="#L-119"><span class="linenos">119</span></a><span class="c1"># actual function body</span>
</span><span id="L-120"><a href="#L-120"><span class="linenos">120</span></a><span class="k">def</span><span class="w"> </span><span class="nf">compute_activations</span><span class="p">(</span>  <span class="c1"># noqa: PLR0915</span>
</span><span id="L-121"><a href="#L-121"><span class="linenos">121</span></a>	<span class="n">prompt</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>
</span><span id="L-122"><a href="#L-122"><span class="linenos">122</span></a>	<span class="n">model</span><span class="p">:</span> <span class="n">HookedTransformer</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="L-123"><a href="#L-123"><span class="linenos">123</span></a>	<span class="n">save_path</span><span class="p">:</span> <span class="n">Path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">DATA_DIR</span><span class="p">),</span>
</span><span id="L-124"><a href="#L-124"><span class="linenos">124</span></a>	<span class="n">names_filter</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="nb">str</span><span class="p">],</span> <span class="nb">bool</span><span class="p">]</span> <span class="o">|</span> <span class="n">re</span><span class="o">.</span><span class="n">Pattern</span> <span class="o">=</span> <span class="n">ATTN_PATTERN_REGEX</span><span class="p">,</span>
</span><span id="L-125"><a href="#L-125"><span class="linenos">125</span></a>	<span class="n">return_cache</span><span class="p">:</span> <span class="n">ReturnCache</span> <span class="o">=</span> <span class="s2">&quot;torch&quot;</span><span class="p">,</span>
</span><span id="L-126"><a href="#L-126"><span class="linenos">126</span></a>	<span class="n">stack_heads</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="L-127"><a href="#L-127"><span class="linenos">127</span></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span>
</span><span id="L-128"><a href="#L-128"><span class="linenos">128</span></a>	<span class="n">Path</span><span class="p">,</span>
</span><span id="L-129"><a href="#L-129"><span class="linenos">129</span></a>	<span class="n">ActivationCacheNp</span>
</span><span id="L-130"><a href="#L-130"><span class="linenos">130</span></a>	<span class="o">|</span> <span class="n">ActivationCache</span>
</span><span id="L-131"><a href="#L-131"><span class="linenos">131</span></a>	<span class="o">|</span> <span class="n">Float</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="s2">&quot;n_layers n_heads n_ctx n_ctx&quot;</span><span class="p">]</span>
</span><span id="L-132"><a href="#L-132"><span class="linenos">132</span></a>	<span class="o">|</span> <span class="n">Float</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">&quot;n_layers n_heads n_ctx n_ctx&quot;</span><span class="p">]</span>
</span><span id="L-133"><a href="#L-133"><span class="linenos">133</span></a>	<span class="o">|</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="L-134"><a href="#L-134"><span class="linenos">134</span></a><span class="p">]:</span>
</span><span id="L-135"><a href="#L-135"><span class="linenos">135</span></a><span class="w">	</span><span class="sd">&quot;&quot;&quot;get activations for a given model and prompt, possibly from a cache</span>
</span><span id="L-136"><a href="#L-136"><span class="linenos">136</span></a>
</span><span id="L-137"><a href="#L-137"><span class="linenos">137</span></a><span class="sd">	if from a cache, prompt_meta must be passed and contain the prompt hash</span>
</span><span id="L-138"><a href="#L-138"><span class="linenos">138</span></a>
</span><span id="L-139"><a href="#L-139"><span class="linenos">139</span></a><span class="sd">	# Parameters:</span>
</span><span id="L-140"><a href="#L-140"><span class="linenos">140</span></a><span class="sd">	- `prompt : dict | None`</span>
</span><span id="L-141"><a href="#L-141"><span class="linenos">141</span></a><span class="sd">		(defaults to `None`)</span>
</span><span id="L-142"><a href="#L-142"><span class="linenos">142</span></a><span class="sd">	- `model : HookedTransformer`</span>
</span><span id="L-143"><a href="#L-143"><span class="linenos">143</span></a><span class="sd">	- `save_path : Path`</span>
</span><span id="L-144"><a href="#L-144"><span class="linenos">144</span></a><span class="sd">		(defaults to `Path(DATA_DIR)`)</span>
</span><span id="L-145"><a href="#L-145"><span class="linenos">145</span></a><span class="sd">	- `names_filter : Callable[[str], bool]|re.Pattern`</span>
</span><span id="L-146"><a href="#L-146"><span class="linenos">146</span></a><span class="sd">		a filter for the names of the activations to return. if an `re.Pattern`, will use `lambda key: names_filter.match(key) is not None`</span>
</span><span id="L-147"><a href="#L-147"><span class="linenos">147</span></a><span class="sd">		(defaults to `ATTN_PATTERN_REGEX`)</span>
</span><span id="L-148"><a href="#L-148"><span class="linenos">148</span></a><span class="sd">	- `return_cache : Literal[None, &quot;numpy&quot;, &quot;torch&quot;]`</span>
</span><span id="L-149"><a href="#L-149"><span class="linenos">149</span></a><span class="sd">		will return `None` as the second element if `None`, otherwise will return the cache in the specified tensor format. `stack_heads` still affects whether it will be a dict (False) or a single tensor (True)</span>
</span><span id="L-150"><a href="#L-150"><span class="linenos">150</span></a><span class="sd">		(defaults to `None`)</span>
</span><span id="L-151"><a href="#L-151"><span class="linenos">151</span></a><span class="sd">	- `stack_heads : bool`</span>
</span><span id="L-152"><a href="#L-152"><span class="linenos">152</span></a><span class="sd">		whether the heads should be stacked in the output. this causes a number of changes:</span>
</span><span id="L-153"><a href="#L-153"><span class="linenos">153</span></a><span class="sd">	- `npy` file with a single `(n_layers, n_heads, n_ctx, n_ctx)` tensor saved for each prompt instead of `npz` file with dict by layer</span>
</span><span id="L-154"><a href="#L-154"><span class="linenos">154</span></a><span class="sd">	- `cache` will be a single `(n_layers, n_heads, n_ctx, n_ctx)` tensor instead of a dict by layer if `return_cache` is `True`</span>
</span><span id="L-155"><a href="#L-155"><span class="linenos">155</span></a><span class="sd">		will assert that everything in the activation cache is only attention patterns, and is all of the attention patterns. raises an exception if not.</span>
</span><span id="L-156"><a href="#L-156"><span class="linenos">156</span></a>
</span><span id="L-157"><a href="#L-157"><span class="linenos">157</span></a><span class="sd">	# Returns:</span>
</span><span id="L-158"><a href="#L-158"><span class="linenos">158</span></a><span class="sd">	```</span>
</span><span id="L-159"><a href="#L-159"><span class="linenos">159</span></a><span class="sd">	tuple[</span>
</span><span id="L-160"><a href="#L-160"><span class="linenos">160</span></a><span class="sd">		Path,</span>
</span><span id="L-161"><a href="#L-161"><span class="linenos">161</span></a><span class="sd">		Union[</span>
</span><span id="L-162"><a href="#L-162"><span class="linenos">162</span></a><span class="sd">			None,</span>
</span><span id="L-163"><a href="#L-163"><span class="linenos">163</span></a><span class="sd">			ActivationCacheNp, ActivationCache,</span>
</span><span id="L-164"><a href="#L-164"><span class="linenos">164</span></a><span class="sd">			Float[np.ndarray, &quot;n_layers n_heads n_ctx n_ctx&quot;], Float[torch.Tensor, &quot;n_layers n_heads n_ctx n_ctx&quot;],</span>
</span><span id="L-165"><a href="#L-165"><span class="linenos">165</span></a><span class="sd">		]</span>
</span><span id="L-166"><a href="#L-166"><span class="linenos">166</span></a><span class="sd">	]</span>
</span><span id="L-167"><a href="#L-167"><span class="linenos">167</span></a><span class="sd">	```</span>
</span><span id="L-168"><a href="#L-168"><span class="linenos">168</span></a><span class="sd">	&quot;&quot;&quot;</span>
</span><span id="L-169"><a href="#L-169"><span class="linenos">169</span></a>	<span class="c1"># check inputs</span>
</span><span id="L-170"><a href="#L-170"><span class="linenos">170</span></a>	<span class="k">assert</span> <span class="n">model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;model must be passed&quot;</span>
</span><span id="L-171"><a href="#L-171"><span class="linenos">171</span></a>	<span class="k">assert</span> <span class="s2">&quot;text&quot;</span> <span class="ow">in</span> <span class="n">prompt</span><span class="p">,</span> <span class="s2">&quot;prompt must contain &#39;text&#39; key&quot;</span>
</span><span id="L-172"><a href="#L-172"><span class="linenos">172</span></a>	<span class="n">prompt_str</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">prompt</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]</span>
</span><span id="L-173"><a href="#L-173"><span class="linenos">173</span></a>
</span><span id="L-174"><a href="#L-174"><span class="linenos">174</span></a>	<span class="c1"># compute or get prompt metadata</span>
</span><span id="L-175"><a href="#L-175"><span class="linenos">175</span></a>	<span class="n">prompt_tokenized</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">prompt</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
</span><span id="L-176"><a href="#L-176"><span class="linenos">176</span></a>		<span class="s2">&quot;tokens&quot;</span><span class="p">,</span>
</span><span id="L-177"><a href="#L-177"><span class="linenos">177</span></a>		<span class="n">model</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">prompt_str</span><span class="p">),</span>
</span><span id="L-178"><a href="#L-178"><span class="linenos">178</span></a>	<span class="p">)</span>
</span><span id="L-179"><a href="#L-179"><span class="linenos">179</span></a>	<span class="n">prompt</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
</span><span id="L-180"><a href="#L-180"><span class="linenos">180</span></a>		<span class="nb">dict</span><span class="p">(</span>
</span><span id="L-181"><a href="#L-181"><span class="linenos">181</span></a>			<span class="n">n_tokens</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">prompt_tokenized</span><span class="p">),</span>
</span><span id="L-182"><a href="#L-182"><span class="linenos">182</span></a>			<span class="n">tokens</span><span class="o">=</span><span class="n">prompt_tokenized</span><span class="p">,</span>
</span><span id="L-183"><a href="#L-183"><span class="linenos">183</span></a>		<span class="p">),</span>
</span><span id="L-184"><a href="#L-184"><span class="linenos">184</span></a>	<span class="p">)</span>
</span><span id="L-185"><a href="#L-185"><span class="linenos">185</span></a>
</span><span id="L-186"><a href="#L-186"><span class="linenos">186</span></a>	<span class="c1"># save metadata</span>
</span><span id="L-187"><a href="#L-187"><span class="linenos">187</span></a>	<span class="n">prompt_dir</span><span class="p">:</span> <span class="n">Path</span> <span class="o">=</span> <span class="n">save_path</span> <span class="o">/</span> <span class="n">model</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">model_name</span> <span class="o">/</span> <span class="s2">&quot;prompts&quot;</span> <span class="o">/</span> <span class="n">prompt</span><span class="p">[</span><span class="s2">&quot;hash&quot;</span><span class="p">]</span>
</span><span id="L-188"><a href="#L-188"><span class="linenos">188</span></a>	<span class="n">prompt_dir</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="L-189"><a href="#L-189"><span class="linenos">189</span></a>	<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">prompt_dir</span> <span class="o">/</span> <span class="s2">&quot;prompt.json&quot;</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span><span id="L-190"><a href="#L-190"><span class="linenos">190</span></a>		<span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
</span><span id="L-191"><a href="#L-191"><span class="linenos">191</span></a>
</span><span id="L-192"><a href="#L-192"><span class="linenos">192</span></a>	<span class="c1"># set up names filter</span>
</span><span id="L-193"><a href="#L-193"><span class="linenos">193</span></a>	<span class="n">names_filter_fn</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="nb">str</span><span class="p">],</span> <span class="nb">bool</span><span class="p">]</span>
</span><span id="L-194"><a href="#L-194"><span class="linenos">194</span></a>	<span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">names_filter</span><span class="p">,</span> <span class="n">re</span><span class="o">.</span><span class="n">Pattern</span><span class="p">):</span>
</span><span id="L-195"><a href="#L-195"><span class="linenos">195</span></a>		<span class="n">names_filter_fn</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">key</span><span class="p">:</span> <span class="n">names_filter</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="n">key</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>  <span class="c1"># noqa: E731</span>
</span><span id="L-196"><a href="#L-196"><span class="linenos">196</span></a>	<span class="k">else</span><span class="p">:</span>
</span><span id="L-197"><a href="#L-197"><span class="linenos">197</span></a>		<span class="n">names_filter_fn</span> <span class="o">=</span> <span class="n">names_filter</span>
</span><span id="L-198"><a href="#L-198"><span class="linenos">198</span></a>
</span><span id="L-199"><a href="#L-199"><span class="linenos">199</span></a>	<span class="c1"># compute activations</span>
</span><span id="L-200"><a href="#L-200"><span class="linenos">200</span></a>	<span class="n">cache_torch</span><span class="p">:</span> <span class="n">ActivationCache</span>
</span><span id="L-201"><a href="#L-201"><span class="linenos">201</span></a>	<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
</span><span id="L-202"><a href="#L-202"><span class="linenos">202</span></a>		<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</span><span id="L-203"><a href="#L-203"><span class="linenos">203</span></a>		<span class="c1"># TODO: batching?</span>
</span><span id="L-204"><a href="#L-204"><span class="linenos">204</span></a>		<span class="n">_</span><span class="p">,</span> <span class="n">cache_torch</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">run_with_cache</span><span class="p">(</span>
</span><span id="L-205"><a href="#L-205"><span class="linenos">205</span></a>			<span class="n">prompt_str</span><span class="p">,</span>
</span><span id="L-206"><a href="#L-206"><span class="linenos">206</span></a>			<span class="n">names_filter</span><span class="o">=</span><span class="n">names_filter_fn</span><span class="p">,</span>
</span><span id="L-207"><a href="#L-207"><span class="linenos">207</span></a>			<span class="n">return_type</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="L-208"><a href="#L-208"><span class="linenos">208</span></a>		<span class="p">)</span>
</span><span id="L-209"><a href="#L-209"><span class="linenos">209</span></a>
</span><span id="L-210"><a href="#L-210"><span class="linenos">210</span></a>	<span class="n">activations_path</span><span class="p">:</span> <span class="n">Path</span>
</span><span id="L-211"><a href="#L-211"><span class="linenos">211</span></a>	<span class="c1"># saving and returning</span>
</span><span id="L-212"><a href="#L-212"><span class="linenos">212</span></a>	<span class="k">if</span> <span class="n">stack_heads</span><span class="p">:</span>
</span><span id="L-213"><a href="#L-213"><span class="linenos">213</span></a>		<span class="n">n_layers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_layers</span>
</span><span id="L-214"><a href="#L-214"><span class="linenos">214</span></a>		<span class="n">key_pattern</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;blocks.</span><span class="si">{i}</span><span class="s2">.attn.hook_pattern&quot;</span>
</span><span id="L-215"><a href="#L-215"><span class="linenos">215</span></a>		<span class="c1"># NOTE: this only works for stacking heads at the moment</span>
</span><span id="L-216"><a href="#L-216"><span class="linenos">216</span></a>		<span class="c1"># activations_specifier: str = key_pattern.format(i=f&#39;0-{n_layers}&#39;)</span>
</span><span id="L-217"><a href="#L-217"><span class="linenos">217</span></a>		<span class="n">activations_specifier</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">key_pattern</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="o">=</span><span class="s2">&quot;-&quot;</span><span class="p">)</span>
</span><span id="L-218"><a href="#L-218"><span class="linenos">218</span></a>		<span class="n">activations_path</span> <span class="o">=</span> <span class="n">prompt_dir</span> <span class="o">/</span> <span class="sa">f</span><span class="s2">&quot;activations-</span><span class="si">{</span><span class="n">activations_specifier</span><span class="si">}</span><span class="s2">.npy&quot;</span>
</span><span id="L-219"><a href="#L-219"><span class="linenos">219</span></a>
</span><span id="L-220"><a href="#L-220"><span class="linenos">220</span></a>		<span class="c1"># check the keys are only attention heads</span>
</span><span id="L-221"><a href="#L-221"><span class="linenos">221</span></a>		<span class="n">head_keys</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">key_pattern</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="o">=</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_layers</span><span class="p">)]</span>
</span><span id="L-222"><a href="#L-222"><span class="linenos">222</span></a>		<span class="n">cache_torch_keys_set</span><span class="p">:</span> <span class="nb">set</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">cache_torch</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
</span><span id="L-223"><a href="#L-223"><span class="linenos">223</span></a>		<span class="k">assert</span> <span class="n">cache_torch_keys_set</span> <span class="o">==</span> <span class="nb">set</span><span class="p">(</span><span class="n">head_keys</span><span class="p">),</span> <span class="p">(</span>
</span><span id="L-224"><a href="#L-224"><span class="linenos">224</span></a>			<span class="sa">f</span><span class="s2">&quot;unexpected keys!</span><span class="se">\n</span><span class="si">{</span><span class="nb">set</span><span class="p">(</span><span class="n">head_keys</span><span class="p">)</span><span class="o">.</span><span class="n">symmetric_difference</span><span class="p">(</span><span class="n">cache_torch_keys_set</span><span class="p">)</span><span class="w"> </span><span class="si">= }</span><span class="se">\n</span><span class="si">{</span><span class="n">cache_torch_keys_set</span><span class="si">}</span><span class="s2"> != </span><span class="si">{</span><span class="nb">set</span><span class="p">(</span><span class="n">head_keys</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
</span><span id="L-225"><a href="#L-225"><span class="linenos">225</span></a>		<span class="p">)</span>
</span><span id="L-226"><a href="#L-226"><span class="linenos">226</span></a>
</span><span id="L-227"><a href="#L-227"><span class="linenos">227</span></a>		<span class="c1"># stack heads</span>
</span><span id="L-228"><a href="#L-228"><span class="linenos">228</span></a>		<span class="n">patterns_stacked</span><span class="p">:</span> <span class="n">Float</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">&quot;n_layers n_heads n_ctx n_ctx&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="L-229"><a href="#L-229"><span class="linenos">229</span></a>			<span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">cache_torch</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">head_keys</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span><span id="L-230"><a href="#L-230"><span class="linenos">230</span></a>		<span class="p">)</span>
</span><span id="L-231"><a href="#L-231"><span class="linenos">231</span></a>		<span class="c1"># check shape</span>
</span><span id="L-232"><a href="#L-232"><span class="linenos">232</span></a>		<span class="n">pattern_shape_no_ctx</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">patterns_stacked</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">3</span><span class="p">])</span>
</span><span id="L-233"><a href="#L-233"><span class="linenos">233</span></a>		<span class="k">assert</span> <span class="n">pattern_shape_no_ctx</span> <span class="o">==</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_heads</span><span class="p">),</span> <span class="p">(</span>
</span><span id="L-234"><a href="#L-234"><span class="linenos">234</span></a>			<span class="sa">f</span><span class="s2">&quot;unexpected shape: </span><span class="si">{</span><span class="n">patterns_stacked</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span><span class="w"> </span><span class="si">= }</span><span class="s2"> (</span><span class="si">{</span><span class="n">pattern_shape_no_ctx</span><span class="w"> </span><span class="si">= }</span><span class="s2">), expected </span><span class="si">{</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">n_layers</span><span class="p">,</span><span class="w"> </span><span class="n">model</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_heads</span><span class="p">)</span><span class="w"> </span><span class="si">= }</span><span class="s2">&quot;</span>
</span><span id="L-235"><a href="#L-235"><span class="linenos">235</span></a>		<span class="p">)</span>
</span><span id="L-236"><a href="#L-236"><span class="linenos">236</span></a>
</span><span id="L-237"><a href="#L-237"><span class="linenos">237</span></a>		<span class="n">patterns_stacked_np</span><span class="p">:</span> <span class="n">Float</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="s2">&quot;n_layers n_heads n_ctx n_ctx&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="L-238"><a href="#L-238"><span class="linenos">238</span></a>			<span class="n">patterns_stacked</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span><span id="L-239"><a href="#L-239"><span class="linenos">239</span></a>		<span class="p">)</span>
</span><span id="L-240"><a href="#L-240"><span class="linenos">240</span></a>
</span><span id="L-241"><a href="#L-241"><span class="linenos">241</span></a>		<span class="c1"># save</span>
</span><span id="L-242"><a href="#L-242"><span class="linenos">242</span></a>		<span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">activations_path</span><span class="p">,</span> <span class="n">patterns_stacked_np</span><span class="p">)</span>
</span><span id="L-243"><a href="#L-243"><span class="linenos">243</span></a>
</span><span id="L-244"><a href="#L-244"><span class="linenos">244</span></a>		<span class="c1"># return</span>
</span><span id="L-245"><a href="#L-245"><span class="linenos">245</span></a>		<span class="k">match</span> <span class="n">return_cache</span><span class="p">:</span>
</span><span id="L-246"><a href="#L-246"><span class="linenos">246</span></a>			<span class="k">case</span> <span class="s2">&quot;numpy&quot;</span><span class="p">:</span>
</span><span id="L-247"><a href="#L-247"><span class="linenos">247</span></a>				<span class="k">return</span> <span class="n">activations_path</span><span class="p">,</span> <span class="n">patterns_stacked_np</span>
</span><span id="L-248"><a href="#L-248"><span class="linenos">248</span></a>			<span class="k">case</span> <span class="s2">&quot;torch&quot;</span><span class="p">:</span>
</span><span id="L-249"><a href="#L-249"><span class="linenos">249</span></a>				<span class="k">return</span> <span class="n">activations_path</span><span class="p">,</span> <span class="n">patterns_stacked</span>
</span><span id="L-250"><a href="#L-250"><span class="linenos">250</span></a>			<span class="k">case</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-251"><a href="#L-251"><span class="linenos">251</span></a>				<span class="k">return</span> <span class="n">activations_path</span><span class="p">,</span> <span class="kc">None</span>
</span><span id="L-252"><a href="#L-252"><span class="linenos">252</span></a>			<span class="k">case</span><span class="w"> </span><span class="k">_</span><span class="p">:</span>
</span><span id="L-253"><a href="#L-253"><span class="linenos">253</span></a>				<span class="n">msg</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;invalid return_cache: </span><span class="si">{</span><span class="n">return_cache</span><span class="w"> </span><span class="si">= }</span><span class="s2">&quot;</span>
</span><span id="L-254"><a href="#L-254"><span class="linenos">254</span></a>				<span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
</span><span id="L-255"><a href="#L-255"><span class="linenos">255</span></a>	<span class="k">else</span><span class="p">:</span>
</span><span id="L-256"><a href="#L-256"><span class="linenos">256</span></a>		<span class="n">activations_path</span> <span class="o">=</span> <span class="n">prompt_dir</span> <span class="o">/</span> <span class="s2">&quot;activations.npz&quot;</span>
</span><span id="L-257"><a href="#L-257"><span class="linenos">257</span></a>
</span><span id="L-258"><a href="#L-258"><span class="linenos">258</span></a>		<span class="c1"># save</span>
</span><span id="L-259"><a href="#L-259"><span class="linenos">259</span></a>		<span class="n">cache_np</span><span class="p">:</span> <span class="n">ActivationCacheNp</span> <span class="o">=</span> <span class="p">{</span>
</span><span id="L-260"><a href="#L-260"><span class="linenos">260</span></a>			<span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">cache_torch</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
</span><span id="L-261"><a href="#L-261"><span class="linenos">261</span></a>		<span class="p">}</span>
</span><span id="L-262"><a href="#L-262"><span class="linenos">262</span></a>
</span><span id="L-263"><a href="#L-263"><span class="linenos">263</span></a>		<span class="n">np</span><span class="o">.</span><span class="n">savez_compressed</span><span class="p">(</span>
</span><span id="L-264"><a href="#L-264"><span class="linenos">264</span></a>			<span class="n">activations_path</span><span class="p">,</span>
</span><span id="L-265"><a href="#L-265"><span class="linenos">265</span></a>			<span class="o">**</span><span class="n">cache_np</span><span class="p">,</span>
</span><span id="L-266"><a href="#L-266"><span class="linenos">266</span></a>		<span class="p">)</span>
</span><span id="L-267"><a href="#L-267"><span class="linenos">267</span></a>
</span><span id="L-268"><a href="#L-268"><span class="linenos">268</span></a>		<span class="c1"># return</span>
</span><span id="L-269"><a href="#L-269"><span class="linenos">269</span></a>		<span class="k">match</span> <span class="n">return_cache</span><span class="p">:</span>
</span><span id="L-270"><a href="#L-270"><span class="linenos">270</span></a>			<span class="k">case</span> <span class="s2">&quot;numpy&quot;</span><span class="p">:</span>
</span><span id="L-271"><a href="#L-271"><span class="linenos">271</span></a>				<span class="k">return</span> <span class="n">activations_path</span><span class="p">,</span> <span class="n">cache_np</span>
</span><span id="L-272"><a href="#L-272"><span class="linenos">272</span></a>			<span class="k">case</span> <span class="s2">&quot;torch&quot;</span><span class="p">:</span>
</span><span id="L-273"><a href="#L-273"><span class="linenos">273</span></a>				<span class="k">return</span> <span class="n">activations_path</span><span class="p">,</span> <span class="n">cache_torch</span>
</span><span id="L-274"><a href="#L-274"><span class="linenos">274</span></a>			<span class="k">case</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-275"><a href="#L-275"><span class="linenos">275</span></a>				<span class="k">return</span> <span class="n">activations_path</span><span class="p">,</span> <span class="kc">None</span>
</span><span id="L-276"><a href="#L-276"><span class="linenos">276</span></a>			<span class="k">case</span><span class="w"> </span><span class="k">_</span><span class="p">:</span>
</span><span id="L-277"><a href="#L-277"><span class="linenos">277</span></a>				<span class="n">msg</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;invalid return_cache: </span><span class="si">{</span><span class="n">return_cache</span><span class="w"> </span><span class="si">= }</span><span class="s2">&quot;</span>
</span><span id="L-278"><a href="#L-278"><span class="linenos">278</span></a>				<span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
</span><span id="L-279"><a href="#L-279"><span class="linenos">279</span></a>
</span><span id="L-280"><a href="#L-280"><span class="linenos">280</span></a>
</span><span id="L-281"><a href="#L-281"><span class="linenos">281</span></a><span class="nd">@overload</span>
</span><span id="L-282"><a href="#L-282"><span class="linenos">282</span></a><span class="k">def</span><span class="w"> </span><span class="nf">get_activations</span><span class="p">(</span>
</span><span id="L-283"><a href="#L-283"><span class="linenos">283</span></a>	<span class="n">prompt</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>
</span><span id="L-284"><a href="#L-284"><span class="linenos">284</span></a>	<span class="n">model</span><span class="p">:</span> <span class="n">HookedTransformer</span> <span class="o">|</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="L-285"><a href="#L-285"><span class="linenos">285</span></a>	<span class="n">save_path</span><span class="p">:</span> <span class="n">Path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">DATA_DIR</span><span class="p">),</span>
</span><span id="L-286"><a href="#L-286"><span class="linenos">286</span></a>	<span class="n">allow_disk_cache</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="L-287"><a href="#L-287"><span class="linenos">287</span></a>	<span class="n">return_cache</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="L-288"><a href="#L-288"><span class="linenos">288</span></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Path</span><span class="p">,</span> <span class="kc">None</span><span class="p">]:</span> <span class="o">...</span>
</span><span id="L-289"><a href="#L-289"><span class="linenos">289</span></a><span class="nd">@overload</span>
</span><span id="L-290"><a href="#L-290"><span class="linenos">290</span></a><span class="k">def</span><span class="w"> </span><span class="nf">get_activations</span><span class="p">(</span>
</span><span id="L-291"><a href="#L-291"><span class="linenos">291</span></a>	<span class="n">prompt</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>
</span><span id="L-292"><a href="#L-292"><span class="linenos">292</span></a>	<span class="n">model</span><span class="p">:</span> <span class="n">HookedTransformer</span> <span class="o">|</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="L-293"><a href="#L-293"><span class="linenos">293</span></a>	<span class="n">save_path</span><span class="p">:</span> <span class="n">Path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">DATA_DIR</span><span class="p">),</span>
</span><span id="L-294"><a href="#L-294"><span class="linenos">294</span></a>	<span class="n">allow_disk_cache</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="L-295"><a href="#L-295"><span class="linenos">295</span></a>	<span class="n">return_cache</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;torch&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;torch&quot;</span><span class="p">,</span>
</span><span id="L-296"><a href="#L-296"><span class="linenos">296</span></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Path</span><span class="p">,</span> <span class="n">ActivationCache</span><span class="p">]:</span> <span class="o">...</span>
</span><span id="L-297"><a href="#L-297"><span class="linenos">297</span></a><span class="nd">@overload</span>
</span><span id="L-298"><a href="#L-298"><span class="linenos">298</span></a><span class="k">def</span><span class="w"> </span><span class="nf">get_activations</span><span class="p">(</span>
</span><span id="L-299"><a href="#L-299"><span class="linenos">299</span></a>	<span class="n">prompt</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>
</span><span id="L-300"><a href="#L-300"><span class="linenos">300</span></a>	<span class="n">model</span><span class="p">:</span> <span class="n">HookedTransformer</span> <span class="o">|</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="L-301"><a href="#L-301"><span class="linenos">301</span></a>	<span class="n">save_path</span><span class="p">:</span> <span class="n">Path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">DATA_DIR</span><span class="p">),</span>
</span><span id="L-302"><a href="#L-302"><span class="linenos">302</span></a>	<span class="n">allow_disk_cache</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="L-303"><a href="#L-303"><span class="linenos">303</span></a>	<span class="n">return_cache</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;numpy&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;numpy&quot;</span><span class="p">,</span>
</span><span id="L-304"><a href="#L-304"><span class="linenos">304</span></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Path</span><span class="p">,</span> <span class="n">ActivationCacheNp</span><span class="p">]:</span> <span class="o">...</span>
</span><span id="L-305"><a href="#L-305"><span class="linenos">305</span></a><span class="k">def</span><span class="w"> </span><span class="nf">get_activations</span><span class="p">(</span>
</span><span id="L-306"><a href="#L-306"><span class="linenos">306</span></a>	<span class="n">prompt</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>
</span><span id="L-307"><a href="#L-307"><span class="linenos">307</span></a>	<span class="n">model</span><span class="p">:</span> <span class="n">HookedTransformer</span> <span class="o">|</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="L-308"><a href="#L-308"><span class="linenos">308</span></a>	<span class="n">save_path</span><span class="p">:</span> <span class="n">Path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">DATA_DIR</span><span class="p">),</span>
</span><span id="L-309"><a href="#L-309"><span class="linenos">309</span></a>	<span class="n">allow_disk_cache</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="L-310"><a href="#L-310"><span class="linenos">310</span></a>	<span class="n">return_cache</span><span class="p">:</span> <span class="n">ReturnCache</span> <span class="o">=</span> <span class="s2">&quot;numpy&quot;</span><span class="p">,</span>
</span><span id="L-311"><a href="#L-311"><span class="linenos">311</span></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Path</span><span class="p">,</span> <span class="n">ActivationCacheNp</span> <span class="o">|</span> <span class="n">ActivationCache</span> <span class="o">|</span> <span class="kc">None</span><span class="p">]:</span>
</span><span id="L-312"><a href="#L-312"><span class="linenos">312</span></a><span class="w">	</span><span class="sd">&quot;&quot;&quot;given a prompt and a model, save or load activations</span>
</span><span id="L-313"><a href="#L-313"><span class="linenos">313</span></a>
</span><span id="L-314"><a href="#L-314"><span class="linenos">314</span></a><span class="sd">	# Parameters:</span>
</span><span id="L-315"><a href="#L-315"><span class="linenos">315</span></a><span class="sd">	- `prompt : dict`</span>
</span><span id="L-316"><a href="#L-316"><span class="linenos">316</span></a><span class="sd">		expected to contain the &#39;text&#39; key</span>
</span><span id="L-317"><a href="#L-317"><span class="linenos">317</span></a><span class="sd">	- `model : HookedTransformer | str`</span>
</span><span id="L-318"><a href="#L-318"><span class="linenos">318</span></a><span class="sd">		either a `HookedTransformer` or a string model name, to be loaded with `HookedTransformer.from_pretrained`</span>
</span><span id="L-319"><a href="#L-319"><span class="linenos">319</span></a><span class="sd">	- `save_path : Path`</span>
</span><span id="L-320"><a href="#L-320"><span class="linenos">320</span></a><span class="sd">		path to save the activations to (and load from)</span>
</span><span id="L-321"><a href="#L-321"><span class="linenos">321</span></a><span class="sd">		(defaults to `Path(DATA_DIR)`)</span>
</span><span id="L-322"><a href="#L-322"><span class="linenos">322</span></a><span class="sd">	- `allow_disk_cache : bool`</span>
</span><span id="L-323"><a href="#L-323"><span class="linenos">323</span></a><span class="sd">		whether to allow loading from disk cache</span>
</span><span id="L-324"><a href="#L-324"><span class="linenos">324</span></a><span class="sd">		(defaults to `True`)</span>
</span><span id="L-325"><a href="#L-325"><span class="linenos">325</span></a><span class="sd">	- `return_cache : Literal[None, &quot;numpy&quot;, &quot;torch&quot;]`</span>
</span><span id="L-326"><a href="#L-326"><span class="linenos">326</span></a><span class="sd">		whether to return the cache, and in what format</span>
</span><span id="L-327"><a href="#L-327"><span class="linenos">327</span></a><span class="sd">		(defaults to `&quot;numpy&quot;`)</span>
</span><span id="L-328"><a href="#L-328"><span class="linenos">328</span></a>
</span><span id="L-329"><a href="#L-329"><span class="linenos">329</span></a><span class="sd">	# Returns:</span>
</span><span id="L-330"><a href="#L-330"><span class="linenos">330</span></a><span class="sd">	- `tuple[Path, ActivationCacheNp | ActivationCache | None]`</span>
</span><span id="L-331"><a href="#L-331"><span class="linenos">331</span></a><span class="sd">		the path to the activations and the cache if `return_cache is not None`</span>
</span><span id="L-332"><a href="#L-332"><span class="linenos">332</span></a>
</span><span id="L-333"><a href="#L-333"><span class="linenos">333</span></a><span class="sd">	&quot;&quot;&quot;</span>
</span><span id="L-334"><a href="#L-334"><span class="linenos">334</span></a>	<span class="c1"># add hash to prompt</span>
</span><span id="L-335"><a href="#L-335"><span class="linenos">335</span></a>	<span class="n">augment_prompt_with_hash</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>
</span><span id="L-336"><a href="#L-336"><span class="linenos">336</span></a>
</span><span id="L-337"><a href="#L-337"><span class="linenos">337</span></a>	<span class="c1"># get the model</span>
</span><span id="L-338"><a href="#L-338"><span class="linenos">338</span></a>	<span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="L-339"><a href="#L-339"><span class="linenos">339</span></a>		<span class="n">model</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">model_name</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">HookedTransformer</span><span class="p">)</span> <span class="k">else</span> <span class="n">model</span>
</span><span id="L-340"><a href="#L-340"><span class="linenos">340</span></a>	<span class="p">)</span>
</span><span id="L-341"><a href="#L-341"><span class="linenos">341</span></a>
</span><span id="L-342"><a href="#L-342"><span class="linenos">342</span></a>	<span class="c1"># from cache</span>
</span><span id="L-343"><a href="#L-343"><span class="linenos">343</span></a>	<span class="k">if</span> <span class="n">allow_disk_cache</span><span class="p">:</span>
</span><span id="L-344"><a href="#L-344"><span class="linenos">344</span></a>		<span class="k">try</span><span class="p">:</span>
</span><span id="L-345"><a href="#L-345"><span class="linenos">345</span></a>			<span class="n">path</span><span class="p">,</span> <span class="n">cache</span> <span class="o">=</span> <span class="n">load_activations</span><span class="p">(</span>
</span><span id="L-346"><a href="#L-346"><span class="linenos">346</span></a>				<span class="n">model_name</span><span class="o">=</span><span class="n">model_name</span><span class="p">,</span>
</span><span id="L-347"><a href="#L-347"><span class="linenos">347</span></a>				<span class="n">prompt</span><span class="o">=</span><span class="n">prompt</span><span class="p">,</span>
</span><span id="L-348"><a href="#L-348"><span class="linenos">348</span></a>				<span class="n">save_path</span><span class="o">=</span><span class="n">save_path</span><span class="p">,</span>
</span><span id="L-349"><a href="#L-349"><span class="linenos">349</span></a>			<span class="p">)</span>
</span><span id="L-350"><a href="#L-350"><span class="linenos">350</span></a>			<span class="k">if</span> <span class="n">return_cache</span><span class="p">:</span>
</span><span id="L-351"><a href="#L-351"><span class="linenos">351</span></a>				<span class="k">return</span> <span class="n">path</span><span class="p">,</span> <span class="n">cache</span>
</span><span id="L-352"><a href="#L-352"><span class="linenos">352</span></a>			<span class="k">else</span><span class="p">:</span>
</span><span id="L-353"><a href="#L-353"><span class="linenos">353</span></a>				<span class="c1"># TODO: this basically does nothing, since we load the activations and then immediately get rid of them.</span>
</span><span id="L-354"><a href="#L-354"><span class="linenos">354</span></a>				<span class="c1"># maybe refactor this so that load_activations can take a parameter to simply assert that the cache exists?</span>
</span><span id="L-355"><a href="#L-355"><span class="linenos">355</span></a>				<span class="c1"># this will let us avoid loading it, which slows things down</span>
</span><span id="L-356"><a href="#L-356"><span class="linenos">356</span></a>				<span class="k">return</span> <span class="n">path</span><span class="p">,</span> <span class="kc">None</span>
</span><span id="L-357"><a href="#L-357"><span class="linenos">357</span></a>		<span class="k">except</span> <span class="n">ActivationsMissingError</span><span class="p">:</span>
</span><span id="L-358"><a href="#L-358"><span class="linenos">358</span></a>			<span class="k">pass</span>
</span><span id="L-359"><a href="#L-359"><span class="linenos">359</span></a>
</span><span id="L-360"><a href="#L-360"><span class="linenos">360</span></a>	<span class="c1"># compute them</span>
</span><span id="L-361"><a href="#L-361"><span class="linenos">361</span></a>	<span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
</span><span id="L-362"><a href="#L-362"><span class="linenos">362</span></a>		<span class="n">model</span> <span class="o">=</span> <span class="n">HookedTransformer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
</span><span id="L-363"><a href="#L-363"><span class="linenos">363</span></a>
</span><span id="L-364"><a href="#L-364"><span class="linenos">364</span></a>	<span class="k">return</span> <span class="n">compute_activations</span><span class="p">(</span>
</span><span id="L-365"><a href="#L-365"><span class="linenos">365</span></a>		<span class="n">prompt</span><span class="o">=</span><span class="n">prompt</span><span class="p">,</span>
</span><span id="L-366"><a href="#L-366"><span class="linenos">366</span></a>		<span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
</span><span id="L-367"><a href="#L-367"><span class="linenos">367</span></a>		<span class="n">save_path</span><span class="o">=</span><span class="n">save_path</span><span class="p">,</span>
</span><span id="L-368"><a href="#L-368"><span class="linenos">368</span></a>		<span class="n">return_cache</span><span class="o">=</span><span class="n">return_cache</span><span class="p">,</span>
</span><span id="L-369"><a href="#L-369"><span class="linenos">369</span></a>	<span class="p">)</span>
</span><span id="L-370"><a href="#L-370"><span class="linenos">370</span></a>
</span><span id="L-371"><a href="#L-371"><span class="linenos">371</span></a>
</span><span id="L-372"><a href="#L-372"><span class="linenos">372</span></a><span class="n">DEFAULT_DEVICE</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span>
</span><span id="L-373"><a href="#L-373"><span class="linenos">373</span></a>	<span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
</span><span id="L-374"><a href="#L-374"><span class="linenos">374</span></a><span class="p">)</span>
</span><span id="L-375"><a href="#L-375"><span class="linenos">375</span></a>
</span><span id="L-376"><a href="#L-376"><span class="linenos">376</span></a>
</span><span id="L-377"><a href="#L-377"><span class="linenos">377</span></a><span class="k">def</span><span class="w"> </span><span class="nf">activations_main</span><span class="p">(</span>
</span><span id="L-378"><a href="#L-378"><span class="linenos">378</span></a>	<span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="L-379"><a href="#L-379"><span class="linenos">379</span></a>	<span class="n">save_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="L-380"><a href="#L-380"><span class="linenos">380</span></a>	<span class="n">prompts_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="L-381"><a href="#L-381"><span class="linenos">381</span></a>	<span class="n">raw_prompts</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
</span><span id="L-382"><a href="#L-382"><span class="linenos">382</span></a>	<span class="n">min_chars</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="L-383"><a href="#L-383"><span class="linenos">383</span></a>	<span class="n">max_chars</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="L-384"><a href="#L-384"><span class="linenos">384</span></a>	<span class="n">force</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
</span><span id="L-385"><a href="#L-385"><span class="linenos">385</span></a>	<span class="n">n_samples</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="L-386"><a href="#L-386"><span class="linenos">386</span></a>	<span class="n">no_index_html</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
</span><span id="L-387"><a href="#L-387"><span class="linenos">387</span></a>	<span class="n">shuffle</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="L-388"><a href="#L-388"><span class="linenos">388</span></a>	<span class="n">stacked_heads</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="L-389"><a href="#L-389"><span class="linenos">389</span></a>	<span class="n">device</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">DEFAULT_DEVICE</span><span class="p">,</span>
</span><span id="L-390"><a href="#L-390"><span class="linenos">390</span></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-391"><a href="#L-391"><span class="linenos">391</span></a><span class="w">	</span><span class="sd">&quot;&quot;&quot;main function for computing activations</span>
</span><span id="L-392"><a href="#L-392"><span class="linenos">392</span></a>
</span><span id="L-393"><a href="#L-393"><span class="linenos">393</span></a><span class="sd">	# Parameters:</span>
</span><span id="L-394"><a href="#L-394"><span class="linenos">394</span></a><span class="sd">	- `model_name : str`</span>
</span><span id="L-395"><a href="#L-395"><span class="linenos">395</span></a><span class="sd">		name of a model to load with `HookedTransformer.from_pretrained`</span>
</span><span id="L-396"><a href="#L-396"><span class="linenos">396</span></a><span class="sd">	- `save_path : str`</span>
</span><span id="L-397"><a href="#L-397"><span class="linenos">397</span></a><span class="sd">		path to save the activations to</span>
</span><span id="L-398"><a href="#L-398"><span class="linenos">398</span></a><span class="sd">	- `prompts_path : str`</span>
</span><span id="L-399"><a href="#L-399"><span class="linenos">399</span></a><span class="sd">		path to the prompts file</span>
</span><span id="L-400"><a href="#L-400"><span class="linenos">400</span></a><span class="sd">	- `raw_prompts : bool`</span>
</span><span id="L-401"><a href="#L-401"><span class="linenos">401</span></a><span class="sd">		whether the prompts are raw, not filtered by length. `load_text_data` will be called if `True`, otherwise just load the &quot;text&quot; field from each line in `prompts_path`</span>
</span><span id="L-402"><a href="#L-402"><span class="linenos">402</span></a><span class="sd">	- `min_chars : int`</span>
</span><span id="L-403"><a href="#L-403"><span class="linenos">403</span></a><span class="sd">		minimum number of characters for a prompt</span>
</span><span id="L-404"><a href="#L-404"><span class="linenos">404</span></a><span class="sd">	- `max_chars : int`</span>
</span><span id="L-405"><a href="#L-405"><span class="linenos">405</span></a><span class="sd">		maximum number of characters for a prompt</span>
</span><span id="L-406"><a href="#L-406"><span class="linenos">406</span></a><span class="sd">	- `force : bool`</span>
</span><span id="L-407"><a href="#L-407"><span class="linenos">407</span></a><span class="sd">		whether to overwrite existing files</span>
</span><span id="L-408"><a href="#L-408"><span class="linenos">408</span></a><span class="sd">	- `n_samples : int`</span>
</span><span id="L-409"><a href="#L-409"><span class="linenos">409</span></a><span class="sd">		maximum number of samples to process</span>
</span><span id="L-410"><a href="#L-410"><span class="linenos">410</span></a><span class="sd">	- `no_index_html : bool`</span>
</span><span id="L-411"><a href="#L-411"><span class="linenos">411</span></a><span class="sd">		whether to write an index.html file</span>
</span><span id="L-412"><a href="#L-412"><span class="linenos">412</span></a><span class="sd">	- `shuffle : bool`</span>
</span><span id="L-413"><a href="#L-413"><span class="linenos">413</span></a><span class="sd">		whether to shuffle the prompts</span>
</span><span id="L-414"><a href="#L-414"><span class="linenos">414</span></a><span class="sd">		(defaults to `False`)</span>
</span><span id="L-415"><a href="#L-415"><span class="linenos">415</span></a><span class="sd">	- `stacked_heads : bool`</span>
</span><span id="L-416"><a href="#L-416"><span class="linenos">416</span></a><span class="sd">		whether	to stack the heads in the output tensor. will save as `.npy` instead of `.npz` if `True`</span>
</span><span id="L-417"><a href="#L-417"><span class="linenos">417</span></a><span class="sd">		(defaults to `False`)</span>
</span><span id="L-418"><a href="#L-418"><span class="linenos">418</span></a><span class="sd">	- `device : str | torch.device`</span>
</span><span id="L-419"><a href="#L-419"><span class="linenos">419</span></a><span class="sd">		the device to use. if a string, will be passed to `torch.device`</span>
</span><span id="L-420"><a href="#L-420"><span class="linenos">420</span></a><span class="sd">	&quot;&quot;&quot;</span>
</span><span id="L-421"><a href="#L-421"><span class="linenos">421</span></a>	<span class="c1"># figure out the device to use</span>
</span><span id="L-422"><a href="#L-422"><span class="linenos">422</span></a>	<span class="n">device_</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span>
</span><span id="L-423"><a href="#L-423"><span class="linenos">423</span></a>	<span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">):</span>
</span><span id="L-424"><a href="#L-424"><span class="linenos">424</span></a>		<span class="n">device_</span> <span class="o">=</span> <span class="n">device</span>
</span><span id="L-425"><a href="#L-425"><span class="linenos">425</span></a>	<span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
</span><span id="L-426"><a href="#L-426"><span class="linenos">426</span></a>		<span class="n">device_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</span><span id="L-427"><a href="#L-427"><span class="linenos">427</span></a>	<span class="k">else</span><span class="p">:</span>
</span><span id="L-428"><a href="#L-428"><span class="linenos">428</span></a>		<span class="n">msg</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;invalid device: </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s2">&quot;</span>
</span><span id="L-429"><a href="#L-429"><span class="linenos">429</span></a>		<span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
</span><span id="L-430"><a href="#L-430"><span class="linenos">430</span></a>
</span><span id="L-431"><a href="#L-431"><span class="linenos">431</span></a>	<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;using device: </span><span class="si">{</span><span class="n">device_</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="L-432"><a href="#L-432"><span class="linenos">432</span></a>
</span><span id="L-433"><a href="#L-433"><span class="linenos">433</span></a>	<span class="k">with</span> <span class="n">SpinnerContext</span><span class="p">(</span><span class="n">message</span><span class="o">=</span><span class="s2">&quot;loading model&quot;</span><span class="p">,</span> <span class="o">**</span><span class="n">SPINNER_KWARGS</span><span class="p">):</span>
</span><span id="L-434"><a href="#L-434"><span class="linenos">434</span></a>		<span class="n">model</span><span class="p">:</span> <span class="n">HookedTransformer</span> <span class="o">=</span> <span class="n">HookedTransformer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
</span><span id="L-435"><a href="#L-435"><span class="linenos">435</span></a>			<span class="n">model_name</span><span class="p">,</span>
</span><span id="L-436"><a href="#L-436"><span class="linenos">436</span></a>			<span class="n">device</span><span class="o">=</span><span class="n">device_</span><span class="p">,</span>
</span><span id="L-437"><a href="#L-437"><span class="linenos">437</span></a>		<span class="p">)</span>
</span><span id="L-438"><a href="#L-438"><span class="linenos">438</span></a>		<span class="n">model</span><span class="o">.</span><span class="n">model_name</span> <span class="o">=</span> <span class="n">model_name</span>
</span><span id="L-439"><a href="#L-439"><span class="linenos">439</span></a>		<span class="n">model</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">model_name</span> <span class="o">=</span> <span class="n">model_name</span>
</span><span id="L-440"><a href="#L-440"><span class="linenos">440</span></a>		<span class="n">n_params</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
</span><span id="L-441"><a href="#L-441"><span class="linenos">441</span></a>	<span class="nb">print</span><span class="p">(</span>
</span><span id="L-442"><a href="#L-442"><span class="linenos">442</span></a>		<span class="sa">f</span><span class="s2">&quot;loaded </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2"> with </span><span class="si">{</span><span class="n">shorten_numerical_to_str</span><span class="p">(</span><span class="n">n_params</span><span class="p">)</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="n">n_params</span><span class="si">}</span><span class="s2">) parameters&quot;</span><span class="p">,</span>
</span><span id="L-443"><a href="#L-443"><span class="linenos">443</span></a>	<span class="p">)</span>
</span><span id="L-444"><a href="#L-444"><span class="linenos">444</span></a>	<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">model devices: </span><span class="si">{</span><span class="w"> </span><span class="p">{</span><span class="n">p</span><span class="o">.</span><span class="n">device</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">p</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()}</span><span class="w"> </span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="L-445"><a href="#L-445"><span class="linenos">445</span></a>
</span><span id="L-446"><a href="#L-446"><span class="linenos">446</span></a>	<span class="n">save_path_p</span><span class="p">:</span> <span class="n">Path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span>
</span><span id="L-447"><a href="#L-447"><span class="linenos">447</span></a>	<span class="n">save_path_p</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="L-448"><a href="#L-448"><span class="linenos">448</span></a>	<span class="n">model_path</span><span class="p">:</span> <span class="n">Path</span> <span class="o">=</span> <span class="n">save_path_p</span> <span class="o">/</span> <span class="n">model_name</span>
</span><span id="L-449"><a href="#L-449"><span class="linenos">449</span></a>	<span class="k">with</span> <span class="n">SpinnerContext</span><span class="p">(</span>
</span><span id="L-450"><a href="#L-450"><span class="linenos">450</span></a>		<span class="n">message</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;saving model info to </span><span class="si">{</span><span class="n">model_path</span><span class="o">.</span><span class="n">as_posix</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
</span><span id="L-451"><a href="#L-451"><span class="linenos">451</span></a>		<span class="o">**</span><span class="n">SPINNER_KWARGS</span><span class="p">,</span>
</span><span id="L-452"><a href="#L-452"><span class="linenos">452</span></a>	<span class="p">):</span>
</span><span id="L-453"><a href="#L-453"><span class="linenos">453</span></a>		<span class="n">model_cfg</span><span class="p">:</span> <span class="n">HookedTransformerConfig</span>
</span><span id="L-454"><a href="#L-454"><span class="linenos">454</span></a>		<span class="n">model_cfg</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">cfg</span>
</span><span id="L-455"><a href="#L-455"><span class="linenos">455</span></a>		<span class="n">model_path</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="L-456"><a href="#L-456"><span class="linenos">456</span></a>		<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">model_path</span> <span class="o">/</span> <span class="s2">&quot;model_cfg.json&quot;</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span><span id="L-457"><a href="#L-457"><span class="linenos">457</span></a>			<span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">json_serialize</span><span class="p">(</span><span class="n">asdict</span><span class="p">(</span><span class="n">model_cfg</span><span class="p">)),</span> <span class="n">f</span><span class="p">)</span>
</span><span id="L-458"><a href="#L-458"><span class="linenos">458</span></a>
</span><span id="L-459"><a href="#L-459"><span class="linenos">459</span></a>	<span class="c1"># load prompts</span>
</span><span id="L-460"><a href="#L-460"><span class="linenos">460</span></a>	<span class="k">with</span> <span class="n">SpinnerContext</span><span class="p">(</span>
</span><span id="L-461"><a href="#L-461"><span class="linenos">461</span></a>		<span class="n">message</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;loading prompts from </span><span class="si">{</span><span class="n">prompts_path</span><span class="w"> </span><span class="si">= }</span><span class="s2">&quot;</span><span class="p">,</span>
</span><span id="L-462"><a href="#L-462"><span class="linenos">462</span></a>		<span class="o">**</span><span class="n">SPINNER_KWARGS</span><span class="p">,</span>
</span><span id="L-463"><a href="#L-463"><span class="linenos">463</span></a>	<span class="p">):</span>
</span><span id="L-464"><a href="#L-464"><span class="linenos">464</span></a>		<span class="n">prompts</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span>
</span><span id="L-465"><a href="#L-465"><span class="linenos">465</span></a>		<span class="k">if</span> <span class="n">raw_prompts</span><span class="p">:</span>
</span><span id="L-466"><a href="#L-466"><span class="linenos">466</span></a>			<span class="n">prompts</span> <span class="o">=</span> <span class="n">load_text_data</span><span class="p">(</span>
</span><span id="L-467"><a href="#L-467"><span class="linenos">467</span></a>				<span class="n">Path</span><span class="p">(</span><span class="n">prompts_path</span><span class="p">),</span>
</span><span id="L-468"><a href="#L-468"><span class="linenos">468</span></a>				<span class="n">min_chars</span><span class="o">=</span><span class="n">min_chars</span><span class="p">,</span>
</span><span id="L-469"><a href="#L-469"><span class="linenos">469</span></a>				<span class="n">max_chars</span><span class="o">=</span><span class="n">max_chars</span><span class="p">,</span>
</span><span id="L-470"><a href="#L-470"><span class="linenos">470</span></a>				<span class="n">shuffle</span><span class="o">=</span><span class="n">shuffle</span><span class="p">,</span>
</span><span id="L-471"><a href="#L-471"><span class="linenos">471</span></a>			<span class="p">)</span>
</span><span id="L-472"><a href="#L-472"><span class="linenos">472</span></a>		<span class="k">else</span><span class="p">:</span>
</span><span id="L-473"><a href="#L-473"><span class="linenos">473</span></a>			<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">model_path</span> <span class="o">/</span> <span class="s2">&quot;prompts.jsonl&quot;</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span><span id="L-474"><a href="#L-474"><span class="linenos">474</span></a>				<span class="n">prompts</span> <span class="o">=</span> <span class="p">[</span><span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">line</span><span class="p">)</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">f</span><span class="o">.</span><span class="n">readlines</span><span class="p">()]</span>
</span><span id="L-475"><a href="#L-475"><span class="linenos">475</span></a>		<span class="c1"># truncate to n_samples</span>
</span><span id="L-476"><a href="#L-476"><span class="linenos">476</span></a>		<span class="n">prompts</span> <span class="o">=</span> <span class="n">prompts</span><span class="p">[:</span><span class="n">n_samples</span><span class="p">]</span>
</span><span id="L-477"><a href="#L-477"><span class="linenos">477</span></a>
</span><span id="L-478"><a href="#L-478"><span class="linenos">478</span></a>	<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">prompts</span><span class="p">)</span><span class="si">}</span><span class="s2"> prompts loaded&quot;</span><span class="p">)</span>
</span><span id="L-479"><a href="#L-479"><span class="linenos">479</span></a>
</span><span id="L-480"><a href="#L-480"><span class="linenos">480</span></a>	<span class="c1"># write index.html</span>
</span><span id="L-481"><a href="#L-481"><span class="linenos">481</span></a>	<span class="k">with</span> <span class="n">SpinnerContext</span><span class="p">(</span><span class="n">message</span><span class="o">=</span><span class="s2">&quot;writing index.html&quot;</span><span class="p">,</span> <span class="o">**</span><span class="n">SPINNER_KWARGS</span><span class="p">):</span>
</span><span id="L-482"><a href="#L-482"><span class="linenos">482</span></a>		<span class="k">if</span> <span class="ow">not</span> <span class="n">no_index_html</span><span class="p">:</span>
</span><span id="L-483"><a href="#L-483"><span class="linenos">483</span></a>			<span class="n">write_html_index</span><span class="p">(</span><span class="n">save_path_p</span><span class="p">)</span>
</span><span id="L-484"><a href="#L-484"><span class="linenos">484</span></a>
</span><span id="L-485"><a href="#L-485"><span class="linenos">485</span></a>	<span class="c1"># TODO: not implemented yet</span>
</span><span id="L-486"><a href="#L-486"><span class="linenos">486</span></a>	<span class="k">if</span> <span class="n">stacked_heads</span><span class="p">:</span>
</span><span id="L-487"><a href="#L-487"><span class="linenos">487</span></a>		<span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;stacked_heads not implemented yet&quot;</span><span class="p">)</span>
</span><span id="L-488"><a href="#L-488"><span class="linenos">488</span></a>
</span><span id="L-489"><a href="#L-489"><span class="linenos">489</span></a>	<span class="c1"># get activations</span>
</span><span id="L-490"><a href="#L-490"><span class="linenos">490</span></a>	<span class="nb">list</span><span class="p">(</span>
</span><span id="L-491"><a href="#L-491"><span class="linenos">491</span></a>		<span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span>
</span><span id="L-492"><a href="#L-492"><span class="linenos">492</span></a>			<span class="nb">map</span><span class="p">(</span>
</span><span id="L-493"><a href="#L-493"><span class="linenos">493</span></a>				<span class="n">functools</span><span class="o">.</span><span class="n">partial</span><span class="p">(</span>
</span><span id="L-494"><a href="#L-494"><span class="linenos">494</span></a>					<span class="n">get_activations</span><span class="p">,</span>
</span><span id="L-495"><a href="#L-495"><span class="linenos">495</span></a>					<span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
</span><span id="L-496"><a href="#L-496"><span class="linenos">496</span></a>					<span class="n">save_path</span><span class="o">=</span><span class="n">save_path_p</span><span class="p">,</span>
</span><span id="L-497"><a href="#L-497"><span class="linenos">497</span></a>					<span class="n">allow_disk_cache</span><span class="o">=</span><span class="ow">not</span> <span class="n">force</span><span class="p">,</span>
</span><span id="L-498"><a href="#L-498"><span class="linenos">498</span></a>					<span class="n">return_cache</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="L-499"><a href="#L-499"><span class="linenos">499</span></a>					<span class="c1"># stacked_heads=stacked_heads,</span>
</span><span id="L-500"><a href="#L-500"><span class="linenos">500</span></a>				<span class="p">),</span>
</span><span id="L-501"><a href="#L-501"><span class="linenos">501</span></a>				<span class="n">prompts</span><span class="p">,</span>
</span><span id="L-502"><a href="#L-502"><span class="linenos">502</span></a>			<span class="p">),</span>
</span><span id="L-503"><a href="#L-503"><span class="linenos">503</span></a>			<span class="n">total</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">prompts</span><span class="p">),</span>
</span><span id="L-504"><a href="#L-504"><span class="linenos">504</span></a>			<span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Computing activations&quot;</span><span class="p">,</span>
</span><span id="L-505"><a href="#L-505"><span class="linenos">505</span></a>			<span class="n">unit</span><span class="o">=</span><span class="s2">&quot;prompt&quot;</span><span class="p">,</span>
</span><span id="L-506"><a href="#L-506"><span class="linenos">506</span></a>		<span class="p">),</span>
</span><span id="L-507"><a href="#L-507"><span class="linenos">507</span></a>	<span class="p">)</span>
</span><span id="L-508"><a href="#L-508"><span class="linenos">508</span></a>
</span><span id="L-509"><a href="#L-509"><span class="linenos">509</span></a>	<span class="k">with</span> <span class="n">SpinnerContext</span><span class="p">(</span>
</span><span id="L-510"><a href="#L-510"><span class="linenos">510</span></a>		<span class="n">message</span><span class="o">=</span><span class="s2">&quot;updating jsonl metadata for models and prompts&quot;</span><span class="p">,</span>
</span><span id="L-511"><a href="#L-511"><span class="linenos">511</span></a>		<span class="o">**</span><span class="n">SPINNER_KWARGS</span><span class="p">,</span>
</span><span id="L-512"><a href="#L-512"><span class="linenos">512</span></a>	<span class="p">):</span>
</span><span id="L-513"><a href="#L-513"><span class="linenos">513</span></a>		<span class="n">generate_models_jsonl</span><span class="p">(</span><span class="n">save_path_p</span><span class="p">)</span>
</span><span id="L-514"><a href="#L-514"><span class="linenos">514</span></a>		<span class="n">generate_prompts_jsonl</span><span class="p">(</span><span class="n">save_path_p</span> <span class="o">/</span> <span class="n">model_name</span><span class="p">)</span>
</span><span id="L-515"><a href="#L-515"><span class="linenos">515</span></a>
</span><span id="L-516"><a href="#L-516"><span class="linenos">516</span></a>
</span><span id="L-517"><a href="#L-517"><span class="linenos">517</span></a><span class="k">def</span><span class="w"> </span><span class="nf">main</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-518"><a href="#L-518"><span class="linenos">518</span></a>	<span class="s2">&quot;generate attention pattern activations for a model and prompts&quot;</span>
</span><span id="L-519"><a href="#L-519"><span class="linenos">519</span></a>	<span class="nb">print</span><span class="p">(</span><span class="n">DIVIDER_S1</span><span class="p">)</span>
</span><span id="L-520"><a href="#L-520"><span class="linenos">520</span></a>	<span class="k">with</span> <span class="n">SpinnerContext</span><span class="p">(</span><span class="n">message</span><span class="o">=</span><span class="s2">&quot;parsing args&quot;</span><span class="p">,</span> <span class="o">**</span><span class="n">SPINNER_KWARGS</span><span class="p">):</span>
</span><span id="L-521"><a href="#L-521"><span class="linenos">521</span></a>		<span class="n">arg_parser</span><span class="p">:</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">()</span>
</span><span id="L-522"><a href="#L-522"><span class="linenos">522</span></a>		<span class="c1"># input and output</span>
</span><span id="L-523"><a href="#L-523"><span class="linenos">523</span></a>		<span class="n">arg_parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
</span><span id="L-524"><a href="#L-524"><span class="linenos">524</span></a>			<span class="s2">&quot;--model&quot;</span><span class="p">,</span>
</span><span id="L-525"><a href="#L-525"><span class="linenos">525</span></a>			<span class="s2">&quot;-m&quot;</span><span class="p">,</span>
</span><span id="L-526"><a href="#L-526"><span class="linenos">526</span></a>			<span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
</span><span id="L-527"><a href="#L-527"><span class="linenos">527</span></a>			<span class="n">required</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="L-528"><a href="#L-528"><span class="linenos">528</span></a>			<span class="n">help</span><span class="o">=</span><span class="s2">&quot;The model name(s) to use. comma separated with no whitespace if multiple&quot;</span><span class="p">,</span>
</span><span id="L-529"><a href="#L-529"><span class="linenos">529</span></a>		<span class="p">)</span>
</span><span id="L-530"><a href="#L-530"><span class="linenos">530</span></a>
</span><span id="L-531"><a href="#L-531"><span class="linenos">531</span></a>		<span class="n">arg_parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
</span><span id="L-532"><a href="#L-532"><span class="linenos">532</span></a>			<span class="s2">&quot;--prompts&quot;</span><span class="p">,</span>
</span><span id="L-533"><a href="#L-533"><span class="linenos">533</span></a>			<span class="s2">&quot;-p&quot;</span><span class="p">,</span>
</span><span id="L-534"><a href="#L-534"><span class="linenos">534</span></a>			<span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
</span><span id="L-535"><a href="#L-535"><span class="linenos">535</span></a>			<span class="n">required</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="L-536"><a href="#L-536"><span class="linenos">536</span></a>			<span class="n">help</span><span class="o">=</span><span class="s2">&quot;The path to the prompts file (jsonl with &#39;text&#39; key on each line). If `None`, expects that `--figures` is passed and will generate figures for all prompts in the model directory&quot;</span><span class="p">,</span>
</span><span id="L-537"><a href="#L-537"><span class="linenos">537</span></a>			<span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="L-538"><a href="#L-538"><span class="linenos">538</span></a>		<span class="p">)</span>
</span><span id="L-539"><a href="#L-539"><span class="linenos">539</span></a>
</span><span id="L-540"><a href="#L-540"><span class="linenos">540</span></a>		<span class="n">arg_parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
</span><span id="L-541"><a href="#L-541"><span class="linenos">541</span></a>			<span class="s2">&quot;--save-path&quot;</span><span class="p">,</span>
</span><span id="L-542"><a href="#L-542"><span class="linenos">542</span></a>			<span class="s2">&quot;-s&quot;</span><span class="p">,</span>
</span><span id="L-543"><a href="#L-543"><span class="linenos">543</span></a>			<span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
</span><span id="L-544"><a href="#L-544"><span class="linenos">544</span></a>			<span class="n">required</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="L-545"><a href="#L-545"><span class="linenos">545</span></a>			<span class="n">help</span><span class="o">=</span><span class="s2">&quot;The path to save the attention patterns&quot;</span><span class="p">,</span>
</span><span id="L-546"><a href="#L-546"><span class="linenos">546</span></a>			<span class="n">default</span><span class="o">=</span><span class="n">DATA_DIR</span><span class="p">,</span>
</span><span id="L-547"><a href="#L-547"><span class="linenos">547</span></a>		<span class="p">)</span>
</span><span id="L-548"><a href="#L-548"><span class="linenos">548</span></a>
</span><span id="L-549"><a href="#L-549"><span class="linenos">549</span></a>		<span class="c1"># min and max prompt lengths</span>
</span><span id="L-550"><a href="#L-550"><span class="linenos">550</span></a>		<span class="n">arg_parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
</span><span id="L-551"><a href="#L-551"><span class="linenos">551</span></a>			<span class="s2">&quot;--min-chars&quot;</span><span class="p">,</span>
</span><span id="L-552"><a href="#L-552"><span class="linenos">552</span></a>			<span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
</span><span id="L-553"><a href="#L-553"><span class="linenos">553</span></a>			<span class="n">required</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="L-554"><a href="#L-554"><span class="linenos">554</span></a>			<span class="n">help</span><span class="o">=</span><span class="s2">&quot;The minimum number of characters for a prompt&quot;</span><span class="p">,</span>
</span><span id="L-555"><a href="#L-555"><span class="linenos">555</span></a>			<span class="n">default</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
</span><span id="L-556"><a href="#L-556"><span class="linenos">556</span></a>		<span class="p">)</span>
</span><span id="L-557"><a href="#L-557"><span class="linenos">557</span></a>		<span class="n">arg_parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
</span><span id="L-558"><a href="#L-558"><span class="linenos">558</span></a>			<span class="s2">&quot;--max-chars&quot;</span><span class="p">,</span>
</span><span id="L-559"><a href="#L-559"><span class="linenos">559</span></a>			<span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
</span><span id="L-560"><a href="#L-560"><span class="linenos">560</span></a>			<span class="n">required</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="L-561"><a href="#L-561"><span class="linenos">561</span></a>			<span class="n">help</span><span class="o">=</span><span class="s2">&quot;The maximum number of characters for a prompt&quot;</span><span class="p">,</span>
</span><span id="L-562"><a href="#L-562"><span class="linenos">562</span></a>			<span class="n">default</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
</span><span id="L-563"><a href="#L-563"><span class="linenos">563</span></a>		<span class="p">)</span>
</span><span id="L-564"><a href="#L-564"><span class="linenos">564</span></a>
</span><span id="L-565"><a href="#L-565"><span class="linenos">565</span></a>		<span class="c1"># number of samples</span>
</span><span id="L-566"><a href="#L-566"><span class="linenos">566</span></a>		<span class="n">arg_parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
</span><span id="L-567"><a href="#L-567"><span class="linenos">567</span></a>			<span class="s2">&quot;--n-samples&quot;</span><span class="p">,</span>
</span><span id="L-568"><a href="#L-568"><span class="linenos">568</span></a>			<span class="s2">&quot;-n&quot;</span><span class="p">,</span>
</span><span id="L-569"><a href="#L-569"><span class="linenos">569</span></a>			<span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
</span><span id="L-570"><a href="#L-570"><span class="linenos">570</span></a>			<span class="n">required</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="L-571"><a href="#L-571"><span class="linenos">571</span></a>			<span class="n">help</span><span class="o">=</span><span class="s2">&quot;The max number of samples to process, do all in the file if None&quot;</span><span class="p">,</span>
</span><span id="L-572"><a href="#L-572"><span class="linenos">572</span></a>			<span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="L-573"><a href="#L-573"><span class="linenos">573</span></a>		<span class="p">)</span>
</span><span id="L-574"><a href="#L-574"><span class="linenos">574</span></a>
</span><span id="L-575"><a href="#L-575"><span class="linenos">575</span></a>		<span class="c1"># force overwrite</span>
</span><span id="L-576"><a href="#L-576"><span class="linenos">576</span></a>		<span class="n">arg_parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
</span><span id="L-577"><a href="#L-577"><span class="linenos">577</span></a>			<span class="s2">&quot;--force&quot;</span><span class="p">,</span>
</span><span id="L-578"><a href="#L-578"><span class="linenos">578</span></a>			<span class="s2">&quot;-f&quot;</span><span class="p">,</span>
</span><span id="L-579"><a href="#L-579"><span class="linenos">579</span></a>			<span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">,</span>
</span><span id="L-580"><a href="#L-580"><span class="linenos">580</span></a>			<span class="n">help</span><span class="o">=</span><span class="s2">&quot;If passed, will overwrite existing files&quot;</span><span class="p">,</span>
</span><span id="L-581"><a href="#L-581"><span class="linenos">581</span></a>		<span class="p">)</span>
</span><span id="L-582"><a href="#L-582"><span class="linenos">582</span></a>
</span><span id="L-583"><a href="#L-583"><span class="linenos">583</span></a>		<span class="c1"># no index html</span>
</span><span id="L-584"><a href="#L-584"><span class="linenos">584</span></a>		<span class="n">arg_parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
</span><span id="L-585"><a href="#L-585"><span class="linenos">585</span></a>			<span class="s2">&quot;--no-index-html&quot;</span><span class="p">,</span>
</span><span id="L-586"><a href="#L-586"><span class="linenos">586</span></a>			<span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">,</span>
</span><span id="L-587"><a href="#L-587"><span class="linenos">587</span></a>			<span class="n">help</span><span class="o">=</span><span class="s2">&quot;If passed, will not write an index.html file for the model&quot;</span><span class="p">,</span>
</span><span id="L-588"><a href="#L-588"><span class="linenos">588</span></a>		<span class="p">)</span>
</span><span id="L-589"><a href="#L-589"><span class="linenos">589</span></a>
</span><span id="L-590"><a href="#L-590"><span class="linenos">590</span></a>		<span class="c1"># raw prompts</span>
</span><span id="L-591"><a href="#L-591"><span class="linenos">591</span></a>		<span class="n">arg_parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
</span><span id="L-592"><a href="#L-592"><span class="linenos">592</span></a>			<span class="s2">&quot;--raw-prompts&quot;</span><span class="p">,</span>
</span><span id="L-593"><a href="#L-593"><span class="linenos">593</span></a>			<span class="s2">&quot;-r&quot;</span><span class="p">,</span>
</span><span id="L-594"><a href="#L-594"><span class="linenos">594</span></a>			<span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">,</span>
</span><span id="L-595"><a href="#L-595"><span class="linenos">595</span></a>			<span class="n">help</span><span class="o">=</span><span class="s2">&quot;pass if the prompts have not been split and tokenized (still needs keys &#39;text&#39; and &#39;meta&#39; for each item)&quot;</span><span class="p">,</span>
</span><span id="L-596"><a href="#L-596"><span class="linenos">596</span></a>		<span class="p">)</span>
</span><span id="L-597"><a href="#L-597"><span class="linenos">597</span></a>
</span><span id="L-598"><a href="#L-598"><span class="linenos">598</span></a>		<span class="c1"># shuffle</span>
</span><span id="L-599"><a href="#L-599"><span class="linenos">599</span></a>		<span class="n">arg_parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
</span><span id="L-600"><a href="#L-600"><span class="linenos">600</span></a>			<span class="s2">&quot;--shuffle&quot;</span><span class="p">,</span>
</span><span id="L-601"><a href="#L-601"><span class="linenos">601</span></a>			<span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">,</span>
</span><span id="L-602"><a href="#L-602"><span class="linenos">602</span></a>			<span class="n">help</span><span class="o">=</span><span class="s2">&quot;If passed, will shuffle the prompts&quot;</span><span class="p">,</span>
</span><span id="L-603"><a href="#L-603"><span class="linenos">603</span></a>		<span class="p">)</span>
</span><span id="L-604"><a href="#L-604"><span class="linenos">604</span></a>
</span><span id="L-605"><a href="#L-605"><span class="linenos">605</span></a>		<span class="c1"># stack heads</span>
</span><span id="L-606"><a href="#L-606"><span class="linenos">606</span></a>		<span class="n">arg_parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
</span><span id="L-607"><a href="#L-607"><span class="linenos">607</span></a>			<span class="s2">&quot;--stacked-heads&quot;</span><span class="p">,</span>
</span><span id="L-608"><a href="#L-608"><span class="linenos">608</span></a>			<span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">,</span>
</span><span id="L-609"><a href="#L-609"><span class="linenos">609</span></a>			<span class="n">help</span><span class="o">=</span><span class="s2">&quot;If passed, will stack the heads in the output tensor&quot;</span><span class="p">,</span>
</span><span id="L-610"><a href="#L-610"><span class="linenos">610</span></a>		<span class="p">)</span>
</span><span id="L-611"><a href="#L-611"><span class="linenos">611</span></a>
</span><span id="L-612"><a href="#L-612"><span class="linenos">612</span></a>		<span class="c1"># device</span>
</span><span id="L-613"><a href="#L-613"><span class="linenos">613</span></a>		<span class="n">arg_parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
</span><span id="L-614"><a href="#L-614"><span class="linenos">614</span></a>			<span class="s2">&quot;--device&quot;</span><span class="p">,</span>
</span><span id="L-615"><a href="#L-615"><span class="linenos">615</span></a>			<span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
</span><span id="L-616"><a href="#L-616"><span class="linenos">616</span></a>			<span class="n">required</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="L-617"><a href="#L-617"><span class="linenos">617</span></a>			<span class="n">help</span><span class="o">=</span><span class="s2">&quot;The device to use for the model&quot;</span><span class="p">,</span>
</span><span id="L-618"><a href="#L-618"><span class="linenos">618</span></a>			<span class="n">default</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
</span><span id="L-619"><a href="#L-619"><span class="linenos">619</span></a>		<span class="p">)</span>
</span><span id="L-620"><a href="#L-620"><span class="linenos">620</span></a>
</span><span id="L-621"><a href="#L-621"><span class="linenos">621</span></a>		<span class="n">args</span><span class="p">:</span> <span class="n">argparse</span><span class="o">.</span><span class="n">Namespace</span> <span class="o">=</span> <span class="n">arg_parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">()</span>
</span><span id="L-622"><a href="#L-622"><span class="linenos">622</span></a>
</span><span id="L-623"><a href="#L-623"><span class="linenos">623</span></a>	<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;args parsed: </span><span class="si">{</span><span class="n">args</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="L-624"><a href="#L-624"><span class="linenos">624</span></a>
</span><span id="L-625"><a href="#L-625"><span class="linenos">625</span></a>	<span class="n">models</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span>
</span><span id="L-626"><a href="#L-626"><span class="linenos">626</span></a>	<span class="k">if</span> <span class="s2">&quot;,&quot;</span> <span class="ow">in</span> <span class="n">args</span><span class="o">.</span><span class="n">model</span><span class="p">:</span>
</span><span id="L-627"><a href="#L-627"><span class="linenos">627</span></a>		<span class="n">models</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;,&quot;</span><span class="p">)</span>
</span><span id="L-628"><a href="#L-628"><span class="linenos">628</span></a>	<span class="k">else</span><span class="p">:</span>
</span><span id="L-629"><a href="#L-629"><span class="linenos">629</span></a>		<span class="n">models</span> <span class="o">=</span> <span class="p">[</span><span class="n">args</span><span class="o">.</span><span class="n">model</span><span class="p">]</span>
</span><span id="L-630"><a href="#L-630"><span class="linenos">630</span></a>
</span><span id="L-631"><a href="#L-631"><span class="linenos">631</span></a>	<span class="n">n_models</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">models</span><span class="p">)</span>
</span><span id="L-632"><a href="#L-632"><span class="linenos">632</span></a>	<span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">model</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">models</span><span class="p">):</span>
</span><span id="L-633"><a href="#L-633"><span class="linenos">633</span></a>		<span class="nb">print</span><span class="p">(</span><span class="n">DIVIDER_S2</span><span class="p">)</span>
</span><span id="L-634"><a href="#L-634"><span class="linenos">634</span></a>		<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;processing model </span><span class="si">{</span><span class="n">idx</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2"> / </span><span class="si">{</span><span class="n">n_models</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">model</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="L-635"><a href="#L-635"><span class="linenos">635</span></a>		<span class="nb">print</span><span class="p">(</span><span class="n">DIVIDER_S2</span><span class="p">)</span>
</span><span id="L-636"><a href="#L-636"><span class="linenos">636</span></a>
</span><span id="L-637"><a href="#L-637"><span class="linenos">637</span></a>		<span class="n">activations_main</span><span class="p">(</span>
</span><span id="L-638"><a href="#L-638"><span class="linenos">638</span></a>			<span class="n">model_name</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
</span><span id="L-639"><a href="#L-639"><span class="linenos">639</span></a>			<span class="n">save_path</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">save_path</span><span class="p">,</span>
</span><span id="L-640"><a href="#L-640"><span class="linenos">640</span></a>			<span class="n">prompts_path</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">prompts</span><span class="p">,</span>
</span><span id="L-641"><a href="#L-641"><span class="linenos">641</span></a>			<span class="n">raw_prompts</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">raw_prompts</span><span class="p">,</span>
</span><span id="L-642"><a href="#L-642"><span class="linenos">642</span></a>			<span class="n">min_chars</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">min_chars</span><span class="p">,</span>
</span><span id="L-643"><a href="#L-643"><span class="linenos">643</span></a>			<span class="n">max_chars</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">max_chars</span><span class="p">,</span>
</span><span id="L-644"><a href="#L-644"><span class="linenos">644</span></a>			<span class="n">force</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">force</span><span class="p">,</span>
</span><span id="L-645"><a href="#L-645"><span class="linenos">645</span></a>			<span class="n">n_samples</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">n_samples</span><span class="p">,</span>
</span><span id="L-646"><a href="#L-646"><span class="linenos">646</span></a>			<span class="n">no_index_html</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">no_index_html</span><span class="p">,</span>
</span><span id="L-647"><a href="#L-647"><span class="linenos">647</span></a>			<span class="n">shuffle</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">shuffle</span><span class="p">,</span>
</span><span id="L-648"><a href="#L-648"><span class="linenos">648</span></a>			<span class="n">stacked_heads</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">stacked_heads</span><span class="p">,</span>
</span><span id="L-649"><a href="#L-649"><span class="linenos">649</span></a>			<span class="n">device</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
</span><span id="L-650"><a href="#L-650"><span class="linenos">650</span></a>		<span class="p">)</span>
</span><span id="L-651"><a href="#L-651"><span class="linenos">651</span></a>		<span class="k">del</span> <span class="n">model</span>
</span><span id="L-652"><a href="#L-652"><span class="linenos">652</span></a>
</span><span id="L-653"><a href="#L-653"><span class="linenos">653</span></a>	<span class="nb">print</span><span class="p">(</span><span class="n">DIVIDER_S1</span><span class="p">)</span>
</span><span id="L-654"><a href="#L-654"><span class="linenos">654</span></a>
</span><span id="L-655"><a href="#L-655"><span class="linenos">655</span></a>
</span><span id="L-656"><a href="#L-656"><span class="linenos">656</span></a><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
</span><span id="L-657"><a href="#L-657"><span class="linenos">657</span></a>	<span class="n">main</span><span class="p">()</span>
</span></pre></div>


                <br/>
            </section>
                <section id="compute_activations">
                            <input id="compute_activations-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">compute_activations</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="n">prompt</span><span class="p">:</span> <span class="nb">dict</span>,</span><span class="param">	<span class="n">model</span><span class="p">:</span> <span class="n">transformer_lens</span><span class="o">.</span><span class="n">HookedTransformer</span><span class="o">.</span><span class="n">HookedTransformer</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">	<span class="n">save_path</span><span class="p">:</span> <span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span> <span class="o">=</span> <span class="n">PosixPath</span><span class="p">(</span><span class="s1">&#39;attn_data&#39;</span><span class="p">)</span>,</span><span class="param">	<span class="n">names_filter</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="nb">str</span><span class="p">],</span> <span class="nb">bool</span><span class="p">]</span> <span class="o">|</span> <span class="n">re</span><span class="o">.</span><span class="n">Pattern</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="s1">&#39;blocks</span><span class="se">\\</span><span class="s1">.(</span><span class="se">\\</span><span class="s1">d+)</span><span class="se">\\</span><span class="s1">.attn</span><span class="se">\\</span><span class="s1">.hook_pattern&#39;</span><span class="p">)</span>,</span><span class="param">	<span class="n">return_cache</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;numpy&#39;</span><span class="p">,</span> <span class="s1">&#39;torch&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;torch&#39;</span>,</span><span class="param">	<span class="n">stack_heads</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span></span><span class="return-annotation">) -> <span class="nb">tuple</span><span class="p">[</span><span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">,</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">|</span> <span class="n">transformer_lens</span><span class="o">.</span><span class="n">ActivationCache</span><span class="o">.</span><span class="n">ActivationCache</span> <span class="o">|</span> <span class="n">jaxtyping</span><span class="o">.</span><span class="n">Float</span><span class="p">[</span><span class="n">ndarray</span><span class="p">,</span> <span class="s1">&#39;n_layers n_heads n_ctx n_ctx&#39;</span><span class="p">]</span> <span class="o">|</span> <span class="n">jaxtyping</span><span class="o">.</span><span class="n">Float</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="s1">&#39;n_layers n_heads n_ctx n_ctx&#39;</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span><span class="p">]</span>:</span></span>

                <div class="source-button-container">
            <label class="pdoc-button view-source-button" for="compute_activations-view-source"><span>View Source</span></label>
            <div class="github-button-wrapper">
                <a class="pdoc-button github-link-button" href="https://github.com/mivanit/pattern-lens/blob/0.4.0activations.py#L120-L278" target="_blank">
                    <span>View on GitHub</span>
                </a>
            </div>
        </div>

    </div>
    <a class="headerlink" href="#compute_activations"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="compute_activations-121"><a href="#compute_activations-121"><span class="linenos">121</span></a><span class="k">def</span><span class="w"> </span><span class="nf">compute_activations</span><span class="p">(</span>  <span class="c1"># noqa: PLR0915</span>
</span><span id="compute_activations-122"><a href="#compute_activations-122"><span class="linenos">122</span></a>	<span class="n">prompt</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>
</span><span id="compute_activations-123"><a href="#compute_activations-123"><span class="linenos">123</span></a>	<span class="n">model</span><span class="p">:</span> <span class="n">HookedTransformer</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="compute_activations-124"><a href="#compute_activations-124"><span class="linenos">124</span></a>	<span class="n">save_path</span><span class="p">:</span> <span class="n">Path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">DATA_DIR</span><span class="p">),</span>
</span><span id="compute_activations-125"><a href="#compute_activations-125"><span class="linenos">125</span></a>	<span class="n">names_filter</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="nb">str</span><span class="p">],</span> <span class="nb">bool</span><span class="p">]</span> <span class="o">|</span> <span class="n">re</span><span class="o">.</span><span class="n">Pattern</span> <span class="o">=</span> <span class="n">ATTN_PATTERN_REGEX</span><span class="p">,</span>
</span><span id="compute_activations-126"><a href="#compute_activations-126"><span class="linenos">126</span></a>	<span class="n">return_cache</span><span class="p">:</span> <span class="n">ReturnCache</span> <span class="o">=</span> <span class="s2">&quot;torch&quot;</span><span class="p">,</span>
</span><span id="compute_activations-127"><a href="#compute_activations-127"><span class="linenos">127</span></a>	<span class="n">stack_heads</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="compute_activations-128"><a href="#compute_activations-128"><span class="linenos">128</span></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span>
</span><span id="compute_activations-129"><a href="#compute_activations-129"><span class="linenos">129</span></a>	<span class="n">Path</span><span class="p">,</span>
</span><span id="compute_activations-130"><a href="#compute_activations-130"><span class="linenos">130</span></a>	<span class="n">ActivationCacheNp</span>
</span><span id="compute_activations-131"><a href="#compute_activations-131"><span class="linenos">131</span></a>	<span class="o">|</span> <span class="n">ActivationCache</span>
</span><span id="compute_activations-132"><a href="#compute_activations-132"><span class="linenos">132</span></a>	<span class="o">|</span> <span class="n">Float</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="s2">&quot;n_layers n_heads n_ctx n_ctx&quot;</span><span class="p">]</span>
</span><span id="compute_activations-133"><a href="#compute_activations-133"><span class="linenos">133</span></a>	<span class="o">|</span> <span class="n">Float</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">&quot;n_layers n_heads n_ctx n_ctx&quot;</span><span class="p">]</span>
</span><span id="compute_activations-134"><a href="#compute_activations-134"><span class="linenos">134</span></a>	<span class="o">|</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="compute_activations-135"><a href="#compute_activations-135"><span class="linenos">135</span></a><span class="p">]:</span>
</span><span id="compute_activations-136"><a href="#compute_activations-136"><span class="linenos">136</span></a><span class="w">	</span><span class="sd">&quot;&quot;&quot;get activations for a given model and prompt, possibly from a cache</span>
</span><span id="compute_activations-137"><a href="#compute_activations-137"><span class="linenos">137</span></a>
</span><span id="compute_activations-138"><a href="#compute_activations-138"><span class="linenos">138</span></a><span class="sd">	if from a cache, prompt_meta must be passed and contain the prompt hash</span>
</span><span id="compute_activations-139"><a href="#compute_activations-139"><span class="linenos">139</span></a>
</span><span id="compute_activations-140"><a href="#compute_activations-140"><span class="linenos">140</span></a><span class="sd">	# Parameters:</span>
</span><span id="compute_activations-141"><a href="#compute_activations-141"><span class="linenos">141</span></a><span class="sd">	- `prompt : dict | None`</span>
</span><span id="compute_activations-142"><a href="#compute_activations-142"><span class="linenos">142</span></a><span class="sd">		(defaults to `None`)</span>
</span><span id="compute_activations-143"><a href="#compute_activations-143"><span class="linenos">143</span></a><span class="sd">	- `model : HookedTransformer`</span>
</span><span id="compute_activations-144"><a href="#compute_activations-144"><span class="linenos">144</span></a><span class="sd">	- `save_path : Path`</span>
</span><span id="compute_activations-145"><a href="#compute_activations-145"><span class="linenos">145</span></a><span class="sd">		(defaults to `Path(DATA_DIR)`)</span>
</span><span id="compute_activations-146"><a href="#compute_activations-146"><span class="linenos">146</span></a><span class="sd">	- `names_filter : Callable[[str], bool]|re.Pattern`</span>
</span><span id="compute_activations-147"><a href="#compute_activations-147"><span class="linenos">147</span></a><span class="sd">		a filter for the names of the activations to return. if an `re.Pattern`, will use `lambda key: names_filter.match(key) is not None`</span>
</span><span id="compute_activations-148"><a href="#compute_activations-148"><span class="linenos">148</span></a><span class="sd">		(defaults to `ATTN_PATTERN_REGEX`)</span>
</span><span id="compute_activations-149"><a href="#compute_activations-149"><span class="linenos">149</span></a><span class="sd">	- `return_cache : Literal[None, &quot;numpy&quot;, &quot;torch&quot;]`</span>
</span><span id="compute_activations-150"><a href="#compute_activations-150"><span class="linenos">150</span></a><span class="sd">		will return `None` as the second element if `None`, otherwise will return the cache in the specified tensor format. `stack_heads` still affects whether it will be a dict (False) or a single tensor (True)</span>
</span><span id="compute_activations-151"><a href="#compute_activations-151"><span class="linenos">151</span></a><span class="sd">		(defaults to `None`)</span>
</span><span id="compute_activations-152"><a href="#compute_activations-152"><span class="linenos">152</span></a><span class="sd">	- `stack_heads : bool`</span>
</span><span id="compute_activations-153"><a href="#compute_activations-153"><span class="linenos">153</span></a><span class="sd">		whether the heads should be stacked in the output. this causes a number of changes:</span>
</span><span id="compute_activations-154"><a href="#compute_activations-154"><span class="linenos">154</span></a><span class="sd">	- `npy` file with a single `(n_layers, n_heads, n_ctx, n_ctx)` tensor saved for each prompt instead of `npz` file with dict by layer</span>
</span><span id="compute_activations-155"><a href="#compute_activations-155"><span class="linenos">155</span></a><span class="sd">	- `cache` will be a single `(n_layers, n_heads, n_ctx, n_ctx)` tensor instead of a dict by layer if `return_cache` is `True`</span>
</span><span id="compute_activations-156"><a href="#compute_activations-156"><span class="linenos">156</span></a><span class="sd">		will assert that everything in the activation cache is only attention patterns, and is all of the attention patterns. raises an exception if not.</span>
</span><span id="compute_activations-157"><a href="#compute_activations-157"><span class="linenos">157</span></a>
</span><span id="compute_activations-158"><a href="#compute_activations-158"><span class="linenos">158</span></a><span class="sd">	# Returns:</span>
</span><span id="compute_activations-159"><a href="#compute_activations-159"><span class="linenos">159</span></a><span class="sd">	```</span>
</span><span id="compute_activations-160"><a href="#compute_activations-160"><span class="linenos">160</span></a><span class="sd">	tuple[</span>
</span><span id="compute_activations-161"><a href="#compute_activations-161"><span class="linenos">161</span></a><span class="sd">		Path,</span>
</span><span id="compute_activations-162"><a href="#compute_activations-162"><span class="linenos">162</span></a><span class="sd">		Union[</span>
</span><span id="compute_activations-163"><a href="#compute_activations-163"><span class="linenos">163</span></a><span class="sd">			None,</span>
</span><span id="compute_activations-164"><a href="#compute_activations-164"><span class="linenos">164</span></a><span class="sd">			ActivationCacheNp, ActivationCache,</span>
</span><span id="compute_activations-165"><a href="#compute_activations-165"><span class="linenos">165</span></a><span class="sd">			Float[np.ndarray, &quot;n_layers n_heads n_ctx n_ctx&quot;], Float[torch.Tensor, &quot;n_layers n_heads n_ctx n_ctx&quot;],</span>
</span><span id="compute_activations-166"><a href="#compute_activations-166"><span class="linenos">166</span></a><span class="sd">		]</span>
</span><span id="compute_activations-167"><a href="#compute_activations-167"><span class="linenos">167</span></a><span class="sd">	]</span>
</span><span id="compute_activations-168"><a href="#compute_activations-168"><span class="linenos">168</span></a><span class="sd">	```</span>
</span><span id="compute_activations-169"><a href="#compute_activations-169"><span class="linenos">169</span></a><span class="sd">	&quot;&quot;&quot;</span>
</span><span id="compute_activations-170"><a href="#compute_activations-170"><span class="linenos">170</span></a>	<span class="c1"># check inputs</span>
</span><span id="compute_activations-171"><a href="#compute_activations-171"><span class="linenos">171</span></a>	<span class="k">assert</span> <span class="n">model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;model must be passed&quot;</span>
</span><span id="compute_activations-172"><a href="#compute_activations-172"><span class="linenos">172</span></a>	<span class="k">assert</span> <span class="s2">&quot;text&quot;</span> <span class="ow">in</span> <span class="n">prompt</span><span class="p">,</span> <span class="s2">&quot;prompt must contain &#39;text&#39; key&quot;</span>
</span><span id="compute_activations-173"><a href="#compute_activations-173"><span class="linenos">173</span></a>	<span class="n">prompt_str</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">prompt</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]</span>
</span><span id="compute_activations-174"><a href="#compute_activations-174"><span class="linenos">174</span></a>
</span><span id="compute_activations-175"><a href="#compute_activations-175"><span class="linenos">175</span></a>	<span class="c1"># compute or get prompt metadata</span>
</span><span id="compute_activations-176"><a href="#compute_activations-176"><span class="linenos">176</span></a>	<span class="n">prompt_tokenized</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">prompt</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
</span><span id="compute_activations-177"><a href="#compute_activations-177"><span class="linenos">177</span></a>		<span class="s2">&quot;tokens&quot;</span><span class="p">,</span>
</span><span id="compute_activations-178"><a href="#compute_activations-178"><span class="linenos">178</span></a>		<span class="n">model</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">prompt_str</span><span class="p">),</span>
</span><span id="compute_activations-179"><a href="#compute_activations-179"><span class="linenos">179</span></a>	<span class="p">)</span>
</span><span id="compute_activations-180"><a href="#compute_activations-180"><span class="linenos">180</span></a>	<span class="n">prompt</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
</span><span id="compute_activations-181"><a href="#compute_activations-181"><span class="linenos">181</span></a>		<span class="nb">dict</span><span class="p">(</span>
</span><span id="compute_activations-182"><a href="#compute_activations-182"><span class="linenos">182</span></a>			<span class="n">n_tokens</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">prompt_tokenized</span><span class="p">),</span>
</span><span id="compute_activations-183"><a href="#compute_activations-183"><span class="linenos">183</span></a>			<span class="n">tokens</span><span class="o">=</span><span class="n">prompt_tokenized</span><span class="p">,</span>
</span><span id="compute_activations-184"><a href="#compute_activations-184"><span class="linenos">184</span></a>		<span class="p">),</span>
</span><span id="compute_activations-185"><a href="#compute_activations-185"><span class="linenos">185</span></a>	<span class="p">)</span>
</span><span id="compute_activations-186"><a href="#compute_activations-186"><span class="linenos">186</span></a>
</span><span id="compute_activations-187"><a href="#compute_activations-187"><span class="linenos">187</span></a>	<span class="c1"># save metadata</span>
</span><span id="compute_activations-188"><a href="#compute_activations-188"><span class="linenos">188</span></a>	<span class="n">prompt_dir</span><span class="p">:</span> <span class="n">Path</span> <span class="o">=</span> <span class="n">save_path</span> <span class="o">/</span> <span class="n">model</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">model_name</span> <span class="o">/</span> <span class="s2">&quot;prompts&quot;</span> <span class="o">/</span> <span class="n">prompt</span><span class="p">[</span><span class="s2">&quot;hash&quot;</span><span class="p">]</span>
</span><span id="compute_activations-189"><a href="#compute_activations-189"><span class="linenos">189</span></a>	<span class="n">prompt_dir</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="compute_activations-190"><a href="#compute_activations-190"><span class="linenos">190</span></a>	<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">prompt_dir</span> <span class="o">/</span> <span class="s2">&quot;prompt.json&quot;</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span><span id="compute_activations-191"><a href="#compute_activations-191"><span class="linenos">191</span></a>		<span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
</span><span id="compute_activations-192"><a href="#compute_activations-192"><span class="linenos">192</span></a>
</span><span id="compute_activations-193"><a href="#compute_activations-193"><span class="linenos">193</span></a>	<span class="c1"># set up names filter</span>
</span><span id="compute_activations-194"><a href="#compute_activations-194"><span class="linenos">194</span></a>	<span class="n">names_filter_fn</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="nb">str</span><span class="p">],</span> <span class="nb">bool</span><span class="p">]</span>
</span><span id="compute_activations-195"><a href="#compute_activations-195"><span class="linenos">195</span></a>	<span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">names_filter</span><span class="p">,</span> <span class="n">re</span><span class="o">.</span><span class="n">Pattern</span><span class="p">):</span>
</span><span id="compute_activations-196"><a href="#compute_activations-196"><span class="linenos">196</span></a>		<span class="n">names_filter_fn</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">key</span><span class="p">:</span> <span class="n">names_filter</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="n">key</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>  <span class="c1"># noqa: E731</span>
</span><span id="compute_activations-197"><a href="#compute_activations-197"><span class="linenos">197</span></a>	<span class="k">else</span><span class="p">:</span>
</span><span id="compute_activations-198"><a href="#compute_activations-198"><span class="linenos">198</span></a>		<span class="n">names_filter_fn</span> <span class="o">=</span> <span class="n">names_filter</span>
</span><span id="compute_activations-199"><a href="#compute_activations-199"><span class="linenos">199</span></a>
</span><span id="compute_activations-200"><a href="#compute_activations-200"><span class="linenos">200</span></a>	<span class="c1"># compute activations</span>
</span><span id="compute_activations-201"><a href="#compute_activations-201"><span class="linenos">201</span></a>	<span class="n">cache_torch</span><span class="p">:</span> <span class="n">ActivationCache</span>
</span><span id="compute_activations-202"><a href="#compute_activations-202"><span class="linenos">202</span></a>	<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
</span><span id="compute_activations-203"><a href="#compute_activations-203"><span class="linenos">203</span></a>		<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</span><span id="compute_activations-204"><a href="#compute_activations-204"><span class="linenos">204</span></a>		<span class="c1"># TODO: batching?</span>
</span><span id="compute_activations-205"><a href="#compute_activations-205"><span class="linenos">205</span></a>		<span class="n">_</span><span class="p">,</span> <span class="n">cache_torch</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">run_with_cache</span><span class="p">(</span>
</span><span id="compute_activations-206"><a href="#compute_activations-206"><span class="linenos">206</span></a>			<span class="n">prompt_str</span><span class="p">,</span>
</span><span id="compute_activations-207"><a href="#compute_activations-207"><span class="linenos">207</span></a>			<span class="n">names_filter</span><span class="o">=</span><span class="n">names_filter_fn</span><span class="p">,</span>
</span><span id="compute_activations-208"><a href="#compute_activations-208"><span class="linenos">208</span></a>			<span class="n">return_type</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="compute_activations-209"><a href="#compute_activations-209"><span class="linenos">209</span></a>		<span class="p">)</span>
</span><span id="compute_activations-210"><a href="#compute_activations-210"><span class="linenos">210</span></a>
</span><span id="compute_activations-211"><a href="#compute_activations-211"><span class="linenos">211</span></a>	<span class="n">activations_path</span><span class="p">:</span> <span class="n">Path</span>
</span><span id="compute_activations-212"><a href="#compute_activations-212"><span class="linenos">212</span></a>	<span class="c1"># saving and returning</span>
</span><span id="compute_activations-213"><a href="#compute_activations-213"><span class="linenos">213</span></a>	<span class="k">if</span> <span class="n">stack_heads</span><span class="p">:</span>
</span><span id="compute_activations-214"><a href="#compute_activations-214"><span class="linenos">214</span></a>		<span class="n">n_layers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_layers</span>
</span><span id="compute_activations-215"><a href="#compute_activations-215"><span class="linenos">215</span></a>		<span class="n">key_pattern</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;blocks.</span><span class="si">{i}</span><span class="s2">.attn.hook_pattern&quot;</span>
</span><span id="compute_activations-216"><a href="#compute_activations-216"><span class="linenos">216</span></a>		<span class="c1"># NOTE: this only works for stacking heads at the moment</span>
</span><span id="compute_activations-217"><a href="#compute_activations-217"><span class="linenos">217</span></a>		<span class="c1"># activations_specifier: str = key_pattern.format(i=f&#39;0-{n_layers}&#39;)</span>
</span><span id="compute_activations-218"><a href="#compute_activations-218"><span class="linenos">218</span></a>		<span class="n">activations_specifier</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">key_pattern</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="o">=</span><span class="s2">&quot;-&quot;</span><span class="p">)</span>
</span><span id="compute_activations-219"><a href="#compute_activations-219"><span class="linenos">219</span></a>		<span class="n">activations_path</span> <span class="o">=</span> <span class="n">prompt_dir</span> <span class="o">/</span> <span class="sa">f</span><span class="s2">&quot;activations-</span><span class="si">{</span><span class="n">activations_specifier</span><span class="si">}</span><span class="s2">.npy&quot;</span>
</span><span id="compute_activations-220"><a href="#compute_activations-220"><span class="linenos">220</span></a>
</span><span id="compute_activations-221"><a href="#compute_activations-221"><span class="linenos">221</span></a>		<span class="c1"># check the keys are only attention heads</span>
</span><span id="compute_activations-222"><a href="#compute_activations-222"><span class="linenos">222</span></a>		<span class="n">head_keys</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">key_pattern</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="o">=</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_layers</span><span class="p">)]</span>
</span><span id="compute_activations-223"><a href="#compute_activations-223"><span class="linenos">223</span></a>		<span class="n">cache_torch_keys_set</span><span class="p">:</span> <span class="nb">set</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">cache_torch</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
</span><span id="compute_activations-224"><a href="#compute_activations-224"><span class="linenos">224</span></a>		<span class="k">assert</span> <span class="n">cache_torch_keys_set</span> <span class="o">==</span> <span class="nb">set</span><span class="p">(</span><span class="n">head_keys</span><span class="p">),</span> <span class="p">(</span>
</span><span id="compute_activations-225"><a href="#compute_activations-225"><span class="linenos">225</span></a>			<span class="sa">f</span><span class="s2">&quot;unexpected keys!</span><span class="se">\n</span><span class="si">{</span><span class="nb">set</span><span class="p">(</span><span class="n">head_keys</span><span class="p">)</span><span class="o">.</span><span class="n">symmetric_difference</span><span class="p">(</span><span class="n">cache_torch_keys_set</span><span class="p">)</span><span class="w"> </span><span class="si">= }</span><span class="se">\n</span><span class="si">{</span><span class="n">cache_torch_keys_set</span><span class="si">}</span><span class="s2"> != </span><span class="si">{</span><span class="nb">set</span><span class="p">(</span><span class="n">head_keys</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
</span><span id="compute_activations-226"><a href="#compute_activations-226"><span class="linenos">226</span></a>		<span class="p">)</span>
</span><span id="compute_activations-227"><a href="#compute_activations-227"><span class="linenos">227</span></a>
</span><span id="compute_activations-228"><a href="#compute_activations-228"><span class="linenos">228</span></a>		<span class="c1"># stack heads</span>
</span><span id="compute_activations-229"><a href="#compute_activations-229"><span class="linenos">229</span></a>		<span class="n">patterns_stacked</span><span class="p">:</span> <span class="n">Float</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">&quot;n_layers n_heads n_ctx n_ctx&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="compute_activations-230"><a href="#compute_activations-230"><span class="linenos">230</span></a>			<span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">cache_torch</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">head_keys</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span><span id="compute_activations-231"><a href="#compute_activations-231"><span class="linenos">231</span></a>		<span class="p">)</span>
</span><span id="compute_activations-232"><a href="#compute_activations-232"><span class="linenos">232</span></a>		<span class="c1"># check shape</span>
</span><span id="compute_activations-233"><a href="#compute_activations-233"><span class="linenos">233</span></a>		<span class="n">pattern_shape_no_ctx</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">patterns_stacked</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">3</span><span class="p">])</span>
</span><span id="compute_activations-234"><a href="#compute_activations-234"><span class="linenos">234</span></a>		<span class="k">assert</span> <span class="n">pattern_shape_no_ctx</span> <span class="o">==</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_heads</span><span class="p">),</span> <span class="p">(</span>
</span><span id="compute_activations-235"><a href="#compute_activations-235"><span class="linenos">235</span></a>			<span class="sa">f</span><span class="s2">&quot;unexpected shape: </span><span class="si">{</span><span class="n">patterns_stacked</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span><span class="w"> </span><span class="si">= }</span><span class="s2"> (</span><span class="si">{</span><span class="n">pattern_shape_no_ctx</span><span class="w"> </span><span class="si">= }</span><span class="s2">), expected </span><span class="si">{</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">n_layers</span><span class="p">,</span><span class="w"> </span><span class="n">model</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_heads</span><span class="p">)</span><span class="w"> </span><span class="si">= }</span><span class="s2">&quot;</span>
</span><span id="compute_activations-236"><a href="#compute_activations-236"><span class="linenos">236</span></a>		<span class="p">)</span>
</span><span id="compute_activations-237"><a href="#compute_activations-237"><span class="linenos">237</span></a>
</span><span id="compute_activations-238"><a href="#compute_activations-238"><span class="linenos">238</span></a>		<span class="n">patterns_stacked_np</span><span class="p">:</span> <span class="n">Float</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="s2">&quot;n_layers n_heads n_ctx n_ctx&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="compute_activations-239"><a href="#compute_activations-239"><span class="linenos">239</span></a>			<span class="n">patterns_stacked</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span><span id="compute_activations-240"><a href="#compute_activations-240"><span class="linenos">240</span></a>		<span class="p">)</span>
</span><span id="compute_activations-241"><a href="#compute_activations-241"><span class="linenos">241</span></a>
</span><span id="compute_activations-242"><a href="#compute_activations-242"><span class="linenos">242</span></a>		<span class="c1"># save</span>
</span><span id="compute_activations-243"><a href="#compute_activations-243"><span class="linenos">243</span></a>		<span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">activations_path</span><span class="p">,</span> <span class="n">patterns_stacked_np</span><span class="p">)</span>
</span><span id="compute_activations-244"><a href="#compute_activations-244"><span class="linenos">244</span></a>
</span><span id="compute_activations-245"><a href="#compute_activations-245"><span class="linenos">245</span></a>		<span class="c1"># return</span>
</span><span id="compute_activations-246"><a href="#compute_activations-246"><span class="linenos">246</span></a>		<span class="k">match</span> <span class="n">return_cache</span><span class="p">:</span>
</span><span id="compute_activations-247"><a href="#compute_activations-247"><span class="linenos">247</span></a>			<span class="k">case</span> <span class="s2">&quot;numpy&quot;</span><span class="p">:</span>
</span><span id="compute_activations-248"><a href="#compute_activations-248"><span class="linenos">248</span></a>				<span class="k">return</span> <span class="n">activations_path</span><span class="p">,</span> <span class="n">patterns_stacked_np</span>
</span><span id="compute_activations-249"><a href="#compute_activations-249"><span class="linenos">249</span></a>			<span class="k">case</span> <span class="s2">&quot;torch&quot;</span><span class="p">:</span>
</span><span id="compute_activations-250"><a href="#compute_activations-250"><span class="linenos">250</span></a>				<span class="k">return</span> <span class="n">activations_path</span><span class="p">,</span> <span class="n">patterns_stacked</span>
</span><span id="compute_activations-251"><a href="#compute_activations-251"><span class="linenos">251</span></a>			<span class="k">case</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="compute_activations-252"><a href="#compute_activations-252"><span class="linenos">252</span></a>				<span class="k">return</span> <span class="n">activations_path</span><span class="p">,</span> <span class="kc">None</span>
</span><span id="compute_activations-253"><a href="#compute_activations-253"><span class="linenos">253</span></a>			<span class="k">case</span><span class="w"> </span><span class="k">_</span><span class="p">:</span>
</span><span id="compute_activations-254"><a href="#compute_activations-254"><span class="linenos">254</span></a>				<span class="n">msg</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;invalid return_cache: </span><span class="si">{</span><span class="n">return_cache</span><span class="w"> </span><span class="si">= }</span><span class="s2">&quot;</span>
</span><span id="compute_activations-255"><a href="#compute_activations-255"><span class="linenos">255</span></a>				<span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
</span><span id="compute_activations-256"><a href="#compute_activations-256"><span class="linenos">256</span></a>	<span class="k">else</span><span class="p">:</span>
</span><span id="compute_activations-257"><a href="#compute_activations-257"><span class="linenos">257</span></a>		<span class="n">activations_path</span> <span class="o">=</span> <span class="n">prompt_dir</span> <span class="o">/</span> <span class="s2">&quot;activations.npz&quot;</span>
</span><span id="compute_activations-258"><a href="#compute_activations-258"><span class="linenos">258</span></a>
</span><span id="compute_activations-259"><a href="#compute_activations-259"><span class="linenos">259</span></a>		<span class="c1"># save</span>
</span><span id="compute_activations-260"><a href="#compute_activations-260"><span class="linenos">260</span></a>		<span class="n">cache_np</span><span class="p">:</span> <span class="n">ActivationCacheNp</span> <span class="o">=</span> <span class="p">{</span>
</span><span id="compute_activations-261"><a href="#compute_activations-261"><span class="linenos">261</span></a>			<span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">cache_torch</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
</span><span id="compute_activations-262"><a href="#compute_activations-262"><span class="linenos">262</span></a>		<span class="p">}</span>
</span><span id="compute_activations-263"><a href="#compute_activations-263"><span class="linenos">263</span></a>
</span><span id="compute_activations-264"><a href="#compute_activations-264"><span class="linenos">264</span></a>		<span class="n">np</span><span class="o">.</span><span class="n">savez_compressed</span><span class="p">(</span>
</span><span id="compute_activations-265"><a href="#compute_activations-265"><span class="linenos">265</span></a>			<span class="n">activations_path</span><span class="p">,</span>
</span><span id="compute_activations-266"><a href="#compute_activations-266"><span class="linenos">266</span></a>			<span class="o">**</span><span class="n">cache_np</span><span class="p">,</span>
</span><span id="compute_activations-267"><a href="#compute_activations-267"><span class="linenos">267</span></a>		<span class="p">)</span>
</span><span id="compute_activations-268"><a href="#compute_activations-268"><span class="linenos">268</span></a>
</span><span id="compute_activations-269"><a href="#compute_activations-269"><span class="linenos">269</span></a>		<span class="c1"># return</span>
</span><span id="compute_activations-270"><a href="#compute_activations-270"><span class="linenos">270</span></a>		<span class="k">match</span> <span class="n">return_cache</span><span class="p">:</span>
</span><span id="compute_activations-271"><a href="#compute_activations-271"><span class="linenos">271</span></a>			<span class="k">case</span> <span class="s2">&quot;numpy&quot;</span><span class="p">:</span>
</span><span id="compute_activations-272"><a href="#compute_activations-272"><span class="linenos">272</span></a>				<span class="k">return</span> <span class="n">activations_path</span><span class="p">,</span> <span class="n">cache_np</span>
</span><span id="compute_activations-273"><a href="#compute_activations-273"><span class="linenos">273</span></a>			<span class="k">case</span> <span class="s2">&quot;torch&quot;</span><span class="p">:</span>
</span><span id="compute_activations-274"><a href="#compute_activations-274"><span class="linenos">274</span></a>				<span class="k">return</span> <span class="n">activations_path</span><span class="p">,</span> <span class="n">cache_torch</span>
</span><span id="compute_activations-275"><a href="#compute_activations-275"><span class="linenos">275</span></a>			<span class="k">case</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="compute_activations-276"><a href="#compute_activations-276"><span class="linenos">276</span></a>				<span class="k">return</span> <span class="n">activations_path</span><span class="p">,</span> <span class="kc">None</span>
</span><span id="compute_activations-277"><a href="#compute_activations-277"><span class="linenos">277</span></a>			<span class="k">case</span><span class="w"> </span><span class="k">_</span><span class="p">:</span>
</span><span id="compute_activations-278"><a href="#compute_activations-278"><span class="linenos">278</span></a>				<span class="n">msg</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;invalid return_cache: </span><span class="si">{</span><span class="n">return_cache</span><span class="w"> </span><span class="si">= }</span><span class="s2">&quot;</span>
</span><span id="compute_activations-279"><a href="#compute_activations-279"><span class="linenos">279</span></a>				<span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>get activations for a given model and prompt, possibly from a cache</p>

<p>if from a cache, prompt_meta must be passed and contain the prompt hash</p>

<h1 id="parameters">Parameters:</h1>

<ul>
<li><code>prompt : dict | None</code>
(defaults to <code>None</code>)</li>
<li><code>model : HookedTransformer</code></li>
<li><code>save_path : Path</code>
(defaults to <code>Path(DATA_DIR)</code>)</li>
<li><code>names_filter : Callable[[str], bool]|re.Pattern</code>
a filter for the names of the activations to return. if an <code>re.Pattern</code>, will use <code>lambda key: names_filter.match(key) is not None</code>
(defaults to <code>ATTN_PATTERN_REGEX</code>)</li>
<li><code>return_cache : Literal[None, "numpy", "torch"]</code>
will return <code>None</code> as the second element if <code>None</code>, otherwise will return the cache in the specified tensor format. <code>stack_heads</code> still affects whether it will be a dict (False) or a single tensor (True)
(defaults to <code>None</code>)</li>
<li><code>stack_heads : bool</code>
whether the heads should be stacked in the output. this causes a number of changes:</li>
<li><code>npy</code> file with a single <code>(n_layers, n_heads, n_ctx, n_ctx)</code> tensor saved for each prompt instead of <code>npz</code> file with dict by layer</li>
<li><code>cache</code> will be a single <code>(n_layers, n_heads, n_ctx, n_ctx)</code> tensor instead of a dict by layer if <code>return_cache</code> is <code>True</code>
will assert that everything in the activation cache is only attention patterns, and is all of the attention patterns. raises an exception if not.</li>
</ul>

<h1 id="returns">Returns:</h1>

<pre><code>tuple[
        Path,
        Union[
                None,
                ActivationCacheNp, ActivationCache,
                Float[np.ndarray, "n_layers n_heads n_ctx n_ctx"], Float[torch.Tensor, "n_layers n_heads n_ctx n_ctx"],
        ]
]
</code></pre>
</div>


                </section>
                <section id="get_activations">
                            <input id="get_activations-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">get_activations</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="n">prompt</span><span class="p">:</span> <span class="nb">dict</span>,</span><span class="param">	<span class="n">model</span><span class="p">:</span> <span class="n">transformer_lens</span><span class="o">.</span><span class="n">HookedTransformer</span><span class="o">.</span><span class="n">HookedTransformer</span> <span class="o">|</span> <span class="nb">str</span>,</span><span class="param">	<span class="n">save_path</span><span class="p">:</span> <span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span> <span class="o">=</span> <span class="n">PosixPath</span><span class="p">(</span><span class="s1">&#39;attn_data&#39;</span><span class="p">)</span>,</span><span class="param">	<span class="n">allow_disk_cache</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>,</span><span class="param">	<span class="n">return_cache</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;numpy&#39;</span><span class="p">,</span> <span class="s1">&#39;torch&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;numpy&#39;</span></span><span class="return-annotation">) -> <span class="nb">tuple</span><span class="p">[</span><span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">,</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">|</span> <span class="n">transformer_lens</span><span class="o">.</span><span class="n">ActivationCache</span><span class="o">.</span><span class="n">ActivationCache</span> <span class="o">|</span> <span class="kc">None</span><span class="p">]</span>:</span></span>

                <div class="source-button-container">
            <label class="pdoc-button view-source-button" for="get_activations-view-source"><span>View Source</span></label>
            <div class="github-button-wrapper">
                <a class="pdoc-button github-link-button" href="https://github.com/mivanit/pattern-lens/blob/0.4.0activations.py#L305-L369" target="_blank">
                    <span>View on GitHub</span>
                </a>
            </div>
        </div>

    </div>
    <a class="headerlink" href="#get_activations"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="get_activations-306"><a href="#get_activations-306"><span class="linenos">306</span></a><span class="k">def</span><span class="w"> </span><span class="nf">get_activations</span><span class="p">(</span>
</span><span id="get_activations-307"><a href="#get_activations-307"><span class="linenos">307</span></a>	<span class="n">prompt</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>
</span><span id="get_activations-308"><a href="#get_activations-308"><span class="linenos">308</span></a>	<span class="n">model</span><span class="p">:</span> <span class="n">HookedTransformer</span> <span class="o">|</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="get_activations-309"><a href="#get_activations-309"><span class="linenos">309</span></a>	<span class="n">save_path</span><span class="p">:</span> <span class="n">Path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">DATA_DIR</span><span class="p">),</span>
</span><span id="get_activations-310"><a href="#get_activations-310"><span class="linenos">310</span></a>	<span class="n">allow_disk_cache</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="get_activations-311"><a href="#get_activations-311"><span class="linenos">311</span></a>	<span class="n">return_cache</span><span class="p">:</span> <span class="n">ReturnCache</span> <span class="o">=</span> <span class="s2">&quot;numpy&quot;</span><span class="p">,</span>
</span><span id="get_activations-312"><a href="#get_activations-312"><span class="linenos">312</span></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Path</span><span class="p">,</span> <span class="n">ActivationCacheNp</span> <span class="o">|</span> <span class="n">ActivationCache</span> <span class="o">|</span> <span class="kc">None</span><span class="p">]:</span>
</span><span id="get_activations-313"><a href="#get_activations-313"><span class="linenos">313</span></a><span class="w">	</span><span class="sd">&quot;&quot;&quot;given a prompt and a model, save or load activations</span>
</span><span id="get_activations-314"><a href="#get_activations-314"><span class="linenos">314</span></a>
</span><span id="get_activations-315"><a href="#get_activations-315"><span class="linenos">315</span></a><span class="sd">	# Parameters:</span>
</span><span id="get_activations-316"><a href="#get_activations-316"><span class="linenos">316</span></a><span class="sd">	- `prompt : dict`</span>
</span><span id="get_activations-317"><a href="#get_activations-317"><span class="linenos">317</span></a><span class="sd">		expected to contain the &#39;text&#39; key</span>
</span><span id="get_activations-318"><a href="#get_activations-318"><span class="linenos">318</span></a><span class="sd">	- `model : HookedTransformer | str`</span>
</span><span id="get_activations-319"><a href="#get_activations-319"><span class="linenos">319</span></a><span class="sd">		either a `HookedTransformer` or a string model name, to be loaded with `HookedTransformer.from_pretrained`</span>
</span><span id="get_activations-320"><a href="#get_activations-320"><span class="linenos">320</span></a><span class="sd">	- `save_path : Path`</span>
</span><span id="get_activations-321"><a href="#get_activations-321"><span class="linenos">321</span></a><span class="sd">		path to save the activations to (and load from)</span>
</span><span id="get_activations-322"><a href="#get_activations-322"><span class="linenos">322</span></a><span class="sd">		(defaults to `Path(DATA_DIR)`)</span>
</span><span id="get_activations-323"><a href="#get_activations-323"><span class="linenos">323</span></a><span class="sd">	- `allow_disk_cache : bool`</span>
</span><span id="get_activations-324"><a href="#get_activations-324"><span class="linenos">324</span></a><span class="sd">		whether to allow loading from disk cache</span>
</span><span id="get_activations-325"><a href="#get_activations-325"><span class="linenos">325</span></a><span class="sd">		(defaults to `True`)</span>
</span><span id="get_activations-326"><a href="#get_activations-326"><span class="linenos">326</span></a><span class="sd">	- `return_cache : Literal[None, &quot;numpy&quot;, &quot;torch&quot;]`</span>
</span><span id="get_activations-327"><a href="#get_activations-327"><span class="linenos">327</span></a><span class="sd">		whether to return the cache, and in what format</span>
</span><span id="get_activations-328"><a href="#get_activations-328"><span class="linenos">328</span></a><span class="sd">		(defaults to `&quot;numpy&quot;`)</span>
</span><span id="get_activations-329"><a href="#get_activations-329"><span class="linenos">329</span></a>
</span><span id="get_activations-330"><a href="#get_activations-330"><span class="linenos">330</span></a><span class="sd">	# Returns:</span>
</span><span id="get_activations-331"><a href="#get_activations-331"><span class="linenos">331</span></a><span class="sd">	- `tuple[Path, ActivationCacheNp | ActivationCache | None]`</span>
</span><span id="get_activations-332"><a href="#get_activations-332"><span class="linenos">332</span></a><span class="sd">		the path to the activations and the cache if `return_cache is not None`</span>
</span><span id="get_activations-333"><a href="#get_activations-333"><span class="linenos">333</span></a>
</span><span id="get_activations-334"><a href="#get_activations-334"><span class="linenos">334</span></a><span class="sd">	&quot;&quot;&quot;</span>
</span><span id="get_activations-335"><a href="#get_activations-335"><span class="linenos">335</span></a>	<span class="c1"># add hash to prompt</span>
</span><span id="get_activations-336"><a href="#get_activations-336"><span class="linenos">336</span></a>	<span class="n">augment_prompt_with_hash</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>
</span><span id="get_activations-337"><a href="#get_activations-337"><span class="linenos">337</span></a>
</span><span id="get_activations-338"><a href="#get_activations-338"><span class="linenos">338</span></a>	<span class="c1"># get the model</span>
</span><span id="get_activations-339"><a href="#get_activations-339"><span class="linenos">339</span></a>	<span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="get_activations-340"><a href="#get_activations-340"><span class="linenos">340</span></a>		<span class="n">model</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">model_name</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">HookedTransformer</span><span class="p">)</span> <span class="k">else</span> <span class="n">model</span>
</span><span id="get_activations-341"><a href="#get_activations-341"><span class="linenos">341</span></a>	<span class="p">)</span>
</span><span id="get_activations-342"><a href="#get_activations-342"><span class="linenos">342</span></a>
</span><span id="get_activations-343"><a href="#get_activations-343"><span class="linenos">343</span></a>	<span class="c1"># from cache</span>
</span><span id="get_activations-344"><a href="#get_activations-344"><span class="linenos">344</span></a>	<span class="k">if</span> <span class="n">allow_disk_cache</span><span class="p">:</span>
</span><span id="get_activations-345"><a href="#get_activations-345"><span class="linenos">345</span></a>		<span class="k">try</span><span class="p">:</span>
</span><span id="get_activations-346"><a href="#get_activations-346"><span class="linenos">346</span></a>			<span class="n">path</span><span class="p">,</span> <span class="n">cache</span> <span class="o">=</span> <span class="n">load_activations</span><span class="p">(</span>
</span><span id="get_activations-347"><a href="#get_activations-347"><span class="linenos">347</span></a>				<span class="n">model_name</span><span class="o">=</span><span class="n">model_name</span><span class="p">,</span>
</span><span id="get_activations-348"><a href="#get_activations-348"><span class="linenos">348</span></a>				<span class="n">prompt</span><span class="o">=</span><span class="n">prompt</span><span class="p">,</span>
</span><span id="get_activations-349"><a href="#get_activations-349"><span class="linenos">349</span></a>				<span class="n">save_path</span><span class="o">=</span><span class="n">save_path</span><span class="p">,</span>
</span><span id="get_activations-350"><a href="#get_activations-350"><span class="linenos">350</span></a>			<span class="p">)</span>
</span><span id="get_activations-351"><a href="#get_activations-351"><span class="linenos">351</span></a>			<span class="k">if</span> <span class="n">return_cache</span><span class="p">:</span>
</span><span id="get_activations-352"><a href="#get_activations-352"><span class="linenos">352</span></a>				<span class="k">return</span> <span class="n">path</span><span class="p">,</span> <span class="n">cache</span>
</span><span id="get_activations-353"><a href="#get_activations-353"><span class="linenos">353</span></a>			<span class="k">else</span><span class="p">:</span>
</span><span id="get_activations-354"><a href="#get_activations-354"><span class="linenos">354</span></a>				<span class="c1"># TODO: this basically does nothing, since we load the activations and then immediately get rid of them.</span>
</span><span id="get_activations-355"><a href="#get_activations-355"><span class="linenos">355</span></a>				<span class="c1"># maybe refactor this so that load_activations can take a parameter to simply assert that the cache exists?</span>
</span><span id="get_activations-356"><a href="#get_activations-356"><span class="linenos">356</span></a>				<span class="c1"># this will let us avoid loading it, which slows things down</span>
</span><span id="get_activations-357"><a href="#get_activations-357"><span class="linenos">357</span></a>				<span class="k">return</span> <span class="n">path</span><span class="p">,</span> <span class="kc">None</span>
</span><span id="get_activations-358"><a href="#get_activations-358"><span class="linenos">358</span></a>		<span class="k">except</span> <span class="n">ActivationsMissingError</span><span class="p">:</span>
</span><span id="get_activations-359"><a href="#get_activations-359"><span class="linenos">359</span></a>			<span class="k">pass</span>
</span><span id="get_activations-360"><a href="#get_activations-360"><span class="linenos">360</span></a>
</span><span id="get_activations-361"><a href="#get_activations-361"><span class="linenos">361</span></a>	<span class="c1"># compute them</span>
</span><span id="get_activations-362"><a href="#get_activations-362"><span class="linenos">362</span></a>	<span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
</span><span id="get_activations-363"><a href="#get_activations-363"><span class="linenos">363</span></a>		<span class="n">model</span> <span class="o">=</span> <span class="n">HookedTransformer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
</span><span id="get_activations-364"><a href="#get_activations-364"><span class="linenos">364</span></a>
</span><span id="get_activations-365"><a href="#get_activations-365"><span class="linenos">365</span></a>	<span class="k">return</span> <span class="n">compute_activations</span><span class="p">(</span>
</span><span id="get_activations-366"><a href="#get_activations-366"><span class="linenos">366</span></a>		<span class="n">prompt</span><span class="o">=</span><span class="n">prompt</span><span class="p">,</span>
</span><span id="get_activations-367"><a href="#get_activations-367"><span class="linenos">367</span></a>		<span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
</span><span id="get_activations-368"><a href="#get_activations-368"><span class="linenos">368</span></a>		<span class="n">save_path</span><span class="o">=</span><span class="n">save_path</span><span class="p">,</span>
</span><span id="get_activations-369"><a href="#get_activations-369"><span class="linenos">369</span></a>		<span class="n">return_cache</span><span class="o">=</span><span class="n">return_cache</span><span class="p">,</span>
</span><span id="get_activations-370"><a href="#get_activations-370"><span class="linenos">370</span></a>	<span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>given a prompt and a model, save or load activations</p>

<h1 id="parameters">Parameters:</h1>

<ul>
<li><code>prompt : dict</code>
expected to contain the 'text' key</li>
<li><code>model : HookedTransformer | str</code>
either a <code>HookedTransformer</code> or a string model name, to be loaded with <code>HookedTransformer.from_pretrained</code></li>
<li><code>save_path : Path</code>
path to save the activations to (and load from)
(defaults to <code>Path(DATA_DIR)</code>)</li>
<li><code>allow_disk_cache : bool</code>
whether to allow loading from disk cache
(defaults to <code>True</code>)</li>
<li><code>return_cache : Literal[None, "numpy", "torch"]</code>
whether to return the cache, and in what format
(defaults to <code>"numpy"</code>)</li>
</ul>

<h1 id="returns">Returns:</h1>

<ul>
<li><code>tuple[Path, ActivationCacheNp | ActivationCache | None]</code>
the path to the activations and the cache if <code>return_cache is not None</code></li>
</ul>
</div>


                </section>
                <section id="DEFAULT_DEVICE">
                    <div class="attr variable">
            <span class="name">DEFAULT_DEVICE</span><span class="annotation">: torch.device</span>        =
<span class="default_value">device(type=&#39;cuda&#39;)</span>

        
    </div>
    <a class="headerlink" href="#DEFAULT_DEVICE"></a>
    
    

                </section>
                <section id="activations_main">
                            <input id="activations_main-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">activations_main</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span>,</span><span class="param">	<span class="n">save_path</span><span class="p">:</span> <span class="nb">str</span>,</span><span class="param">	<span class="n">prompts_path</span><span class="p">:</span> <span class="nb">str</span>,</span><span class="param">	<span class="n">raw_prompts</span><span class="p">:</span> <span class="nb">bool</span>,</span><span class="param">	<span class="n">min_chars</span><span class="p">:</span> <span class="nb">int</span>,</span><span class="param">	<span class="n">max_chars</span><span class="p">:</span> <span class="nb">int</span>,</span><span class="param">	<span class="n">force</span><span class="p">:</span> <span class="nb">bool</span>,</span><span class="param">	<span class="n">n_samples</span><span class="p">:</span> <span class="nb">int</span>,</span><span class="param">	<span class="n">no_index_html</span><span class="p">:</span> <span class="nb">bool</span>,</span><span class="param">	<span class="n">shuffle</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>,</span><span class="param">	<span class="n">stacked_heads</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>,</span><span class="param">	<span class="n">device</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">device</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s1">&#39;cuda&#39;</span><span class="p">)</span></span><span class="return-annotation">) -> <span class="kc">None</span>:</span></span>

                <div class="source-button-container">
            <label class="pdoc-button view-source-button" for="activations_main-view-source"><span>View Source</span></label>
            <div class="github-button-wrapper">
                <a class="pdoc-button github-link-button" href="https://github.com/mivanit/pattern-lens/blob/0.4.0activations.py#L377-L514" target="_blank">
                    <span>View on GitHub</span>
                </a>
            </div>
        </div>

    </div>
    <a class="headerlink" href="#activations_main"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="activations_main-378"><a href="#activations_main-378"><span class="linenos">378</span></a><span class="k">def</span><span class="w"> </span><span class="nf">activations_main</span><span class="p">(</span>
</span><span id="activations_main-379"><a href="#activations_main-379"><span class="linenos">379</span></a>	<span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="activations_main-380"><a href="#activations_main-380"><span class="linenos">380</span></a>	<span class="n">save_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="activations_main-381"><a href="#activations_main-381"><span class="linenos">381</span></a>	<span class="n">prompts_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="activations_main-382"><a href="#activations_main-382"><span class="linenos">382</span></a>	<span class="n">raw_prompts</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
</span><span id="activations_main-383"><a href="#activations_main-383"><span class="linenos">383</span></a>	<span class="n">min_chars</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="activations_main-384"><a href="#activations_main-384"><span class="linenos">384</span></a>	<span class="n">max_chars</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="activations_main-385"><a href="#activations_main-385"><span class="linenos">385</span></a>	<span class="n">force</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
</span><span id="activations_main-386"><a href="#activations_main-386"><span class="linenos">386</span></a>	<span class="n">n_samples</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="activations_main-387"><a href="#activations_main-387"><span class="linenos">387</span></a>	<span class="n">no_index_html</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
</span><span id="activations_main-388"><a href="#activations_main-388"><span class="linenos">388</span></a>	<span class="n">shuffle</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="activations_main-389"><a href="#activations_main-389"><span class="linenos">389</span></a>	<span class="n">stacked_heads</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="activations_main-390"><a href="#activations_main-390"><span class="linenos">390</span></a>	<span class="n">device</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">DEFAULT_DEVICE</span><span class="p">,</span>
</span><span id="activations_main-391"><a href="#activations_main-391"><span class="linenos">391</span></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="activations_main-392"><a href="#activations_main-392"><span class="linenos">392</span></a><span class="w">	</span><span class="sd">&quot;&quot;&quot;main function for computing activations</span>
</span><span id="activations_main-393"><a href="#activations_main-393"><span class="linenos">393</span></a>
</span><span id="activations_main-394"><a href="#activations_main-394"><span class="linenos">394</span></a><span class="sd">	# Parameters:</span>
</span><span id="activations_main-395"><a href="#activations_main-395"><span class="linenos">395</span></a><span class="sd">	- `model_name : str`</span>
</span><span id="activations_main-396"><a href="#activations_main-396"><span class="linenos">396</span></a><span class="sd">		name of a model to load with `HookedTransformer.from_pretrained`</span>
</span><span id="activations_main-397"><a href="#activations_main-397"><span class="linenos">397</span></a><span class="sd">	- `save_path : str`</span>
</span><span id="activations_main-398"><a href="#activations_main-398"><span class="linenos">398</span></a><span class="sd">		path to save the activations to</span>
</span><span id="activations_main-399"><a href="#activations_main-399"><span class="linenos">399</span></a><span class="sd">	- `prompts_path : str`</span>
</span><span id="activations_main-400"><a href="#activations_main-400"><span class="linenos">400</span></a><span class="sd">		path to the prompts file</span>
</span><span id="activations_main-401"><a href="#activations_main-401"><span class="linenos">401</span></a><span class="sd">	- `raw_prompts : bool`</span>
</span><span id="activations_main-402"><a href="#activations_main-402"><span class="linenos">402</span></a><span class="sd">		whether the prompts are raw, not filtered by length. `load_text_data` will be called if `True`, otherwise just load the &quot;text&quot; field from each line in `prompts_path`</span>
</span><span id="activations_main-403"><a href="#activations_main-403"><span class="linenos">403</span></a><span class="sd">	- `min_chars : int`</span>
</span><span id="activations_main-404"><a href="#activations_main-404"><span class="linenos">404</span></a><span class="sd">		minimum number of characters for a prompt</span>
</span><span id="activations_main-405"><a href="#activations_main-405"><span class="linenos">405</span></a><span class="sd">	- `max_chars : int`</span>
</span><span id="activations_main-406"><a href="#activations_main-406"><span class="linenos">406</span></a><span class="sd">		maximum number of characters for a prompt</span>
</span><span id="activations_main-407"><a href="#activations_main-407"><span class="linenos">407</span></a><span class="sd">	- `force : bool`</span>
</span><span id="activations_main-408"><a href="#activations_main-408"><span class="linenos">408</span></a><span class="sd">		whether to overwrite existing files</span>
</span><span id="activations_main-409"><a href="#activations_main-409"><span class="linenos">409</span></a><span class="sd">	- `n_samples : int`</span>
</span><span id="activations_main-410"><a href="#activations_main-410"><span class="linenos">410</span></a><span class="sd">		maximum number of samples to process</span>
</span><span id="activations_main-411"><a href="#activations_main-411"><span class="linenos">411</span></a><span class="sd">	- `no_index_html : bool`</span>
</span><span id="activations_main-412"><a href="#activations_main-412"><span class="linenos">412</span></a><span class="sd">		whether to write an index.html file</span>
</span><span id="activations_main-413"><a href="#activations_main-413"><span class="linenos">413</span></a><span class="sd">	- `shuffle : bool`</span>
</span><span id="activations_main-414"><a href="#activations_main-414"><span class="linenos">414</span></a><span class="sd">		whether to shuffle the prompts</span>
</span><span id="activations_main-415"><a href="#activations_main-415"><span class="linenos">415</span></a><span class="sd">		(defaults to `False`)</span>
</span><span id="activations_main-416"><a href="#activations_main-416"><span class="linenos">416</span></a><span class="sd">	- `stacked_heads : bool`</span>
</span><span id="activations_main-417"><a href="#activations_main-417"><span class="linenos">417</span></a><span class="sd">		whether	to stack the heads in the output tensor. will save as `.npy` instead of `.npz` if `True`</span>
</span><span id="activations_main-418"><a href="#activations_main-418"><span class="linenos">418</span></a><span class="sd">		(defaults to `False`)</span>
</span><span id="activations_main-419"><a href="#activations_main-419"><span class="linenos">419</span></a><span class="sd">	- `device : str | torch.device`</span>
</span><span id="activations_main-420"><a href="#activations_main-420"><span class="linenos">420</span></a><span class="sd">		the device to use. if a string, will be passed to `torch.device`</span>
</span><span id="activations_main-421"><a href="#activations_main-421"><span class="linenos">421</span></a><span class="sd">	&quot;&quot;&quot;</span>
</span><span id="activations_main-422"><a href="#activations_main-422"><span class="linenos">422</span></a>	<span class="c1"># figure out the device to use</span>
</span><span id="activations_main-423"><a href="#activations_main-423"><span class="linenos">423</span></a>	<span class="n">device_</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span>
</span><span id="activations_main-424"><a href="#activations_main-424"><span class="linenos">424</span></a>	<span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">):</span>
</span><span id="activations_main-425"><a href="#activations_main-425"><span class="linenos">425</span></a>		<span class="n">device_</span> <span class="o">=</span> <span class="n">device</span>
</span><span id="activations_main-426"><a href="#activations_main-426"><span class="linenos">426</span></a>	<span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
</span><span id="activations_main-427"><a href="#activations_main-427"><span class="linenos">427</span></a>		<span class="n">device_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</span><span id="activations_main-428"><a href="#activations_main-428"><span class="linenos">428</span></a>	<span class="k">else</span><span class="p">:</span>
</span><span id="activations_main-429"><a href="#activations_main-429"><span class="linenos">429</span></a>		<span class="n">msg</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;invalid device: </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s2">&quot;</span>
</span><span id="activations_main-430"><a href="#activations_main-430"><span class="linenos">430</span></a>		<span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
</span><span id="activations_main-431"><a href="#activations_main-431"><span class="linenos">431</span></a>
</span><span id="activations_main-432"><a href="#activations_main-432"><span class="linenos">432</span></a>	<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;using device: </span><span class="si">{</span><span class="n">device_</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="activations_main-433"><a href="#activations_main-433"><span class="linenos">433</span></a>
</span><span id="activations_main-434"><a href="#activations_main-434"><span class="linenos">434</span></a>	<span class="k">with</span> <span class="n">SpinnerContext</span><span class="p">(</span><span class="n">message</span><span class="o">=</span><span class="s2">&quot;loading model&quot;</span><span class="p">,</span> <span class="o">**</span><span class="n">SPINNER_KWARGS</span><span class="p">):</span>
</span><span id="activations_main-435"><a href="#activations_main-435"><span class="linenos">435</span></a>		<span class="n">model</span><span class="p">:</span> <span class="n">HookedTransformer</span> <span class="o">=</span> <span class="n">HookedTransformer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
</span><span id="activations_main-436"><a href="#activations_main-436"><span class="linenos">436</span></a>			<span class="n">model_name</span><span class="p">,</span>
</span><span id="activations_main-437"><a href="#activations_main-437"><span class="linenos">437</span></a>			<span class="n">device</span><span class="o">=</span><span class="n">device_</span><span class="p">,</span>
</span><span id="activations_main-438"><a href="#activations_main-438"><span class="linenos">438</span></a>		<span class="p">)</span>
</span><span id="activations_main-439"><a href="#activations_main-439"><span class="linenos">439</span></a>		<span class="n">model</span><span class="o">.</span><span class="n">model_name</span> <span class="o">=</span> <span class="n">model_name</span>
</span><span id="activations_main-440"><a href="#activations_main-440"><span class="linenos">440</span></a>		<span class="n">model</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">model_name</span> <span class="o">=</span> <span class="n">model_name</span>
</span><span id="activations_main-441"><a href="#activations_main-441"><span class="linenos">441</span></a>		<span class="n">n_params</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
</span><span id="activations_main-442"><a href="#activations_main-442"><span class="linenos">442</span></a>	<span class="nb">print</span><span class="p">(</span>
</span><span id="activations_main-443"><a href="#activations_main-443"><span class="linenos">443</span></a>		<span class="sa">f</span><span class="s2">&quot;loaded </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2"> with </span><span class="si">{</span><span class="n">shorten_numerical_to_str</span><span class="p">(</span><span class="n">n_params</span><span class="p">)</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="n">n_params</span><span class="si">}</span><span class="s2">) parameters&quot;</span><span class="p">,</span>
</span><span id="activations_main-444"><a href="#activations_main-444"><span class="linenos">444</span></a>	<span class="p">)</span>
</span><span id="activations_main-445"><a href="#activations_main-445"><span class="linenos">445</span></a>	<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">model devices: </span><span class="si">{</span><span class="w"> </span><span class="p">{</span><span class="n">p</span><span class="o">.</span><span class="n">device</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">p</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()}</span><span class="w"> </span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="activations_main-446"><a href="#activations_main-446"><span class="linenos">446</span></a>
</span><span id="activations_main-447"><a href="#activations_main-447"><span class="linenos">447</span></a>	<span class="n">save_path_p</span><span class="p">:</span> <span class="n">Path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span>
</span><span id="activations_main-448"><a href="#activations_main-448"><span class="linenos">448</span></a>	<span class="n">save_path_p</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="activations_main-449"><a href="#activations_main-449"><span class="linenos">449</span></a>	<span class="n">model_path</span><span class="p">:</span> <span class="n">Path</span> <span class="o">=</span> <span class="n">save_path_p</span> <span class="o">/</span> <span class="n">model_name</span>
</span><span id="activations_main-450"><a href="#activations_main-450"><span class="linenos">450</span></a>	<span class="k">with</span> <span class="n">SpinnerContext</span><span class="p">(</span>
</span><span id="activations_main-451"><a href="#activations_main-451"><span class="linenos">451</span></a>		<span class="n">message</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;saving model info to </span><span class="si">{</span><span class="n">model_path</span><span class="o">.</span><span class="n">as_posix</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
</span><span id="activations_main-452"><a href="#activations_main-452"><span class="linenos">452</span></a>		<span class="o">**</span><span class="n">SPINNER_KWARGS</span><span class="p">,</span>
</span><span id="activations_main-453"><a href="#activations_main-453"><span class="linenos">453</span></a>	<span class="p">):</span>
</span><span id="activations_main-454"><a href="#activations_main-454"><span class="linenos">454</span></a>		<span class="n">model_cfg</span><span class="p">:</span> <span class="n">HookedTransformerConfig</span>
</span><span id="activations_main-455"><a href="#activations_main-455"><span class="linenos">455</span></a>		<span class="n">model_cfg</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">cfg</span>
</span><span id="activations_main-456"><a href="#activations_main-456"><span class="linenos">456</span></a>		<span class="n">model_path</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="activations_main-457"><a href="#activations_main-457"><span class="linenos">457</span></a>		<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">model_path</span> <span class="o">/</span> <span class="s2">&quot;model_cfg.json&quot;</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span><span id="activations_main-458"><a href="#activations_main-458"><span class="linenos">458</span></a>			<span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">json_serialize</span><span class="p">(</span><span class="n">asdict</span><span class="p">(</span><span class="n">model_cfg</span><span class="p">)),</span> <span class="n">f</span><span class="p">)</span>
</span><span id="activations_main-459"><a href="#activations_main-459"><span class="linenos">459</span></a>
</span><span id="activations_main-460"><a href="#activations_main-460"><span class="linenos">460</span></a>	<span class="c1"># load prompts</span>
</span><span id="activations_main-461"><a href="#activations_main-461"><span class="linenos">461</span></a>	<span class="k">with</span> <span class="n">SpinnerContext</span><span class="p">(</span>
</span><span id="activations_main-462"><a href="#activations_main-462"><span class="linenos">462</span></a>		<span class="n">message</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;loading prompts from </span><span class="si">{</span><span class="n">prompts_path</span><span class="w"> </span><span class="si">= }</span><span class="s2">&quot;</span><span class="p">,</span>
</span><span id="activations_main-463"><a href="#activations_main-463"><span class="linenos">463</span></a>		<span class="o">**</span><span class="n">SPINNER_KWARGS</span><span class="p">,</span>
</span><span id="activations_main-464"><a href="#activations_main-464"><span class="linenos">464</span></a>	<span class="p">):</span>
</span><span id="activations_main-465"><a href="#activations_main-465"><span class="linenos">465</span></a>		<span class="n">prompts</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span>
</span><span id="activations_main-466"><a href="#activations_main-466"><span class="linenos">466</span></a>		<span class="k">if</span> <span class="n">raw_prompts</span><span class="p">:</span>
</span><span id="activations_main-467"><a href="#activations_main-467"><span class="linenos">467</span></a>			<span class="n">prompts</span> <span class="o">=</span> <span class="n">load_text_data</span><span class="p">(</span>
</span><span id="activations_main-468"><a href="#activations_main-468"><span class="linenos">468</span></a>				<span class="n">Path</span><span class="p">(</span><span class="n">prompts_path</span><span class="p">),</span>
</span><span id="activations_main-469"><a href="#activations_main-469"><span class="linenos">469</span></a>				<span class="n">min_chars</span><span class="o">=</span><span class="n">min_chars</span><span class="p">,</span>
</span><span id="activations_main-470"><a href="#activations_main-470"><span class="linenos">470</span></a>				<span class="n">max_chars</span><span class="o">=</span><span class="n">max_chars</span><span class="p">,</span>
</span><span id="activations_main-471"><a href="#activations_main-471"><span class="linenos">471</span></a>				<span class="n">shuffle</span><span class="o">=</span><span class="n">shuffle</span><span class="p">,</span>
</span><span id="activations_main-472"><a href="#activations_main-472"><span class="linenos">472</span></a>			<span class="p">)</span>
</span><span id="activations_main-473"><a href="#activations_main-473"><span class="linenos">473</span></a>		<span class="k">else</span><span class="p">:</span>
</span><span id="activations_main-474"><a href="#activations_main-474"><span class="linenos">474</span></a>			<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">model_path</span> <span class="o">/</span> <span class="s2">&quot;prompts.jsonl&quot;</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span><span id="activations_main-475"><a href="#activations_main-475"><span class="linenos">475</span></a>				<span class="n">prompts</span> <span class="o">=</span> <span class="p">[</span><span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">line</span><span class="p">)</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">f</span><span class="o">.</span><span class="n">readlines</span><span class="p">()]</span>
</span><span id="activations_main-476"><a href="#activations_main-476"><span class="linenos">476</span></a>		<span class="c1"># truncate to n_samples</span>
</span><span id="activations_main-477"><a href="#activations_main-477"><span class="linenos">477</span></a>		<span class="n">prompts</span> <span class="o">=</span> <span class="n">prompts</span><span class="p">[:</span><span class="n">n_samples</span><span class="p">]</span>
</span><span id="activations_main-478"><a href="#activations_main-478"><span class="linenos">478</span></a>
</span><span id="activations_main-479"><a href="#activations_main-479"><span class="linenos">479</span></a>	<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">prompts</span><span class="p">)</span><span class="si">}</span><span class="s2"> prompts loaded&quot;</span><span class="p">)</span>
</span><span id="activations_main-480"><a href="#activations_main-480"><span class="linenos">480</span></a>
</span><span id="activations_main-481"><a href="#activations_main-481"><span class="linenos">481</span></a>	<span class="c1"># write index.html</span>
</span><span id="activations_main-482"><a href="#activations_main-482"><span class="linenos">482</span></a>	<span class="k">with</span> <span class="n">SpinnerContext</span><span class="p">(</span><span class="n">message</span><span class="o">=</span><span class="s2">&quot;writing index.html&quot;</span><span class="p">,</span> <span class="o">**</span><span class="n">SPINNER_KWARGS</span><span class="p">):</span>
</span><span id="activations_main-483"><a href="#activations_main-483"><span class="linenos">483</span></a>		<span class="k">if</span> <span class="ow">not</span> <span class="n">no_index_html</span><span class="p">:</span>
</span><span id="activations_main-484"><a href="#activations_main-484"><span class="linenos">484</span></a>			<span class="n">write_html_index</span><span class="p">(</span><span class="n">save_path_p</span><span class="p">)</span>
</span><span id="activations_main-485"><a href="#activations_main-485"><span class="linenos">485</span></a>
</span><span id="activations_main-486"><a href="#activations_main-486"><span class="linenos">486</span></a>	<span class="c1"># TODO: not implemented yet</span>
</span><span id="activations_main-487"><a href="#activations_main-487"><span class="linenos">487</span></a>	<span class="k">if</span> <span class="n">stacked_heads</span><span class="p">:</span>
</span><span id="activations_main-488"><a href="#activations_main-488"><span class="linenos">488</span></a>		<span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;stacked_heads not implemented yet&quot;</span><span class="p">)</span>
</span><span id="activations_main-489"><a href="#activations_main-489"><span class="linenos">489</span></a>
</span><span id="activations_main-490"><a href="#activations_main-490"><span class="linenos">490</span></a>	<span class="c1"># get activations</span>
</span><span id="activations_main-491"><a href="#activations_main-491"><span class="linenos">491</span></a>	<span class="nb">list</span><span class="p">(</span>
</span><span id="activations_main-492"><a href="#activations_main-492"><span class="linenos">492</span></a>		<span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span>
</span><span id="activations_main-493"><a href="#activations_main-493"><span class="linenos">493</span></a>			<span class="nb">map</span><span class="p">(</span>
</span><span id="activations_main-494"><a href="#activations_main-494"><span class="linenos">494</span></a>				<span class="n">functools</span><span class="o">.</span><span class="n">partial</span><span class="p">(</span>
</span><span id="activations_main-495"><a href="#activations_main-495"><span class="linenos">495</span></a>					<span class="n">get_activations</span><span class="p">,</span>
</span><span id="activations_main-496"><a href="#activations_main-496"><span class="linenos">496</span></a>					<span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
</span><span id="activations_main-497"><a href="#activations_main-497"><span class="linenos">497</span></a>					<span class="n">save_path</span><span class="o">=</span><span class="n">save_path_p</span><span class="p">,</span>
</span><span id="activations_main-498"><a href="#activations_main-498"><span class="linenos">498</span></a>					<span class="n">allow_disk_cache</span><span class="o">=</span><span class="ow">not</span> <span class="n">force</span><span class="p">,</span>
</span><span id="activations_main-499"><a href="#activations_main-499"><span class="linenos">499</span></a>					<span class="n">return_cache</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="activations_main-500"><a href="#activations_main-500"><span class="linenos">500</span></a>					<span class="c1"># stacked_heads=stacked_heads,</span>
</span><span id="activations_main-501"><a href="#activations_main-501"><span class="linenos">501</span></a>				<span class="p">),</span>
</span><span id="activations_main-502"><a href="#activations_main-502"><span class="linenos">502</span></a>				<span class="n">prompts</span><span class="p">,</span>
</span><span id="activations_main-503"><a href="#activations_main-503"><span class="linenos">503</span></a>			<span class="p">),</span>
</span><span id="activations_main-504"><a href="#activations_main-504"><span class="linenos">504</span></a>			<span class="n">total</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">prompts</span><span class="p">),</span>
</span><span id="activations_main-505"><a href="#activations_main-505"><span class="linenos">505</span></a>			<span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Computing activations&quot;</span><span class="p">,</span>
</span><span id="activations_main-506"><a href="#activations_main-506"><span class="linenos">506</span></a>			<span class="n">unit</span><span class="o">=</span><span class="s2">&quot;prompt&quot;</span><span class="p">,</span>
</span><span id="activations_main-507"><a href="#activations_main-507"><span class="linenos">507</span></a>		<span class="p">),</span>
</span><span id="activations_main-508"><a href="#activations_main-508"><span class="linenos">508</span></a>	<span class="p">)</span>
</span><span id="activations_main-509"><a href="#activations_main-509"><span class="linenos">509</span></a>
</span><span id="activations_main-510"><a href="#activations_main-510"><span class="linenos">510</span></a>	<span class="k">with</span> <span class="n">SpinnerContext</span><span class="p">(</span>
</span><span id="activations_main-511"><a href="#activations_main-511"><span class="linenos">511</span></a>		<span class="n">message</span><span class="o">=</span><span class="s2">&quot;updating jsonl metadata for models and prompts&quot;</span><span class="p">,</span>
</span><span id="activations_main-512"><a href="#activations_main-512"><span class="linenos">512</span></a>		<span class="o">**</span><span class="n">SPINNER_KWARGS</span><span class="p">,</span>
</span><span id="activations_main-513"><a href="#activations_main-513"><span class="linenos">513</span></a>	<span class="p">):</span>
</span><span id="activations_main-514"><a href="#activations_main-514"><span class="linenos">514</span></a>		<span class="n">generate_models_jsonl</span><span class="p">(</span><span class="n">save_path_p</span><span class="p">)</span>
</span><span id="activations_main-515"><a href="#activations_main-515"><span class="linenos">515</span></a>		<span class="n">generate_prompts_jsonl</span><span class="p">(</span><span class="n">save_path_p</span> <span class="o">/</span> <span class="n">model_name</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>main function for computing activations</p>

<h1 id="parameters">Parameters:</h1>

<ul>
<li><code>model_name : str</code>
name of a model to load with <code>HookedTransformer.from_pretrained</code></li>
<li><code>save_path : str</code>
path to save the activations to</li>
<li><code>prompts_path : str</code>
path to the prompts file</li>
<li><code>raw_prompts : bool</code>
whether the prompts are raw, not filtered by length. <code>load_text_data</code> will be called if <code>True</code>, otherwise just load the "text" field from each line in <code>prompts_path</code></li>
<li><code>min_chars : int</code>
minimum number of characters for a prompt</li>
<li><code>max_chars : int</code>
maximum number of characters for a prompt</li>
<li><code>force : bool</code>
whether to overwrite existing files</li>
<li><code>n_samples : int</code>
maximum number of samples to process</li>
<li><code>no_index_html : bool</code>
whether to write an index.html file</li>
<li><code>shuffle : bool</code>
whether to shuffle the prompts
(defaults to <code>False</code>)</li>
<li><code>stacked_heads : bool</code>
whether to stack the heads in the output tensor. will save as <code>.npy</code> instead of <code>.npz</code> if <code>True</code>
(defaults to <code>False</code>)</li>
<li><code>device : str | torch.device</code>
the device to use. if a string, will be passed to <code>torch.device</code></li>
</ul>
</div>


                </section>
                <section id="main">
                            <input id="main-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">main</span><span class="signature pdoc-code condensed">(<span class="return-annotation">) -> <span class="kc">None</span>:</span></span>

                <div class="source-button-container">
            <label class="pdoc-button view-source-button" for="main-view-source"><span>View Source</span></label>
            <div class="github-button-wrapper">
                <a class="pdoc-button github-link-button" href="https://github.com/mivanit/pattern-lens/blob/0.4.0activations.py#L517-L653" target="_blank">
                    <span>View on GitHub</span>
                </a>
            </div>
        </div>

    </div>
    <a class="headerlink" href="#main"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="main-518"><a href="#main-518"><span class="linenos">518</span></a><span class="k">def</span><span class="w"> </span><span class="nf">main</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="main-519"><a href="#main-519"><span class="linenos">519</span></a>	<span class="s2">&quot;generate attention pattern activations for a model and prompts&quot;</span>
</span><span id="main-520"><a href="#main-520"><span class="linenos">520</span></a>	<span class="nb">print</span><span class="p">(</span><span class="n">DIVIDER_S1</span><span class="p">)</span>
</span><span id="main-521"><a href="#main-521"><span class="linenos">521</span></a>	<span class="k">with</span> <span class="n">SpinnerContext</span><span class="p">(</span><span class="n">message</span><span class="o">=</span><span class="s2">&quot;parsing args&quot;</span><span class="p">,</span> <span class="o">**</span><span class="n">SPINNER_KWARGS</span><span class="p">):</span>
</span><span id="main-522"><a href="#main-522"><span class="linenos">522</span></a>		<span class="n">arg_parser</span><span class="p">:</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">()</span>
</span><span id="main-523"><a href="#main-523"><span class="linenos">523</span></a>		<span class="c1"># input and output</span>
</span><span id="main-524"><a href="#main-524"><span class="linenos">524</span></a>		<span class="n">arg_parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
</span><span id="main-525"><a href="#main-525"><span class="linenos">525</span></a>			<span class="s2">&quot;--model&quot;</span><span class="p">,</span>
</span><span id="main-526"><a href="#main-526"><span class="linenos">526</span></a>			<span class="s2">&quot;-m&quot;</span><span class="p">,</span>
</span><span id="main-527"><a href="#main-527"><span class="linenos">527</span></a>			<span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
</span><span id="main-528"><a href="#main-528"><span class="linenos">528</span></a>			<span class="n">required</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="main-529"><a href="#main-529"><span class="linenos">529</span></a>			<span class="n">help</span><span class="o">=</span><span class="s2">&quot;The model name(s) to use. comma separated with no whitespace if multiple&quot;</span><span class="p">,</span>
</span><span id="main-530"><a href="#main-530"><span class="linenos">530</span></a>		<span class="p">)</span>
</span><span id="main-531"><a href="#main-531"><span class="linenos">531</span></a>
</span><span id="main-532"><a href="#main-532"><span class="linenos">532</span></a>		<span class="n">arg_parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
</span><span id="main-533"><a href="#main-533"><span class="linenos">533</span></a>			<span class="s2">&quot;--prompts&quot;</span><span class="p">,</span>
</span><span id="main-534"><a href="#main-534"><span class="linenos">534</span></a>			<span class="s2">&quot;-p&quot;</span><span class="p">,</span>
</span><span id="main-535"><a href="#main-535"><span class="linenos">535</span></a>			<span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
</span><span id="main-536"><a href="#main-536"><span class="linenos">536</span></a>			<span class="n">required</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="main-537"><a href="#main-537"><span class="linenos">537</span></a>			<span class="n">help</span><span class="o">=</span><span class="s2">&quot;The path to the prompts file (jsonl with &#39;text&#39; key on each line). If `None`, expects that `--figures` is passed and will generate figures for all prompts in the model directory&quot;</span><span class="p">,</span>
</span><span id="main-538"><a href="#main-538"><span class="linenos">538</span></a>			<span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="main-539"><a href="#main-539"><span class="linenos">539</span></a>		<span class="p">)</span>
</span><span id="main-540"><a href="#main-540"><span class="linenos">540</span></a>
</span><span id="main-541"><a href="#main-541"><span class="linenos">541</span></a>		<span class="n">arg_parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
</span><span id="main-542"><a href="#main-542"><span class="linenos">542</span></a>			<span class="s2">&quot;--save-path&quot;</span><span class="p">,</span>
</span><span id="main-543"><a href="#main-543"><span class="linenos">543</span></a>			<span class="s2">&quot;-s&quot;</span><span class="p">,</span>
</span><span id="main-544"><a href="#main-544"><span class="linenos">544</span></a>			<span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
</span><span id="main-545"><a href="#main-545"><span class="linenos">545</span></a>			<span class="n">required</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="main-546"><a href="#main-546"><span class="linenos">546</span></a>			<span class="n">help</span><span class="o">=</span><span class="s2">&quot;The path to save the attention patterns&quot;</span><span class="p">,</span>
</span><span id="main-547"><a href="#main-547"><span class="linenos">547</span></a>			<span class="n">default</span><span class="o">=</span><span class="n">DATA_DIR</span><span class="p">,</span>
</span><span id="main-548"><a href="#main-548"><span class="linenos">548</span></a>		<span class="p">)</span>
</span><span id="main-549"><a href="#main-549"><span class="linenos">549</span></a>
</span><span id="main-550"><a href="#main-550"><span class="linenos">550</span></a>		<span class="c1"># min and max prompt lengths</span>
</span><span id="main-551"><a href="#main-551"><span class="linenos">551</span></a>		<span class="n">arg_parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
</span><span id="main-552"><a href="#main-552"><span class="linenos">552</span></a>			<span class="s2">&quot;--min-chars&quot;</span><span class="p">,</span>
</span><span id="main-553"><a href="#main-553"><span class="linenos">553</span></a>			<span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
</span><span id="main-554"><a href="#main-554"><span class="linenos">554</span></a>			<span class="n">required</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="main-555"><a href="#main-555"><span class="linenos">555</span></a>			<span class="n">help</span><span class="o">=</span><span class="s2">&quot;The minimum number of characters for a prompt&quot;</span><span class="p">,</span>
</span><span id="main-556"><a href="#main-556"><span class="linenos">556</span></a>			<span class="n">default</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
</span><span id="main-557"><a href="#main-557"><span class="linenos">557</span></a>		<span class="p">)</span>
</span><span id="main-558"><a href="#main-558"><span class="linenos">558</span></a>		<span class="n">arg_parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
</span><span id="main-559"><a href="#main-559"><span class="linenos">559</span></a>			<span class="s2">&quot;--max-chars&quot;</span><span class="p">,</span>
</span><span id="main-560"><a href="#main-560"><span class="linenos">560</span></a>			<span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
</span><span id="main-561"><a href="#main-561"><span class="linenos">561</span></a>			<span class="n">required</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="main-562"><a href="#main-562"><span class="linenos">562</span></a>			<span class="n">help</span><span class="o">=</span><span class="s2">&quot;The maximum number of characters for a prompt&quot;</span><span class="p">,</span>
</span><span id="main-563"><a href="#main-563"><span class="linenos">563</span></a>			<span class="n">default</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
</span><span id="main-564"><a href="#main-564"><span class="linenos">564</span></a>		<span class="p">)</span>
</span><span id="main-565"><a href="#main-565"><span class="linenos">565</span></a>
</span><span id="main-566"><a href="#main-566"><span class="linenos">566</span></a>		<span class="c1"># number of samples</span>
</span><span id="main-567"><a href="#main-567"><span class="linenos">567</span></a>		<span class="n">arg_parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
</span><span id="main-568"><a href="#main-568"><span class="linenos">568</span></a>			<span class="s2">&quot;--n-samples&quot;</span><span class="p">,</span>
</span><span id="main-569"><a href="#main-569"><span class="linenos">569</span></a>			<span class="s2">&quot;-n&quot;</span><span class="p">,</span>
</span><span id="main-570"><a href="#main-570"><span class="linenos">570</span></a>			<span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
</span><span id="main-571"><a href="#main-571"><span class="linenos">571</span></a>			<span class="n">required</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="main-572"><a href="#main-572"><span class="linenos">572</span></a>			<span class="n">help</span><span class="o">=</span><span class="s2">&quot;The max number of samples to process, do all in the file if None&quot;</span><span class="p">,</span>
</span><span id="main-573"><a href="#main-573"><span class="linenos">573</span></a>			<span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="main-574"><a href="#main-574"><span class="linenos">574</span></a>		<span class="p">)</span>
</span><span id="main-575"><a href="#main-575"><span class="linenos">575</span></a>
</span><span id="main-576"><a href="#main-576"><span class="linenos">576</span></a>		<span class="c1"># force overwrite</span>
</span><span id="main-577"><a href="#main-577"><span class="linenos">577</span></a>		<span class="n">arg_parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
</span><span id="main-578"><a href="#main-578"><span class="linenos">578</span></a>			<span class="s2">&quot;--force&quot;</span><span class="p">,</span>
</span><span id="main-579"><a href="#main-579"><span class="linenos">579</span></a>			<span class="s2">&quot;-f&quot;</span><span class="p">,</span>
</span><span id="main-580"><a href="#main-580"><span class="linenos">580</span></a>			<span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">,</span>
</span><span id="main-581"><a href="#main-581"><span class="linenos">581</span></a>			<span class="n">help</span><span class="o">=</span><span class="s2">&quot;If passed, will overwrite existing files&quot;</span><span class="p">,</span>
</span><span id="main-582"><a href="#main-582"><span class="linenos">582</span></a>		<span class="p">)</span>
</span><span id="main-583"><a href="#main-583"><span class="linenos">583</span></a>
</span><span id="main-584"><a href="#main-584"><span class="linenos">584</span></a>		<span class="c1"># no index html</span>
</span><span id="main-585"><a href="#main-585"><span class="linenos">585</span></a>		<span class="n">arg_parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
</span><span id="main-586"><a href="#main-586"><span class="linenos">586</span></a>			<span class="s2">&quot;--no-index-html&quot;</span><span class="p">,</span>
</span><span id="main-587"><a href="#main-587"><span class="linenos">587</span></a>			<span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">,</span>
</span><span id="main-588"><a href="#main-588"><span class="linenos">588</span></a>			<span class="n">help</span><span class="o">=</span><span class="s2">&quot;If passed, will not write an index.html file for the model&quot;</span><span class="p">,</span>
</span><span id="main-589"><a href="#main-589"><span class="linenos">589</span></a>		<span class="p">)</span>
</span><span id="main-590"><a href="#main-590"><span class="linenos">590</span></a>
</span><span id="main-591"><a href="#main-591"><span class="linenos">591</span></a>		<span class="c1"># raw prompts</span>
</span><span id="main-592"><a href="#main-592"><span class="linenos">592</span></a>		<span class="n">arg_parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
</span><span id="main-593"><a href="#main-593"><span class="linenos">593</span></a>			<span class="s2">&quot;--raw-prompts&quot;</span><span class="p">,</span>
</span><span id="main-594"><a href="#main-594"><span class="linenos">594</span></a>			<span class="s2">&quot;-r&quot;</span><span class="p">,</span>
</span><span id="main-595"><a href="#main-595"><span class="linenos">595</span></a>			<span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">,</span>
</span><span id="main-596"><a href="#main-596"><span class="linenos">596</span></a>			<span class="n">help</span><span class="o">=</span><span class="s2">&quot;pass if the prompts have not been split and tokenized (still needs keys &#39;text&#39; and &#39;meta&#39; for each item)&quot;</span><span class="p">,</span>
</span><span id="main-597"><a href="#main-597"><span class="linenos">597</span></a>		<span class="p">)</span>
</span><span id="main-598"><a href="#main-598"><span class="linenos">598</span></a>
</span><span id="main-599"><a href="#main-599"><span class="linenos">599</span></a>		<span class="c1"># shuffle</span>
</span><span id="main-600"><a href="#main-600"><span class="linenos">600</span></a>		<span class="n">arg_parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
</span><span id="main-601"><a href="#main-601"><span class="linenos">601</span></a>			<span class="s2">&quot;--shuffle&quot;</span><span class="p">,</span>
</span><span id="main-602"><a href="#main-602"><span class="linenos">602</span></a>			<span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">,</span>
</span><span id="main-603"><a href="#main-603"><span class="linenos">603</span></a>			<span class="n">help</span><span class="o">=</span><span class="s2">&quot;If passed, will shuffle the prompts&quot;</span><span class="p">,</span>
</span><span id="main-604"><a href="#main-604"><span class="linenos">604</span></a>		<span class="p">)</span>
</span><span id="main-605"><a href="#main-605"><span class="linenos">605</span></a>
</span><span id="main-606"><a href="#main-606"><span class="linenos">606</span></a>		<span class="c1"># stack heads</span>
</span><span id="main-607"><a href="#main-607"><span class="linenos">607</span></a>		<span class="n">arg_parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
</span><span id="main-608"><a href="#main-608"><span class="linenos">608</span></a>			<span class="s2">&quot;--stacked-heads&quot;</span><span class="p">,</span>
</span><span id="main-609"><a href="#main-609"><span class="linenos">609</span></a>			<span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">,</span>
</span><span id="main-610"><a href="#main-610"><span class="linenos">610</span></a>			<span class="n">help</span><span class="o">=</span><span class="s2">&quot;If passed, will stack the heads in the output tensor&quot;</span><span class="p">,</span>
</span><span id="main-611"><a href="#main-611"><span class="linenos">611</span></a>		<span class="p">)</span>
</span><span id="main-612"><a href="#main-612"><span class="linenos">612</span></a>
</span><span id="main-613"><a href="#main-613"><span class="linenos">613</span></a>		<span class="c1"># device</span>
</span><span id="main-614"><a href="#main-614"><span class="linenos">614</span></a>		<span class="n">arg_parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
</span><span id="main-615"><a href="#main-615"><span class="linenos">615</span></a>			<span class="s2">&quot;--device&quot;</span><span class="p">,</span>
</span><span id="main-616"><a href="#main-616"><span class="linenos">616</span></a>			<span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
</span><span id="main-617"><a href="#main-617"><span class="linenos">617</span></a>			<span class="n">required</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="main-618"><a href="#main-618"><span class="linenos">618</span></a>			<span class="n">help</span><span class="o">=</span><span class="s2">&quot;The device to use for the model&quot;</span><span class="p">,</span>
</span><span id="main-619"><a href="#main-619"><span class="linenos">619</span></a>			<span class="n">default</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
</span><span id="main-620"><a href="#main-620"><span class="linenos">620</span></a>		<span class="p">)</span>
</span><span id="main-621"><a href="#main-621"><span class="linenos">621</span></a>
</span><span id="main-622"><a href="#main-622"><span class="linenos">622</span></a>		<span class="n">args</span><span class="p">:</span> <span class="n">argparse</span><span class="o">.</span><span class="n">Namespace</span> <span class="o">=</span> <span class="n">arg_parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">()</span>
</span><span id="main-623"><a href="#main-623"><span class="linenos">623</span></a>
</span><span id="main-624"><a href="#main-624"><span class="linenos">624</span></a>	<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;args parsed: </span><span class="si">{</span><span class="n">args</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="main-625"><a href="#main-625"><span class="linenos">625</span></a>
</span><span id="main-626"><a href="#main-626"><span class="linenos">626</span></a>	<span class="n">models</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span>
</span><span id="main-627"><a href="#main-627"><span class="linenos">627</span></a>	<span class="k">if</span> <span class="s2">&quot;,&quot;</span> <span class="ow">in</span> <span class="n">args</span><span class="o">.</span><span class="n">model</span><span class="p">:</span>
</span><span id="main-628"><a href="#main-628"><span class="linenos">628</span></a>		<span class="n">models</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;,&quot;</span><span class="p">)</span>
</span><span id="main-629"><a href="#main-629"><span class="linenos">629</span></a>	<span class="k">else</span><span class="p">:</span>
</span><span id="main-630"><a href="#main-630"><span class="linenos">630</span></a>		<span class="n">models</span> <span class="o">=</span> <span class="p">[</span><span class="n">args</span><span class="o">.</span><span class="n">model</span><span class="p">]</span>
</span><span id="main-631"><a href="#main-631"><span class="linenos">631</span></a>
</span><span id="main-632"><a href="#main-632"><span class="linenos">632</span></a>	<span class="n">n_models</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">models</span><span class="p">)</span>
</span><span id="main-633"><a href="#main-633"><span class="linenos">633</span></a>	<span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">model</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">models</span><span class="p">):</span>
</span><span id="main-634"><a href="#main-634"><span class="linenos">634</span></a>		<span class="nb">print</span><span class="p">(</span><span class="n">DIVIDER_S2</span><span class="p">)</span>
</span><span id="main-635"><a href="#main-635"><span class="linenos">635</span></a>		<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;processing model </span><span class="si">{</span><span class="n">idx</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2"> / </span><span class="si">{</span><span class="n">n_models</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">model</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="main-636"><a href="#main-636"><span class="linenos">636</span></a>		<span class="nb">print</span><span class="p">(</span><span class="n">DIVIDER_S2</span><span class="p">)</span>
</span><span id="main-637"><a href="#main-637"><span class="linenos">637</span></a>
</span><span id="main-638"><a href="#main-638"><span class="linenos">638</span></a>		<span class="n">activations_main</span><span class="p">(</span>
</span><span id="main-639"><a href="#main-639"><span class="linenos">639</span></a>			<span class="n">model_name</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
</span><span id="main-640"><a href="#main-640"><span class="linenos">640</span></a>			<span class="n">save_path</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">save_path</span><span class="p">,</span>
</span><span id="main-641"><a href="#main-641"><span class="linenos">641</span></a>			<span class="n">prompts_path</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">prompts</span><span class="p">,</span>
</span><span id="main-642"><a href="#main-642"><span class="linenos">642</span></a>			<span class="n">raw_prompts</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">raw_prompts</span><span class="p">,</span>
</span><span id="main-643"><a href="#main-643"><span class="linenos">643</span></a>			<span class="n">min_chars</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">min_chars</span><span class="p">,</span>
</span><span id="main-644"><a href="#main-644"><span class="linenos">644</span></a>			<span class="n">max_chars</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">max_chars</span><span class="p">,</span>
</span><span id="main-645"><a href="#main-645"><span class="linenos">645</span></a>			<span class="n">force</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">force</span><span class="p">,</span>
</span><span id="main-646"><a href="#main-646"><span class="linenos">646</span></a>			<span class="n">n_samples</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">n_samples</span><span class="p">,</span>
</span><span id="main-647"><a href="#main-647"><span class="linenos">647</span></a>			<span class="n">no_index_html</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">no_index_html</span><span class="p">,</span>
</span><span id="main-648"><a href="#main-648"><span class="linenos">648</span></a>			<span class="n">shuffle</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">shuffle</span><span class="p">,</span>
</span><span id="main-649"><a href="#main-649"><span class="linenos">649</span></a>			<span class="n">stacked_heads</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">stacked_heads</span><span class="p">,</span>
</span><span id="main-650"><a href="#main-650"><span class="linenos">650</span></a>			<span class="n">device</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
</span><span id="main-651"><a href="#main-651"><span class="linenos">651</span></a>		<span class="p">)</span>
</span><span id="main-652"><a href="#main-652"><span class="linenos">652</span></a>		<span class="k">del</span> <span class="n">model</span>
</span><span id="main-653"><a href="#main-653"><span class="linenos">653</span></a>
</span><span id="main-654"><a href="#main-654"><span class="linenos">654</span></a>	<span class="nb">print</span><span class="p">(</span><span class="n">DIVIDER_S1</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>generate attention pattern activations for a model and prompts</p>
</div>


                </section>
    </main>
<script>
    function escapeHTML(html) {
        return document.createElement('div').appendChild(document.createTextNode(html)).parentNode.innerHTML;
    }

    const originalContent = document.querySelector("main.pdoc");
    let currentContent = originalContent;

    function setContent(innerHTML) {
        let elem;
        if (innerHTML) {
            elem = document.createElement("main");
            elem.classList.add("pdoc");
            elem.innerHTML = innerHTML;
        } else {
            elem = originalContent;
        }
        if (currentContent !== elem) {
            currentContent.replaceWith(elem);
            currentContent = elem;
        }
    }

    function getSearchTerm() {
        return (new URL(window.location)).searchParams.get("search");
    }

    const searchBox = document.querySelector(".pdoc input[type=search]");
    searchBox.addEventListener("input", function () {
        let url = new URL(window.location);
        if (searchBox.value.trim()) {
            url.hash = "";
            url.searchParams.set("search", searchBox.value);
        } else {
            url.searchParams.delete("search");
        }
        history.replaceState("", "", url.toString());
        onInput();
    });
    window.addEventListener("popstate", onInput);


    let search, searchErr;

    async function initialize() {
        try {
            search = await new Promise((resolve, reject) => {
                const script = document.createElement("script");
                script.type = "text/javascript";
                script.async = true;
                script.onload = () => resolve(window.pdocSearch);
                script.onerror = (e) => reject(e);
                script.src = "../search.js";
                document.getElementsByTagName("head")[0].appendChild(script);
            });
        } catch (e) {
            console.error("Cannot fetch pdoc search index");
            searchErr = "Cannot fetch search index.";
        }
        onInput();

        document.querySelector("nav.pdoc").addEventListener("click", e => {
            if (e.target.hash) {
                searchBox.value = "";
                searchBox.dispatchEvent(new Event("input"));
            }
        });
    }

    function onInput() {
        setContent((() => {
            const term = getSearchTerm();
            if (!term) {
                return null
            }
            if (searchErr) {
                return `<h3>Error: ${searchErr}</h3>`
            }
            if (!search) {
                return "<h3>Searching...</h3>"
            }

            window.scrollTo({top: 0, left: 0, behavior: 'auto'});

            const results = search(term);

            let html;
            if (results.length === 0) {
                html = `No search results for '${escapeHTML(term)}'.`
            } else {
                html = `<h4>${results.length} search result${results.length > 1 ? "s" : ""} for '${escapeHTML(term)}'.</h4>`;
            }
            for (let result of results.slice(0, 10)) {
                let doc = result.doc;
                let url = `../${doc.modulename.replaceAll(".", "/")}.html`;
                if (doc.qualname) {
                    url += `#${doc.qualname}`;
                }

                let heading;
                switch (result.doc.kind) {
                    case "function":
                        if (doc.fullname.endsWith(".__init__")) {
                            heading = `<span class="name">${doc.fullname.replace(/\.__init__$/, "")}</span>${doc.signature}`;
                        } else {
                            heading = `<span class="def">${doc.funcdef}</span> <span class="name">${doc.fullname}</span>${doc.signature}`;
                        }
                        break;
                    case "class":
                        heading = `<span class="def">class</span> <span class="name">${doc.fullname}</span>`;
                        if (doc.bases)
                            heading += `<wbr>(<span class="base">${doc.bases}</span>)`;
                        heading += `:`;
                        break;
                    case "variable":
                        heading = `<span class="name">${doc.fullname}</span>`;
                        if (doc.annotation)
                            heading += `<span class="annotation">${doc.annotation}</span>`;
                        if (doc.default_value)
                            heading += `<span class="default_value"> = ${doc.default_value}</span>`;
                        break;
                    default:
                        heading = `<span class="name">${doc.fullname}</span>`;
                        break;
                }
                html += `
                        <section class="search-result">
                        <a href="${url}" class="attr ${doc.kind}">${heading}</a>
                        <div class="docstring">${doc.doc}</div>
                        </section>
                    `;

            }
            return html;
        })());
    }

    if (getSearchTerm()) {
        initialize();
        searchBox.value = getSearchTerm();
        onInput();
    } else {
        searchBox.addEventListener("focus", initialize, {once: true});
    }

    searchBox.addEventListener("keydown", e => {
        if (["ArrowDown", "ArrowUp", "Enter"].includes(e.key)) {
            let focused = currentContent.querySelector(".search-result.focused");
            if (!focused) {
                currentContent.querySelector(".search-result").classList.add("focused");
            } else if (
                e.key === "ArrowDown"
                && focused.nextElementSibling
                && focused.nextElementSibling.classList.contains("search-result")
            ) {
                focused.classList.remove("focused");
                focused.nextElementSibling.classList.add("focused");
                focused.nextElementSibling.scrollIntoView({
                    behavior: "smooth",
                    block: "nearest",
                    inline: "nearest"
                });
            } else if (
                e.key === "ArrowUp"
                && focused.previousElementSibling
                && focused.previousElementSibling.classList.contains("search-result")
            ) {
                focused.classList.remove("focused");
                focused.previousElementSibling.classList.add("focused");
                focused.previousElementSibling.scrollIntoView({
                    behavior: "smooth",
                    block: "nearest",
                    inline: "nearest"
                });
            } else if (
                e.key === "Enter"
            ) {
                focused.querySelector("a").click();
            }
        }
    });
</script></body>
</html>