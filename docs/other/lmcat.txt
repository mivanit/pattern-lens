# Stats
- 28 files
- 6156 (6.2K) lines
- 563536 (564K) chars
- 198332 (198K) `gpt2` tokens

# File Tree

```
pattern-lens                         
├── .github                          
│   └── workflows                    
│    └── checks.yml                  [   85L   1,688C    844T]
├── data                             
│   ├── pile_5.jsonl                 [    5L  22,124C  6,858T]
│   └── pile_demo.jsonl              [   96L 343,715C 98,803T]
├── pattern_lens                     
│   ├── frontend                     
│   │   └── index.html               [1,733L  71,573C 43,359T]
│   ├── __init__.py                  [   13L     180C     83T]
│   ├── activations.py               [  657L  18,397C  7,077T]
│   ├── attn_figure_funcs.py         [  118L   3,127C  1,159T]
│   ├── consts.py                    [   37L   1,093C    354T]
│   ├── figure_util.py               [  515L  16,788C  6,213T]
│   ├── figures.py                   [  357L  10,461C  3,916T]
│   ├── indexes.py                   [  147L   4,398C  1,683T]
│   ├── load_activations.py          [  167L   4,270C  1,579T]
│   ├── prompts.py                   [   82L   1,721C    743T]
│   ├── py.typed                     [    0L       0C      0T]
│   └── server.py                    [   59L   1,372C    493T]
├── tests                            
│   ├── integration                  
│   │   ├── test_clis.py             [  158L   4,314C  1,666T]
│   │   └── test_pipeline.py         [   38L     835C    385T]
│   └── unit                         
│    ├── test_activations.py         [  170L   4,691C  1,774T]
│    ├── test_activations_return.py  [  168L   4,804C  1,820T]
│    ├── test_figure_util.py         [  291L   8,605C  3,519T]
│    ├── test_figures.py             [  157L   4,736C  1,807T]
│    ├── test_load_activations.py    [  138L   3,866C  1,389T]
│    ├── test_multifig.py            [  130L   4,851C  1,720T]
│    └── test_server.py              [   35L   1,234C    415T]
├── README.md                        [  106L   3,862C  1,295T]
├── demo.ipynb                       [  165L   4,787C  2,343T]
├── makefile                         [1,667L  50,779C 19,568T]
├── pyproject.toml                   [  223L   7,121C  3,718T]
```

# File Contents

``````{ path=".github/workflows/checks.yml"  }
name: Checks

on:
  workflow_dispatch:
  pull_request:
    branches:
      - '*'
  push:
    branches:
      - main

jobs:
  dep-check:
    name: Check dependencies
    runs-on: ubuntu-latest
    strategy:
      matrix:
        versions:
          - python: "3.11"
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0 # whole history for making version
      
      - uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.versions.python }}

      - name: set up uv
        run: curl -LsSf https://astral.sh/uv/install.sh | sh

      - name: print python version
        run: python --version

      - name: check deps
        run: make dep-check
      

  lint:
    name: Lint
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: install
        run: |
          curl -LsSf https://astral.sh/uv/install.sh | sh
          make setup

      - name: format-check
        run: make format-check

  test:
    name: Test
    runs-on: ubuntu-latest
    strategy:
      matrix:
        versions:
          - python: "3.11"
          - python: "3.12"
          - python: "3.13"
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.versions.python }}

      - name: install
        run: |
          curl -LsSf https://astral.sh/uv/install.sh | sh
          make setup

      - name: Tests
        run: make test

      - name: typing
        run: make typing
    
      - name: run demo (no server)
        run: make demo-docs
     
``````{ end_of_file=".github/workflows/checks.yml" }

``````{ path="data/pile_5.jsonl"  }
{"text": "It is done, and submitted. You can play \u201cSurvival of the Tastiest\u201d on Android, and on the web. Playing on the web works, but you have to simulate multi-touch for table moving and that can be a bit confusing.\n\nThere\u2019s a lot I\u2019d like to talk about. I\u2019ll go through every topic, insted of making the typical what went right/wrong list.\n\nConcept\n\nWorking over the theme was probably one of the hardest tasks I had to face.\n\nOriginally, I had an idea of what kind of game I wanted to develop, gameplay wise \u2013 something with lots of enemies/actors, simple graphics, maybe set in space, controlled from a top-down view. I was confident I could fit any theme around it.\n\nIn the end, the problem with a theme like \u201cEvolution\u201d in a game is that evolution is unassisted. It happens through several seemingly random mutations over time, with the most apt permutation surviving. This genetic car simulator is, in my opinion, a great example of actual evolution of a species facing a challenge. But is it a game?\n\nIn a game, you need to control something to reach an objective. That control goes against what evolution is supposed to be like. If you allow the user to pick how to evolve something, it\u2019s not evolution anymore \u2013 it\u2019s the equivalent of intelligent design, the fable invented by creationists to combat the very idea of evolution. Being agnostic and a Pastafarian, that\u2019s not something that rubbed me the right way.\n\nHence, my biggest dillema when deciding what to create was not with what I wanted to create, but with what I did not. I didn\u2019t want to create an \u201cintelligent design\u201d simulator and wrongly call it evolution.\n\nThis is a problem, of course, every other contestant also had to face. And judging by the entries submitted, not many managed to work around it. I\u2019d say the only real solution was through the use of artificial selection, somehow. So far, I haven\u2019t seen any entry using this at its core gameplay.\n\nAlas, this is just a fun competition and after a while I decided not to be as strict with the game idea, and allowed myself to pick whatever I thought would work out.\n\nMy initial idea was to create something where humanity tried to evolve to a next level but had some kind of foe trying to stop them from doing so. I kind of had this image of human souls flying in space towards a monolith or a space baby (all based in 2001: A Space Odyssey of course) but I couldn\u2019t think of compelling (read: serious) mechanics for that.\n\nBorgs were my next inspiration, as their whole hypothesis fit pretty well into the evolution theme. But how to make it work? Are you the borg, or fighting the Borg?\n\nThe third and final idea came to me through my girlfriend, who somehow gave me the idea of making something about the evolution of Pasta. The more I thought about it the more it sounded like it would work, so I decided to go with it.\n\nConversations with my inspiring co-worker Roushey (who also created the \u201cMechanical Underdogs\u201d signature logo for my intros) further matured the concept, as it involved into the idea of having individual pieces of pasta flying around and trying to evolve until they became all-powerful. A secondary idea here was that the game would work to explain how the Flying Spaghetti Monster came to exist \u2013 by evolving from a normal dinner table.\n\nSo the idea evolved more or less into this: you are sitting a table. You have your own plate, with is your \u201cbase\u201d. There are 5 other guests at the table, each with their own plate.\n\nYour plate can spawn little pieces of pasta. You do so by \u201cordering\u201d them through a menu. Some pastas are better than others; some are faster, some are stronger. They have varying costs, which are debited from your credits (you start with a number of credits).\n\nOnce spawned, your pastas start flying around. Their instinct is to fly to other plates, in order to conquer them (the objective of the game is having your pasta conquer all the plates on the table). But they are really autonomous, so after being spawned, you have no control over your pasta (think DotA or LoL creeps).\n\nYour pasta doesn\u2019t like other people\u2019s pasta, so if they meet, they shoot sauce at each other until one dies. You get credits for other pastas your own pasta kill.\n\nOnce a pasta is in the vicinity of a plate, it starts conquering it for its team. It takes around 10 seconds for a plate to be conquered; less if more pasta from the same team are around. If pasta from other team are around, though, they get locked down in their attempt, unable to conquer the plate, until one of them die (think Battlefield\u2019s standard \u201cConquest\u201d mode).\n\nYou get points every second for every plate you own.\n\nOver time, the concept also evolved to use an Italian bistro as its main scenario.\n\nCarlos, Carlos\u2019 Bistro\u2019s founder and owner\n\nSetup\n\nNo major changes were made from my work setup. I used FDT and Starling creating an Adobe AIR (ActionScript) project, all tools or frameworks I already had some knowledge with.\n\nOne big change for me was that I livestreamed my work through a twitch.tv account. This was a new thing for me. As recommended by Roushey, I used a program called XSplit and I got to say, it is pretty amazing. It made the livestream pretty effortless and the features are awesome, even for the free version. It was great to have some of my friends watch me, and then interact with them and random people through chat. It was also good knowing that I was also recording a local version of the files, so I could make a timelapse video later.\n\nKnowing the video was being recorded also made me a lot more self-conscious about my computer use, as if someone was watching over my shoulder. It made me realize that sometimes I spend too much time in seemingly inane tasks (I ended up wasting the longest time just to get some text alignment the way I wanted \u2013 it\u2019ll probably drive someone crazy if they watch it) and that I do way too many typos where writing code. I pretty much spend half of the time writing a line and the other half fixing the crazy characters in it.\n\nMy own stream was probably boring to watch since I was coding for the most time. But livestreaming is one of the cool things to do as a spectator too. It was great seeing other people working \u2013 I had a few tabs opened on my second monitor all the time. It\u2019s actually a bit sad, because if I could, I could have spent the whole weekend just watching other people working! But I had to do my own work, so I\u2019d only do it once in a while, when resting for a bit.\n\nDesign\n\nAlthough I wanted some simple, low-fi, high-contrast kind of design, I ended up going with somewhat realistic (vector) art. I think it worked very well, fitting the mood of the game, but I also went overboard.\n\nFor example: to know the state of a plate (who owns it, who\u2019s conquering it and how much time they have left before conquering it, which pasta units are in the queue, etc), you have to look at the plate\u2019s bill.\n\nThe problem I realized when doing some tests is that people never look at the bill! They think it\u2019s some kind of prop, so they never actually read its details.\n\nPlus, if you\u2019re zoomed out too much, you can\u2019t actually read it, so it\u2019s hard to know what\u2019s going on with the game until you zoom in to the area of a specific plate.\n\nOne other solution that didn\u2019t turn out to be as perfect as I thought was how to indicate who a plate base belongs to. In the game, that\u2019s indicated by the plate\u2019s decoration \u2013 its color denotes the team owner. But it\u2019s something that fits so well into the design that people never realized it, until they were told about it.\n\nIn the end, the idea of going with a full physical metaphor is one that should be done with care. Things that are very important risk becoming background noise, unless the player knows its importance.\n\nOriginally, I wanted to avoid any kind of heads-up display in my game. In the end, I ended up adding it at the bottom to indicate your credits and bases owned, as well as the hideous out-of-place-and-still-not-obvious \u201cCall Waiter\u201d button. But in hindsight, I should have gone with a simple HUD from the start, especially one that indicated each team\u2019s colors and general state of the game without the need for zooming in and out.\n\nDevelopment\n\nDevelopment went fast. But not fast enough.\n\nEven though I worked around 32+ hours for this Ludum Dare, the biggest problem I had to face in the end was overscoping. I had too much planned, and couldn\u2019t get it all done.\n\nContent-wise, I had several kinds of pasta planned (Wikipedia is just amazing in that regard), split into several different groups, from small Pastina to huge Pasta al forno. But because of time constraints, I ended up scratching most of them, and ended up with 5 different types of very small pasta \u2013 barely something to start when talking about the evolution of Pasta.\n\nPastas used in the game. Unfortunately, the macs where never used\n\nWhich is one of the saddest things about the project, really. It had the framework and the features to allow an endless number of elements in there, but I just didn\u2019t have time to draw the rest of the assets needed (something I loved to do, by the way).\n\nOther non-obvious features had to be dropped, too. For example, when ordering some pasta, you were supposed to select what kind of sauce you\u2019d like with your pasta, each with different attributes. Bolognese, for example, is very strong, but inaccurate; Pesto is very accurate and has great range, but it\u2019s weaker; and my favorite, Vodka, would triggers 10% loss of speed on the pasta hit by it.\n\nThe code for that is mostly in there. But in the end, I didn\u2019t have time to implement the sauce selection interface; all pasta ended up using bolognese sauce.\n\nTo-do list: lots of things were not done\n\nActual programming also took a toll in the development time. Having been programming for a while, I like to believe I got to a point where I know how to make things right, but at the expense of forgetting how to do things wrong in a seemingly good way. What I mean is that I had to take a lot of shortcuts in my code to save time (e.g. a lot of singletons references for cross-communication rather than events or observers, all-encompassing check loops, not fast enough) that left a very sour taste in my mouth. While I know I used to do those a few years ago and survive, I almost cannot accept the state my code is in right now.\n\nAt the same time, I do know it was the right thing to do given the timeframe.\n\nOne small thing that had some impact was using a somewhat new platform for me. That\u2019s Starling, the accelerated graphics framework I used in Flash. I had tested it before and I knew how to use it well \u2013 the API is very similar to Flash itself. However, there were some small details that had some impact during development, making me feel somewhat uneasy the whole time I was writing the game. It was, again, the right thing to do, but I should have used Starling more deeply before (which is the conundrum: I used it for Ludum Dare just so I could learn more about it).\n\nArgument and user experience\n\nOne final aspect of the game that I learned is that making the game obvious for your players goes a long way into making it fun. If you have to spend the longest time explaining things, your game is doing something wrong.\n\nAnd that\u2019s exactly the problem Survival of the Tastiest ultimately faced. It\u2019s very hard for people to understand what\u2019s going on with the game, why, and how. I did have some introductory text at the beginning, but that was a last-minute thing. More importantly, I should have had a better interface or simplified the whole concept so it would be easier for people to understand.\n\nThat doesn\u2019t mean the game itself should be simple. It just means that the experience and interface should be approachable and understandable.\n\nConclusion\n\nI\u2019m extremely happy with what I\u2019ve done and, especially given that this was my first Ludum Dare. However, I feel like I\u2019ve learned a lot of what not to do.\n\nThe biggest problem is overscoping. Like Eric Decker said, the biggest lesson we can learn with this is probably with scoping \u2013 deciding what to do beforehand in a way you can complete it without having to rush and do something half-assed.\n\nI\u2019m sure I will do more Ludum Dares in the future. But if there are any lessons I can take of it, they are to make it simple, to use frameworks and platforms you already have some absolute experience with (otherwise you\u2019ll spend too much time trying to solve easy questions), and to scope for a game that you can complete in one day only (that way, you can actually take two days and make it cool).\n\nThis entry was posted\non Monday, August 27th, 2012 at 10:54 am and is filed under LD #24.\nYou can follow any responses to this entry through the RSS 2.0 feed.\nYou can skip to the end and leave a response. Pinging is currently not allowed.\n\n3 Responses to \u201c\u201cSurvival of the Tastiest\u201d Post-mortem\u201d\n\ndarn it , knowing that I missed your livestream makes me a sad panda ;( but more to the point, the game is \u2026 well for a startup its original to say the least ;D it has some really neat ideas and more importantly its designed arround touch screens whitch by the looks of the submission is something rare ;o or that could be just me and my short memory -_-! awesum game, love et <3", "meta": {"pile_set_name": "Pile-CC"}}
{"text": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\r\n<segment>\r\n    <name>PD1</name>\r\n    <description>Patient Additional Demographic</description>\r\n    <elements>\r\n        <field minOccurs=\"0\" maxOccurs=\"0\">\r\n            <name>PD1.1</name>\r\n            <description>Living Dependency</description>\r\n            <datatype>IS</datatype>\r\n        </field>\r\n        <field minOccurs=\"0\" maxOccurs=\"0\">\r\n            <name>PD1.2</name>\r\n            <description>Living Arrangement</description>\r\n            <datatype>IS</datatype>\r\n        </field>\r\n        <field minOccurs=\"0\" maxOccurs=\"0\">\r\n            <name>PD1.3</name>\r\n            <description>Patient Primary Facility</description>\r\n            <datatype>XON</datatype>\r\n        </field>\r\n        <field minOccurs=\"0\" maxOccurs=\"0\">\r\n            <name>PD1.4</name>\r\n            <description>Patient Primary Care Provider Name &amp; ID No.</description>\r\n            <datatype>XCN</datatype>\r\n        </field>\r\n        <field minOccurs=\"0\" maxOccurs=\"0\">\r\n            <name>PD1.5</name>\r\n            <description>Student Indicator</description>\r\n            <datatype>IS</datatype>\r\n        </field>\r\n        <field minOccurs=\"0\" maxOccurs=\"0\">\r\n            <name>PD1.6</name>\r\n            <description>Handicap</description>\r\n            <datatype>IS</datatype>\r\n        </field>\r\n        <field minOccurs=\"0\" maxOccurs=\"0\">\r\n            <name>PD1.7</name>\r\n            <description>Living Will Code</description>\r\n            <datatype>IS</datatype>\r\n        </field>\r\n        <field minOccurs=\"0\" maxOccurs=\"0\">\r\n            <name>PD1.8</name>\r\n            <description>Organ Donor Code</description>\r\n            <datatype>IS</datatype>\r\n        </field>\r\n        <field minOccurs=\"0\" maxOccurs=\"0\">\r\n            <name>PD1.9</name>\r\n            <description>Separate Bill</description>\r\n            <datatype>ID</datatype>\r\n        </field>\r\n        <field minOccurs=\"0\" maxOccurs=\"0\">\r\n            <name>PD1.10</name>\r\n            <description>Duplicate Patient</description>\r\n            <datatype>CX</datatype>\r\n        </field>\r\n        <field minOccurs=\"0\" maxOccurs=\"0\">\r\n            <name>PD1.11</name>\r\n            <description>Publicity Code</description>\r\n            <datatype>CE</datatype>\r\n        </field>\r\n        <field minOccurs=\"0\" maxOccurs=\"0\">\r\n            <name>PD1.12</name>\r\n            <description>Protection Indicator</description>\r\n            <datatype>ID</datatype>\r\n        </field>\r\n        <field minOccurs=\"0\" maxOccurs=\"0\">\r\n            <name>PD1.13</name>\r\n            <description>Protection Indicator Effective Date</description>\r\n            <datatype>DT</datatype>\r\n        </field>\r\n        <field minOccurs=\"0\" maxOccurs=\"0\">\r\n            <name>PD1.14</name>\r\n            <description>Place of Worship</description>\r\n            <datatype>XON</datatype>\r\n        </field>\r\n        <field minOccurs=\"0\" maxOccurs=\"0\">\r\n            <name>PD1.15</name>\r\n            <description>Advance Directive Code</description>\r\n            <datatype>CE</datatype>\r\n        </field>\r\n        <field minOccurs=\"0\" maxOccurs=\"0\">\r\n            <name>PD1.16</name>\r\n            <description>Immunization Registry Status</description>\r\n            <datatype>IS</datatype>\r\n        </field>\r\n        <field minOccurs=\"0\" maxOccurs=\"0\">\r\n            <name>PD1.17</name>\r\n            <description>Immunization Registry Status Effective Date</description>\r\n            <datatype>DT</datatype>\r\n        </field>\r\n        <field minOccurs=\"0\" maxOccurs=\"0\">\r\n            <name>PD1.18</name>\r\n            <description>Publicity Code Effective Date</description>\r\n            <datatype>DT</datatype>\r\n        </field>\r\n        <field minOccurs=\"0\" maxOccurs=\"0\">\r\n            <name>PD1.19</name>\r\n            <description>Military Branch</description>\r\n            <datatype>IS</datatype>\r\n        </field>\r\n        <field minOccurs=\"0\" maxOccurs=\"0\">\r\n            <name>PD1.20</name>\r\n            <description>Military Rank/Grade</description>\r\n            <datatype>IS</datatype>\r\n        </field>\r\n        <field minOccurs=\"0\" maxOccurs=\"0\">\r\n            <name>PD1.21</name>\r\n            <description>Military Status</description>\r\n            <datatype>IS</datatype>\r\n        </field>\r\n    </elements>\r\n</segment>\r\n", "meta": {"pile_set_name": "Github"}}
{"text": "Article content\n\nHuman behavior has a tremendous impact on investing \u2014 more so than most realize \u2014 and one of our biggest weaknesses is the tendency to constantly compare and contrast ourselves to others.\n\n[np_storybar title=\u201dFollow Financial Post\u201d link=\u201d\u201d]\n\nWe apologize, but this video has failed to load.\n\ntap here to see other videos from our team. Try refreshing your browser, or Three signs bubbles are brewing again in the market \u2014 and one of them has wheels Back to video\n\n\u2022 Twitter\n\n\u2022 Facebook\n\n[/np_storybar]\n\nFor example, a 1995 study by the Harvard School of Public Health indicated that people will forgo a stronger income scenario in favour of a weaker one as long as it meant earning more than their neighbours.\n\nUnfortunately, many in the investment world are keenly aware of this and will structure their marketing efforts accordingly. As a result, you have a compounding of momentum or trends in the market as investors buy at or near market tops for fear of not doing as well as or better than others.\n\nFor the same reason, investors piled into technology stocks in 2000 with only the promise of earnings in some distant future, and into housing-related investments in 2007 that were backstopped by very low incomes.", "meta": {"pile_set_name": "OpenWebText2"}}
{"text": "Topic: reinvent midnight madness\n\nAmazon announced a new service at the AWS re:Invent Midnight Madness event. Amazon Sumerian is a solution that aims to make it easier for developers to build virtual reality, augmented reality, and 3D applications. It features a user friendly editor, which can be used to drag and drop 3D objects and characters into scenes. Amazon \u2026 continue reading", "meta": {"pile_set_name": "Pile-CC"}}
{"text": "About Grand Slam Fishing Charters\n\nAs a family owned business we know how important it is that your trip becomes the best memory of your vacation, we are proud of our islands, our waters and our crew and we are desperate show you the best possible time during your stay. We can not guarantee fish every time but we can guarantee you a great time! The biggest perk of our job is seeing so many of our customers become close friends\u201d\n\nA Great Way To Make New Friends!\n\nOur dockside parties are a great way to make new friends! Everyone is welcome!\n\nAndrea runs the whole operation, from discussing your initial needs by phone or email through to ensuring you have sufficient potato chips. Andrea has worked as concierge for many International resorts and fully understands the high expectations of international visitors.\n\n\u201cLife\u2019s A Game But Fishing Is Serious!\u201d\n\nUnlike many tour operators, our crew are highly valued and have been with us since day 1. Each have their own personalities and sense of humour and understand the importance of making your day perfect, for us the saying is true, \u201cLifes a game but fishing is serious!\u201d\n\nTRIP ADVISOR\n\nPlan Your Trip!\n\nAJ and Earl were excellent. My son and I did a half day deep sea trip and though the fish weren\u2019t too cooperative, they did everything to try to get something to bite. Very knowledgeable about the waters and my son was able to land a nice barracuda. The next day my wife, daughter, son [\u2026]\n\nWhen we arrived the crew made us feel right at home. They made us feel comfortable and answered all questions. The crew worked hard all day to put us on fish. We were successful in landing a nice size Wahoo even though the weather did not cooperate the entire day was enjoyable. I highly recommend [\u2026]", "meta": {"pile_set_name": "Pile-CC"}}
``````{ end_of_file="data/pile_5.jsonl" }

``````{ path="data/pile_demo.jsonl"  }
{"text": "Sen. Bernie Sanders (I-VT) will clinch victory in the first-in-the-nation primary in New Hampshire, according to a CNN projection, powered by his strength among blue-collar, younger and more liberal voters.", "meta": {"pile_set_name": "OpenWebText2"}}
{"text": "{\n  \"fpsLimit\": 60,\n  \"preset\": \"basic\",\n  \"background\": {\n    \"color\": \"#0d47a1\",\n    \"image\": \"\",\n    \"position\": \"50% 50%\",\n    \"repeat\": \"no-repeat\",\n    \"size\": \"cover\"\n  }\n}", "meta": {"pile_set_name": "Github"}}
{"text": "Q:\n\nUsing M-Test to show you can differentiate term by term.\n\nI have the series $\\sum_{n=1}^\\infty \\frac{\\lambda^{n-1}n}{n!}=\\sum_{n=1}^\\infty \\frac{d}{d\\lambda}\\big(\\frac{\\lambda^n}{n!} \\big)$\nand I would like it to be $\\frac{d}{d\\lambda}\\big(\\sum_{n=1}^\\infty \\frac{\\lambda^n}{n!})$.\nI'm trying to show that this sequence of functions converges uniformly on $(0,\\infty)$ and so I'm trying the M-Test.  So I need to find bounds $M_n$ for $\\big|\\frac{\\lambda^n}{n!}\\big|$, such that $\\sum M_n$ converges.\nThanks.  This is in order to show that I can actually do the differentiation term by term.\n\nA:\n\nYou deal with a power series with radius of convergence $R=+\\infty$ so you can differentiate term by term.\n\n", "meta": {"pile_set_name": "StackExchange"}}
{"text": "2017 XIXO Ladies Open H\u00f3dmez\u0151v\u00e1s\u00e1rhely \u2013 Doubles\n\nLaura Pigossi and Nadia Podoroska were the defending champions, but both players chose not to participate.\n\nKotomi Takahata and Prarthana Thombare won the title after Ulrikke Eikeri and Tereza Mrde\u017ea retired in the final at 1\u20130.\n\nSeeds\n\nDraw\n\nReferences\nMain Draw\n\nXIXO Ladies Open H\u00f3dmez\u0151v\u00e1s\u00e1rhely - Doubles", "meta": {"pile_set_name": "Wikipedia (en)"}}
{"text": "Following the airport shooting, Steube doubled down on his view that license holders ought to bring guns into venues like airports, claiming that gun-free zones are more likely to be targeted by shooters. In fact, most major airports are not gun-free zones, as they have armed and unarmed security personnel. In addition, several studies show the vast majority of mass shootings do not occur in gun-free zones. In his book, \"Rampage Nation,\" Louis Klarevas of the University of Massachusetts found that 93 of 111 mass shootings from 1966 to 2015 occurred in zones in which guns were not prohibited.", "meta": {"pile_set_name": "OpenWebText2"}}
{"text": "Jeanette Sawyer Cohen, PhD, clinical assistant professor of psychology in pediatrics at Weill Cornell Medical College in New York City\n\nPediatric Psychologist\n\nHow to Teach Independence?\n\nHow can I teach my toddler to do things independently?\n\nYou\u2019ve probably become more patient since you started this whole parenthood thing. And you\u2019re going to have to practice patience even more as your toddler learns to become more independent.\n\nFor example, she tells you she can\u2019t finish the puzzle she\u2019s doing. Instead of jumping right in and telling her which piece goes where, you\u2019re going to have to tell her you\u2019ll help a little. Go ahead and help, but let her do a lot of it herself, and make sure she\u2019s the one to finish the job. That will give her a sense of accomplishment and the confidence to try again next time.\n\nRemember that children each progress at their own rate. It\u2019s not always fast \u2014 and there will be setbacks along the way. But the more you can allow them to do on their own without stepping in, the more they\u2019ll be likely to try for themselves again and again.", "meta": {"pile_set_name": "Pile-CC"}}
{"text": "Q:\n\nWhat's the simplest way to pass a file as an argument in a simple shell script?\n\nThe following works fine on Mac OS X:\n#!/bin/bash\nR CMD Sweave myfile.Rnw\npdflatex myfile.tex\nopen myfile.pdf\n\nNow, I realize that these 3 lines of code are really helpful for my work \u2013 independently of some particular file. Thus I'd like to use the file as an argument. I know how to use an argument itself but have problems splitting the input after the string and concat it afterwards. If I was able to split the filename argument like: \nsplit($1,\".\") # return some array or list (\"name\",\"ext\")\n\nOr is there a simpler, completely different way than using Python within a shell script?\nThx in advance for any general advice and examples as well !\n\nA:\n\nI do all my shell scripting in python.\nIt's easier to read, more powerful and works on windows as well.\n\nA:\n\nYou could just take the base name as an argument and use $1.Rnw, $1.tex, and $1.pdf. Python is great for shell scripts, but I usually stick with bash for things less than 10 lines long.\nIf you really want to take a file name, you can use cut -f 1 -d '.' $1.\n\n", "meta": {"pile_set_name": "StackExchange"}}
{"text": "Inorganic phosphate uptake in intact vacuoles isolated from suspension-cultured cells of Catharanthus roseus (L.) G. Don under varying Pi status.\nInorganic phosphate (Pi) uptake across the vacuolar membrane of intact vacuoles isolated from Catharanthus roseus suspension-cultured cells was measured. Under low Pi status, Pi uptake into the vacuole was strongly activated compared to high Pi status. Since Pi uptake across the vacuolar membrane is correlated with H+ pumping, we examined the dependency of H+ pumping on plant Pi status. Both H+ pumping and the activities of the vacuolar H+-pumps, the V-type H+-ATPase and the H+-PPase were enhanced under low Pi status. Despite this increase in H+ pumping, Western blot analysis showed no distinct increase in the amount of proton pump proteins. Possible mechanisms for the activation of Pi uptake into the vacuole under low Pi status are discussed.", "meta": {"pile_set_name": "PubMed Abstracts"}}
{"text": "Topic: reinvent midnight madness\n\nAmazon announced a new service at the AWS re:Invent Midnight Madness event. Amazon Sumerian is a solution that aims to make it easier for developers to build virtual reality, augmented reality, and 3D applications. It features a user friendly editor, which can be used to drag and drop 3D objects and characters into scenes. Amazon \u2026 continue reading", "meta": {"pile_set_name": "Pile-CC"}}
{"text": "Article content\n\nHuman behavior has a tremendous impact on investing \u2014 more so than most realize \u2014 and one of our biggest weaknesses is the tendency to constantly compare and contrast ourselves to others.\n\n[np_storybar title=\u201dFollow Financial Post\u201d link=\u201d\u201d]\n\nWe apologize, but this video has failed to load.\n\ntap here to see other videos from our team. Try refreshing your browser, or Three signs bubbles are brewing again in the market \u2014 and one of them has wheels Back to video\n\n\u2022 Twitter\n\n\u2022 Facebook\n\n[/np_storybar]\n\nFor example, a 1995 study by the Harvard School of Public Health indicated that people will forgo a stronger income scenario in favour of a weaker one as long as it meant earning more than their neighbours.\n\nUnfortunately, many in the investment world are keenly aware of this and will structure their marketing efforts accordingly. As a result, you have a compounding of momentum or trends in the market as investors buy at or near market tops for fear of not doing as well as or better than others.\n\nFor the same reason, investors piled into technology stocks in 2000 with only the promise of earnings in some distant future, and into housing-related investments in 2007 that were backstopped by very low incomes.", "meta": {"pile_set_name": "OpenWebText2"}}
{"text": "Q:\n\nTextView Not centered in app but centered in match_constraint\n\nI've created a simple activity design using ConstraintLayout.\nWhenever I try to center a textView, it does it correctly in the blueprints but never does it in the actual app. Not sure if i am doing something wrong or I'm losing my mind.\nHere is the image\nHere is the XML code\n<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<android.support.constraint.ConstraintLayout \nxmlns:android=\"http://schemas.android.com/apk/res/android\"\nxmlns:app=\"http://schemas.android.com/apk/res-auto\"\nxmlns:tools=\"http://schemas.android.com/tools\"\nandroid:layout_width=\"match_parent\"\nandroid:layout_height=\"match_parent\"\nandroid:background=\"@color/background_green\"\ntools:context=\"nz.co.listcosolutions.StartActivity\">\n\n<ImageView\n    android:id=\"@+id/imageView4\"\n    android:layout_width=\"160dp\"\n    android:layout_height=\"163dp\"\n    android:layout_marginEnd=\"95dp\"\n    android:layout_marginStart=\"95dp\"\n    android:layout_marginTop=\"32dp\"\n    app:layout_constraintEnd_toEndOf=\"parent\"\n    app:layout_constraintStart_toStartOf=\"parent\"\n    app:layout_constraintTop_toTopOf=\"parent\"\n    app:srcCompat=\"@drawable/baby_plant\" />\n\n<Button\n    android:id=\"@+id/btnNext\"\n    android:layout_width=\"wrap_content\"\n    android:layout_height=\"wrap_content\"\n    android:layout_marginEnd=\"32dp\"\n    android:layout_marginStart=\"32dp\"\n    android:layout_marginTop=\"64dp\"\n    android:text=\"@string/next\"\n    android:textColor=\"@color/background_green\"\n    android:textSize=\"18sp\"\n    app:layout_constraintEnd_toEndOf=\"parent\"\n    app:layout_constraintStart_toStartOf=\"parent\"\n    app:layout_constraintTop_toBottomOf=\"@+id/textView3\" />\n\n<TextView\n    android:id=\"@+id/textView3\"\n    android:layout_width=\"0dp\"\n    android:layout_height=\"wrap_content\"\n    android:layout_marginEnd=\"8dp\"\n    android:layout_marginStart=\"8dp\"\n    android:layout_marginTop=\"20dp\"\n    android:text=\"Welcome to My App\"\n    android:textAlignment=\"center\"\n    android:textColor=\"@android:color/white\"\n    android:textSize=\"24sp\"\n    app:layout_constraintEnd_toEndOf=\"parent\"\n    app:layout_constraintStart_toStartOf=\"parent\"\n    app:layout_constraintTop_toBottomOf=\"@+id/imageView4\" />\n\n</android.support.constraint.ConstraintLayout>\n\nIm also using the latest version of ConstraintLayout\ncompile 'com.android.support.constraint:constraint-layout:1.0.2'\n\nA:\n\nYou need to add:\n\nandroid:gravity=\"center\"\n\nto the TextView.\nThis is the only certain way to center the text inside a TextView object or one of its subclasses.\nThe android:textAlignment is not working in all the cases and as reported by this answer that it has problems in lower API levels. \n\n", "meta": {"pile_set_name": "StackExchange"}}
{"text": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\r\n<segment>\r\n    <name>PD1</name>\r\n    <description>Patient Additional Demographic</description>\r\n    <elements>\r\n        <field minOccurs=\"0\" maxOccurs=\"0\">\r\n            <name>PD1.1</name>\r\n            <description>Living Dependency</description>\r\n            <datatype>IS</datatype>\r\n        </field>\r\n        <field minOccurs=\"0\" maxOccurs=\"0\">\r\n            <name>PD1.2</name>\r\n            <description>Living Arrangement</description>\r\n            <datatype>IS</datatype>\r\n        </field>\r\n        <field minOccurs=\"0\" maxOccurs=\"0\">\r\n            <name>PD1.3</name>\r\n            <description>Patient Primary Facility</description>\r\n            <datatype>XON</datatype>\r\n        </field>\r\n        <field minOccurs=\"0\" maxOccurs=\"0\">\r\n            <name>PD1.4</name>\r\n            <description>Patient Primary Care Provider Name &amp; ID No.</description>\r\n            <datatype>XCN</datatype>\r\n        </field>\r\n        <field minOccurs=\"0\" maxOccurs=\"0\">\r\n            <name>PD1.5</name>\r\n            <description>Student Indicator</description>\r\n            <datatype>IS</datatype>\r\n        </field>\r\n        <field minOccurs=\"0\" maxOccurs=\"0\">\r\n            <name>PD1.6</name>\r\n            <description>Handicap</description>\r\n            <datatype>IS</datatype>\r\n        </field>\r\n        <field minOccurs=\"0\" maxOccurs=\"0\">\r\n            <name>PD1.7</name>\r\n            <description>Living Will Code</description>\r\n            <datatype>IS</datatype>\r\n        </field>\r\n        <field minOccurs=\"0\" maxOccurs=\"0\">\r\n            <name>PD1.8</name>\r\n            <description>Organ Donor Code</description>\r\n            <datatype>IS</datatype>\r\n        </field>\r\n        <field minOccurs=\"0\" maxOccurs=\"0\">\r\n            <name>PD1.9</name>\r\n            <description>Separate Bill</description>\r\n            <datatype>ID</datatype>\r\n        </field>\r\n        <field minOccurs=\"0\" maxOccurs=\"0\">\r\n            <name>PD1.10</name>\r\n            <description>Duplicate Patient</description>\r\n            <datatype>CX</datatype>\r\n        </field>\r\n        <field minOccurs=\"0\" maxOccurs=\"0\">\r\n            <name>PD1.11</name>\r\n            <description>Publicity Code</description>\r\n            <datatype>CE</datatype>\r\n        </field>\r\n        <field minOccurs=\"0\" maxOccurs=\"0\">\r\n            <name>PD1.12</name>\r\n            <description>Protection Indicator</description>\r\n            <datatype>ID</datatype>\r\n        </field>\r\n        <field minOccurs=\"0\" maxOccurs=\"0\">\r\n            <name>PD1.13</name>\r\n            <description>Protection Indicator Effective Date</description>\r\n            <datatype>DT</datatype>\r\n        </field>\r\n        <field minOccurs=\"0\" maxOccurs=\"0\">\r\n            <name>PD1.14</name>\r\n            <description>Place of Worship</description>\r\n            <datatype>XON</datatype>\r\n        </field>\r\n        <field minOccurs=\"0\" maxOccurs=\"0\">\r\n            <name>PD1.15</name>\r\n            <description>Advance Directive Code</description>\r\n            <datatype>CE</datatype>\r\n        </field>\r\n        <field minOccurs=\"0\" maxOccurs=\"0\">\r\n            <name>PD1.16</name>\r\n            <description>Immunization Registry Status</description>\r\n            <datatype>IS</datatype>\r\n        </field>\r\n        <field minOccurs=\"0\" maxOccurs=\"0\">\r\n            <name>PD1.17</name>\r\n            <description>Immunization Registry Status Effective Date</description>\r\n            <datatype>DT</datatype>\r\n        </field>\r\n        <field minOccurs=\"0\" maxOccurs=\"0\">\r\n            <name>PD1.18</name>\r\n            <description>Publicity Code Effective Date</description>\r\n            <datatype>DT</datatype>\r\n        </field>\r\n        <field minOccurs=\"0\" maxOccurs=\"0\">\r\n            <name>PD1.19</name>\r\n            <description>Military Branch</description>\r\n            <datatype>IS</datatype>\r\n        </field>\r\n        <field minOccurs=\"0\" maxOccurs=\"0\">\r\n            <name>PD1.20</name>\r\n            <description>Military Rank/Grade</description>\r\n            <datatype>IS</datatype>\r\n        </field>\r\n        <field minOccurs=\"0\" maxOccurs=\"0\">\r\n            <name>PD1.21</name>\r\n            <description>Military Status</description>\r\n            <datatype>IS</datatype>\r\n        </field>\r\n    </elements>\r\n</segment>\r\n", "meta": {"pile_set_name": "Github"}}
{"text": "About Grand Slam Fishing Charters\n\nAs a family owned business we know how important it is that your trip becomes the best memory of your vacation, we are proud of our islands, our waters and our crew and we are desperate show you the best possible time during your stay. We can not guarantee fish every time but we can guarantee you a great time! The biggest perk of our job is seeing so many of our customers become close friends\u201d\n\nA Great Way To Make New Friends!\n\nOur dockside parties are a great way to make new friends! Everyone is welcome!\n\nAndrea runs the whole operation, from discussing your initial needs by phone or email through to ensuring you have sufficient potato chips. Andrea has worked as concierge for many International resorts and fully understands the high expectations of international visitors.\n\n\u201cLife\u2019s A Game But Fishing Is Serious!\u201d\n\nUnlike many tour operators, our crew are highly valued and have been with us since day 1. Each have their own personalities and sense of humour and understand the importance of making your day perfect, for us the saying is true, \u201cLifes a game but fishing is serious!\u201d\n\nTRIP ADVISOR\n\nPlan Your Trip!\n\nAJ and Earl were excellent. My son and I did a half day deep sea trip and though the fish weren\u2019t too cooperative, they did everything to try to get something to bite. Very knowledgeable about the waters and my son was able to land a nice barracuda. The next day my wife, daughter, son [\u2026]\n\nWhen we arrived the crew made us feel right at home. They made us feel comfortable and answered all questions. The crew worked hard all day to put us on fish. We were successful in landing a nice size Wahoo even though the weather did not cooperate the entire day was enjoyable. I highly recommend [\u2026]", "meta": {"pile_set_name": "Pile-CC"}}
{"text": "Q:\n\nWhy was Mundungus banned from the Hog's Head?\n\nIn Order of the Phoenix while the trio were in the Hogs Head for the first time plotting the start of Dumbledore's Army, it transpires that ol' Dung was lurking in the pub in a disguise, having been banned 20 years previously according to Sirius. \nFirstly, why was he banned? this could possibly be the tight spot that Albus had helped Dung with in the first place that made him loyal to Albus.  \nAnd secondly, how is it that he is then speaking to Aberforth in Halfblood Prince? (assuming the ban was for something rather unforgivable, 20 years is a long time?) \nThey both could have been in the Order by then, but unlikely given Aberforth's attitude in Deathly Hallows once the trio arrive in Hogsmeade looking for the tiara.  We learn now that a lot of trafficking goes on through the Hogs Head so maybe Dung was trading with Aberforth, Sirius' mirror and various other Black artifacts, he just was not allowed in the pub. \nAnyone with something in canon or more plausible?\n\nA:\n\nwhy was he banned?\nI'm not able to find any canon data on that, either book text search or interviews transcripts.\n\nhow is it that he is then speaking to Aberforth in Halfblood Prince?\nIn HBP, he's speaking to Aberforth, NOT being inside Hog's Head. The topic was selling stuff he stole from Sirius' place:\n\nNikki: How did sirius twoway mirror end up with aberforth or is it another twoway mirror?\n  J.K. Rowling: You see Aberforth meeting Mundungus in Hogsmeade. That was the occasion on which Dung, who had taken Sirius\u2019s mirror from Grimmauld Place, sold it to Aberforth.\n  (src: J.K. Rowling Interview / The Deathly Hallows Web Chat / July 2007)\n\nAs a note - this was important since one of the things sold was the 2-way mirror that Harry used to request help when they were imprisoned at Malfoy's in DH.\nSo, he was banned from the pub (probably, to avoid causing Aberforth's establishment further trouble), but doesn't mean Aberforth won't talk/do business with him otherwise.\n\n", "meta": {"pile_set_name": "StackExchange"}}
{"text": "Working Women, Special Provision and the Debate on Equality\n\nThere has been considerable coverage in the media recently about the possibility of offering women in employment paid leave from work during their menstrual period. This has generated a broad range of responses relating to long-standing discussions about \u2018equality\u2019 and \u2018difference\u2019: is women\u2019s equality best achieved by treating them the same as men or by making provisions that recognise their differences in terms of physiological constitution and biological functions?\n\nIf the UK introduces such an initiative, it would not be the first country in the contemporary world to do so. Many countries in Asia already make the provision and Russia debated introducing a law in 2013. The policy also has a significant historical precedent. A whole chapter of my book Women Workers in the Soviet Interwar Economy: From \u2018Protection\u2019 to \u2018Equality\u2019 (Macmillan, 1999), based on extensive research conducted for my PhD, is devoted to \u2018Provision for \u201cMenstrual Leave\u201d\u2019.\n\nIn the 1920s, scientific researchers and labour hygiene specialists in the Soviet Union conducted extensive investigations into the impact of menstruation on women\u2019s capacity to work in manual and industrial jobs requiring a significant degree of physical labour. Their recommendations led to two decrees being issued that targeted specific categories of women workers:\n\nDecree \u2018On the release from work during menstruation of machinists and iron press workers working on cutting machines without mechanised gears in the garment industry\u2019, 11 January 1922\n\nDecree \u2018On the working conditions of women tractor and lorry drivers\u2019, 9 May 1931\n\nThese decrees arose from research that suggested, amongst other things, that inadequate seating at machines and on tractors resulted in congestion and tension in the abdomen that was exacerbated during menstruation. In practice, the decrees did not provide for regular absence from work. Women seeking to benefit from the provision had to provide a doctor\u2019s note, similar to the usual requirements for sick leave.\n\nThe official research into the impact of menstruation on women\u2019s capacity to work and the application of the decrees in practice raised a number of issues on both sides of the argument. I offer only a summary of the contemporary research findings and observer commentary here:\n\nFor the provision:\n\u2022 employers have a responsibility to protect the health of their workers and unhealthy, poor and inadequate working environments can have a detrimental impact on women\u2019s reproductive health\n\u2022 women\u2019s labour productivity and output would rise as a result\n\u2022 it is essential to protect the professionalism of certain categories of workers: the debates here centred on performance artists and female theatrical employees engaged in highly physical and intensely emotional work\n\u2022 heavy physical labour and strenuous exercise can lead to disruptions of the menstrual cycle\n\u2022 women\u2019s physical and intellectual capacities are reduced during menstruation; women lose muscular strength and powers of concentration\n\u2022 women\u2019s biological constitution and reproductive functions require specific recognition in law\n\nAgainst the provision:\n\u2022 employers are less likely to appoint women if they are guaranteed paid time off work during menstruation\n\u2022 (often from male workers, who viewed the employment of women as competition) women should not be employed in jobs for which they lack the physical strength and mental capacity\n\u2022 if necessary, women could be transferred to different tasks involving easier work during menstruation\n\u2022 the provision would be open to uneven application and abuse\n\u2022 women cannot expect to be considered equal with men if they are given special treatment in the law\n\nIt is worth noting also that the various research projects often revealed that the vast majority of women reported no regular problems or abnormalities with menstruation, and that men commonly reported higher levels of sickness than their female colleagues. Many of the problems experienced by women in the workplace could be mitigated by the introduction of improvements to their physical working conditions (not sitting down or standing up in the same position for long periods of time) or by the simple introduction of very short breaks that would allow women to walk around and get some exercise.\n\nDebates in the UK, on the TV and in the press, are unlikely to reach a consensus on this issue. What do you think?", "meta": {"pile_set_name": "Pile-CC"}}
{"text": "Major League Baseball All-Century Team\n\nIn 1999, the Major League Baseball All-Century Team was chosen by popular vote of fans. To select the team, a panel of experts first compiled a list of the 100 greatest Major League Baseball players from the past century. Over two million fans then voted on the players using paper and online ballots.\n\nThe top two vote-getters from each position, except outfielders (nine), and the top six pitchers were placed on the team. A select panel then added five legends to create a thirty-man team:\u2014Warren Spahn (who finished #10 among pitchers), Christy Mathewson (#14 among pitchers), Lefty Grove (#18 among pitchers), Honus Wagner (#4 among shortstops), and Stan Musial (#11 among outfielders).\n\nThe nominees for the All-Century team were presented at the 1999 All-Star Game at Fenway Park. Preceding Game 2 of the 1999 World Series, the members of the All-Century Team were revealed. Every living player named to the team attended.\n\nFor the complete list of the 100 players nominated, see The MLB All-Century Team.\n\nSelected players\n\nPete Rose controversy\nThere was controversy over the inclusion in the All-Century Team of Pete Rose, who had been banned from baseball for life 10 years earlier. Some questioned Rose's presence on a team officially endorsed by Major League Baseball, but fans at the stadium gave him a standing ovation. During the on-field ceremony, which was emceed by Hall of Fame broadcaster Vin Scully, NBC Sports' Jim Gray questioned Rose about his refusal to admit to gambling on baseball.  Gray's interview became controversial, with some arguing that it was good journalism, while others objected that the occasion was an inappropriate setting for Gray's persistence.  After initially refusing to do so, Gray apologized a few days later.  On January 8, 2004, more than four years later, Rose admitted publicly to betting on baseball games in his autobiography My Prison Without Bars.\n\nSee also\nMajor League Baseball All-Time Team, a similar team chosen by the Baseball Writers' Association of America in \nLatino Legends Team\nDHL Hometown Heroes (2006): the most outstanding player in the history of each MLB franchise, based on on-field performance, leadership quality and character value\n\nList of MLB awards\nTeam of the century\nNational Baseball Hall of Fame and Museum\n\nReferences\n\nExternal links\nAll-Century Team Vote Totals from ESPN.com\nAll-Century Team DVD from Amazon.com\nAll-Century Team Information from Baseball Almanac\n\nCategory:1999 Major League Baseball season\nCategory:Major League Baseball trophies and awards\nCategory:History of Major League Baseball\nCategory:Awards established in 1999", "meta": {"pile_set_name": "Wikipedia (en)"}}
{"text": "PCI Alternative Using Sustained Exercise (PAUSE): Rationale and trial design.\nCardiovascular disease (CVD) currently claims nearly one million lives yearly in the US, accounting for nearly 40% of all deaths. Coronary artery disease (CAD) accounts for the largest number of these deaths. While efforts aimed at treating CAD in recent decades have concentrated on surgical and catheter-based interventions, limited resources have been directed toward prevention and rehabilitation. CAD is commonly treated using percutaneous coronary intervention (PCI), and this treatment has increased exponentially since its adoption over three decades ago. Recent questions have been raised regarding the cost-effectiveness of PCI, the extent to which PCI is overused, and whether selected patients may benefit from optimal medical therapy in lieu of PCI. One alternative therapy that has been shown to improve outcomes in CAD is exercise therapy; exercise programs have been shown to have numerous physiological benefits, and a growing number of studies have demonstrated reductions in mortality. Given the high volume of PCI, its high cost, its lack of effect on survival and the potential for alternative treatments including exercise, the current study is termed \"PCI Alternative Using Sustained Exercise\" (PAUSE). The primary aim of PAUSE is to determine whether patients randomized to exercise and lifestyle intervention have greater improvement in coronary function and anatomy compared to those randomized to PCI. Coronary function and anatomy is determined using positron emission tomography combined with computed tomographic angiography (PET/CTA). Our objective is to demonstrate the utility of a non-invasive technology to document the efficacy of exercise as an alternative treatment strategy to PCI.", "meta": {"pile_set_name": "PubMed Abstracts"}}
{"text": "Q:\n\n\u00bfPorqu\u00e9 en este loop de JavaScript la impresi\u00f3n de la variable es desde counter y no desde counter-1?\n\nen mi b\u00fasqueda por aprender programaci\u00f3n por mis propios medios, me he topado con el tema de recursividad y este simple c\u00f3digo... mi pregunta ya que la variable counter comienza desde 10 y dentro del loop While el contador resta 1, porqu\u00e9 en la \"impresi\u00f3n\" aparece desde el 10. S\u00e9 que si quisiera empezar desde 10 colocar\u00eda el contador en 11... pero obviamente tengo la curiosidad y no entiendo.\nvar counter = 10;\nwhile(counter > 0) {\n    console.log(counter--);\n}\n\nresultado:\n10\n9\n8\n7\n6\n5\n4\n3\n2\n1\n\nA:\n\nLa raz\u00f3n es simple, en recursividad lo que haces es pasar una variable o arreglo en la mayor parte de los caso para modificarlos o simplemente imprimirlos, en tu caso quieres restar un numero por cada iteracion dentro de tu ciclo while pero aqui lo que tu quieres conseguir es que primero te imprima el 9 por la l\u00f3gica que encuentras en tu programa y aunque no es del todo err\u00f3nea eso no suceder\u00e1 jamas por la siguiente raz\u00f3n.\nEn tu codigo lo que tienes es la impresion de tu variable e imprimes lo que es counter-- y a pesar de que si te resta -1 en esa misma iteracion sucede que primero te imprimira la variable antes de hacer dicha operacion ya que es lo que primero lee javascript, es como si tu codigo estuviera dividido en dos partes.\nEJEMPLO\nvar counter = 10;\nwhile(counter > 0) {\n    console.log(counter); // Lee antes el valor variable\n    counter--; // Despu\u00e9s realiza operaci\u00f3n\n}\n\nEsto sucede asi porque es como funciona internamente lo que realizas con javascript ya que a pesar de que parece un metodo simple de resta internamente esta compuesto de dos partes. Para cuando javascript hace la operacion tu valor ya esta en pantalla.\nEJEMPLO VISUAL\n\nPrimera iteraci\u00f3n:\ncounter = 10 | counter-- | counter = 9\ncounter = 9 | counter-- | counter = 8\ncounter = 8 | counter-- | counter = 7\n...\ncounter = 1 | counter-- | counter = 0\ncounter = 0 | counter-- | counter = -1 -> En este caso ya no cumples con la condici\u00f3n por lo cual nunca se imprime.\n\nPara realizar el proceso que quieres en el caso de que primero quieras que se imprima el 9 entonces deberas de hacer lo siguiente:\n\nvar counter = 10;\nwhile(counter > 0) {\n    counter--;\n    console.log(counter);\n}\n.as-console-wrapper { max-height: 100% !important; top: 0; }\n\n", "meta": {"pile_set_name": "StackExchange"}}
{"text": "Running\n\nStat\n\nDinner with people is always better than eating alone, especially when the food is good. Good food tastes even better when enjoyed with people. Tonight Amy came over to try my second attempt at the Brussels Sprouts Veggie Soup to which I have made some changes (see recipe below in previous post) for a better result, I believe.\n\nWe were at the store earlier and saw some nice looking haricot verts and heirloom tomatoes, so we decide to assemble a simple salad from those. Of course while I\u2019m at the market, I can\u2019t not get some five peppercorn salami. Our simple dinner of soup, salami, bread, cheese, salad, and wine was on the table in 15 minutes.", "meta": {"pile_set_name": "Pile-CC"}}
{"text": "Monday's are never fun...except when it's West Ham Q&A day and that's exactly what it is today!\n\nTo say there is a lot going on in the world of West Ham wouldn't quite be true as, in all honesty, its been fairly quiet. Last week, there was transfer movement on a couple of fronts and the club also sealed the free transfer of Ryan Fredericks from Fulham on a four-year deal.\n\nThere is still little to no progress on moves for Felipe Anderson and Marlon Santos, while the Hammers were also dealt a disastrous injury blow in Barcelona.\n\nIn training with Argentina, Manuel Lanzini ruptured his anterior cruciate ligament in his right knee and football.london understands that it's a whole lot worse than first feared and the attacking midfielder could miss the entire 2018/19 season in a worse case scenario.\n\nThat will no doubt impact on Manuel Pellegrini's transfer plans for the remainder of the window, with any moves now unlikely to happen until after the World Cup.\n\n(Image: FILIPPO MONTEFORTE/AFP/Getty Images)\n\nWe also had news from the continent on Monday about where West Ham are set to be based for ten days of their pre-season tour this summer, more of which you will find out about later in the live blog.\n\nSo, sit back, relax and enjoy our weekly Q&A with Hammers wrtier Sam Inkersole, where he will answer questions posed to him on his Twitter account, which you can follow @Sam_InkersoleTM\n\nKeep up to date with the latest news, features and exclusives from football.london via the freefootball.london app for iPhone and Android.\n\nAvailable to download from the App Store and Google Play.", "meta": {"pile_set_name": "OpenWebText2"}}
{"text": "TiO2 nanotubes for bone regeneration.\nNanostructured materials are believed to play a fundamental role in orthopedic research because bone itself has a structural hierarchy at the first level in the nanometer regime. Here, we report on titanium oxide (TiO(2)) surface nanostructures utilized for orthopedic implant considerations. Specifically, the effects of TiO(2) nanotube surfaces for bone regeneration will be discussed. This unique 3D tube shaped nanostructure created by electrochemical anodization has profound effects on osteogenic cells and is stimulating new avenues for orthopedic material surface designs. There is a growing body of data elucidating the benefits of using TiO(2) nanotubes for enhanced orthopedic implant surfaces. The current trends discussed within foreshadow the great potential of TiO(2) nanotubes for clinical use.", "meta": {"pile_set_name": "PubMed Abstracts"}}
{"text": "Benjamin Lok describes how the robot butt sensors work 2:26\n\nProstate exams are potentially-life saving. But the process of getting one can be nerve-racking \u2014 both for the doctor and the patient.\n\nA group of scientists from Drexel University and the Universities of Wisconsin and Florida are hoping to assist with that. They've designed a robot to help medical students give better prostate exams.\n\nThe robot's name is \"Patrick\" and he's an interactive butt.\n\nProfessor Benjamin Lok\n\n\"Patrick is part of a simulation where students get to practice prostate exams,\" lead researcher and University of Florida professor Benjamin Lok explains to As It Happens guest host Tom Harrington. \"The simulator itself is a piece of plastic and around the anus area is a foam, rubbery material. It's anatomically correct, and inside, they have placed a prostate so that they can actually feel what a prostate would feel like.\"\n\nBut the physical examination is actually the last part of the training process. Initially, students start using the simulator to work on their beside manner.\n\n\"Students have to talk to Patrick for about five to eight minutes,\" the University of Florida professor says. \"They work on their social skills. They try to obtain a patient history, but also have to work through anxiety that Patrick's having.\"\n\nA student interacting with \"Patrick\" (Courtesy of Andrew Robb, University of Florida)\n\nAs the interview progresses \u2014 and the student realizes that Patrick needs a prostate exam \u2014 Patrick becomes quite hesitant to proceed. Lok says the robot will say, \"Do you really have to do this? I don't understand why we have to do this right now.\"\n\nOnce Patrick is convinced, the student begins the examination.\n\n\"We can show you in real-time, as you're doing the exam... whether you're pressing all the regions and if you're pressing with enough pressure,\" Lok continues.\n\nThe sensor displays traffic light-style signals of green, yellow or red depending on the appropriate pressure applied.\n\n\"That helps educate the user and what a good prostate exam should feel like,\" he says.\n\nBut why not have Patrick yell or respond in a more human-like way? Lok says they thought about doing this, but for freshmen medical students, that would increase the level of anxiety.\n\n\"We want the system to provide positive experiences, where they can get good feedback but also help reduce some of the anxiety before they first practice on what are often called standardized patients, which are called actors.\"\n\nMany medical schools pay professional actors who are specially trained to receive numerous prostate exams by students. However, as you might imagine, there are a limited number of actors willing to do this.\n\nPostate exam program, \"Patrick\" (Courtesy of Andrew Robb, University of Florida)\n\nLike a pilot who practices in a simulator before actually flying a plane, Lok hopes Patrick will serve the same purpose for medical students.\n\n\"You can make mistakes with Patrick and start over, that's one of the advantages of a simulator.\"\n\nPatrick is currently being used by medical students at the University of Florida and Drexel University. Lok hopes the technology will be used in more medical schools across the United States.", "meta": {"pile_set_name": "OpenWebText2"}}
{"text": "In general, absorbent articles should comfortably fit the body of a wearer. Most absorbent articles include an absorbent pad formed by an absorbent core contained in a wrap comprising a barrier tissue and/or a forming tissue. The subject invention discloses an absorbent article generally having extensibility in at least one direction, preferably the cross-direction. Such extensibility permits an absorbent article to extend and expand about the wearer and thus to better conform to the body of the wearer. Such extension and expansion about the wearer is feasible because both the bodyside liner and the outer cover are extensible in at least the one direction.\nIn conventional structures, the outer cover is typically adhesively secured to the forming tissue of the absorbent pad. In such embodiments, extending the outer cover in the cross-direction extends the forming tissue in the cross-direction. The force used to extend the outer cover, and thence the absorbent pad, can tear or otherwise damage the forming tissue or the barrier tissue of the absorbent pad. Since the absorbent pad is typically a sealed enclosure, namely an absorbent core enclosed within the combination of a forming tissue and a barrier tissue, tearing the absorbent pad, namely either the forming tissue or the barrier tissue, can release superabsorbent particles and other absorbent materials, such as cellulose fluff into contact with the body of the wearer. Superabsorbent particles can irritate the skin of the wearer. Such tearing of the absorbent pad indicates failure of the absorbent article to perform properly. Therefore, it is critical to find a way to prevent tearing or other structural failure of the absorbent pad.", "meta": {"pile_set_name": "USPTO Backgrounds"}}
{"text": "Standardised protocol for primate faecal analysis.\nMacroscopic analysis of primate faeces as a way to study diet is well established, but lack of standardisation of methods may handicap comparative studies of the resulting data. Here we present a proven technique, including equipment and supplies, protocol and procedure, that yields quantitative data suitable for systematic investigation within and across primate taxa. As the problems of habituation become more obvious, the application of such indirect methods may increase in usefulness.", "meta": {"pile_set_name": "PubMed Abstracts"}}
{"text": "Examination of factors affecting gait properties in healthy older adults: focusing on knee extension strength, visual acuity, and knee joint pain.\nGait properties change with age because of a decrease in lower limb strength and visual acuity or knee joint disorders. Gait changes commonly result from these combined factors. This study aimed to examine the effects of knee extension strength, visual acuity, and knee joint pain on gait properties of for 181 healthy female older adults (age: 76.1 (5.7) years). Walking speed, cadence, stance time, swing time, double support time, step length, step width, walking angle, and toe angle were selected as gait parameters. Knee extension strength was measured by isometric dynamometry; and decreased visual acuity and knee joint pain were evaluated by subjective judgment whether or not such factors created a hindrance during walking. Among older adults without vision problems and knee joint pain that affected walking, those with superior knee extension strength had significantly greater walking speed and step length than those with inferior knee extension strength (P < .05). Persons with visual acuity problems had higher cadence and shorter stance time. In addition, persons with pain in both knees showed slower walking speed and longer stance time and double support time. A decrease of knee extension strength and visual acuity and knee joint pain are factors affecting gait in the female older adults. Decreased knee extension strength and knee joint pain mainly affect respective distance and time parameters of the gait.", "meta": {"pile_set_name": "PubMed Abstracts"}}
{"text": "Volunteer Services\n\nVolunteer Services\n\nAs Charleston Area Medical Center volunteers, our mission is to serve as support for patients, families and hospital staff, and to provide a caring, comforting and courteous environment.\n\nVolunteers at CAMC bring their unique personalities and skills to our hospital. They range in age from 15 to 99. Our ranks are made up of men and women; students and retirees; homemakers and business people. Last year, 334 volunteers contributed over 36,000 hours to our hospitals and Cancer Center.\n\nWe are looking for volunteers who exemplify CAMC's core values of respect, integrity, stewardship, quality, service with compassion and safety. These volunteers will help us with our mission of \"striving to provide the best health care to every patient, every day.\"", "meta": {"pile_set_name": "Pile-CC"}}
{"text": "Q:\n\nPython: My return variable is always None\n\nSo I found a strange thing that happens in python whenever I try to return an optional parameter or at least I think that is why it is happening.\nHere is my code\ndef reverse(string, output = \"\"):\n    if string == \"\":\n        print \"winner: \", output\n        return output\n    output = output + string[-1]\n    string = string[:-1]\n    reverse(string, output=output)\n\nAnd here is what happens when I run it:\n>>> output = reverse(\"hello\")\nwinner:  olleh\n>>> print output\nNone\n\nAnyone know why my return is always None?\n\nA:\n\nYou have to return the return value of the recursive call.\ndef reverse(string, output = \"\"):\n    if string == \"\":\n        print \"winner: \", output\n        return output\n    output = output + string[-1]\n    string = string[:-1]\n    return reverse(string, output=output)\n\n", "meta": {"pile_set_name": "StackExchange"}}
{"text": "Formulation and application of a biosurfactant from Bacillus methylotrophicus as collector in the flotation of oily water in industrial environment.\nThe present study describes the formulation of a biosurfactant produced by Bacillus methylotrophicus UCP1616 and investigates its long-term stability for application as a collector in a bench-scale dissolved air flotation (DAF) prototype. For formulation, the conservative potassium sorbate was added to the biosurfactant with or without prior heat treatment at 80 \u00b0C for 30 min. After formulation, the biosurfactant samples were stored at room temperature for 180 days and the tensioactive properties of the biomolecule were determined with different pH values, temperatures and concentrations of salt. Then, a central composite rotatable design was used to evaluate the influence of the independent variables (effluent flow rate and formulated biosurfactant flow rate) on the oil removal efficiency in the DAF prototype. The formulated biosurfactant demonstrated good stability in both conservation methods, with tolerance to a wide pH range, salinity and high temperatures, enabling its use in environments with extreme conditions. The efficiency of the formulated biomolecule through heating and addition of sorbate was demonstrated by the 92% oil removal rate in the DAF prototype. The findings demonstrate that the biosurfactant from Bacillus methylotrophicus enhances the efficiency of the DAF process, making this technology cleaner. This biosurfactant can assist in the mitigation and management of industrial effluents, contributing toward a reduction in environmental pollution caused by petroleum-based hydrocarbons.", "meta": {"pile_set_name": "PubMed Abstracts"}}
{"text": "Playing back a meeting recording\n\n\u2026Let me show you how to locate and play back a meeting that you have recorded.\u2026First, let's understand how WebEx Meetings store and prepare your meeting recordings.\u2026The meetings are recorded on the WebEx server.\u2026WebEx will post the recording to their\u2026server within 24 hours of the meeting completion.\u2026When your recording is ready, you'll receive an update on\u2026your dashboard homepage with the playback link and the recording information.\u2026Let me show you how that looks.\u2026When you get this notification, you can click the link that says Play Recording.\u2026And WebEx will play back the video for you with the WebEx network recording player.\u2026\n\nTo locate your meeting recording manually, if\u2026you miss the notification, the easiest thing\u2026to do is look at the meetings space for the meeting that you recorded.\u2026First, find the meeting in your meetings list by clicking the Meetings tab.\u2026Click the Recent tab.\u2026You'll note, in the list, whether it's recorded or not.\u2026Click on the meeting title to visit the meeting space page for that meeting.\u2026\n\nResume Transcript Auto-Scroll\n\nAuthor\n\nReleased\n\n6/9/2014\n\nConnect and collaborate across the globe with WebEx Meetings. In this course, author and webinar specialist Sally Norred shows you how to use WebEx Meetings to host, run, and record online meetings. Discover how to set up an online meeting and invite attendees, work with interactivity, let attendees participate and present, and save and record a meeting. Also check out the quick tips sheets (free to all members) for a list of handy shortcuts for hosts, presenters, and attendees alike.", "meta": {"pile_set_name": "Pile-CC"}}
{"text": "A&E\u2019s hit reality TV show was ensnared in controversy after its star\u2019s controversial comments about gays and African-Americans\n\nA record-setting reality show appears to be paddling in the wrong direction as its fifth season gets underway.\n\nCiting data from Nielsen, Variety reports that just 6.65 million viewers watched Wednesday night\u2019s episode of Duck Dynasty on A&E. That\u2019s down from the 8.5 million who tuned into last week\u2019s season premiere. The ratings are the lowest for an original episode of the show since December 2012.\n\nDuck was ensnared in controversy late last year when star Phil Robertson made derogatory remarks about gays and African Americans. The show focuses on a family that made a fortune on duck-hunting accessories.\n\nIts fourth-season premiere was the most-watched cable reality TV episode in history, attracting 11.77 million viewers. Last year, it was the second most watched cable TV program overall, after AMC\u2019s Walking Dead.\n\n[Variety]", "meta": {"pile_set_name": "OpenWebText2"}}
{"text": "But something is happening here and you don\u2019t know what it is\n\nDo you, Mr, Jones? (Bob Dylan, 1965)\n\nRulers seldom know what\u2019s happening, do they? They have the intelligence apparatus and their party politicos feeding them whatever the powerful like to hear, but the assessment of the people can be in delicious discord.\n\nAtal Bihari Vajpayee ordered elections early because his India was shining. He paid the price. Through cries of policy paralysis and corruption, Manmohan Singh went in expecting to be reasonably rewarded. After all, his government had delivered a nearly 7-8% (9-10% by today\u2019s yardstick) rate of growth over most of his ten-year period, unprecedented for a democracy. Yet, the result was a shock.\n\nWhat was common between the two governments \u2013 covering a period of about 16 years of elite section boy-scout optimism \u2013 was bubbly talk for much of the time by economists, policy wonks, and the World Bank and the IMF. In the end, the politics probably turned on a less talked about variable: jobless growth, which analysts hadn\u2019t troubled themselves with.\n\nIn the strapped situation of lukewarm private sector investment we are in today, and the major employment-generating informal economy sector having taken a hit since demonetisation, no analyst or political planner can afford to overlook jobless growth.\n\nPakora growth, a close enough synonym, staring the country in the face is hardly a pleasing outcome after four years of \u201cgame-changing\u201d economics, no matter how combatively BJP chief Amit Shah defended it in his maiden speech in the Rajya Sabha.\n\nYoung Indians of any class, on whose shoulders rides the much-vaunted promise of the demographic dividend, are not amused.\n\nRampant joblessness is a feature the Modi sarkar shares with the governments of Vajpayee and Singh. Alas, what it does not share with their time in office is a long patch of striking expansion of the economy.\n\nAlso Read\n\nNot to put too fine a point on it, we now find ourselves stuck in a time of creeping pessimism, although international capital has done its best to talk up the India story through friendly statements issued by the IMF and the World Bank that the Modi regimes perversely quotes all the time, though it only has to look around to find the truth.\n\nWhat\u2019s worse, India is slipping when the US and Europe have recovered and when the international price of oil is still in benign territory.\n\nThe dim economic outlook is likely to impose a cut-and-run political strategy on the prime minister, although MPs in general, not just of the ruling party, do not like their term cut short.\n\nFor Modi, an early election is, therefore, likely to be a political compulsion. In this respect, his story is different from that of Vajpayee\u2019s. The latter had chosen to go to the country early of his own volition in order to seize what his advisors thought might be a bright moment.\n\nThe contrast in circumstances Modi finds himself in has been accentuated by the morale-sapping defeat in the recent by-elections in Rajasthan. Ordinarily, losing by-elections is not the end of the world, although ruling parties frequently coast to easy victories in them. However, the BJP lost every one of the 16 Assembly segments that make up the Lok Sabha constituencies of Alwar and Ajmer.\n\nThat is a lot of territory to lose in one go and should be a distinct worry for the saffron party. Rajasthan has an old and active RSS network, which in recent times was lubricated through political and social actions of the Hindutva variety, most notably cow vigilante actions. But none of this counted with the voter.\n\nThe \u201csecular\u201d realm \u2013 jobs, prices, the economy, living conditions \u2013 trumped the world of perverse ideas delivered slickly through clever propaganda disseminated not just by fanatical Hindutva outfits but also a section of the fawning media.\n\nAssembly elections in Rajasthan, Madhya Pradesh and Chhatisgarh are due in December this year and the Lok Sabha poll should in the normal course be held in April-May, 2019. However, when the prognosis for the BJP in these states is none too bright \u2013 and remember the bad news began to pour in from Modi\u2019s the home state Gujarat, where BJP\u2019s win was so tenuous that the party cannot even celebrate it \u2013 and the Rajasthan results hammered home a bitter truth, can the prime minister risk holding the Lok Sabha election after a potentially weak showing in three BJP-ruled states?\n\nThis will be the singular consideration guiding the prime minister if he decides to go to the country early, not some high-intentioned thinking on the presumed benefits to the country of holding parliament and state polls simultaneously.\n\nThe year 2017 began brilliantly for Modi and Amit Shah with a staggering win in Uttar Pradesh. But the year ended on a sobering note on account of the factors that became evident first in Gujarat and then in Rajasthan \u2013 rampant joblessness, farmers\u2019 plight, the woes of the working classes in the \u2018rurban\u2019 areas and in cities proper. If a week is a long time in politics, a year is an eternity.\n\nAnand K. Sahay is a journalist who lives and works in New Delhi.", "meta": {"pile_set_name": "OpenWebText2"}}
{"text": "Computer assisted learning: the potential for teaching and assessing in nursing.\nThis article discusses computer assisted learning (CAL) and the importance of applying it in nurse education. The articles recognizes the general technological developments as exemplified by the Teaching and Learning Technology Programme (TLTP) from which ideas about application and benefits came. The ideas from TLTP are hereby used in CAL and applied to nursing and health-care undergraduate programmes in one university. In the light of this experience the main intention of this article is to consider the benefits and costs of introducing computer programmes as part of the teaching provision for nurses and other health-care professionals both at beginner and advanced level. The article further argues that CAL can also be used for patient teaching thus providing transferable skills and benefits for teachers as well as learners, be they students or patients. To support such multiple uses of CAL selected examples will be offered and appropriate conclusions will be drawn.", "meta": {"pile_set_name": "PubMed Abstracts"}}
{"text": "Adventure Time, Mission Impossible, The A-Team, Harry Potter and the new Ghostbusters are about to land on LEGO Dimensions.\n\nImages of the new additions were picked up by users on /r/LEGO, the source of which seems to be early listings on the Mexican version of Amazon. This pretty much breaks the street date of a LEGO Dimensions announcement which is supposed to happen today (June 9th).\n\nThe game already features characters, locations, items and more from popular franchises such as DC Comics, Back To The Future and Scooby-Doo.\n\nAdventure Time was already slated to be a LEGO Ideas official set, so it\u2019s appearance on the subreddit wasn\u2019t such a shock. Mission Impossible and The A-Team, on the other hand, are a complete surprise here.\n\nThat being said, we still really like these new additions and would love to play them\u2026 if it wasn\u2019t for the fact that the game, in any iteration, has still not been released in South Africa.\n\nIt was initially released north of the equator on September 27th, so local interested parties have been waiting for it for quite sometime. Hopefully it\u2019ll arrive here soon. We can dream\u2026\n\nUPDATE 09/06:\n\nThanks to an official trailer made for E3, we now know that the above leaks are all official. To make the news even better (and to empty your wallet even more), E.T., The Goonies, Gremlins, Teen Titans GO!, Knight Rider and even Sonic will be appearing in the game at a future date.\n\n[Source \u2013 /r/ LEGO", "meta": {"pile_set_name": "OpenWebText2"}}
{"text": "Q:\n\nPython Segmentation Fault?\n\nFirst off, I didnt even know a memory error / segfault was possible in python. Kudos to learning something new!\nI have this database I create\ndatabase = DBManager(dbEndpoint,dbUser,dbPass,dbSchema)\n\nAnd then I try to use it in a thread\ndef stateTimeThreadStart():\n     database.getTable('CLIENTS')\n\nthreads = []\nthreads.append(threading.Thread(name='State Updater', target=stateTimeThreadStart, args=()))\nthreads[0].start()\n\nThe output is \nSegmentation fault: 11\n\nWhat on earth is going on here? It definetly has something to do with database.getTable('CLIENTS') because when I comment it out the issue does not occur. In addition, I have also tried to pass the database to the thread with no luck. Any ideas?\nThanks!\n\nA:\n\nSegmentation faults in Python can occur due to database connectors. The drivers used to connect to the database are usually coded in a C base, so in case of RAM overload or perhaps other reasons it throws Segmentation Faults.\nThis is further exacerbated by the fact that you are using multithreading. Most database drivers are known to throw Segmentation Faults if multithreading isn't handled very carefully. Most database driver protocols can not handle multiple threads using the same connection at once.\nThe rule of thumb is to not share a single connection between threads.\n\n", "meta": {"pile_set_name": "StackExchange"}}
{"text": "NEW YORK (CBSNewYork) \u2014 A fight between two roommates inside a homeless shelter in Harlem turned deadly Friday morning.\n\nIt happened inside a shelter for men with alcohol, drug and mental health problems at 149 W. 132nd St., which is run by the nonprofit Bowery Residents Committee.\n\nPolice said the two men got into a dispute in their fifth-floor apartment using kitchen knives, CBS2\u2019s Brian Conybeare reported.\n\nPolice say the two roommates pulled out kitchen knives during a dipute. A 44-year-old was killed, and a 39-year-old was critically injured. No charges had been filed as of Friday evening.\n\nA shelter resident, who did not want to give his name, said he heard the fight just after 7 a.m. and that it sounded like somebody fell out of bed.\n\n\u201cI heard something go boom,\u201d the man said, adding that he does not feel safe in the shelter.\n\nNeighbors told CBS2 the block is home to at least three different homeless shelters, and some say the shelter where the incident happened is a constant source of trouble.\n\n\u201cAnytime there\u2019s an ambulance, a fire engine or a police car, we are worried that something happened, and unfortunately now something really bad happened, and that\u2019s scary,\u201d said Francesco Fabba, who has lived on the block since 2009.\n\nHe pointed to empty liquor bottles littering the sidewalk as evidence of the ongoing trouble and fear shelter residents cause.\n\n\u201cWe try to cope as much as we can with that,\u201d Fabba said.\n\n\u201cMaybe you try to walk on this side of the street and not that side, depends on who\u2019s outside the building,\u201d he added.\n\nOthers on the gentrifying street, which includes million-dollar brownstones, say the shelter residents don\u2019t frighten them, that they\u2019re just regular people struggling with mental health issues and trying to get some help.\n\n\u201cMost of them are very kind to me,\u201d said neighbor Moneke Coates. \u201cI\u2019ve never felt threatened.\u201d\n\nCoates said the shelter was there long before a new wave of wealthier people moved in.\n\n\u201cIt\u2019s just that they want them out of here,\u201d she said. \u201cIt doesn\u2019t look good for them.\u201d\n\nCommunity activist Iesha Sekou understands both sides, but said the city needs more affordable housing and the homeless system needs to do more screening.\n\n\u201cMental illness has to definitely be addressed before people are going into shelters,\u201d Sekou said. \u201cWe have to assess whether or not there is a danger to other people.\u201d\n\nThe Bowery Residents Committee would not go on camera. In an email statement to CBS2, the organization said that it is saddened by what happened.", "meta": {"pile_set_name": "OpenWebText2"}}
{"text": "Q:\n\nHP MSA70 / P800 Array Failure - Shows 2 drives in each slot, 13/25 drives \"missing\"\n\nWe have an HP MSA70 with 25 x 600GB HP SAS 10k DP drives, connected to an HP P800 controller.  The drives are configured in RAID 6.  \nYesterday, some kind of unknown \"event\" occurred and the array dropped offline.  We rebooted the server (running CENTOS 6.2) and upon startup, the Array Controller reported that 13 of the drives are \"missing\".  When we look at the volume in the Array management, there are two entries for each slot for slots 1-12.  One shows a 600gb drive and one shows a 0gb drive.  There are no more entries after 12.\nWe contacted HP support, who sent us to Tier 2 support, and after many hours gave up.  They said they have never seen this, before (my favorite thing to hear from a vendor).\nHas anybody seen this before, and have we lost all of the data?\nThank you.\n\nA:\n\nOld, old, old, old...\n\nCentOS 6.2 is old (6.2, 6 December 2011 (kernel 2.6.32-220))\nHP StorageWorks MSA70 is old. (End of Life - October 2010)\nHP Smart Array P800 is old. (End of Life - 2010)\n\nSo this makes me think that firmware and drivers are also old. E.g. there's no reason to run CentOS 6.2 in 2015... And I'm assuming no effort was made to keep anything current.\nThis also makes me think that the systems are not being monitored. Assuming HP server hardware, what did the system IML logs say? Are you running HP management agents? If not, important messages about the server and storage health could have been missed.\nDid you check information from the HP Array Configuration Utility (or HP SSA)?\nBut in the end, you've probably suffered a port failure or expander/backplane failure:\n\nHow many SAS cables are connected to the enclosure? If 1 cable is connected, then you likely have a backplane issue because of the SAS expander in the enclosure. \nIf two cables are connected, you may have a SAS cable, MSA70 controller or P800 port failure.\n\nYour data is likely intact, but you need to isolate the issue and determine which one of the above issues is the culprit. Replacing a SAS cable is a lot easier than swapping the MSA70 controller or RAID controller card... but I guess you can get another MSA70 for $40 on eBay...\n\n", "meta": {"pile_set_name": "StackExchange"}}
{"text": "POV: Henry vs Martin + a poll\n\nI won\u2019t make claims as to their gifts and charms, but H & M do resemble me in various ways :)\n\nI usually like to write stories from a single point of view. It\u2019s obviously a limited perspective, but I enjoy the constraints. As far as I\u2019m concerned, there\u2019s no such thing as a reliable narrator. Characters misinterpret things, miss things, draw the wrong conclusions, and it can be tricky and fun to work the \u201ctruth\u201d into a story alongside the character\u2019s perceptions. For instance, I think it\u2019s obvious to the reader that Martin is DTF from the get-go, but Henry, equipped with the same amount of information, simply doesn\u2019t get it.\n\nWhen I started writing the Ganymede Quartet books, it seemed obvious to me that the story needed to be told from the master\u2019s point of view. Whether or not he\u2019s actually prepared to take responsibility, the fact remains that Henry\u2019s the one in charge and he sets the tone. It\u2019s Martin\u2019s job to adapt and respond and accommodate and serve. Obviously, Martin is better-equipped to steer this particular ship, but, unfortunately for Henry, the roles in this relationship weren\u2019t assigned based on fitness or merit. If you\u2019ve read A Most Personal Property (GQ Book 1), you know that when the opportunity finally arises for Martin to take charge, he does so with great effect, but he does wait for Henry to create the opportunity. He\u2019s very well-trained.\n\nI think it\u2019s apparent that Martin is miserable for most of AMPP, and writing weeks of self-doubt and misery even greater than Henry\u2019s, from the perspective of a character who has even less power to effect change\u2026I don\u2019t think anyone wants to read that book, actually.\n\nHenry also needed to be the POV character for the main books because Henry is the one who has the most growing to do. They\u2019re both young, both immature, but Martin is less immature, his sense of self is more solid and, well, he\u2019s a lot smarter. Henry learns a lot over the course of the series, which is not to say that Martin doesn\u2019t, but as the one nominally in charge, Henry\u2019s growth has a greater impact on both of them.\n\nIt was possibly something of a risk, but I left out or delayed certain trains of thought because Henry isn\u2019t necessarily considering all aspects and implications of the master/slave dynamic from early on in their relationship. He\u2019s very loving, but he\u2019s not the most insightful person, and it takes him awhile to consider things that a savvier fellow might have questioned from the beginning. It really does take Henry a long time to wonder how Martin\u2019s position and training impact the way Martin responds to him.\n\nI anticipate going a little deeper into Martin\u2019s background, in a way, for the story that will accompany Book 3. I also have a pretty good idea which aspect of Book 4 I\u2019ll present from Martin\u2019s perspective. So far, the Martin stories have been really fun to write, and I definitely look forward to doing them. I think they\u2019re so easy and enjoyable to work on because they revisit territory that I\u2019ve already covered from Henry\u2019s perspective to some extent, and when I\u2019m writing Henry, I\u2019m always considering how Martin might view a given situation, as well.\n\nOffering Martin\u2019s POV at all was actually a pretty late development. It occurred to me shortly before publishing A Most Personal Property that the stories I was busy telling myself about Martin\u2019s past would probably be of interest to anyone who was interested in AMPP, and so I quickly wrote A Superior Slave. I hoped that people who enjoyed reading ASS (ugh, that acronym!) for free might be interested in paying for AMPP, and I think that did happen to some small extent. I\u2019ve gotten the impression (whether it\u2019s true or not) that Martin might be the reader favorite by a small margin, so it just seems like a nice idea to continue offering Martin POV stories alongside the main books. While I think a person can enjoy the main books and Henry\u2019s POV without side stories, I like to think Martin\u2019s perspective is a valuable addition.\n\nI plan on adding additional points of view from other characters in the universe. I\u2019ve got stories written about a couple of Henry\u2019s friends to show how slave ownership works in private for other people. I\u2019ve got at least two stories I want to write about Henry\u2019s cousin Jesse. I think Tom gets his own novella :D\n\nWith A Proper Lover (GQ Book 2) and A Master\u2019s Fidelity (GQ Book 2.5) released, I\u2019m just going immediately into editing Book 3 and fleshing out the notes I have for the Martin story. I\u2019d had vague ideas about taking a break, but I honestly don\u2019t know what that would mean at this point. I don\u2019t know what I\u2019d be doing during a break! Right now, the idea of downtime just makes me cranky. Knowing that there are people eager for the next books makes me want to work on getting them out. Besides, working on Martin\u2019s POV is a treat :)", "meta": {"pile_set_name": "Pile-CC"}}
{"text": "Over every mountain there is a path, although it may not be seen from the valley\n\nI'm now taking commissions, if you're interested in some high quality terrain PM me.\n\n\n\n\n\nWorldPainter (for creating the map)\n\n\n\nChunky (for rendering the map)\n\n\n\nThanks for stopping by, if you enjoyed this submission please consider leaving a diamond!\n\nThe sweeping sunset of the Roughhew Rocks is deceiving. The mountain becomes beautiful, the forests become picturesque and the rugged rocks look tamed. Even the birds sing a loud song heard far and wide over the coastal rocks. Don't be fooled, you're not safe. The beauty is the danger, one feels so safe, so alive, so free in Roughhew. But the same cannot be said for the human. Only two people have escaped Roughhew alive, and the thousands that are enticed here each season are slain. Some say it is nature that kills them, others say it's haunted, some claim the beauty was too much for them. While nobody knows the cause of death of these people there is one thing that cannot be disputed - this region has the highest rate of death in all the land.I like this map but I found it incredibly difficult to get nice renders of it. As such it marks the first map I've made where the cover photo is from the ground rather than a top down isometric view. This map I changed normal smooth stone for rock, a combination of stone and cobblestone, to create a rougher and more rugged terrain and I'm pleased with how it turned out. I also used gravel in the valleys to show heavy erosion and an unstable land, despite the towering mountain looming over it.I used the following tools to create this map:", "meta": {"pile_set_name": "OpenWebText2"}}
{"text": "The terrifying 38-minute ordeal suffered by Hawaii residents on Saturday, when the state\u2019s emergency-management agency sent out a false alert warning of an imminent ballistic-missile strike amid rising tensions with North Korea, seems to have sparked an unusually rapid response on Capitol Hill.\n\nHawaii\u2019s Sen. Brian Schatz, a Democrat on the Senate Commerce Committee, told National Journal that he is working with other Senate Democrats on a bill that would implement a federal best-practice framework for the ballistic-missile-alert systems administered by U.S. states, localities, and territories. And while Republicans don\u2019t appear to be involved in the process, relevant GOP chairs in both chambers have expressed a willingness to work with Schatz on the issue.\n\nInitial reports indicate that Hawaii\u2019s screwup\u2014which sent people across the archipelago scrambling for shelter before the all-clear was called more than a half-hour later\u2014was because of an employee mistakenly pressing the wrong link on a confusingly designed interface. But for something as serious as a ballistic-missile alert, Schatz suggested that the potential for human error can, and should, be mitigated through federal safeguards.\n\n\u201cYou want a system that accounts for the fact that somebody may be sleepy or careless, or an interface may not be the most user-friendly, and yet it all works anyway,\u201d Schatz said. \u201cWe have best practices for disaster notifications for natural disasters, for terrorism events. We just don\u2019t have it for this.\u201d\n\nOn Wednesday, Schatz said he had convened a phone call with officials from the Federal Communications Commission, the Homeland Security Department, the Pentagon, and other relevant agencies to address the inconsistency.\n\n\u201cWe think it should be done legislatively, but I don\u2019t know that for sure yet,\u201d he told reporters, explaining that the ultimate goal is to craft \u201ca federal law to establish a framework that states can use.\u201d\n\nThe way America\u2019s missile-alert system operates is fundamentally different from how citizens are alerted to most other catastrophes, when local authorities often possess the best information. While states and cities are ultimately responsible for alerting civilians of an imminent attack, they lack the ability to detect and track incoming missiles.\n\nIn the seconds and minutes after a launch, details of the threat would have to cascade through phone calls from the Pentagon to DHS. From there, officials at the Federal Emergency Management Agency would send the warning to at-risk states and localities, whose own alert systems would only then spring into life.\n\nThat chain of causation was disrupted on Saturday. But David Simpson, a former admiral in the U.S. Navy who ran the FCC\u2019s Public Safety and Homeland Security Bureau from November 2013 to January 2017, said federal legislation should seek to dismantle that outdated process altogether.\n\n\u201cThat\u2019s a 1950s kind of structure,\u201d Simpson said, arguing that machine-to-machine communication technology should be utilized to eliminate lag time and cut down on human error.\n\nOne way to do that could be for the FCC to create, at the direction of Congress, a unique wireless-alert category for ballistic-missile threats. \u201cThat would then ensure that the machine elements of this system could be built around that narrow bucket,\u201d Simpson said.\n\nBut that still wouldn\u2019t solve the problem entirely. \u201cThe machine-to-machine piece of that, so it could be really useful, would require DHS and [Defense Department] plumbing changes that would be beyond the authorities of the FCC,\u201d Simpson said.\n\nSimpson largely endorsed Schatz\u2019s plan for a uniform federal missile-alert framework that states and localities can follow. \u201cThere\u2019s over 1,000 alert originators at the state and local level, and I would say five, six, seven vendors for the user-interface systems,\u201d he said.\n\nIn a bid to improve innovation, DHS gave state governments broad leeway to design their own missile-alert interfaces. But Simpson said that decision has clearly come with a cost.\n\n\u201cThat variation is fine for notification about fire, notification about a tsunami coming in,\u201d Simpson said. \u201cBut ballistic-missile warnings ought to be consistent, reliable, secure\u2014because we don\u2019t want it cyberattacked\u2014across the entire country.\u201d\n\nRepublicans seem receptive to Schatz\u2019s plan for missile-alert legislation. Schatz said he plans to introduce his bill through the Senate Commerce Committee, which is chaired by Republican John Thune. Frederick Hill, a Thune spokesman, told National Journal that the chairman \u201cis considering convening a full committee hearing which would help inform legislative efforts.\u201d\n\nHouse Republicans are further along than their Senate counterparts, with plans to hold an Energy and Commerce hearing on Hawaii\u2019s false missile alert in the coming weeks. On Wednesday, committee chairman Greg Walden said he would be \u201chappy to work\u201d with Schatz on legislation, if needed. \u201cWe just haven\u2019t got into the weeds on it,\u201d Walden said.\n\nAs long as lawmakers can work out issues surrounding committee and agency jurisdiction, Simpson said the chances for bipartisan support are high. But stakeholders from Homeland Security and the Pentagon\u2014as well as the congressional committees that oversee them\u2014will also need to weigh in. And Simpson worries those agencies may be loath to take responsibility for what\u2019s widely viewed as a state-level mistake.\n\n\u201cIt\u2019s a perfect bipartisan issue, as long as we don\u2019t let the various lobbies and the competition between agencies pervert and potentially dilute the ultimate outcome,\u201d Simpson said.\n\n\"Two more House Republicans have joined the discharge petition to force votes on immigration, potentially leaving centrists just two signatures short of success. Reps. Tom Reed (R-N.Y.) and Brian Fitzpatrick (R-Pa.) signed the discharge petition Thursday before the House left town for the Memorial Day recess. If all Democrats endorse the petition, just two more GOP signatures would be needed to reach the magic number of 218.\"\n\nSource:\n\nFIRED FROM RUSSIAN LAUNCHER\n\nInvestigators Pin Destruction of Malaysian Airliner on Russia\n\n3 hours ago\n\nTHE DETAILS\n\n\"A missile that brought down Malaysia Airlines Flight 17 in eastern Ukraine in 2014 was fired from a launcher belonging to Russia's 53rd anti-aircraft missile brigade, investigators said Thursday. The announcement is the first time the investigative team has identified a specific division of the Russian military as possibly being involved in the strike. Russia has repeatedly denied involvement in the incident.\"\n\nSource:\n\nTHREE INTERVIEWS PLANNED FOR JUNE\n\nHouse GOP Will Conduct New Interviews in Clinton Probe\n\n3 hours ago\n\nTHE LATEST\n\n\"House Republicans are preparing to conduct the first interviews in over four months in their investigation into the FBI\u2019s handling of the Clinton email probe. A joint investigation run by the Judiciary and Oversight Committees has set three witness interviews for June, including testimony from Bill Priestap, the assistant director of the FBI\u2019s counterintelligence division, and Michael Steinbach, the former head of the FBI\u2019s national security division.\"\n\nSource:\n\nIN OPEN LETTER TO KIM JONG UN\n\nTrump Cancels North Korea Summit\n\n5 hours ago\n\nTHE LATEST\n\nGANG OF EIGHT WILL GET SEPARATE MEETING\n\nBriefings at White House Will Now Be Bipartisan\n\n7 hours ago\n\nTHE LATEST\n\n\"The White House confirmed Wednesday it is planning for a bipartisan group of House and Senate leaders, known as the 'Gang of 8,' to receive a highly-classified intelligence briefing on the FBI's investigation into Russian meddling, reversing plans to exclude Democrats altogether. ABC News first reported the plans to hold a separate briefing for Democrats, citing multiple administration and congressional sources. While details of the bipartisan meeting are still being worked out, a Republican-only briefing will go on as scheduled Thursday.\"", "meta": {"pile_set_name": "Pile-CC"}}
{"text": "HONG KONG \u2014 July 4th may be a holiday for Americans, but in China it is the eve of nationwide release of \u201cMan Of Tai Chi,\u201d the feature directing debut of Keanu Reeves.\n\nThat\u2019s a big deal for the Canadian star and part of a giant screen success story for China.\n\nIn addition to the film\u2019s July 5 release in an initial 1,600 conventional digital theaters, \u201cMan Of Tai Chi\u201d has also been re-mastered to a large screen format with IMAX DMR technology.\n\nIMAX insiders report that the picture has no edits or narrative differences from the conventional version, other than by now standard reworked image and sound enhancements.\n\nThe film is one of the first Chinese-language movies (it is actually in Mandarin, Cantonese and English) to be made in China by a North American and is a genuine made-in-China co-venture involving China Film Group, Wanda Media, Village Roadshow Pictures Asia, and Universal Pictures.\n\nThe contemporary action-drama was shot in Beijing and Hong Kong and is described as \u201cthe spiritual journey of a young martial artist,\u201d who is lured into the dark world of underground combat with promises of money, glamour and power. It has also been getting a lot of heat as the star has put in thousands of air miles touring the major cities of the Middle Kingdom and doing promo work at the recent Beijing, Shanghai and Cannes festivals.\n\nThe giant screen brand has been popular with China\u2019s status-obsessed new middle classes. Chinese audiences are willing to pay hefty premium prices for the giant screen and amped up sound systems.\n\nSo popular that more movies are being made or converted for the format and that earlier this year IMAX quietly dropped its previous policy of just showing a single title on each screen. \u201cMan of Tai Chi\u201d will have to compete for screen space with \u201cMan of Steel,\u201d and by Variety\u2019s count it appears to be getting play at some 116 venues in its opening frame.\n\nChinese, and to a lesser extent Korean, producers have been the keenest non-Hollywood film-makers to embrace IMAX presentation and in Sept 2012 leading local studio Huayi Brothers pacted with IMAX to deliver a minimum of seven future movies in IMAX format.\n\nMore than half a dozen Chinese films have been made or converted into IMAX, four flowing from Huayi; the Feng Xiaogang-directed \u201cAftershock\u201d and \u201c1942,\u201d and the Stephen Fung comedy action pair \u201cTai Chi Zero\u201d and \u201cTai Chi Hero.\u201d Other studios have also jumped in: CFG with \u201cThe Great Revival;\u201d Bona Film Group with Tsui Hark\u2019s \u201cFlying Swords of Dragon Gate;\u201d and the Jackie Chan production-starring vehicle \u201cCZ12,\u201d which Huayi released.\n\nIMAX is a huge commercial success story in China. As of March this year, the company had 110 screens in operation in China, compared with just 10 in 2010. That makes China IMAX\u2019s second biggest territory behind the US and its top international location.\n\nChina has witnessed some of the most gargantuan orders for new screens. While cinema chains in other territories have ordered IMAX screens in ones and twos, Dalian Wanda in March 2011 put in an order for 75 screens. In Nov 2012 South Korea\u2019s CGV booked 15 IMAX screens for its expanding Chinese theater circuit. With some 120-plus giant screens committed or under construction in China, IMAX has branch offices in both Beijing and Shanghai and last year launched a dedicated Chinese-language website.\n\n(Clifford Coonan in Beijing also contributed to this story.)", "meta": {"pile_set_name": "OpenWebText2"}}
{"text": "South Africa\u2019s top financial institutions have recommend in a new report that whistle-blowing be rewarded in an environment of growing corruption and mismanagement.\n\nThe 2018 Financial Markets Review, published by the South African Reserve Bank (SARB), in conjunction with Financial Sector Conduct Authority (FSCA), noted that international cases of misconduct in wholesale financial markets have focused the attention of regulators and market participants on measures to strengthen standards of market practice; and increase the accountability of financial institutions and individuals for the ethos and conduct of business.\n\n\u201cFollowing the global financial crisis of 2007\u201308, it was observed that senior executives and senior managers in many financial intuitions had a laissez-faire attitude towards corporate governance principles and risk culture within their institutions,\u201d the Reserve Bank said.\n\n\u201cThe international focus on strengthening codes and standards in light of misconduct scandals means that South Africa cannot afford to be complacent,\u201d it said.\n\nAs a result, South Africa\u2019s financial sector authorities \u2013 National Treasury, the South African Reserve Bank (SARB) and the FSCA established the Financial Markets Review Committee (FMRC) to develop recommendations to reinforce conduct standards in wholesale financial markets.\n\nThe report would focus on specific tools to strengthen the implementation and governance of conduct standards by market participants; and areas where changes to financial markets legislation and associated subordinate legislation are required to support a new conduct framework.\n\nRecommendations by Treasury in the Financial Markets Review, include, among other things, that regulators consider implementing a programme that rewards whistle-blowers for providing information about substantial misconduct in financial markets that leads to a successful enforcement action with monetary sanctions.\n\nThe report noted that in more opaque markets, whistle-blowers who inform regulators of suspected instances of misconduct can be a vital source of information to support regulation against misconduct.\n\n\u201cMarket regulators can incentivise market participants to provide such information by ensuring that necessary protections are in place so that no retaliation is taken against a whistle-blower for disclosure of information and, in certain circumstances, monetary rewards are provided,\u201d it said.\n\nIn the UK, the report highlighted that banks, building societies, large investment firms and insurers are required to establish and maintain an independent whistle-blowing channel through which staff may make disclosures.\n\nThese firms are also required to appoint a senior individual as a whistle-blowers\u2019 champion to ensure the effectiveness of the whistle-blowing arrangements.\n\nIn the US, the Securities and Exchanges Commission (SEC) has established a whistle-blower programme in terms of which the SEC is authorised to pay an award of between 10% and 30% of amounts collected if an eligible whistle-blower voluntarily provides original information that leads to a successful enforcement action with monetary sanctions exceeding $1 million.\n\nIn terms of whistle-blower protection, under the Wall Street Reform and Consumer Protection Act of 2010 (Dodd-Frank Act), \u201cno employer may discharge, demote, suspend, threaten or harass, directly or indirectly, or in any other manner discriminate against, a whistle-blower in the terms and conditions of employment because of any lawful act done by the whistle-blower\u201d.\n\nAn individual may bring a private right of action in federal court against his/her employer for such retaliation. In addition, the SEC may bring an enforcement action against a company for violation of these anti-retaliation provisions, the report stated.\n\nIn South Africa, Treasury pointed out that whistle-blowers are protected by legislation.\n\n\u201cThe Protected Disclosures Act 26 of 2000 makes provision for employees to report unlawful or irregular conduct by employers and fellow employees while providing protection for employees who blow the whistle.\u201d\n\n\u201cThe Act provides such protection for any disclosure made in good faith by an employee who reasonably believes that the information disclosed, and any allegation contained in it, is substantially true, and who does not make the disclosure for purposes of personal gain, excluding any reward payable in terms of any law.\u201d\n\nRead: The 10 biggest complaints on SA\u2019s anti-corruption hotline", "meta": {"pile_set_name": "OpenWebText2"}}
{"text": "This application is based upon and claims the benefit of priority from the prior Japanese Patent Application No. 2000-159163, filed Mar. 31, 2000, the entire contents of which are incorporated herein by reference.\nThe present invention relates to a method of forming a composite member, in which a conductive portion is formed in an insulator, the composite member being used in, for example, a wiring board in the fields of electric appliances, electronic appliances and electric and electronic communication. The present invention also relates to a photosensitive composition and an insulating material that can be suitably used in the manufacturing method of the composite member. Further, the present invention relates to a composite member manufactured by the manufacturing method of the present invention and to a multi-layer wiring board and an electronic package including the particular composite member.\nIn recent years, increase in the degree of integration and miniaturization of various electric and electronic parts including a semiconductor device are being promoted. The particular tendency will be further promoted in the future without fail. In this connection, various measures are being proposed and tried in an attempt to apply a high density mounting to a printed circuit board including formation of a fine pattern and a fine pitch of a metal wiring and formation of a steric wiring.\nParticularly, the steric wiring is indispensable to a high density mounting and, thus, various methods are being proposed in an attempt to manufacture a wiring board having a steric wiring. In general, the steric wirings are of a multi-layered structure such as a built-up wiring board prepared by laminating two dimensional printed wiring boards and a multi-layered wiring board. It is difficult to form a steric wiring having a free three dimensional shape. The built-up wiring board or the multi-layered wiring board has a structure that adjacent wiring layers are connected to each other by a conductive column called via. The via is formed by processing an insulating layer by a photolithography process using a photosensitive polyimide or resist, followed by selectively applying a plating to the via or by filling the via with a conductive paste. For forming a via by such a method, it is necessary to repeat a plurality of times the steps of resist coating, light exposure and etching, making the via formation highly laborious. In addition, it is difficult to improve the yield.\nIt is also possible to form the via by forming a through-hole (via hole) of a predetermined size in an insulating substrate constituting a printed wiring board by using a drill or a CO2 laser, followed by applying plating to the via hole or by filling the via hole with a conductive paste. In these methods, however, it is difficult to form freely a fine via having a size of scores of microns or less at a desired position.\nIn the method disclosed in Japanese Patent Disclosure No. 7-207450, a compound having a hydrophilic group is introduced into pores of three dimensional porous film such as a PTFE film. Under this condition, the film is subjected to a light exposure in a predetermined pattern by using a low pressure mercury lamp (wave lengths of 185 nm and 254 nm), thereby forming the hydrophilic group on the three dimensional porous film. Further, a metal plating is applied to the three dimensional porous film.\nIn the conventional method described above, however, the material forming the three dimensional porous film is deteriorated because a light beam having a short wavelength is used for the light exposure. Also, the light for the light exposure is absorbed by the three dimensional porous film and, thus, fails to reach the inner region of the porous body, resulting in failure to form fine vias.\nFurther, in the conventional method described above, the PTFE forming the three dimensional porous film reacts with the light for the light exposure so as to selectively form hydrophilic groups. However, PTFE is defective in that the molding workability is low and that PTFE is costly.\nAnother method of forming a via is disclosed in Japanese Patent Disclosure No. 11-24977. In this method, the entire surface of a porous insulating member is impregnated with a photosensitive composition containing, for example, a photosensitive reducing agent and a metal salt. Then, a light exposure is applied in a predetermined pattern to the impregnated insulating member so as to reduce the cation of the metal salt in the light exposed portion to a metal nucleus, followed by removing by washing the photosensitive composition in the non-light exposed portion. Further, an electroless plating or a soldering is applied to the residual metal nuclei so as to form vias of a predetermined pattern.\nIn the method described above, however, the entire surface of the porous insulating member is impregnated with a photosensitive composition containing a metal salt as described above, making it difficult to remove completely the metal salt adsorbed on the portion corresponding to the non-exposed portion after the light exposure step. As a result, a difficulty is brought about that the metal nuclei are precipitated on undesired portions in the subsequent reducing step. Such an abnormal deposition of the metal nuclei gives rise to a problem in terms of the insulating properties between adjacent vias and between adjacent wiring layers with progress in the fine pulverization of the pattern.\nAlso, in the via formed in the insulating substrate by the conventional method of manufacturing a wiring board, the insulating body and the conductive portion are brought into a direct contact. In this case, since the adhesion between the insulating body and the conductive portion is poor, a problem is generated that the conductive portion is peeled off the insulating substrate during the use.\nFurther, where a multi-layered wiring board is prepared by laminating a plurality of wiring boards manufactured by the conventional method of manufacturing a wiring board, it is required to further improve the electrical connection between the wiring layers of the wiring boards and the conductivity of the wiring.\nAn object of the present invention is to provide a method of manufacturing a composite member, which has a high degree of freedom in the design of a conductive circuit, in which deterioration of the insulating body is not brought about by the light exposure, and which is free from an abnormal deposition of a metal on the insulating body so as to form a conductive portion having a fine pattern.\nAnother object of the present invention is to provide a method of manufacturing a composite member, which has a high degree of freedom in the design of a conductive circuit, which permits manufacturing a composite member at a low manufacturing cost without giving adverse effects to the selectivity of the material of the insulating portion and to the molding workability, and which is free from an abnormal deposition of a metal on the insulating body so as to form a conductive portion having a fine pattern.\nAnother object of the present invention is to provide a photosensitive composition and an insulating material used for the manufacturing method of a composite member described above.\nAnother object of the present invention is to provide a composite member manufactured by the method described above.\nAnother object of the present invention is to provide a multi-layered wiring board comprising a composite member manufactured by the method described above.\nStill another object of the present invention is to provide an electronic package using a composite member or a multi-layered wiring board manufactured by the method described above.\nAccording to a first aspect of the present invention, there is provided a method of manufacturing a composite member in which a conductive portion is selectively formed in an insulating body, comprising:\n(1) forming a photosensitive composition layer within or on the surface of said insulating body, said photosensitive composition containing a compound forming an ion-exchange group upon irradiation with light having a wavelength not shorter than 280 nm;\n(2) exposing selectively the photosensitive composition layer to light having a wavelength not shorter than 280 nm so as to form ion-exchange groups in the light exposed portion; and\n(3) forming the conductive portion by bonding a metal ion or metal to the ion-exchange group formed in the light exposed portion by the exposing.\nAccording to a second aspect of the present invention, there is provided a method of manufacturing a composite member in which a conductive portion is selectively formed in an insulating body, comprising:\n(1) forming a photosensitive composition layer within or on the surface of said insulating body, said photosensitive composition containing a compound having an ion-exchange group;\n(2) exposing selectively the photosensitive composition layer to light having a wavelength not shorter than 280 nm so as to cause ion-exchange groups in the light exposed portion to disappear and to cause the ion-exchange groups to remain in the unexposed portion; and\n(3) forming the conductive portion by bonding a metal ion or metal to be bonded to the ion-exchange group remaining in the unexposed portion after the exposing.\nAccording to a third aspect of the present invention, there is provided a method of manufacturing a composite member in which a conductive portion is selectively formed in an insulating body, comprising:\n(1) forming a photosensitive composition layer within or on the surface of said insulating body, said photosensitive composition containing a compound forming an ion-exchange group upon irradiation with light, and said compound being selected from the group consisting of an onium salt derivative, a sulfonium ester derivative, a carboxylic acid derivative and a naphthoquinone diazide derivative;\n(2) exposing selectively the photosensitive composition layer to light so as to form ion-exchange groups in the light exposed portion; and\n(3) forming the conductive portion by bonding a metal ion or metal to the ion-exchange group formed in the light exposed portion by the exposing.\nAccording to a fourth aspect of the present invention, there is provided a method of manufacturing a composite member in which a conductive portion is selectively formed in an insulating body, comprising:\n(1) forming a photosensitive composition layer within or on the surface of said insulating body, said photosensitive composition containing a compound having an ion-exchange group;\n(2) exposing selectively the photosensitive composition layer to light so as to cause ion-exchange groups in the light exposed portion to disappear and to cause the ion-exchange groups to remain in the unexposed portion; and\n(3) forming the conductive portion by bonding a metal ion or metal to the ion-exchange group remaining in the unexposed portion after the light exposure in a pattern.\nAccording to a further aspect of the present invention, there is provided a method of manufacturing a composite member in which a conductive portion is selectively formed in an insulating body, comprising:\n(1) forming a photosensitive composition layer within or on the surface of said insulating body, said photosensitive composition containing a compound forming an ion-exchange group in the presence of acid and a photo acid generating agent;\n(2) exposing selectively to light and heating the photosensitive composition layer so as to form ion-exchange group in the light exposed portion; and\n(3) forming the conductive portion by bonding a metal ion or metal to the ion-exchange group formed in the light exposed portion by the exposing.\nIt is desirable for the method of the present invention to further comprise the step of applying an electroless plating to the surface of the conductive portion formed in the third step.\nAccording to another embodiment of the present invention, there is provided a photosensitive composition used for manufacturing a composite member, the composition containing a naphthoquinone diazide derivative and a polycarbodiimide derivative.\nAccording to another embodiment of the present invention, there is provided a porous insulating body having the inner surface of the pore covered with a photosensitive composition containing a naphthoquinone diazide derivative.\nAccording to another embodiment of the present invention, there is provided a composite member having a conductive portion formed on at least one of the surface and the inner region of a porous insulating body via an organic compound, wherein the amount of the organic compound, which is present between the insulating body and the conductive portion, per unit area of the surface of the insulating body is larger than the amount of the organic compound that is not in contact with the conductive portion.\nAccording to another embodiment of the present invention, there is provided a multi-layered wiring board including a plurality of substrates that are laminated one upon the other, wherein the substrate comprises a porous insulating body having fine pores and a conductive portion formed on at least one of the surface and the inner region of the fine pore of the porous insulating body, and a layer formed of a conductive body that does not contain the component of the insulating body is formed on the outermost surface of the conductive portion of each substrate.\nFurther, according to still another embodiment of the present invention, there is provided an electronic package comprising a wiring board consisting of the composite body described above or a multi-layered wiring board described above and an electronic part electrically connected to the wiring board.", "meta": {"pile_set_name": "USPTO Backgrounds"}}
{"text": "The Indian supermarket will add 4,000 square feet to its current space. View Full Caption DNAinfo/Katie Honan\n\nJACKSON HEIGHTS \u2014 Indian grocery store Patel Brothers is planning a renovation and expansion at its 74th Street location that will feature a larger produce section and wider aisles, according to its manager.\n\nThe 7,000-square-foot store, which opened at 37-27 74th St. in 1984, will grow by another 4,000 square feet by taking over the former Mumbai Grill next door, manager Dapash Patel said.\n\nThe owners wanted to create more space in the busy supermarket, which is known for its authentic Indian groceries, spices and imported food.\n\n\"This is too small,\" Patel said. \"It's getting a little crowded.\"\n\nThe expansion should be finished in August, and will create wider aisles and a larger produce department and frozen food aisle, according to Patel.\n\nThe store will stay open during construction, and its existing space will also be renovated once the expansion is complete, he said.\n\nThe Patel brothers opened their first supermarket in 1974 in Chicago, and now have 53 locations across the country.", "meta": {"pile_set_name": "OpenWebText2"}}
{"text": "Dorsomedial hypothalamic lesions alter intake of an imbalanced amino acid diet in rats.\nWithin 3 h of ingesting an imbalanced amino acid diet (IAAD), rats show attenuated intake. The associated conditioned taste aversion can be ameliorated by giving the serotonin3 receptor blocker, tropisetron (TROP). A recent c-fos study indicated that the dorsomedial hypothalamic nucleus (DMN) may be activated 2-3 h after ingestion of IAAD. In Experiment 1, DMN-lesioned rats (DMNL) or sham-operated (SHAM) rats were injected with saline (SAL) or TROP just before introduction of IAAD. By 3 h, SAL-DMNL rats consumed more (P < 0.01) of the IAAD than did the SAL-SHAM rats. Thereafter, over the next 21 h, the intake of the SAL-DMNL group returned to control levels. TROP treatment enhanced the intake of the treated groups; the TROP and the lesion effect were additive (P < 0.01). By d 4 of receiving the IAAD, the DMNL groups were eating less than SHAM rats (P < 0.05). The data suggest that the DMN may be involved in the early detection of the amino acid deficiency induced by IAAD, is not involved in the TROP effect and is necessary for proper long-term adaptation to an IAAD.", "meta": {"pile_set_name": "PubMed Abstracts"}}
{"text": "Tag: Eloy Casados\n\nOriginal US release date: December 5, 2008 Production budget: $25,000,000 Worldwide gross: $27,426,335 There are timely films and then there are films that are before their time. Ron Howard is probably seen by most as a director who frequently makes good or very good films and occasionally makes a great one. Most recently, a lot... Continue Reading \u2192", "meta": {"pile_set_name": "Pile-CC"}}
{"text": "The present invention relates generally to improved means and methods for processing documents using electronic imaging, and more particularly, to the use of electronic imaging for processing financial documents, such as checks and related documents in a banking environment.\nToday's financial services industry is facing the immense challenge of processing huge amounts of documents efficiently. Predictions that document payment methods would decline have not been realized. In fact, document payment methods have grown worldwide and are expected to continue increasing. There is thus a vital need to devise improved means and methods for processing such documents.\nThe use of imaging technology as an aid to document processing has been recognized as one way of significantly improving document processing, as disclosed, for example, in U.S. Pat. Nos. 4,205,780, 4,264,808, and 4,672,186. Generally, imaging involves optically scanning documents to produce electronic images that are processed electronically and stored on high capacity storage media (such as magnetic disc drives and/or optical memory) for later retrieval and display. It is apparent that document imaging provides the opportunity to reduce document handling and movement, since these electronic images can be used in place of the actual documents.\nHowever, despite technological advances in imaging in recent years, prior art document processing systems employing imaging, such as disclosed in the aforementioned patents, do not realized sufficient improvements to justify the added implementations costs.", "meta": {"pile_set_name": "USPTO Backgrounds"}}
{"text": "At our best, we motivate ourselves every day to get dressed and go to work or school. Although there are larger incentives at work, it's our own volition that powers us through our innumerable daily tasks.\n\nIf we could learn to control the motivational centers of our brains that drive volition, would it lead us toward healthier, more productive lives? Using a new brain imaging strategy, Duke University scientists have now taken a first step in understanding how to manipulate specific neural circuits using thoughts and imagery.\n\nThe technique, which is described in the March 16 issue of the journal Neuron, is part of a larger approach called 'neurofeedback,' which gives participants a dynamic readout of brain activity, in this case from a brain area critical for motivation.\n\n\"These methods show a direct route for manipulating brain networks centrally involved in healthy brain function and daily behavior,\" said the study's senior investigator R. Alison Adcock, an assistant professor of psychiatry and behavioral sciences and associate director of the Center for Cognitive Neuroscience in the Duke University Institute for Brain Sciences.\n\nNeurofeedback is a specialized form of biofeedback, a technique that allows people to monitor aspects of their own physiology, such as heart rate and skin temperature. It can help generate strategies to overcome anxiety and stress or to cope with other medical conditions.\n\nNeurofeedback has historically relied on electroencephalography or EEG, in which patterns of electrical activity are monitored noninvasively by electrodes attached to the scalp. But these measures provide only rough estimates of where activity occurs in the brain.\n\nadvertisement\n\nIn contrast, the new study employed functional magnetic resonance imaging (fMRI), which measures changes in blood oxygen levels, allowing more precisely localized measurements of brain activity.\n\nAdcock's team has been working on ways to use thoughts and behavior to tune brain function for the past eight years. In this time, they've developed tools allowing them to analyze complex brain imaging data in real time and to display it to participants as neurofeedback while they are in the fMRI scanner.\n\nThis study focused on the ventral tegmental area (VTA), a small area deep within the brain that is a major source of dopamine, a neurochemical well known for its role in motivation, experiencing rewards, learning, and memory.\n\nAccording to Adcock's previous research, when people are given incentives to remember specific images, an increase in VTA activation before the image appears predicts whether the participants are going to successfully remember the image.\n\nExternal incentives like money work well to stimulate the VTA, but it was unclear whether people could exercise this area on their own, said co-author Jeff MacInnes, a postdoctoral researcher in Adcock's lab.\n\nadvertisement\n\nIn the new study, the team encouraged participants in the scanner to generate feelings of motivation -- using their own personal strategies -- during 20-second intervals. They weren't able to raise their VTA activity consistently on their own.\n\nBut when the scientists provided participants with neurofeedback from the VTA, presented in the form of a fluctuating thermometer, participants were able to learn which strategies worked, and ultimately adopt more effective strategies. Compared to control groups, the neurofeedback-trained participants successfully elevated their VTA activity.\n\nParticipants reported using a variety of different motivational strategies, from imagining parents or coaches encouraging them, to playing out hypothetical scenarios in which their efforts were rewarded, said co-author Kathryn Dickerson, a postdoctoral researcher in Adcock's group.\n\nThe self-generated boost in VTA activation worked even after the thermometer display was removed. Only the participants who had received accurate neurofeedback were able to consistently raise their VTA levels.\n\n\"Because this is the first demonstration of its kind, there is much still to be understood,\" Adcock added. \"But these tools could offer benefits for everyone, particularly those with depression or attention problems.\"\n\nThe neurofeedback training also activated other regions involved in learning and experiencing rewards, confirming that, at least in the short term, the brain changes its activity more broadly as a result of neurofeedback, Dickerson said.\n\nAdcock said one caveat of the study is that the team has not tested whether the neurofeedback drove changes in behavior. The group is working on those studies now and also plans to conduct the same study in participants with depression and attention deficit hyperactivity disorder (ADHD).\n\nThis research was supported by the National Institute of Mental Health (MH9743, MH100764), the Alfred P. Sloan Foundation, the Esther A. & Joseph Klingenstein Fund, and the Dana Foundation.", "meta": {"pile_set_name": "OpenWebText2"}}
{"text": "     The summaries of the Colorado Court of Appeals published opinions\n  constitute no part of the opinion of the division but have been prepared by\n  the division for the convenience of the reader. The summaries may not be\n    cited or relied upon as they are not the official language of the division.\n  Any discrepancy between the language in the summary and in the opinion\n           should be resolved in favor of the language in the opinion.\n\n\n                                                                  SUMMARY\n                                                            February 8, 2018\n\n                                2018COA12\n\nNo. 14CA0144, People v. Trujillo \u2014 Criminal Law \u2014 Sentencing\n\u2014 Probation \u2014 Indeterminate Sentence\n\n     A division of the court of appeals considers whether a\n\nColorado statute authorizes imposition of a sentence to an\n\nindeterminate term of probation and whether the defendant was\n\nentitled to the benefit of amendments to the statute criminalizing\n\ntheft. Relying on People v. Jenkins, 2013 COA 76, 305 P.3d 420,\n\nthe division concludes that section 18-1.3-202(1), C.R.S. 2017,\n\nprovides statutory authority for the imposition of an indeterminate\n\nprobation sentence. Following People v. Stellabotte, 2016 COA 106,\n\n___ P.3d ___ (cert. granted Feb. 6, 2017), the majority further\n\nconcludes that the defendant is entitled to the benefit of\n\namendments to the theft statute. The partial dissent concludes\n\fthat the amendments to the theft statute do not apply retroactively,\n\nand would therefore affirm the sentence in full.\n\n     Additionally, the division rejects the defendant\u2019s contentions\n\nthat reversal is required due to the trial court\u2019s rejection of\n\ndefense-tendered jury instructions, wrongfully admitted character\n\nevidence, and prosecutorial misconduct. However, the division\n\nremands for the trial court to make findings of fact concerning the\n\nassessment of the costs of prosecution.\n\n     Accordingly, the division affirms the conviction, affirms the\n\nsentence in part, vacates the sentence in part, and remands the\n\ncase with directions.\n\fCOLORADO COURT OF APPEALS                                          2018COA12\n\n\nCourt of Appeals No. 14CA0144\nMesa County District Court No. 11CR447\nHonorable Valerie J. Robison, Judge\n\n\nThe People of the State of Colorado,\n\nPlaintiff-Appellee,\n\nv.\n\nMichael Floyd Trujillo,\n\nDefendant-Appellant.\n\n\n         JUDGMENT AFFIRMED, SENTENCE AFFIRMED IN PART AND\n        VACATED IN PART, AND CASE REMANDED WITH DIRECTIONS\n\n                                  Division I\n                        Opinion by JUDGE TAUBMAN\n                             Richman, J., concurs\n                Furman, J., concurs in part and dissents in part\n\n                          Announced February 8, 2018\n\n\nCynthia H. Coffman, Attorney General, Joseph G. Michaels, Assistant Attorney\nGeneral, Denver, Colorado, for Plaintiff-Appellee\n\nDouglas K. Wilson, Colorado State Public Defender, James S. Hardy, Deputy\nState Public Defender, Denver, Colorado, for Defendant-Appellant\n\f\u00b61    Defendant, Michael Floyd Trujillo, appeals his judgment of\n\n conviction entered on a jury verdict finding him guilty of one count\n\n of theft of more than $20,000 and one count of criminal mischief of\n\n $20,000 or more. He also appeals his sentence. We perceive no\n\n basis for reversing his convictions, but remand for the trial court to\n\n make findings of fact regarding the assessment of the costs of\n\n prosecution and to reclassify his theft conviction as a class 4 felony.\n\n                            I. Background\n\n\u00b62    In 2007, Trujillo began building a home, doing much of the\n\n labor himself and initially using his own money to fund the project.\n\n He later took out a construction loan from the victim, a bank, for\n\n just under $255,000. After construction was completed on the\n\n house, Trujillo stopped making his monthly loan payments. The\n\n bank declined to restructure the loan and initiated foreclosure\n\n proceedings in September 2010.\n\n\u00b63    Before the foreclosure sale, Trujillo removed or destroyed\n\n property in the house, including kitchen cabinets, countertops,\n\n interior and exterior doors, doorjambs and casings, flooring,\n\n baseboards, light fixtures, bathroom fixtures, the fireplace,\n\n handrails, the boiler, the air conditioner, and the garage door.\n\n\n                                    1\n\f Because of this damage, the house was appraised at $150,000;\n\n however, the appraiser estimated that if the house were in good\n\n repair, it would have been worth $320,000.\n\n\u00b64    Trujillo was charged with defrauding a secured creditor, theft\n\n of $20,000 or more, but less than $100,000, and criminal mischief\n\n of $20,000 or more, but less than $100,000. The jury found him\n\n not guilty of defrauding a secured creditor and guilty of theft and\n\n criminal mischief.\n\n\u00b65    On appeal, Trujillo raises six contentions: (1) the trial court\n\n erred in rejecting defense-tendered jury instructions; (2) the trial\n\n court erred in allowing evidence of a prior foreclosure against\n\n Trujillo; (3) prosecutorial misconduct during direct examination of a\n\n witness and closing rebuttal argument warrants reversal; (4) the\n\n trial court imposed an illegal sentence of indeterminate probation;\n\n (5) the trial court erred in awarding the People costs of prosecution;\n\n and (6) an amendment to the theft statute applies to his conviction.\n\n We perceive no basis for reversal with respect to the first four\n\n contentions, but agree with Trujillo\u2019s final two contentions. We\n\n therefore affirm the convictions and the sentence in part but vacate\n\n the sentence in part and remand with directions.\n\n\n                                    2\n\f                          II. Jury Instructions\n\n\u00b66    Trujillo asserts that the trial court erred in rejecting various\n\n jury instructions regarding his theory of the case. We disagree.\n\n                           A. Additional Facts\n\n\u00b67    Throughout trial, the defense\u2019s theory of the case was that\n\n Trujillo lacked the requisite intent to commit the charged offenses\n\n because he believed that the property he removed from the house\n\n belonged to him. The defense tendered five jury instructions related\n\n to this theory of the case.\n\n\u00b68    Trujillo\u2019s tendered jury instructions detailed property law\n\n concepts. For example, the first tendered instruction stated that\n\n \u201cthe person who has title to real property is still the owner of the\n\n property even if there is a lien or secured interest on the property.\u201d\n\n Another tendered instruction defined \u201ctitle,\u201d \u201cdeed of trust,\u201d and\n\n \u201cholder of a certificate of purchase[].\u201d One instruction described the\n\n lien theory detailed in section 38-35-117, C.R.S. 2017, and another\n\n instructed that title to property \u201cdoes not vest with the purchaser\n\n until eight days after [a] foreclosure sale.\u201d\n\n\u00b69    The trial court declined to give these instructions as tendered.\n\n However, portions of the defense-tendered instructions were\n\n\n                                     3\n\f  included in a final definitional jury instruction. The final\n\n  instructions defined \u201cdeed of trust\u201d and stated that the title to\n\n  property is transferred to the holder of the certificate of purchase\n\n  eight days after a foreclosure sale. Though it rejected other\n\n  portions of the defense-tendered instructions, the trial court\n\n  permitted defense counsel to argue the issues raised in the\n\n  instructions during closing argument.\n\n\u00b6 10   The defense also tendered an instruction which the trial court\n\n  modified and gave as a theory of the case instruction. That\n\n  instruction stated, \u201cTrujillo contends that the items removed from\n\n  the home . . . were his; purchased by him and installed by him. . . .\n\n  Trujillo conten[d]s that the items that he took and damaged were\n\n  his sole property.\u201d\n\n                         B. Standard of Review\n\n\u00b6 11   We review jury instructions de novo to determine whether, as\n\n  a whole, they accurately informed the jury of the governing law.\n\n  Riley v. People, 266 P.3d 1089, 1092-93 (Colo. 2011). If the jury\n\n  instructions properly inform the jury of the law, the district court\n\n  has \u201cbroad discretion to determine the form and style of jury\n\n  instructions.\u201d Day v. Johnson, 255 P.3d 1064, 1067 (Colo. 2011).\n\n\n                                     4\n\f  Accordingly, we review a trial court\u2019s decision concerning a\n\n  proposed jury instruction for an abuse of discretion and will not\n\n  disturb the ruling unless it is manifestly arbitrary, unreasonable, or\n\n  unfair. Id.\n\n\u00b6 12   When a defendant objects to the trial court\u2019s ruling on a jury\n\n  instruction, we review for nonconstitutional harmless error and will\n\n  thus affirm if \u201cthere is not a reasonable probability that the error\n\n  contributed to the defendant\u2019s conviction.\u201d People v. Garcia, 28\n\n  P.3d 340, 344 (Colo. 2001) (quoting Salcedo v. People, 999 P.2d\n\n  833, 841 (Colo. 2000)).\n\n                            C. Applicable Law\n\n\u00b6 13   \u201c[A]n instruction embodying a defendant\u2019s theory of the case\n\n  must be given by the trial court if the record contains any evidence\n\n  to support the theory.\u201d People v. Nunez, 841 P.2d 261, 264 (Colo.\n\n  1992). Moreover, a trial court has \u201can affirmative obligation\u201d to\n\n  work with counsel to correct a tendered theory of the case\n\n  instruction \u201cor to incorporate the substance of such in an\n\n  instruction drafted by the court.\u201d Id. at 265; see also People v.\n\n  Tippett, 733 P.2d 1183, 1195 (Colo. 1987) (a trial court may refuse\n\n  to give an instruction already embodied in other instructions).\n\n\n                                     5\n\f\u00b6 14   In considering whether a jury was adequately informed of a\n\n  defendant\u2019s theory of the case, a reviewing court can take into\n\n  account whether defense counsel\u2019s closing argument \u201cfairly\n\n  represented\u201d the theory to the jury. People v. Dore, 997 P.2d 1214,\n\n  1222 (Colo. App. 1999).\n\n                               D. Analysis\n\n\u00b6 15   Trujillo contends that the trial court abused its discretion in\n\n  rejecting the tendered instructions. We disagree.\n\n\u00b6 16   Trujillo asserts that the tendered instructions were essential\n\n  because they communicated his theory of the case. However, the\n\n  trial court instructed the jury on his theory of the case in an\n\n  instruction that clearly stated that he believed the property he took\n\n  from the house was \u201chis sole property.\u201d To the extent that the trial\n\n  court had a duty to work with the defense in crafting a proper\n\n  theory of defense instruction, we conclude that the trial court\n\n  fulfilled that duty here by giving an alternative theory of the case\n\n  instruction that encompassed Trujillo\u2019s tendered instructions. See\n\n  Nunez, 841 P.2d at 265 n.9. Moreover, the trial court specifically\n\n  stated that defense counsel would be allowed to incorporate the\n\n\n\n\n                                     6\n\f  property law concepts into her closing argument, which defense\n\n  counsel did.\n\n\u00b6 17   Trujillo asserts that the instructions he tendered were\n\n  accurate statements of property law. In contrast, the People argue\n\n  that the instructions misstated the law as it applies in criminal\n\n  prosecutions for theft and criminal mischief. Because we conclude\n\n  that the trial court did not abuse its discretion in drafting a theory\n\n  of defense instruction that encompassed the defense\u2019s tendered\n\n  instructions, we do not address whether the rejected instructions\n\n  were accurate statements of the law.\n\n\u00b6 18   The jury instructions, as a whole, \u201cfairly and adequately\n\n  cover[ed] the issues presented.\u201d People v. Pahl, 169 P.3d 169, 183\n\n  (Colo. App. 2006). Thus, we conclude that the trial court did not\n\n  abuse its discretion in rejecting in part the defense-tendered jury\n\n  instructions.\n\n                    III. Evidence of Prior Foreclosure\n\n\u00b6 19   Trujillo next asserts that the trial court erred in allowing the\n\n  People to introduce evidence that another property of his had been\n\n  foreclosed. We disagree.\n\n\n\n\n                                     7\n\f                           A. Additional Facts\n\n\u00b6 20   Before trial, Trujillo filed a motion to exclude evidence of other\n\n  acts or res gestae evidence. Trujillo\u2019s motion addressed several\n\n  categories of other acts evidence, including evidence related to any\n\n  \u201cfinancial and/or legal problems\u201d unrelated to the charged offenses.\n\n  During a motions hearing, the People stated that they did not\n\n  intend to introduce any other acts or res gestae evidence. In a\n\n  written ruling, the trial court granted Trujillo\u2019s motion to exclude\n\n  evidence of his unrelated financial and legal problems \u201cunless the\n\n  prosecution fe[lt] that the \u2018door ha[d] been opened.\u2019\u201d The trial court\n\n  further ordered that, if the People felt Trujillo introduced evidence of\n\n  his other financial and legal problems, the People could request a\n\n  bench conference during trial.\n\n\u00b6 21   On the first day of trial, defense counsel stated that she was\n\n  withdrawing her motion to exclude other acts evidence insofar as it\n\n  pertained to evidence of Trujillo\u2019s bankruptcy proceedings. During\n\n  her opening statement, defense counsel then mentioned those\n\n  proceedings.\n\n\u00b6 22   Later, the People called the bank\u2019s former vice president as an\n\n  expert witness. During direct examination, the prosecutor asked\n\n\n                                     8\n\f  the witness why the bank had declined to restructure Trujillo\u2019s\n\n  loan. The prosecutor also asked about Trujillo\u2019s demeanor during\n\n  interactions with the bank. Trujillo objected. After a bench\n\n  conference, the trial court allowed the witness to testify on both\n\n  matters.\n\n\u00b6 23   Specifically, the witness testified that, during a conversation\n\n  about restructuring the loan, Trujillo \u201cseemed like he was very\n\n  upset.\u201d The witness recalled, \u201cHe got into [that] he had a piece of\n\n  property that [another bank] had foreclosed on and it sounded like\n\n  they had sold it for what [Trujillo] believed was a lot less, leaving\n\n  him a large deficiency balance.\u201d\n\n\u00b6 24   During closing argument, the People alluded to the witness\u2019s\n\n  testimony and referred several times to Trujillo\u2019s general animosity\n\n  against banks.\n\n                          B. Standard of Review\n\n\u00b6 25   We review a trial court\u2019s decision to admit other acts or res\n\n  gestae evidence for an abuse of discretion. People v. Jimenez, 217\n\n  P.3d 841, 846 (Colo. App. 2008). A court abuses its discretion if its\n\n  decision to admit such evidence is manifestly arbitrary,\n\n  unreasonable, or unfair. Id.\n\n\n                                      9\n\f\u00b6 26   We review a preserved claim of nonconstitutional error for\n\n  harmless error, reversing only if any error \u201csubstantially influenced\n\n  the verdict or affected the fairness of the trial proceedings.\u201d Hagos\n\n  v. People, 2012 CO 63, \u00b6 12, 288 P.3d 116, 119 (quoting Tevlin v.\n\n  People, 715 P.2d 338, 342 (Colo. 1986)).\n\n                           C. Applicable Law\n\n\u00b6 27   Evidence is relevant if it has \u201cany tendency to make the\n\n  existence of any fact that is of consequence to the determination of\n\n  the action more probable or less probable than it would be without\n\n  the evidence.\u201d CRE 401. Generally speaking, \u201c[t]he Colorado Rules\n\n  of Evidence strongly favor the admission of relevant evidence.\u201d\n\n  People v. Brown, 2014 COA 155M-2, \u00b6 22, 360 P.3d 167, 172.\n\n  However, relevant evidence is nevertheless inadmissible when \u201cits\n\n  probative value is substantially outweighed by the danger of unfair\n\n  prejudice, confusion of the issues, or misleading the jury.\u201d CRE\n\n  403. Similarly, evidence of \u201cother crimes, wrongs, or acts\u201d is\n\n  inadmissible to prove a person\u2019s character \u201cin order to show that he\n\n  acted in conformity therewith,\u201d though it may be admissible for\n\n  other purposes, including proving intent. CRE 404(b).\n\n\n\n\n                                    10\n\f\u00b6 28   \u201cRes gestae is a theory of relevance which recognizes that\n\n  certain evidence is relevant because of its unique relationship to the\n\n  charged crime.\u201d People v. Greenlee, 200 P.3d 363, 368 (Colo. 2009).\n\n  However, \u201cthere is no need to consider an alternative theory of\n\n  relevance, such as res gestae, where the evidence is admissible\n\n  under general rules of relevancy.\u201d Id.\n\n                               D. Analysis\n\n\u00b6 29   Trujillo contends that the evidence of the prior foreclosure\n\n  action portrayed him as a \u201cserial defaulter\u201d and was impermissible\n\n  under CRE 404(b) and 403. The People assert that the evidence\n\n  was admissible as \u201cdirectly relevant\u201d to Trujillo\u2019s intent and motive.\n\n  In the alternative, the People argue that the evidence was res gestae\n\n  evidence. We agree with the People\u2019s first argument that the\n\n  evidence was admissible under CRE 401, and was not barred by\n\n  CRE 403.1\n\n\n\n  1 During the bench conference, the trial court allowed the bank\u2019s\n  former vice president to testify after conducting an abbreviated CRE\n  404(b) analysis that did not specifically address the four-factor test\n  set forth in People v. Spoto, 795 P.2d 1314, 1318 (Colo. 1990). The\n  trial court did not admit the evidence under the res gestae doctrine.\n  However, we can affirm a trial court\u2019s evidentiary ruling on any\n  ground supported by the record, \u201ceven if that ground was not\n\n                                    11\n\f\u00b6 30   The evidence of the prior foreclosure was probative of the\n\n  interactions between Trujillo and the bank \u2014 it made it more\n\n  probable that Trujillo had the requisite intent to commit theft. It\n\n  was therefore relevant under CRE 401. Further, the risk of unfair\n\n  prejudice did not substantially outweigh the probative value of the\n\n  evidence, especially where the prior foreclosure was referenced only\n\n  in passing and the details of that foreclosure were not revealed.\n\n  Thus, the evidence was not barred by CRE 403.\n\n\u00b6 31   Because we conclude that the evidence of the prior foreclosure\n\n  was relevant under CRE 401 and admissible under CRE 403, we\n\n  need not address whether the evidence was res gestae evidence or\n\n  \u201cother acts\u201d evidence under CRE 404(b). See Greenlee, 200 P.3d at\n\n  368-69. Accordingly, we conclude that the trial court did not err in\n\n  allowing the testimony concerning the prior foreclosure action.\n\n                      IV. Prosecutorial Misconduct\n\n\u00b6 32   Trujillo argues that the prosecutor improperly commented on\n\n  the district attorney\u2019s screening process for bringing charges and\n\n\n\n\n  articulated or considered by the trial court.\u201d People v. Phillips, 2012\n  COA 176, \u00b6 63, 315 P.3d 136, 153.\n\n                                    12\n\f  Trujillo\u2019s right not to testify, and improperly denigrated defense\n\n  counsel. We perceive no basis for reversal.\n\n                           A. Additional Facts\n\n\u00b6 33   During redirect examination of one of the People\u2019s expert\n\n  witnesses, an attorney who worked at the bank, the prosecutor\n\n  asked whether the bank played a role in charging Trujillo. The\n\n  prosecutor asked if the witness himself made the decision to file a\n\n  criminal case, to which the witness replied, \u201cNo.\u201d The prosecutor\n\n  then asked, \u201c[W]ho is it, according to your understanding, that\n\n  makes those decisions on whether a case gets filed criminally?\u201d The\n\n  witness responded, \u201cA complaint\u2019s made to a police department or\n\n  sheriff\u2019s department and they make that decision in conjunction\n\n  with I believe you.\u201d The prosecutor clarified that \u201cyou\u201d meant the\n\n  district attorney\u2019s office. The defense did not object.\n\n\u00b6 34   During rebuttal closing argument, the prosecutor said,\n\n             Did you hear all that? [Defense counsel]\u2019s\n             talking about all of this stuff, about what\n             Trujillo\u2019s intent was. And then did you hear\n             her towards the end what she did? She says,\n             and correct \u2013 this part was correct of what she\n             said. My job is to prove intent, right. That is\n             my burden. And she\u2019s absolutely right. The\n             Defendant has every right to remain silent,\n\n\n\n                                    13\n\f            and he exercised that right and that is\n            something that you cannot use against him.\n\n            But it is completely ridiculous for [defense\n            counsel] to get up here and say that [Trujillo]\n            didn\u2019t testify to what his intent was and then\n            to go on and talk about what his intent\n            actually was. We don\u2019t know what his intent\n            was because he never testified to that, which\n            he has every right to do. But did you hear\n            her? She\u2019s up here saying his intent was this.\n\n\u00b6 35   Trujillo objected on the basis that the prosecutor was\n\n  denigrating defense counsel. The trial court sustained the objection\n\n  as to the prosecutor\u2019s tone, but overruled it as to content. The\n\n  prosecutor then argued, \u201c[I]f you go out and run somebody over and\n\n  \u2013 and think that you had the right to do that, is that gonna be a\n\n  legitimate defense by saying, well, I thought I could do that. I didn\u2019t\n\n  \u2013 nobody ever told me. Nobody put it in writing. When I bought my\n\n  car, in the instruction manual, nothing said that about that. That\u2019s\n\n  preposterous.\u201d Trujillo did not renew his objection.\n\n                         B. Standard of Review\n\n\u00b6 36   In reviewing alleged prosecutorial misconduct, an appellate\n\n  court engages in a two-step analysis. First, we determine whether\n\n  the prosecutor\u2019s conduct was improper based on the totality of the\n\n  circumstances. Wend v. People, 235 P.3d 1089, 1096 (Colo. 2010).\n\n\n                                    14\n\f  Second, we determine whether any misconduct warrants reversal\n\n  under the proper standard of review. Id.\n\n\u00b6 37   When the alleged misconduct is objected to at trial and is of\n\n  constitutional magnitude, we review for constitutional harmless\n\n  error. Id. When the alleged misconduct is not of a constitutional\n\n  magnitude, and when the defense objected at trial, we subject the\n\n  prosecutorial misconduct to harmless error review. Id. at 1097.\n\n  Such prosecutorial misconduct will be considered harmless\n\n  \u201cwhenever there is no reasonable probability that it contributed to\n\n  the defendant\u2019s conviction.\u201d Crider v. People, 186 P.3d 39, 42 (Colo.\n\n  2008). When the defense did not object to the misconduct, we\n\n  review for plain error. Wend, 235 P.3d at 1097-98.\n\n                           C. Applicable Law\n\n\u00b6 38   A prosecutor cannot comment on a \u201cscreening process\u201d for\n\n  charging cases \u201cbecause it both hints that additional evidence\n\n  supporting guilt exists and reveals the personal opinion of the\n\n  prosecutor.\u201d Domingo-Gomez v. People, 125 P.3d 1043, 1052 (Colo.\n\n  2005). It is also improper for a prosecutor to make remarks \u201cfor the\n\n  obvious purpose of denigrating defense counsel.\u201d People v. Jones,\n\n  832 P.2d 1036, 1038 (Colo. App. 1991). It is similarly improper for\n\n\n                                   15\n\f  a prosecutor to comment on a defendant\u2019s decision not to testify.\n\n  Griffin v. California, 380 U.S. 609, 614 (1965); see also People v.\n\n  Martinez, 652 P.2d 174, 177 (Colo. App. 1981) (noting that a\n\n  prosecutor\u2019s comment on a defendant\u2019s silence constitutes\n\n  reversible error when \u201cthe prosecution argued that such silence\n\n  constituted an implied admission of guilt\u201d).\n\n\u00b6 39   Nevertheless, \u201c[a] prosecutor is allowed considerable latitude\n\n  in responding to the argument made by opposing counsel.\u201d People\n\n  v. Ramirez, 997 P.2d 1200, 1211 (Colo. App. 1999), aff\u2019d, 43 P.3d\n\n  611 (Colo. 2001). Further, \u201c[a]lthough it is improper for a\n\n  prosecutor to assert that opposing counsel knows that the\n\n  accused\u2019s case is not meritorious,\u201d the prosecutor may permissibly\n\n  argue \u201cthat the evidence in support of defendant\u2019s innocence lacked\n\n  substance.\u201d Id. at 1211; see also People v. Samson, 2012 COA 167,\n\n  \u00b6 31, 302 P.3d 311, 317 (stating that a prosecutor may permissibly\n\n  \u201ccomment on the absence of evidence to support a defendant\u2019s\n\n  contentions\u201d).\n\n\u00b6 40   Appellate courts consider several factors in determining\n\n  whether prosecutorial misconduct was prejudicial, including the\n\n  nature of the error, the pervasiveness of the misconduct, the\n\n\n                                    16\n\f  context, and the overall strength of the evidence supporting the\n\n  conviction. People v. McBride, 228 P.3d 216, 225 (Colo. App. 2009);\n\n  see also Crider, 186 P.3d at 43. For example, a reviewing court may\n\n  consider whether proper jury instructions mitigated the prejudicial\n\n  effect of prosecutorial misconduct. See People v. Castillo, 2014 COA\n\n  140M, \u00b6 78, ___ P.3d ___, ___ (concluding prosecutor\u2019s\n\n  misstatements were harmless in light of instructions from the trial\n\n  court and the defense\u2019s closing argument) (cert. granted in part Nov.\n\n  23, 2015).\n\n                               D. Analysis\n\n\u00b6 41   Trujillo contends that three instances of prosecutorial\n\n  misconduct require reversal. We disagree.\n\n\u00b6 42   Trujillo first contends that the prosecutor improperly referred\n\n  to a screening process while examining the expert witness. We\n\n  perceive no prosecutorial misconduct. The prosecutor here did not\n\n  imply that he had engaged in a screening process to \u201cweed out the\n\n  weaker cases and, implicitly, that the State d[id] not consider this a\n\n  weak case.\u201d Domingo-Gomez, 125 P.3d at 1052 (concluding the\n\n  prosecutor\u2019s comment that \u201cit takes a lot more than somebody\n\n  saying that person did it\u201d to bring charges was improper). Rather,\n\n\n                                    17\n\f  the prosecutor clarified that the bank did not bring criminal\n\n  charges and that the witness himself did not stand to gain as a\n\n  result of Trujillo\u2019s conviction. The People assert, and we agree, that\n\n  the prosecutor\u2019s question merely elicited testimony to establish that\n\n  the district attorney\u2019s office was responsible for pursuing the\n\n  criminal charges against Trujillo.\n\n\u00b6 43   Second, Trujillo asserts that the prosecutor impermissibly\n\n  commented on his decision not to testify. We disagree. Even if we\n\n  assume the comment on Trujillo\u2019s decision not to testify was\n\n  improper, not every comment on a defendant\u2019s choice not to testify\n\n  requires reversal. See Martinez, 652 P.2d at 177. \u201cThe determining\n\n  factor is whether the defendant\u2019s silence was used by the\n\n  prosecution as a means of creating an inference of guilt,\u201d id., and\n\n  we conclude that the prosecutor\u2019s comments here did not raise\n\n  such an inference.\n\n\u00b6 44   Finally, Trujillo contends that the prosecutor impermissibly\n\n  denigrated defense counsel and the defense\u2019s theory of the case\n\n  during rebuttal closing argument. We agree that the prosecutor\n\n  improperly denigrated defense counsel and the defense\u2019s theory of\n\n\n\n\n                                       18\n\f  the case when he characterized her arguments as \u201ccompletely\n\n  ridiculous\u201d and \u201cpreposterous.\u201d\n\n\u00b6 45   However, we perceive no basis for reversal as a result of these\n\n  improper remarks. The comments were limited to the People\u2019s\n\n  rebuttal closing argument. Moreover, significant evidence\n\n  corroborated the jury\u2019s finding of guilt \u2014 specifically, the\n\n  undisputed evidence that Trujillo had removed an extensive amount\n\n  of property from the house. Viewing the record as a whole, we\n\n  cannot say that there was a \u201creasonable probability\u201d that the\n\n  prosecutor\u2019s remarks denigrating defense counsel contributed to\n\n  Trujillo\u2019s convictions. See Crider, 186 P.3d at 42. Thus, we\n\n  determine the error was harmless.\n\n\u00b6 46   In sum, though we agree that the prosecutor improperly\n\n  denigrated defense counsel, we perceive no basis for reversal.\n\n                       V. Indeterminate Probation\n\n\u00b6 47   Trujillo contends that the trial court did not have the statutory\n\n  authority to sentence him to indeterminate probation. We disagree.\n\n                           A. Additional Facts\n\n\u00b6 48   During the sentencing hearing, the People requested that\n\n  Trujillo be placed on a \u201clong period of probation . . . somewhere in\n\n\n                                    19\n\f  the neighborhood of eight to ten years\u201d because they anticipated\n\n  that Trujillo would be ordered to pay substantial restitution.2\n\n  Trujillo requested unsupervised probation with a collections\n\n  investigator monitoring his restitution payments.\n\n\u00b6 49   The trial court imposed an \u201cindefinite probation sentence\u201d\n\n  because of the substantial restitution that Trujillo was expected to\n\n  owe. In imposing an indeterminate probation sentence, the trial\n\n  court stated, \u201cThere is case law that talks about whether\n\n  [indeterminate probation] is something that can or should be\n\n  imposed and it\u2019s certainly something that is allowed regardless of\n\n  the type of conviction that has been entered.\u201d\n\n\u00b6 50   The mittimus states that the sentence imposed was a term of\n\n  probation for seven years to life.\n\n                          B. Standard of Review\n\n\u00b6 51   The People contend that we should not consider this claim\n\n  because a sentence to probation is not ordinarily subject to\n\n\n\n  2 The trial court ultimately ordered Trujillo to pay $171,421.97 in\n  restitution. Trujillo separately appealed that order, and a division\n  of this court affirmed in part, reversed in part, and remanded for\n  reconsideration. People v. Trujillo, (Colo. App. No. 14CA2486, Oct.\n  5, 2017) (not published pursuant to C.A.R. 35(e)).\n\n                                       20\n\f  appellate review. However, \u201cwhere, as here, a defendant contends\n\n  that \u2018a court has exceeded its statutory authority\u2019 in imposing a\n\n  probationary sentence, appellate review is warranted.\u201d People v.\n\n  Jenkins, 2013 COA 76, \u00b6 10, 305 P.3d 420, 423 (quoting People v.\n\n  Rossman, 140 P.3d 172, 174 (Colo. App. 2006)).\n\n\u00b6 52   \u201cWe review sentencing decisions that are within the statutory\n\n  range for an abuse of discretion.\u201d People v. Torrez, 2013 COA 37,\n\n  \u00b6 71, 316 P.3d 25, 37. However, where the defendant contends that\n\n  a court exceeded its statutory sentencing authority, our inquiry\n\n  involves statutory interpretation. Jenkins, \u00b6 12, 305 P.3d at 423.\n\n  We review such issues of statutory interpretation de novo. Id.\n\n                           C. Applicable Law\n\n\u00b6 53   Under section 18-1.3-202(1)(a), C.R.S. 2017, a trial court \u201cmay\n\n  grant the defendant probation for such period and upon such terms\n\n  and conditions as it deems best.\u201d Further, \u201c[t]he length of probation\n\n  shall be subject to the discretion of the court and may exceed the\n\n  maximum period of incarceration authorized for the classification of\n\n  the offense of which the defendant is convicted.\u201d Id.\n\n\u00b6 54   In Jenkins, a division of this court concluded that section 18-\n\n  1.3-202(1) \u201cauthorizes a trial court to impose an indeterminate term\n\n\n                                   21\n\f  of probation.\u201d Jenkins, \u00b6 38, 305 P.3d at 426. The Jenkins division\n\n  bolstered its conclusion by looking to the plain language of the\n\n  statute \u2014 which the division noted \u201ccontemplate[s] both\n\n  determinate and indeterminate terms of probation\u201d \u2014 and to the\n\n  provision\u2019s legislative history. Id. at \u00b6\u00b6 40, 42, 46, 305 P.3d at 426-\n\n  28. Finally, the division noted that section 18-1.3-202(1) \u201cgenerally\n\n  pertains to a broad class of cases, and it simply allows a trial court\n\n  to elect an indeterminate term if it sentences an offender who has\n\n  been convicted of a felony to probation.\u201d Id. at \u00b6 50, 305 P.3d at\n\n  428 (upholding probationary sentence of ten years to life); see also\n\n  People v. Martinez, 844 P.2d 1203, 1206 (Colo. App. 1992)\n\n  (concluding that a trial court has authority to impose a term of\n\n  probation that exceeds the sentence to imprisonment in the\n\n  statutory aggravated range for an offense).\n\n                               D. Analysis\n\n\u00b6 55   Trujillo asserts that the trial court exceeded its statutory\n\n  authority in imposing an indeterminate probationary sentence. We\n\n  disagree.\n\n\u00b6 56   Like the Jenkins division, we conclude that section 18-1.3-\n\n  202(1) gives a trial court the authority to sentence a defendant\n\n\n                                    22\n\f  convicted of a felony to an indefinite probationary period. Trujillo\n\n  urges that the statute limits a trial court\u2019s authority to impose an\n\n  indeterminate probation sentence. Under Trujillo\u2019s logic, a sentence\n\n  to probation for 100 years is permissible, but an indeterminate\n\n  probation sentence is outside the trial court\u2019s statutory authority.\n\n  The statute offers no basis for reaching this conclusion.\n\n\u00b6 57   Trujillo asserts that Jenkins is distinguishable because that\n\n  case concerned whether a defendant convicted of a sex offense not\n\n  falling under the supervision scheme of the Colorado Sex Offender\n\n  Lifetime Supervision Act of 1998 (SOLSA), see \u00a7\u00a7 18-1.3-1001\n\n  to -1012, C.R.S. 2017, could nevertheless be sentenced to\n\n  indeterminate probation. Jenkins, \u00b6 1, 305 P.3d at 422. Trujillo\n\n  contends that Jenkins was limited to the particular circumstances\n\n  of that case, and does not widely apply to all offenses and\n\n  defendants. However, the Jenkins division made clear that section\n\n  18-1.3-202(1) \u201cestablishes a general rule as far as the possibility of\n\n  an indeterminate probationary term for felonies\u201d and \u201cauthorizes a\n\n  trial court to impose an indeterminate term of probation.\u201d Id. at\n\n  \u00b6\u00b6 38, 50, 305 P.3d at 426, 428. In fact, Jenkins explicitly rejected\n\n  the argument that a sentence of indeterminate probation could be\n\n\n                                    23\n\f  imposed only in sex offense cases subject to SOLSA. Id. at \u00b6\u00b6 49-\n\n  50, 305 P.3d at 428. Thus, Trujillo\u2019s argument that Jenkins is\n\n  limited to sex offenses is unavailing.\n\n\u00b6 58   In sum, we conclude that the trial court did not exceed its\n\n  statutory authority in imposing the probation sentence here.\n\n                         VI. Costs of Prosecution\n\n\u00b6 59   Trujillo next asserts that the trial court erred in awarding the\n\n  full costs of prosecution requested by the People without making a\n\n  finding on whether any portion of the costs was attributable to the\n\n  charge on which he was acquitted. We agree.\n\n                           A. Additional Facts\n\n\u00b6 60   Before sentencing, the People moved for reimbursement of the\n\n  costs of prosecution pursuant to section 18-1.3-701, C.R.S. 2017.\n\n  The People requested $768.70. Trujillo opposed the motion on the\n\n  basis that the People bore responsibility for the costs incurred to\n\n  prove the defrauding a secured creditor charge, of which Trujillo\n\n  was acquitted.\n\n\u00b6 61   During the sentencing hearing, the trial court awarded the\n\n  requested costs of prosecution, ordering Trujillo to pay $768.70.\n\n\n\n\n                                    24\n\f                          B. Standard of Review\n\n\u00b6 62   The trial court, in its discretion, may assess reasonable and\n\n  necessary costs of prosecution against a convicted defendant. See\n\n  \u00a7 18-1.3-701(2)(j.5). Thus, we review an assessment of costs of\n\n  prosecution for an abuse of discretion, reversing if the trial court\u2019s\n\n  determination is manifestly arbitrary, unreasonable, or unfair,\n\n  People v. Palomo, 272 P.3d 1106, 1110 (Colo. App. 2011), or if the\n\n  trial court misapplied the law, People v. Jefferson, 2017 CO 35,\n\n  \u00b6 25, 393 P.3d 493, 499.\n\n                             C. Applicable Law\n\n\u00b6 63   Under section 16-18-101(1), C.R.S. 2017, the state bears the\n\n  costs of prosecution when a defendant is acquitted. Such costs\n\n  may include witness fees, mileage, lodging expenses, transportation\n\n  costs, and other reasonable and necessary costs that directly result\n\n  from prosecuting the defendant. \u00a7 18-1.3-701(2); see also People v.\n\n  Sinovcic, 2013 COA 38, \u00b6\u00b6 15-16, 304 P.3d 1176, 1179. If a\n\n  defendant is convicted of fewer than all of the charged counts, the\n\n  court may assess only those costs attributable to the counts for\n\n  which the defendant was convicted, if an allocation is practicable.\n\n  Palomo, 272 P.3d at 1112.\n\n\n                                    25\n\f                               D. Analysis\n\n\u00b6 64   Trujillo asserts that the trial court erred in not making a\n\n  finding as to whether some portion of the requested costs of\n\n  prosecution were allocable to the acquitted charge. We agree.\n\n\u00b6 65   As Trujillo concedes, it is possible that the costs cannot be\n\n  allocated between the charge on which he was acquitted and the\n\n  two charges on which he was convicted. However, the trial court\n\n  did not find that such an allocation was impracticable. Because the\n\n  trial court was required to consider whether some portion of the\n\n  requested costs was practicably attributable to the acquitted\n\n  charge, the trial court abused its discretion. See DeBella v. People,\n\n  233 P.3d 664, 667 (Colo. 2010) (failure to exercise discretion\n\n  constitutes an abuse of the court\u2019s discretion).\n\n\u00b6 66   Accordingly, we vacate the order awarding the People costs of\n\n  prosecution and remand for the trial court to make appropriate\n\n  findings of fact and \u201cassess only those costs that are related to the\n\n  prosecution of the . . . counts of which [Trujillo] was convicted, to\n\n  the extent an allocation is practicable.\u201d Palomo, 272 P.3d at 1113.\n\n\n\n\n                                    26\n\f                    VII. Amendment to Theft Statute\n\n\u00b6 67   Trujillo contends that he should have benefited from an\n\n  amendment to the theft statute reclassifying theft between $20,000\n\n  and $100,000 as a class 4 felony. We agree.\n\n                            A. Additional Facts\n\n\u00b6 68   The General Assembly amended the theft statute on June 5,\n\n  2013. See Ch. 373, sec. 1, \u00a7 18-4-401, 2013 Colo. Sess. Laws\n\n  2196. Under the amended statute, theft between $20,000 and\n\n  $100,000 constitutes a class 4 felony. See \u00a7 18-4-401(2)(h), C.R.S.\n\n  2017. Prior to the amendment, theft over $20,000 constituted a\n\n  class 3 felony. \u00a7 18-4-401(2)(d), C.R.S. 2011.\n\n\u00b6 69   Trujillo was charged with theft of $20,000 or more in April\n\n  2011. He was convicted in October 2013 and sentenced in\n\n  December 2013. His theft conviction was recorded on the mittimus\n\n  as a class 3 felony.\n\n                         B. Standard of Review\n\n\u00b6 70   The People assert that, because Trujillo did not make this\n\n  argument before the trial court, we should review only for plain\n\n  error. However, the division in People v. Stellabotte rejected this\n\n  argument. 2016 COA 106, \u00b6 42, ___ P.3d ___, ___ (noting that plain\n\n\n                                    27\n\f  error review was inappropriate because \u201ca defendant may raise a\n\n  claim at any time that his or her sentence was not authorized by\n\n  law\u201d) (cert. granted Feb. 6, 2017). Following Stellabotte, we review\n\n  the legality of the sentence de novo. Id. at \u00b6 4, ___ P.3d at ___.\n\n                             C. Applicable Law\n\n\u00b6 71   In determining whether to apply amendments to legislation,\n\n  we first look to the plain language of the statute. People v.\n\n  Summers, 208 P.3d 251, 253-54 (Colo. 2009). If a statute explicitly\n\n  states that it applies only to offenses committed after the effective\n\n  date, it must be applied accordingly. See People v. McCoy, 764 P.2d\n\n  1171, 1174 (Colo. 1988).\n\n\u00b6 72   As a general rule, \u201c[a] statute is presumed to be prospective in\n\n  its operation.\u201d \u00a7 2-4-202, C.R.S. 2017. However, if a statute is\n\n  silent as to whether it applies only prospectively, a defendant may\n\n  seek retroactive application if he or she benefits from a significant\n\n  change in the law. \u00a7 18-1-410(1)(f)(I), C.R.S. 2017; see also People\n\n  v. Thornton, 187 Colo. 202, 203, 529 P.2d 628, 628 (1974) (allowing\n\n  defendant to seek relief on direct appeal under statute).\n\n\u00b6 73   In Stellabotte, a division of this court concluded that the\n\n  amendatory theft legislation \u201capplies retroactively to cases pending\n\n\n                                    28\n\f  in the trial court when the amendment was enacted.\u201d Stellabotte,\n\n  \u00b6 45, ___ P.3d at ___; People v. Patton, 2016 COA 187, \u00b6 32, ___ P.3d\n\n  ___, ___; see also People v. Patton, (Colo. App. No. 14CA2359, Aug.\n\n  11, 2016) (not published pursuant to C.A.R. 35(e)) (cert. granted\n\n  Feb. 6, 2017).\n\n                                D. Analysis\n\n\u00b6 74   Trujillo contends that the amendment to the theft statute\n\n  requires that we vacate his sentence and remand for the trial court\n\n  to enter his theft conviction as a class 4 felony. We agree.\n\n\u00b6 75   As the division noted in Stellabotte, the theft amendment does\n\n  not explicitly state that it is either retroactive or prospective.\n\n  Stellabotte, \u00b6 45, ___ P.3d at ___. In the face of this legislative\n\n  silence, the division held that a defendant who committed theft\n\n  prior to the statutory amendment but was not convicted until after\n\n  its passage was entitled to the benefit retroactively. See id. at\n\n  \u00b6\u00b6 39, 45, ___ P.3d at ___. The same is true here.\n\n\u00b6 76   Trujillo was charged with theft before the statute was\n\n  amended, but was not convicted or sentenced until after the\n\n  General Assembly lowered the classification for theft between\n\n\n\n\n                                      29\n\f  $20,000 and $100,000.3 Thus, like the defendant in Stellabotte,\n\n  Trujillo is entitled to the benefit of the amendment. As a result, we\n\n  vacate the sentence for the theft conviction and remand for the\n\n  conviction to be entered as a class 4 felony.\n\n\u00b6 77   The partial dissent looks to several statutory provisions in\n\n  support of its conclusion that Trujillo is not entitled to the benefit of\n\n  the amendatory legislation. First, the partial dissent cites section\n\n  2-4-202, which states the general presumption that statutes apply\n\n  prospectively. However, as the division noted in Stellabotte, section\n\n  18-1-410 is a specific exception to the general rule expressed in\n\n  section 2-4-202. Stellabotte, \u00b6 47 n.4, ___ P.3d at ___ n.4. We\n\n  agree with that analysis. Thus, the general presumption that\n\n  statutes apply prospectively does not apply here where Trujillo\n\n  seeks the benefit of a \u201csignificant change in the law, . . . allowing in\n\n\n\n\n  3 Trujillo asserts that the theft was between $20,000 and $100,000\n  based on testimony from trial. The People do not contest the value\n  of the stolen property in this case. We therefore assume that\n  Trujillo\u2019s offense properly fell within the value range set forth in\n  section 18-4-401(2)(h), C.R.S. 2017.\n\n                                     30\n\f  the interests of justice retroactive application of the changed legal\n\n  standard.\u201d4 \u00a7 18-1-410(1)(f)(I).\n\n\u00b6 78   The partial dissent also invokes section 2-4-303, C.R.S. 2017,\n\n  in support of its conclusion. Section 2-4-303 states:\n\n             The repeal, revision, amendment, or\n             consolidation of any statute or part of a statute\n             or section or part of a section of any statute\n             shall not have the effect to release, extinguish,\n             alter, modify, or change in whole or in part any\n             penalty, forfeiture, or liability, either civil or\n             criminal, which shall have been incurred\n             under such statute, unless the repealing,\n             revising, amending, or consolidating act so\n             expressly provides.\n\n\u00b6 79   However, the supreme court has noted that the \u201cgeneral\n\n  saving\u201d provision codified in this statute is not applicable to\n\n  criminal cases; instead, the court noted in dictum that it \u201chas\n\n\n  4 The partial dissent also asserts that section 18-1-410(1)(f)(I),\n  C.R.S. 2017, does not provide any relief to Trujillo because that\n  provision requires that \u201cthere has been significant change in the\n  law, applied to the [defendant\u2019s] conviction or sentence.\u201d The\n  partial dissent asserts that the phrase \u201capplied to\u201d requires that the\n  legislation expressly state that it applies retroactively. We disagree\n  with that interpretation, and believe that our view finds authority in\n  supreme court case law. See People v. Thomas, 185 Colo. 395, 397,\n  525 P.2d 1136, 1137 (1974) (noting that \u201c[t]he legislature intended\n  the changed legal standards to apply wherever constitutionally\n  permissible\u201d but making no mention of whether the amendatory\n  legislation reclassifying attempted second degree burglary explicitly\n  stated that it applied retroactively).\n\n                                     31\n\f  consistently adhered to the principle . . . that a defendant is entitled\n\n  to the benefits of amendatory legislation when relief is sought before\n\n  finality has attached to the judgment of conviction.\u201d Noe v. Dolan,\n\n  197 Colo. 32, 36 n.3, 589 P.2d 483, 486 n.3 (1979).\n\n\u00b6 80   In People v. Boyd, a division of the court of appeals concluded\n\n  that section 2-4-303 did not prevent the retroactive effect of an\n\n  amendatory constitutional provision. 2015 COA 109, \u00b6 27, 395\n\n  P.3d 1128, 1134, aff\u2019d, 2017 CO 2, 387 P.3d 755.5 The division\n\n  noted the supreme court\u2019s language in Noe. Id. at \u00b6 28, 395 P.3d at\n\n  1134. To the extent that other supreme court cases included\n\n  contrary statements, the Boyd division concluded that such\n\n  statements were dicta and that the supreme court had not\n\n  overruled or disapproved of either Noe or People v. Thomas, 185\n\n  Colo. 395, 398, 525 P.2d 1136, 1138 (1974) (holding that\n\n  \u201camendatory legislation mitigating the penalties for crimes should\n\n  be applied to any case which has not received final judgment\u201d).\n\n\n\n  5 The supreme court in Boyd affirmed the Court of Appeals decision\n  on different grounds, concluding that the marijuana criminal\n  offense statute had been rendered inoperative by Amendment 64.\n  Neither the majority nor the dissent in Boyd cited section 2-4-303,\n  C.R.S. 2017.\n\n                                    32\n\f  Boyd, \u00b6\u00b6 29-30, 395 P.3d at 1134-35. Finally, the Boyd division\n\n  concluded that section 18-1-410(1)(f)(I) controls over section 2-4-\n\n  303 because the former sets forth a specific exception to the latter,\n\n  which codifies a \u201cgeneral rule[] of construction regarding\n\n  prospective effect for amendatory legislation.\u201d Id. at \u00b6\u00b6 31-32, 395\n\n  P.3d at 1135. We agree with the Boyd division\u2019s analysis and\n\n  therefore do not perceive section 2-4-303 as a bar to the relief\n\n  Trujillo seeks.\n\n\u00b6 81   In making its statutory arguments, the partial dissent relies\n\n  on the plain meaning of both section 2-4-303 and section 18-1-\n\n  410(1)(f)(I). However, as discussed, the supreme court has not\n\n  given either provision its plain meaning. Despite express reference\n\n  in section 2-4-303 to civil and criminal penalties, the supreme court\n\n  has indicated that the provision does not apply to criminal cases.\n\n  Noe, 197 Colo. at 36 n.3, 589 P.2d at 486 n.3. Similarly, while\n\n  section 18-1-410(1)(f)(I) by its express terms applies to defendants\n\n  seeking postconviction relief, the supreme court has held that the\n\n  statute also extends to defendants seeking relief on direct appeal.\n\n  Thornton, 187 Colo. at 203, 529 P.2d at 628. In light of the\n\n\n\n\n                                    33\n\f  supreme court\u2019s interpretation of these statutes, we cannot give\n\n  them the meanings that the partial dissent ascribes to them.\n\n\u00b6 82   Finally, the partial dissent also relies on Riley v. People, in\n\n  which the supreme court noted that it has \u201cemphasized that a\n\n  defendant is not entitled to the ameliorative effects of amendatory\n\n  legislation if the General Assembly has not clearly indicated its\n\n  intent to require such retroactive application.\u201d 828 P.2d 254, 258\n\n  (Colo. 1992). However, we do not consider this statement to have\n\n  the controlling effect the partial dissent gives it. In Riley, the\n\n  defendant committed a crime in April 1988 and sought relief under\n\n  two sentencing provisions that expressly stated they applied to acts\n\n  \u201ccommitted on or after\u201d July 1, 1988. Id. at 255-56. The Riley\n\n  court held the defendant there was not entitled to relief because\n\n  applying the statutes retroactively would require the court to ignore\n\n  the \u201cclear legislative determination\u201d that the amended sentencing\n\n  provisions would apply only to acts after that date. Id. at 257.\n\n\u00b6 83   Thus, Riley is readily distinguishable from the present case,\n\n  where the amendments to the theft statute do not expressly provide\n\n  an effective date, and the language relied on by the partial dissent is\n\n  dicta. Accord McCoy, 764 P.2d at 1174 (noting that, where\n\n\n                                     34\n\f  legislation expressly stated it applied to acts committed on or after\n\n  its effective date, a \u201cdefendant does not receive any ameliorative\n\n  benefit\u201d because \u201cretroactive application of the amendatory\n\n  legislation is clearly not intended by its own terms\u201d); People v.\n\n  Macias, 631 P.2d 584, 587 (Colo. 1981) (same).\n\n\u00b6 84   Thus, we conclude, in accordance with Stellabotte, that Trujillo\n\n  should receive the benefit of the amendment to the theft statute\n\n  reclassifying theft between $20,000 and $100,000 as a class 4\n\n  felony. See Stellabotte, \u00b6 40, ___ P.3d at ___.\n\n                               VIII. Conclusion\n\n\u00b6 85   Accordingly, the judgment of conviction is affirmed. The\n\n  sentence is affirmed in part and vacated in part, and the case is\n\n  remanded for further proceedings consistent with the views\n\n  expressed in this opinion.\n\n       JUDGE RICHMAN concurs.\n\n       JUDGE FURMAN concurs in part and dissents in part.\n\n\n\n\n                                     35\n\f          JUDGE FURMAN, concurring in part and dissenting in part.\n\n\u00b6 86      I respectfully dissent from the majority\u2019s opinion only as to the\n\n  effect of the 2013 amendments to the theft statute. I conclude that\n\n  the 2013 amendments to the theft statute do not apply retroactively\n\n  to Trujillo\u2019s case. I reach this conclusion for several reasons.\n\n\u00b6 87      First, the General Assembly has made it clear that a \u201cstatute is\n\n  presumed to be prospective in its operation.\u201d \u00a7 2-4-202, C.R.S.\n\n  2017. The 2013 amendments to the theft statute are silent as to\n\n  whether they apply prospectively or retroactively. Therefore, I\n\n  presume that the 2013 amendments are prospective in operation\n\n  and do not apply to Trujillo\u2019s offense, which occurred before 2013.\n\n  See id.\n\n\u00b6 88      Second, an amendment to a criminal statute does not change\n\n  the penalty for crimes already committed under the statute unless\n\n  the amendatory legislation expressly provides for such a change.\n\n  See \u00a7 2-4-303, C.R.S. 2017. Section 2-4-303 provides, in relevant\n\n  part:\n\n               The . . . amendment . . . of any statute or part\n               of a statute . . . shall not have the effect to\n               release, extinguish, alter, modify, or change in\n               whole or in part any penalty, forfeiture, or\n               liability, either civil or criminal, which shall\n\n\n                                      36\n\f             have been incurred under such statute, unless\n             the . . . amending . . . act so expressly\n             provides, and such statute or part of a statute\n             . . . so . . . amended . . . shall be treated and\n             held as still remaining in force for the purpose\n             of sustaining any and all proper actions, suits,\n             proceedings, and prosecutions, criminal as\n             well as civil, for the enforcement of such\n             penalty, forfeiture, or liability, as well as for\n             the purpose of sustaining any judgment,\n             decree, or order which can or may be rendered,\n             entered, or made in such actions, suits,\n             proceedings, or prosecutions imposing,\n             inflicting, or declaring such penalty, forfeiture,\n             or liability.\n\n  Because the 2013 amendments to the theft statute do not expressly\n\n  provide that they apply retroactively, and Trujillo committed his\n\n  crime before 2013, he is liable for theft as it was defined when he\n\n  committed the offense. See id.\n\n\u00b6 89   Third, in Riley v. People, 828 P.2d 254, 258 (Colo. 1992), our\n\n  supreme court \u201cemphasized that a defendant is not entitled to the\n\n  ameliorative effects of amendatory legislation if the General\n\n  Assembly has not clearly indicated its intent to require such\n\n  retroactive application.\u201d Id. I consider this statement by the\n\n  supreme court about its own jurisprudence on this issue to be\n\n  controlling.\n\n\n\n\n                                    37\n\f\u00b6 90   Fourth, section 18-1-410(1)(f)(I), C.R.S. 2017, does not allow\n\n  Trujillo, on direct appeal, to seek retroactive application of the 2013\n\n  amendments to his case. Section 18-1-410(1)(f)(I) allows a\n\n  defendant to seek retroactive application of a \u201csignificant change in\n\n  the law, applied to\u201d a defendant\u2019s \u201cconviction or sentence.\u201d I believe\n\n  that the phrase \u201capplied to\u201d reflects the General Assembly\u2019s intent\n\n  that, for amendatory legislation to apply retroactively to a\n\n  defendant\u2019s conviction or sentence, the legislation must state that it\n\n  applies retroactively. Thus, because, as noted, the 2013\n\n  amendments do not state that they apply retroactively to Trujillo\u2019s\n\n  conviction and sentence, he may not seek retroactive application\n\n  under section 18-1-410(1)(f)(I).\n\n\u00b6 91   Finally, and with all due respect, I decline to follow People v.\n\n  Stellabotte, 2016 COA 106 (cert. granted Feb. 6, 2017). Indeed, I\n\n  agree with Judge Dailey\u2019s dissent in Stellabotte. See id. at \u00b6\u00b6 62-70\n\n  (Dailey, J., concurring in part and dissenting in part).\n\n\n\n\n                                     38\n\f", "meta": {"pile_set_name": "FreeLaw"}}
{"text": "Q:\n\nsql queries and inserts\n\nI have a random question. If I were to do a sql select and while the sql server was querying my request someone else does a insert statement... could that data that was inputted in that insert statement also be retrieved from my select statement?\n\nA:\n\nQueries are queued, so if the SELECT occurs before the INSERT there's no possibility of seeing the newly inserted data.\nUsing default isolation levels, SELECT is generally given higher privilege over others but still only reads COMMITTED data.  So if the INSERT data has not been committed by the time the SELECT occurs--again, you wouldn't see the newly inserted data.  If the INSERT has been committed, the subsequent SELECT will include the newly inserted data.\nIf the isolation level allowed reading UNCOMMITTED (AKA dirty) data, then yes--a SELECT occurring after the INSERT but before the INSERT data was committed would return that data.  This is not recommended practice, because UNCOMMITTED data could be subject to a ROLLBACK.\n\n", "meta": {"pile_set_name": "StackExchange"}}
{"text": "Slapp straff, men mister lappen\n\nUngdommene som ble tatt i hasjaksjonene i Fana la alle kortene p\u00e5 bordet. Cannabisbruken de innr\u00f8mmet i avh\u00f8r, brukes n\u00e5 til \u00e5 ta fra dem lappen.\n\nPublisert Publisert 16. august 2014\n\nLA KORTENE P\u00c5 BORDET: Dette er noen av bildene politiet fant p\u00e5 mobiltelefonene til dem som ble p\u00e5grepet i cannabisaksjonene. Bildet i midten er fra et beslag politiet gjorde i forkant av aksjonene. Foto: POLITIET\n\nDenne artikkelen er over seks \u00e5r gammel\n\nFlere av ungdommene som ble tatt i hasjaksjonene i Bergen s\u00f8r i februar i \u00e5r har mistet retten til \u00e5 f\u00f8re motorvogn.\n\nDet skjer etter at det i midten av juni i \u00e5r dumpet et brev ned i postkassen til flere av dem.\n\n\u2014 I avh\u00f8r skal De ha opplyst at De har r\u00f8yket marihuana, omtrent annenhver helg, i forbindelse med fest. (...) Det at De har brukt marihuana over en lengre periode, fra 2013 til 2014, vitner om at deres bruk ikke er forenlig med \u00e5 inneha f\u00f8rerretten til motorvogn. P\u00e5 denne bakgrunn har politiet skjellig grunn til \u00e5 tro at De har et rusproblem og s\u00e5ledes ikke fyller kravene til helse som kreves for \u00e5 inneha retten til \u00e5 f\u00f8re f\u00f8rerkortpliktig motorvogn, st\u00e5r det i ett av brevene fra Fellesforvaltningsenheten til Hordaland politidistrikt.\n\nDet skal v\u00e6re et titall ungdommer som n\u00e5 har mistet sertifikatet. Flere av dem har hyret inn advokat for \u00e5 bestride saken.\n\n- Ingen heksejakt\n\nDet er ogs\u00e5 flere som har \u00f8nsket \u00e5 kj\u00f8re opp til lappen, som ikke f\u00e5r lov av f\u00f8rerkortkontoret. Ogs\u00e5 det er en f\u00f8lge av cannabisbruken de har innr\u00f8mmet i avh\u00f8r.\n\nIf\u00f8lge Morten \u00d8rn, stasjonssjef ved Bergen S\u00f8r politistasjon, er det ikke snakk om noen koordinert aksjon for \u00e5 frata dem som ble p\u00e5grepet f\u00f8rerkortet.\n\n\u2014 Det er en administrativ sak som g\u00e5r parallelt med Tidlig ute-prosjektet, sier han.\n\nDe fleste av ungdommene som ble p\u00e5grepet, fikk p\u00e5taleunnlatelse mot at de gjennomf\u00f8rte det forebyggende programmet.\n\nTre ganger p\u00e5 to \u00e5r\n\nJurist Kirsti F\u00fcrstenberg ved Forvaltningsavdelingen sier de tar utgangspunkt i h\u00e5ndhevingsinstruksen fra Politidirektoratet og en dom fra Borgarting lagmannsrett n\u00e5r de avgj\u00f8r om en person skal miste f\u00f8rerretten som f\u00f8lge av en bekymringsmelding.\n\n\u2014 S\u00e5 gj\u00f8res det en skj\u00f8nnsmessig helhetsvurdering i hvert tilfelle. Vi g\u00e5r konkret inn i hvert tilfelle og ser gjennom dokumentene vi har.\n\nI dommen fra lagmannsretten, som legges til grunn for tilbakekallelsen av f\u00f8rerretten, st\u00e5r det at \u00e9n overtredelse i \u00e5ret ikke er tilstrekkelig for \u00e5 tibakekallelse. \u00abTo kan v\u00e6re det men formuleringen flere tyder p\u00e5 at det m\u00e5 v\u00e6re minst tre overtredelser i l\u00f8pet av siste par \u00e5r\u00bb, st\u00e5r det i dommernes tolkning av Vegtrafikkloven.\n\nTar ikke hensyn til lovlighet\n\nF\u00f8r ungdommene mistet lappen, fikk de et forh\u00e5ndsvarsel fra Forvaltningsenheten. Deretter fikk de 14 dager p\u00e5 seg med \u00e5 komme med informasjon de mener er relevant for saken.\n\n\u2014 Det er mange som kommer med uttalelser. Det inng\u00e5r som en del av sakens dokumenter, og blir en del av helhetsvurderingen, sier F\u00fcrstenberg, som igjen understreker at det gj\u00f8res en skj\u00f8nnsmessig vurdering i hvert tilfelle, og at hun uttaler seg p\u00e5 generelt grunnlag.\n\nForvaltningsenheten tar ikke hensyn til lovligheten av rusmiddelet som benyttes, n\u00e5r det gjelder vurderingen av edruelighet.\n\n\u2014 Vi ser p\u00e5 en konkret helhetsvurdering av ruseffekten, sier F\u00fcrstenberg.\n\nAlkohol = narkotika\n\nI prinsippet kan dermed alkoholbruk og narkotikabruk dermed behandles likt med tanke p\u00e5 om man f\u00e5r beholde f\u00f8rerkortet.\n\n\u2014 Det vi m\u00e5 vurdere er om bruken tilsier en \u00f8kt risiko i trafikken.\n\nFor \u00e5 f\u00e5 sertifikatet tilbake, m\u00e5 ungdommene vise til dokumentert rusfrihet i ett \u00e5r.\n\n\u2014 Det blir en konkret vurdering i hvert tilfelle, men de m\u00e5 sannsynliggj\u00f8re edruelighet. Det er opp til personen selv og skaffe bevis for dette, gjerne fra lege, sier hun.\n\n\u00d8kning i f\u00f8rerkortbeslag\n\nFra 1. januar til 5. august i \u00e5r, har politiet i Hordaland fattet 644 vedtak om tilbakekallelse av f\u00f8rerretten.\n\n550 av disse vedtakene kommer som f\u00f8lge av vedtak fattet av fylkesmannen, mens 94 av dem er p\u00e5 bakgrunn av saker politiet selv har initiert.\n\nSamme periode i fjor, var det totalt 578 vedtak, og bare 34 av dem kom p\u00e5 bakgrunn av saker politiet selv initierte.\n\n\u2014 Vi ser at antallet egeninitierte saker g\u00e5r opp etter at vi innf\u00f8rte den nye metodikken. Det er et mer str\u00f8mlinjeformet system, som vi er glade for, sier Ane Kvaal, politiinspekt\u00f8r og leder for forvaltningsenheten i Hordaland-politiet.\n\nNytt prosjekt\n\nDet som har skjedd i mellomtiden, er nemlig at politiet har implementert prosjektet Forebygging gjennom forvaltning. Det er i praksis en ny struktur for \u00e5 fange opp meldinger fra politiets egne ansatte om personer hvor det er grunn til \u00e5 tro at vedkommende ikke lenger fyller vilk\u00e5rene for \u00e5 inneha en tillatelse fra politiet.\n\nKvaal er forsiktig med \u00e5 tilskrive det nye prosjektet all \u00e6ren for at antallet vedtak som f\u00f8lge av egeninitierte saker g\u00e5r opp.\n\n\u2014 \u00d8kningen kan jo skyldes at politiet har blitt flinkere til p\u00e5 melde fra, eller at det finnes flere personer som ikke burde ha f\u00f8rerkort. Men det er vanskelig med sikkerhet \u00e5 si hva sammenhengen er.\n\nVet du noe om saken? Send MMS/SMS til 2211, eller skriv e-post\n\nPublisert Publisert: 16. august 2014 16:51 Oppdatert: 16. august 2014 18:15", "meta": {"pile_set_name": "OpenWebText2"}}
{"text": "Introduction {#sec1-1}\n============\n\nInfliximab (IFX), a chimeric anti-TNF\u03b1 antibody, is effective in inducing and maintaining remission in a considerable proportion of IBD patients refractory to any other treatments \\[[@ref1],[@ref2]\\]. However, 8-12% of adult and/or pediatric patients fail to respond to the induction regimen (known as primary non responders) and approximately 40% of patients who respond initially and achieve clinical remission inevitably lose response over time\\[[@ref3],[@ref7]\\]. Lack of response to IFX is a stable trait and suggests that the differences in response might be in part genetically determined. Considering the high cost and safety profile of this drug, genetic targeting of patients responding to this therapy is certainly of great interest \\[[@ref8]\\]. So far, limited candidate gene association studies with response to IFX have been reported \\[[@ref9]-[@ref11]\\]. Recently, a genome-wide association study (GWAS) in paediatric IBD patients has revealed that the 21q22.2/BRWDI loci were associated with primary non response \\[[@ref12]\\]. Furthermore, although TNFa gene is of great interest as a candidate gene for pharmacogenetic approaches few studies have been performed to date and some have led to contradictory results \\[[@ref10],[@ref11],[@ref13]-[@ref15]\\].\n\nAll anti-TNF agents share an IgG1 Fc fragment, but the contribution of the Fc portion to the response to treatment among currently used TNF blockers remains unknown. Receptors for IgG-Fc portion (FcR) are important regulatory molecules of inflammatory responses. FcR polymorphisms alter receptor function by enhancing or diminishing the affinity for immunoglobulins \\[[@ref16]\\]. Three major classes of FcR that are capable of binding IgG antibodies are recognised: Fc\u03b3R\u0399 (CD64), Fc\u03b3R\u0399\u0399 (CD32), and Fc\u03b3R\u0399\u0399\u0399 (CD16). Fc\u03b3R\u0399\u0399 and Fc\u03b3R\u0399\u0399\u0399 have multiple isoforms (Fc\u03b3R\u0399\u0399\u0399A/C and B; Fc\u03b3R\u0399\u0399\u0399A and B) \\[[@ref16]\\]. The most frequent polymorphism of *Fc\u03b3R\u0399\u0399\u0399A* is a point mutation affecting amino acids in codon 158 in the extracellular domain. This results in either a valine (V158) or a phenylalanine (F158) at this position. Recently, it has been reported that CD patients with *Fc\u03b3R\u0399\u0399\u0399A* -158V/V genotype had a better biological and possibly better clinical response to IFX \\[[@ref17]\\]. However, further studies did not confirm this observation \\[[@ref18]\\].\n\nThe aim of this study was to assess whether the *TNF* and/ or *Fc\u03b3R\u0399\u0399\u0399A* gene polymorphisms are genetic predictors of response to IFX, in a cohort of Greek patients with adult or paediatric onset of CD.\n\nPatients - Methods {#sec1-2}\n==================\n\nPatients {#sec2-1}\n--------\n\nWe enrolled 106 consecutive patients with newly diagnosed CD attending the outpatient IBD Clinic at the 1^st^ Department of Gastroenterology, \"Evangelismos\" Hospital (79 adults) or the 1^st^ Department of Pediatrics, University Hospital of Athens \"Aghia Sophia\"(27 children). The diagnosis of CD was based on standard clinical, endoscopic, radiological, and histological criteria \\[[@ref1],[@ref19]\\]. Eligible patients should have inflammatory (luminal) disease and be naive to IFX.\n\nIFX was administered intravenously at a dose of 5mg/kg at weeks 0, 2, 6 and then every 8 weeks. Clinical and serological responses were assessed using the Harvey-Bradshaw Index (HBI) \\[[@ref20]\\] and the serum levels of C-reactive protein (CRP), respectively, at baseline (before the 1st infusion of IFX), the day before each subsequent IFX infusion and after 12 weeks of treatment. Ileocolonoscopy was performed by a single endoscopist (GJM) at baseline and after 12-20 weeks of therapy to assess mucosal healing. Any changes in endoscopic appearance compared to baseline endoscopy were classified in four categories \\[[@ref21],[@ref22]\\] \\[[Table 1](#T1){ref-type=\"table\"}\\]. Patients were classified in accordance to response to IFX therapy as shown in [table 2](#T2){ref-type=\"table\"}. The ethical committee of the participating hospitals approved the study. Research was carried out according to Helsinki Convention (1975) and written inform consent was obtained in advance from each patient.\n\n###### \n\nGrading of endoscopic mucosal lesions \\[[@ref21],[@ref22]\\]\n\n![](AnnGastroenterol-24-35-g001)\n\n###### \n\nClassification of the study population due to response to infliximab therapy\n\n![](AnnGastroenterol-24-35-g002)\n\nGenotyping {#sec2-2}\n----------\n\nGenomic DNA from whole blood containing EDTA was extracted using standard techniques (NucleoSpin Blood kit, Macherey-Nagel, Germany). All polymerase chain reactions (PCRs) were run under conditions previously described \\[[@ref23]\\]. Primer sequences for the gene polymorphism at --308 were forward 5\u2032-GGG ACA CAC AAG CAT CAA GG-3\u2032 and reverse 5\u2032-GGG ACA CAC AAG CAT CAA GG-3\u2032, for the polymorphism at \u2212238 forward 5\u2032-ATC TGG AGG AAG CGG TAG TG-3\u2032 and reverse 5\u2032-AGA AGA CCC CCC TCG GAA CC-3\u2032. The PCR products were digested at 37 \u00b0C with NcoI to detect the SNP in the \u2212308 gene allele and MspI to detect the polymorphism of the \u2212238 nucleotide. The -857 C/T polymorphism was analyzed by allele-specific PCR method24 using the primers TNF857-C: 5\u2032-aag gat aag ggc tca gag ag-3\u2032, TNF857-N: 5\u2032-cta cat ggc cct gtc ttc g-3\u2032 and TNF857-M: 5\u2032-t cta cat ggc cct gtc ttc a-3\u2032. The --158V/F polymorphism of Fc\u03b3R\u0399\u0399\u0399A gene was detected as described by Leppers-van de Straat et al \\[[@ref25]\\] using the primers 5\u2032-CTG AAG ACA CAT TTT TACT CC CAA (A/C)-3\u2032 and 5\u2032-TCC AAA AGC CAC ACT CAA AGA C-3\u2032. The PCR products were then subjected to 3% agarose-gel electrophoresis. \"No target\" controls were included in each PCR batch to ensure that reagents had not been contaminated.\n\nStatistical Analysis {#sec2-3}\n--------------------\n\nGenotype frequencies were compared with the chi-square with Yate's correction using S-Plus (v. 6.2Insightful, Seattle, WA). Odds ratios (ORs) and 95 confidence intervals (CIs) were obtained with GraphPad (v. 3.00, GraphPad Software, San Diego, CA). The p values are all two-sided. Correction for multiple testing was not applied in this study. *P* values of \\< 0.05 were considered to be significant.\n\nResults {#sec1-3}\n=======\n\nPatient demographic and clinical characteristics are given in [Table 3](#T3){ref-type=\"table\"}. There were 68 (64.15%) complete responders, 25 (23.58%) partial responders and 13 (12.26%) non responders to IFX in this study. There were no statistical differences in the mean age, gender, disease duration, location and behavior and smoking habits between complete or partial responders and primary non-responders. There was no disagreement between HBI scores and serum CRP levels. Although, the post-treatment CRP levels were significantly lower in complete responders compared to partial and non-responders, the decrease in CRP levels did not differ significantly between the three groups. Post-treatment CRP levels and mean HBI score were significantly lower in complete responders compared to pre-treatment values in contrast to partial and/or non-responders where the CRP levels and the mean HBI score did not differ significantly.\n\n###### \n\nDemographic, clinical and biological characteristics of the study population\n\n![](AnnGastroenterol-24-35-g003)\n\nThe -238 G/A, -308 G/A, and -857 C/T polymorphisms of the TNF gene and the -158 V/F polymorphism in the *Fc\u03b3R\u0399\u0399\u0399A* gene were successfully determined in all subjects. The genotype distribution in complete, partial and non-responders were presented in [Table 4](#T4){ref-type=\"table\"}. No significant difference was observed for the polymorphism tested. In addition, although there may be genetic differences in early (paediatric)-onset and late (adult)-onset CD we were unable to detect any such differences although the number of paediatric patients included in the current study did not allow firm conclusions.\n\n###### \n\nGenotype frequency in complete responders, partial responders and non responders\n\n![](AnnGastroenterol-24-35-g004)\n\nIn the present study, we could not correlate the decrease in serum CRP levels with the genotypes tested in any particular group of patients since in most of the cases serum CRP levels dropped by more than 25% after 12 weeks of treatment. However, no significant decrease in CRP was observed between the TNF genotypes tested. Regarding the -158 V/F polymorphism in the *Fc\u03b3R\u0399\u0399\u0399A* gene, the relative decrease in serum CRP levels was greatest in VV homozygotes (78.15 \u00b1 33.68%) and lowest in FF homozygotes (69.84 \u00b1 28.7%) but this difference was not significant. Due to the small number of cases we did not stratify the genotype frequencies according to age.\n\nDiscussion {#sec1-4}\n==========\n\nThe mechanism of IFX action in IBD seems to be multifactorial and the response to IFX is a complex phenomenon influenced by several parameters \\[[@ref1]\\]. Interestingly, a certain proportion of patients do not respond to IFX at all whereas a significant proportion will lose response over time \\[[@ref3]-[@ref7]\\]. This is the first Greek study aiming at identifying any significant associationbetween the -238 G/A, -308 G/A, and -857 C/T polymorphisms in the promoter region of the TNF gene and the -158V/F polymorphism in *Fc\u03b3R\u0399\u0399\u0399A* gene and response to IFX in a cohort of adult and paediatric patients with CD and it was negative.\n\nEfficacy of IFX was assessed by clinical, serological and endoscopic parameters. Clinical response to IFX was evaluated using the HBI, which has been used in many clinical trials, is simple to use and has shown good correlation with the Crohn's Disease Activity Index (CDAI) \\[[@ref26]\\]. Serological evaluation of response to IFX was based on changes in serum levels of CRP, which has shown a good correlation with clinical activity and to a certain degree with endoscopic activity of CD \\[[@ref27]\\]. Finally, endoscopic activity of disease was assessed before and after IFX therapy using a simple description of healing of ulcerative and non ulcerative lesions \\[[Table 1](#T1){ref-type=\"table\"}\\] as has been previously described \\[[@ref21],[@ref22]\\]. Endoscopic healing was assessed after 12-20 weeks of IFX treatment. It is conceivable that 12 weeks may be early to assess mucosal healing induced by biologic therapies \\[[@ref27]\\] but the vast majority of patients underwent endoscopy at least 16 weeks after initiation of IFX therapy (average time 17.6 weeks) and therefore it is unlikely that we have not obtained an objective view of the intestinal mucosal at follow up ileocolonoscopy.\n\nRegarding the *TNF* genotypes, our results are in agreement with Louis et al \\[[@ref11]\\] who did not find any significant difference between response groups when genotyped CD patients for the TNF -308G/A polymorphism and compared response rates after IFX treatment. The same results were reported by Mascheretti et al \\[[@ref10]\\] and Dideberg et al \\[[@ref13]\\]. Moreover, our results are in agreement with Tomita et al \\[[@ref28]\\] who reported no significant difference on *TNFa*, *FcgammaRIIA* and *FcgammaRIIIA* between responders and non responders 8 weeks after IFX treatment as well as with results of ACCENT I study where the relative decrease in serum CRP levels after IFX treatment was greatest in -158 VV homozygotes and lowest in FF homozygotes \\[[@ref18]\\]. In contrast, Louis et al \\[[@ref17]\\] observed a significant association between the -158V/F polymorphism in *Fc\u03b3R\u0399\u0399\u0399A* and both the proportion of patients who had a drop in serum CRP levels after IFX treatment and the magnitude in decrease of serum CRP levels. This may account for the relatively small population of patients in our study, genetic differences in the studied populations and/or methodological differences between studies.\n\nAlthough it would be useful to genetically differentiate 'responders' from 'non-responders', there are not enough data on TNF polymorphisms in IBD and often only selected polymorphisms are genotyped. Small studies have shown possible associations between poor response to IFX and increasing mucosal levels of activated NF-kappaB, homozygosity for the polymorphism in exon 6 of TNFR2 (genotype Arg196Arg), positivity for perinuclear antineutrophil cytoplasmic antibodies and with the presence of increased numbers of activated lamina propia mononuclear cells producing interferon-gamma and TNFa \\[[@ref29]\\].\n\nIn conclusion, our study did not detect any associations between three TNF\u03b1 gene polymorphisms or the -158 V/F polymorphism in the *Fc\u03b3R\u0399\u0399\u0399A* gene and response to IFX in CD. However, in view of discrepant results in the literature large-scale pharmacogenetic studies in different populations, with similar baseline disease phenotypes and treatment protocols are needed to adequately estimate associations between genetic polymorphisms and treatment outcomes.\n\nConflict of interest: None\n\n^a^Evangelismos Hospital, ^b^Laboratory of Biology, School of Medicine, ^c^1^st^ Department of Pediatrics, School of Medicine, University of Athens, Greece\n", "meta": {"pile_set_name": "PubMed Central"}}
{"text": "---------------------- Forwarded by Benjamin Rogers/HOU/ECT on 10/19/2000 \n03:13 PM ---------------------------\n\n\nDplflan@aol.com on 10/18/2000 06:18:51 PM\nTo: Benjamin.Rogers@enron.com\ncc:  \nSubject: (no subject)\n\n\nBen-\nThis is a lengthy info/doc request - please give me feedback on how best we\ncan close the loop.\n\nThanks\nSusan Flanagan\n\n - DocReq 001013b.doc", "meta": {"pile_set_name": "Enron Emails"}}
{"text": "The two classes `KinesisRecorder` and `KinesisFirehoseRecorder` allow you to interface with Amazon Kinesis Data Streams and Amazon Kinesis Data Firehose to stream analytics data for real-time processing.\n\n## What is Amazon Kinesis Data Streams?\n\n[Amazon Kinesis Data Streams](http://aws.amazon.com/kinesis/) is a fully managed service for real-time processing of streaming data at massive scale. Amazon Kinesis can collect and process hundreds of terabytes of data per hour from hundreds of thousands of sources, so you can write applications that process information in real-time. With Amazon Kinesis applications, you can build real-time dashboards, capture exceptions and generate alerts, drive recommendations, and make other real-time business or operational decisions. You can also easily send data to other services such as Amazon Simple Storage Service, Amazon DynamoDB, and Amazon Redshift.\n\nThe Kinesis Data Streams `KinesisRecorder` client lets you store your Kinesis requests on disk and then send them all at once using the [PutRecords](https://docs.aws.amazon.com/kinesis/latest/APIReference/API_PutRecords.html) API call of Kinesis. This is useful because many mobile applications that use Kinesis Data Streams will create multiple requests per second. Sending an individual request under `PutRecord` action could adversely impact battery life. Moreover, the requests could be lost if the device goes offline. Thus, using the high-level Kinesis Data Streams client for batching can preserve both battery life and data.\n\n## What is Amazon Kinesis Data Firehose?\n\n[Amazon Kinesis Data Firehose](http://aws.amazon.com/kinesis/firehose/) is a fully managed service for delivering real-time streaming data to destinations such as Amazon Simple Storage Service (Amazon S3) and Amazon Redshift. With Kinesis Data Firehose, you do not need to write any applications or manage any resources. You configure your data producers to send data to Firehose and it automatically delivers the data to the destination that you specified.\n\nThe Amazon Kinesis Data Firehose `KinesisFirehoseRecorder` client lets you store your Kinesis Data Firehose requests on disk and then send them using the [PutRecordBatch](https://docs.aws.amazon.com/firehose/latest/APIReference/API_PutRecordBatch.html) API call of Kinesis Data Firehose.\n\nFor more information about Amazon Kinesis Data Firehose, see [Amazon Kinesis Data Firehose](http://docs.aws.amazon.com/firehose/latest/dev/what-is-this-service.html).\n\n## Integrating Amazon Kinesis\n\nSet up AWS Mobile SDK components by including the following libraries in your `app/build.gradle` dependencies list.\n\n```groovy\ndependencies {\n  implementation 'com.amazonaws:aws-android-sdk-kinesis:2.15.+'\n  implementation ('com.amazonaws:aws-android-sdk-mobile-client:2.15.+@aar') { transitive = true }\n}\n```\n\n* `aws-android-sdk-kinesis` library enables sending analytics to Amazon Kinesis.\n* `aws-android-sdk-mobile-client` library gives access to the AWS credentials provider and configurations.\n\nAdd the following imports to the main activity of your app.\n\n```java\nimport com.amazonaws.mobileconnectors.kinesis.kinesisrecorder.*;\nimport com.amazonaws.mobile.client.AWSMobileClient;\nimport com.amazonaws.regions.Regions;\n```\n\nTo use Kinesis Data Streams in an application, you must set the correct permissions. The following IAM policy allows the user to submit records to a specific data stream, which is identified by [ARN](http://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html).\n\n```json\n{\n    \"Statement\": [{\n        \"Effect\": \"Allow\",\n        \"Action\": \"kinesis:PutRecords\",\n        \"Resource\": \"arn:aws:kinesis:us-west-2:111122223333:stream/mystream\"\n    }]\n}\n```\n\nThe following IAM policy allows the user to submit records to a specific  Kinesis Data Firehose delivery stream.\n\n```json\n{\n    \"Statement\": [{\n        \"Effect\": \"Allow\",\n        \"Action\": \"firehose:PutRecordBatch\",\n        \"Resource\": \"arn:aws:firehose:us-west-2:111122223333:deliverystream/mystream\"\n    }]\n}\n```\n\nThis policy should be applied to roles assigned to the Amazon Cognito identity pool, but you need to replace the `Resource` value with the correct ARN for your Amazon Kinesis or Amazon Kinesis Data Firehose stream. You can apply policies at the [IAM console](https://console.aws.amazon.com/iam/). To learn more about IAM policies, see [Using IAM](http://docs.aws.amazon.com/IAM/latest/UserGuide/IAM_Introduction.html).\n\nTo learn more about Amazon Kinesis Data Streams policies, see [Controlling Access to Amazon Kinesis Data Streams Resources with IAM](http://docs.aws.amazon.com/kinesis/latest/dev/kinesis-using-iam.html).\n\nTo learn more about Amazon Kinesis Data Firehose policies, see [Controlling Access with Amazon Kinesis Data Firehose](http://docs.aws.amazon.com/firehose/latest/dev/controlling-access.html).\n\n## Working with the API\n\nYou can use `AWSMobileClient` to setup the Cognito credentials that are required to authenticate your requests with Amazon Kinesis.\n\n```java\nAWSMobileClient.getInstance().initialize(getApplicationContext(), new Callback<UserStateDetails>() {\n        @Override\n        public void onResult(UserStateDetails userStateDetails) {\n            Log.i(\"INIT\", userStateDetails.getUserState().toString());\n        }\n\n        @Override\n        public void onError(Exception e) {\n            Log.e(\"INIT\", \"Initialization error.\", e);\n        }\n    }\n);\n```\n\nOnce you have credentials, you can use `KinesisRecorder` with Amazon Kinesis. The following snippet creates a directory and instantiates the `KinesisRecorder` client: \n\n```java\nString kinesisDirectory = \"YOUR_UNIQUE_DIRECTORY\";\nKinesisRecorder recorder = new KinesisRecorder(\n    myActivity.getDir(kinesisDirectory, 0),\n    Regions.<YOUR-AWS-REGION>,\n    AWSMobileClient.getInstance()\n);\n\n// KinesisRecorder uses synchronous calls, so you shouldn't call KinesisRecorder methods on the main thread.\n```\n\nTo use `KinesisFirehoseRecorder`, you need to pass the object in a directory where streaming data is saved. We recommend you use an app private directory because the data is not encrypted.\n\n```java\nKinesisFirehoseRecorder firehoseRecorder = new KinesisFirehoseRecorder(\n    context.getCachedDir(), \n    Regions.<YOUR-AWS-REGION>,\n    AWSMobileClient.getInstance());\n```\n\nConfigure Kinesis:\n\nYou can configure `KinesisRecorder` or `KinesisFirehoseRecorder` through their properties:\n\nYou can configure the maximum allowed storage via the `withMaxStorageSize()` method of `KinesisRecorderConfig`.\n\nYou can retrieve the same information by getting the `KinesisRecorderConfig` object for the recorder and calling `getMaxStorageSize():`\n\n```java\nKinesisRecorderConfig kinesisRecorderConfig = recorder.getKinesisRecorderConfig();\nLong maxStorageSize = kinesisRecorderConfig.getMaxStorageSize();\n// Do something with maxStorageSize\n```\n\nTo check the number of bytes currently stored in the directory passed in to the `KinesisRecorder` constructor, call `getDiskBytesUsed()`:\n\n```java\nLong bytesUsed = recorder.getDiskBytesUsed();\n// Do something with bytesUsed\n```\n\nTo see how much space the `KinesisRecorder` client is allowed to use, you can call `getDiskByteLimit()`.\n\n```java\nLong byteLimit = recorder.getDiskByteLimit();\n// Do something with byteLimit\n```\n\nWith `KinesisRecorder` created and configured, you can use `saveRecord()` to save records and then send them in a batch.\n\n```java\nrecorder.saveRecord(\n\t\"MyData\".getBytes(),\n\t\"MyStreamName\");\nrecorder.submitAllRecords();\n```\n\nFor the `saveRecord()` request above to work, you would have to have created a stream named `MyStreamName`. You can create new streams in the [Amazon Kinesis console](https://console.aws.amazon.com/kinesis).\n\nIf `submitAllRecords()` is called while the app is online, requests will be sent and removed from the disk. If `submitAllRecords()` is called while the app is offline, requests will be kept on disk until `submitAllRecords()` is called while online. This applies even if you lose your internet connection midway through a submit. So if you save ten requests, call `submitAllRecords()`, send five, and then lose the Internet connection, you have five requests left on disk. These remaining five will be sent the next time `submitAllRecords()` is invoked online.\n\nHere is a similar snippet for Amazon Kinesis Data Firehose:\n\n```java\n// Start to save data, either a String or a byte array\nfirehoseRecorder.saveRecord(\"Hello world!\\n\");\nfirehoseRecorder.saveRecord(\"Streaming data to Amazon S3 via Amazon Kinesis Data Firehose is easy.\\n\");\n\n// Send previously saved data to Amazon Kinesis Data Firehose\n// Note: submitAllRecords() makes network calls, so wrap it in an AsyncTask.\nnew AsyncTask<Void, Void, Void>() {\n   @Override\n   protected Void doInBackground(Void... v) {\n       try {\n           firehoseRecorder.submitAllRecords();\n       } catch (AmazonClientException ace) {\n           // handle error\n       }\n   }\n}.execute();\n```\n\nTo learn more about working with Kinesis Data Streams, see the [Amazon Kinesis Data Streams resources](http://aws.amazon.com/kinesis/developer-resources/).\n\nTo learn more about the Kinesis Data Streams classes, see the [class reference for KinesisRecorder](https://aws-amplify.github.io/aws-sdk-android/docs/reference/com/amazonaws/mobileconnectors/kinesis/kinesisrecorder/KinesisRecorder.html).\n\nTo learn more about the Kinesis Data Firehose classes, see the [class reference for KinesisFirehoseRecorder](https://aws-amplify.github.io/aws-sdk-android/docs/reference/com/amazonaws/mobileconnectors/kinesis/kinesisrecorder/KinesisFirehoseRecorder.html).\n", "meta": {"pile_set_name": "Github"}}
{"text": "Q:\n\nComo passar objetos entre controllers no MVC utilizando POO\n\nBasicamente, eu preciso que ser o login for bem sucedido salvar o nome de usu\u00e1rio em uma vari\u00e1vel e utilizar-l\u00e1 em outro controller.\nModel.php:\n   public function login($email, $password) {\n    session_start();\n\n    $sql = \"SELECT * FROM users WHERE email = :email AND password= :password;\";\n    $query = $this->db->prepare($sql);\n\n    $parameters = array(':email' => $email, ':password' => $password);\n    $query->execute($parameters);\n    $rows = $query->fetch(PDO::FETCH_NUM);\n\n    if($rows > 0) {\n        header (\"Location: \" . URL . \"home\");\n    } else {\n        exit ('Email or password incorrect');\n    }\n}\n\nController.php \n  public function login() {\n    if (isset($_POST['login_submit']) AND isset($_POST['email']) AND isset($_POST['password'])) {\n        $this->model->login($_POST['email'], $_POST['password']);\n    }\n}\n\nA:\n\nN\u00e3o foi explicito mas parece que voc\u00ea quer que seja mandado por session. Sendo assim voc\u00ea pode simplesmente setar na sess\u00e3o e pegar de volta  no outro controle.\n<?php\n// declara\u00e7\u00e3o da classe Pessoa\nclass Pessoa {\n    public $nome;\n}\n\n// No Controller que envia os parametros\nsession_start();\n$joao = new Pessoa();\n$joao->nome = \"Jo\u00e3o\";\n$_SESSION['pessoa'] = $joao;\n\n// No Controller que recebe os dados\nsession_start();\n$joao = $_SESSION['pessoa'];\nprint_r($joao);\n\nOu se quiser padronizar isso e jogar no paradigma de orienta\u00e7\u00e3o a objetos\n<?php\n\n// controller que envia \n$joao = new Pessoa();\n$joao->nome = \"Jo\u00e3o\";\nSessionUtils::setPropriedade('pessoa', $joao);\n\n// controller que recebe \n$joao = SessionUtils::getPropriedadeLimpar('pessoa');\nprint_r($joao);\n\n// declara\u00e7\u00e3o da classe Pessoa\nclass Pessoa {\n    public $nome;\n}\n\n// classe util para a sess\u00e3o\nclass SessionUtils {\n\n    private static $BASE_PROPRIEDADES = \"props\";\n\n    /**\n     * Pega uma propriedade da sess\u00e3o \n     * @return a propriedade ou null se n\u00e3o existir\n     */\n    public static function getPropriedade($nome){\n        self::configurarSessao();\n        $sessao = self::getSessao();\n        return @$sessao[$nome];\n    }\n\n    /**\n     * Pega uma propriedade da sess\u00e3o e depois a exclui da mesma\n     * @return a propriedade ou null se n\u00e3o existir\n     */\n    public static function getPropriedadeLimpar($nome){\n        self::configurarSessao();\n        $sessao = self::getSessao();\n        $valor  = @$sessao[$nome];\n        self::setPropriedade($nome, null);\n        return $valor;\n    }\n\n    /**\n     * Seta uma propriedade na sess\u00e3o\n     */\n    public static function setPropriedade($nome, $valor){\n        self::configurarSessao();\n        $_SESSION[self::$BASE_PROPRIEDADES][$nome] = $valor;\n    }\n\n    /**\n     * Configura a sess\u00e3o para guardar os itens\n     */\n    private static function configurarSessao(){\n        if(!isset($_SESSION)){\n            session_start();\n        }\n        if(!self::getSessao() || !is_array(self::getSessao())){\n            self::setSessao(array());\n        }\n    }\n\n    private static function getSessao(){\n        return $_SESSION[self::$BASE_PROPRIEDADES];\n    }\n\n    private static function setSessao($valor){\n        $_SESSION[self::$BASE_PROPRIEDADES] = $valor;\n    }\n}\n\n", "meta": {"pile_set_name": "StackExchange"}}
{"text": "Retrieval of blade implants with piezosurgery: two clinical cases.\nIn this work an ultrasound device was used to perform an ostectomy for the removal of blade implants in order to save as much bone tissue as possible, so that root form implants might later be inserted. Two patients underwent surgery for the removal of two blade implants (one maxillary, the other mandibular) that were no longer functional. The peri-implant ostectomy was carried out with a piezoelectric surgery device. The instrument demonstrated to be effective and precise during ostectomy, providing an extremely thin cutting line. During the course of the operation and at controls after 7 and 30 days, patients did not show any relevant complications and both still had sufficient alveolar bone to be treated with root form implants. The piezosurgery device proved to be an effective instrument in interventions requiring a significant saving of bone tissue, extreme precision in cutting, and respect of soft tissues.", "meta": {"pile_set_name": "PubMed Abstracts"}}
{"text": "Writing my last blog post really got me thinking about that guy and all the crazy things we done. The more I thought about it, the more memories came flooding back and I decided that this blog has been a little too sad/awkward so far and anyone reading must think I\u2019ve had a whole bunch of horrible experiences. It\u2019s about time I chronicled the peaks of my journey so far and this guy is definitely a peak. In fact, I almost peak myself just thinking about him.\n\nWe met in a field. I was there \u201ccamping\u201d with friends. There were no tents. Our trip basically involved trekking into a little patch of woodland on a farm outside of town and getting really drunk/high and having sex round a badly made campfire. It was surprisingly fun. I hadn\u2019t been for a few months because I had actually fallen pregnant there, made it nearly three months into the pregnancy and miscarried. The dad wanted nothing to do with me and I hadn\u2019t told my mum. So instead of facing up to the tragedy and going to hospital, I decided that going back and getting high in conception field was a better idea. I was clearly a child genius.\n\nI hated the entire night. I hadn\u2019t been around for months, I didn\u2019t feel like I belonged anymore and I secretly resented everyone around the campfire for not being a little more sensitive to my situation. I was just a little ball of anger in the corner, curled up in a giant \u201cgoth\u201d hoodie and unable to even look at the bush in which I had regretfully created life in a drunken fumble. I was starting to see this entire thing for what it really was. Irresponsible and moronic. That\u2019s when he showed up. He looked like an angel in the firelight. He was ballsy and arrogant yet he noticed right away that I wasn\u2019t right. He was the only person that night to ask me if I was ok and he was the only one I hadn\u2019t met before. Don\u2019t get me wrong, he was hardly playing the role of my saviour but there was something about him, beyond the air of arrogance, that just drew me in. I could tell that he also hated the whole \u201cdrinking in the woods\u201d scene. At one point he asked me to go home with him but I said no, having just suffered the consequences of losing the only good thing to come out of my last drunken encounter.\n\nEveryone got drunk and stripped to their pants except me. There was a lot of jumping over the fire and running around nearly naked. It was fun to watch actually. He played guitar by the fire as we got high until the sun came up and it was just us two left. The night ended with him spooning me on the muddy floor and in the morning, he left with my number and my story. He said I needed reminding of what life is really about and that I was going about it the wrong way in those muddy woods. If I\u2019m honest I expected it to end there, I was broken and he was very aware of how hot he was. I didn\u2019t see why he\u2019d bother with a girl so obviously damaged. But he did.\n\nA week later, he calls me and invites me round for pizza and beer at his flat. I don\u2019t know why I went but I did. There was something about his attitude towards life that appealed to me at that time in my life. I\u2019d just miscarried my drunken regret, I was just about to sit important exams, my friends were horrible people and I was self-harming badly. I walked into that guy\u2019s flat a broken mess and by the time we were over, I\u2019d turned my life around and discovered who I really was. One day, I\u2019ll thank him for that.\n\nAnyways, back on track with the sex part of \u201csex blog\u201d. He was a serial charmer and holy god, he was good at it. He made me dinner, we got high and he listened to me as I told him more about how I\u2019d gotten to be where I was in life. Not to mention that he was unbelievably sexy. Before long, he was helping me out of my oversized slipknot hoodie and I had forgotten entirely about my new found chastity. He kissed away all of my resistance with a style of kissing I have since adopted myself, passionate with a lot of lip but no tongue. I was mesmerised and more turned on than I\u2019d ever been before. For once, I wasn\u2019t having sex for attention, for reassurance, for control. I was driven entirely by lust and I loved it.\n\nNow, when we were at the campsite the previous week he\u2019d told me that he\u2019d always been insecure about his small penis. He genuinely seemed so down about it which really didn\u2019t match his personality at all as he oozed confidence. At the time, I was flattered that he\u2019d confided in me about it and hadn\u2019t thought much of it. However, as he knelt between my legs about to unveil his tiny penis I was suddenly filled with dread. I was terrified that if I didn\u2019t at least pretend to have the time of my life, his complex would be worsened and I didn\u2019t wanna do that to him. So as he was about to pull off his (very tight and very sexy) boxers, I braced myself for a shrivelled little thing to greet me. Now, the room was dimly lit and I\u2019d been wearing jeans so I had no idea what was about to pop out.\n\nIt turns out he\u2019d lied about his penis being tiny purely because he liked the look on girls\u2019 faces when they came face to face with what I can only describe as the most perfect penis I\u2019ve ever seen after expecting something insignificant. How deviously twisted of him. I found it hilarious, personally. It definitely tickled me pink.\n\nWhat followed was literally life-changing sex. His tongue gave me tingles in places I didn\u2019t even know could tingle and he done things with his penis that I have never been able to replicate since. It was raw, carnal and rough. I\u2019d been with dominant guys before but I\u2019d always felt like ultimately, I was in control. Not this time. He truly owned every part of me that night and I loved it. He held me down and teased me until I begged and then kept teasing. A few hours in, he\u2019d turned me from a timid and sad girl into a ferocious sex toy and I had never felt so alive. I spent that night acting purely upon selfish impulses and the desire for new sensations rather than thought and logic like usual. He was exactly what I needed to wake me up from the pit of teenage angst I\u2019d fallen into. I went home aching everywhere and grinning ear to ear. I was hooked.\n\nI was back the next day and he knew I would be. This time I thought I was ready for him, that I knew what was coming but I\u2019d soon learn that would never be the case with this one. He loved pushing boundaries and was inherently unpredictable. This time we had shower sex and he found it hilarious that I was unable to stay standing when I orgasmed. The next time he tied me up with duct tape and teased me for hours. I just kept coming back for more. Soon I started skipping school to spend time with him. We had high sex, drunk sex,, rough sex, morning sex, slow sex, half asleep sex, angry sex, and ultimately sad sex. It didn\u2019t take me long to convince my immature self that I loved this boy. He\u2019d woken me up from my sadness and I soon confused this new found happiness and emotion with love. I wanted him to myself and even then it was apparent that he was untameable.\n\nOne time I showed up at his place with fresh cuts on my legs. He was so disappointed. He\u2019d spent weeks building my confidence, teaching me to stop wearing my heart on my sleeve and now I\u2019d relapsed. This was when he really turned my life around. He took me shopping, made me try on girly clothes instead of the usual baggy black clothes I usually wore. He bought me my first lingerie corset-suspender set and my first vibrator (Hamish). He took me to his flat, dressed me up in the lingerie and went over every inch of my body telling me what he found sexy about it. He cuddled me after sex and told me about his view of life, about how I was way too young to be carrying so much bitterness and sadness around on my sleeve. How I\u2019d regret missing out on being young when I\u2019m older. Then he played his guitar and sung his own songs naked (honestly).\n\nSince that night I have never cut myself on purpose again.\n\nWe continued our whirlwind romance. He sneaked me into pubs despite both of us being underage, his charm got him served easily. I tried my first shot with him. He took me to his favourite shop \u2013 a little vintage place outside of the city centre. He taught me how to roll a joint and we\u2019d fall asleep during high sex, him still inside me. He encouraged me to help myself along during sex and I had the most powerful orgasms I\u2019d ever had doing that. I starred in my very first sex video with him. I tried anal for he first time after he tied me up with my stockings, gagged me and used my vibrator on me. I found out all of my limits with him and loved every second and every time he pushed me just a little bit further.\n\nHe pushed me to look for who I really was but despite all of the sweet and sexy things he\u2019d do for me I knew deep down he wasn\u2019t just mine. He refused to commit, he saw other girls and didn\u2019t keep in regular contact. I hated it and pushed for commitment. Then, he found out he was gonna be a dad. He\u2019d gotten some other girl pregnant. I was upset but in my stupid teenage infatuation, I stayed with him. Then I walked in on him and that other girl and that\u2019s where my last post starts.\n\nIt wasn\u2019t how I\u2019d hoped it would end but by that stage I\u2019d grown in confidence so much that I\u2019d realised that he had given me all I needed to get by on my own. He was a wild one and had no plans for the future and had a baby on the way. I had just aced all of my exams and my future was whatever I wanted it to be. Limitless.\n\nThe girl went on to have a baby boy. He now has a 4 year old son and last I heard was selling drugs and in a band. He texted me later on and asked if I wanted to have another threesome with him and the baby\u2019s mum or wanted any drugs. I said no and that\u2019s the last I ever heard of the wild boy who taught me how to push boundaries and to be proud of my own body and what I can do with it.", "meta": {"pile_set_name": "OpenWebText2"}}
{"text": "Sun aims powerful flares at Earth\n\nTop: Two large sunspot groups are visible in this image of the sun obtained by the Solar and Heliospheric Observatory (SOHO). Below: This SOHO image shows a large filament eruption that occurred February 26. The disk in the center is a mask that blocks out direct sunlight.\n\nBy Richard Stenger\nCNN Interactive Staff Writer\n\nMarch 1, 2000\nWeb posted at: 3:24 p.m. EST (2024 GMT)\n\n(CNN) -- The sun should place the Earth squarely in its\nsights this week as it aims its solar ray gun. Astronomers\ntell terrestrial dwellers not to sweat it too much, despite\nthe fact that solar activity is approaching an 11-year peak.\n\nTwo large sunspots moving across the surface of the sun are\nexpected to directly face the Earth soon for up to several\ndays, according to solar scientists. Such sunspots often\nherald powerful coronal mass ejections and solar flares,\nspace storms that can disrupt weather and electrical systems\non Earth.\n\nSolar flares are the largest explosions in the solar system.\nA typical one can release the energy equivalent of millions\nof 100-megaton hydrogen bombs exploding at once.\n\nHighly charged particles from large flares can overload power\ngrids and damage satellites. In 1989, one space storm knocked\nout a major power plant in Canada, leaving millions without\npower for hours.\n\nSolar activity generally waxes and wanes during an 11-year\ncycle and astronomers expect it to peak either this or next\nyear. But so far, the sun has produced only a \"disappointing\"\nlevel of fireworks, said Joseph Gurman, a solar physicist who\nanalyzes data from the Solar and Heliospheric Observatory.\n\nCoronal mass ejections are much more likely to produce\neffects, Gurman said. Like flares, they send streams of highly\ncharged particles, but they also can emit a billion tons of\nplasma, or ionized gas.\n\nFortunately the Earth's magnetosphere usually bears the brunt\nof plasma particles. \"If we were exposed to them, we\nliterally would be fried,\" Gurman said.", "meta": {"pile_set_name": "Pile-CC"}}
{"text": "Q:\n\nStAX and arraylist java\n\nI'm trying to read an xml document with StAX but I have a little problem and i don't know how to fix it, I've tried to look for over internet (maybe i'm using the wrong key word for my problem :/)\nso I've this XML:\n<questionReponses\nxmlns:xsi='http://www.w3.org/2001/XMLSchema-instance'\nxmlns='http://polytis.fr/studentest'\nxsi:schemaLocation='http://polytis.fr/studentest qanda.xsd'>\n<questionReponse>\n    <categorie>Biologie</categorie>\n    <question>Question 1</question>\n    <reponse>reponse correcte 1</reponse>\n    <mauvaiseReponse>reponse fausse 1.1</mauvaiseReponse>\n    <mauvaiseReponse>reponse fausse 1.2</mauvaiseReponse>\n    <mauvaiseReponse>reponse fausse 1.3</mauvaiseReponse>\n</questionReponse>\n<questionReponse>\n    <categorie>Chimie</categorie>\n    <question>Question 2</question>\n    <reponse>reponse correcte 2</reponse>\n    <mauvaiseReponse>reponse fausse 2.1</mauvaiseReponse>\n    <mauvaiseReponse>reponse fausse 2.2</mauvaiseReponse>\n    <mauvaiseReponse>reponse fausse 2.3</mauvaiseReponse>\n</questionReponse>\n<questionReponse>\n    <categorie>CultureG</categorie>\n    <question>Question 3</question>\n    <reponse>reponse correcte 3</reponse>\n    <mauvaiseReponse>reponse fausse 3.1</mauvaiseReponse>\n    <mauvaiseReponse>reponse fausse 3.2</mauvaiseReponse>\n    <mauvaiseReponse>reponse fausse 3.3</mauvaiseReponse>\n</questionReponse>\n\nhere is my parser:\ntry {\n        // instanciation du parser\n        InputStream in = new FileInputStream(nomFichier);\n        XMLInputFactory factory = XMLInputFactory.newInstance();\n        XMLStreamReader parser = factory.createXMLStreamReader(in);\n\n        // lecture des evenements\n        for (int event = parser.next(); event != XMLStreamConstants.END_DOCUMENT; event = parser.next()) {\n            // traitement selon l'evenement\n            switch (event) {\n                case XMLStreamConstants.START_ELEMENT:\n                    break;\n                case XMLStreamConstants.END_ELEMENT:\n                    if (parser.getLocalName().equals(\"questionReponse\")) {\n                        question = new Question(categorieCourante,questionCourante,bonneReponseCourante,mauvaisesReponses);\n                        quizz.add(question);\n                    }               \n                    if (parser.getLocalName().equals(\"categorie\")) {\n                        categorieCourante = donneesCourantes;\n                    }\n                    if (parser.getLocalName().equals(\"question\")) {\n                        questionCourante = donneesCourantes;\n                    }\n                    if (parser.getLocalName().equals(\"reponse\")) {\n                        bonneReponseCourante = donneesCourantes;\n                    }\n                    if (parser.getLocalName().equals(\"mauvaiseReponse\")) {\n                        mauvaisesReponses.add(donneesCourantes);\n                    }\n                    break;\n                case XMLStreamConstants.CHARACTERS:\n                    donneesCourantes = parser.getText();\n                    break;\n            } // end switch\n        } // end for\n        parser.close();\n    }\n\nand the result is not the one expected:\nquestion 1\n[categorie = \nBiologie\nquestion = \nQuestion 1\nbonne reponse = \nreponse correcte 1\nmauvaises reponse = \nreponse fausse 1.1\nreponse fausse 1.2\nreponse fausse 1.3\nreponse fausse 2.1\nreponse fausse 2.2\nreponse fausse 2.3\nreponse fausse 3.1\nreponse fausse 3.2\nreponse fausse 3.3\n\n, categorie = \nChimie\nquestion = \nQuestion 2\nbonne reponse = \nreponse correcte 2\nmauvaises reponse = \nreponse fausse 1.1\nreponse fausse 1.2\nreponse fausse 1.3\nreponse fausse 2.1\nreponse fausse 2.2\nreponse fausse 2.3\nreponse fausse 3.1\nreponse fausse 3.2\nreponse fausse 3.3\n\n, categorie = \nCultureG\nquestion = \nQuestion 3\nbonne reponse = \nreponse correcte 3\nmauvaises reponse = \nreponse fausse 1.1\nreponse fausse 1.2\nreponse fausse 1.3\nreponse fausse 2.1\nreponse fausse 2.2\nreponse fausse 2.3\nreponse fausse 3.1\nreponse fausse 3.2\nreponse fausse 3.3\n\n]\n\nand it's the same for the 3 question i have. When i parse \"mauvaiseReponse\" all the the \"mauvaiseReponse\" balise are streamed and added.\nthe result i'm looking for is something like this:\nquestion 1\ncategorie = \nBiologie\nquestion = \nQuestion 1\nbonne reponse = \nreponse correcte 1\nmauvaises reponse = \nreponse fausse 1.1\nreponse fausse 1.2\nreponse fausse 1.3\n\ni'm sorry if my english isn't that good, i hope you will undestand my problem and can help me with this\n\nA:\n\nExplanation\nSimply, you must renew your badAnswers (mauvaisesReponses) list on each completed Question instance.\nI've written a sample code for the provided input xml file. For simplicity, I've created the Question class in the same file with solution;\n    // A - first instantiation of badAnswers list\n    List<String> badAnswers = new LinkedList<>();\n    for (int event = parser.next(); event != XMLStreamConstants.END_DOCUMENT; event = parser.next()) {\n\n        switch (event) {\n            case XMLStreamConstants.START_ELEMENT:\n                break;\n\n            case XMLStreamConstants.END_ELEMENT:\n                if (parser.getLocalName().equals(\"questionReponse\")) {\n                    Question question = new Question(currentCategory, currentQuestion, currentRightAnswer, badAnswers);\n                    quiz.add(question);\n                    // B - Renew badAnswers after each Question entry insert\n                    badAnswers = new LinkedList<>();    \n                }   \n\nPlease also note that I've used LinkedList implementation here to demonstrate that your problem is not related to the List implementation, it is implementation-agnostic.\nSolution Code\nimport java.io.FileInputStream;\nimport java.io.FileNotFoundException;\nimport java.io.InputStream;\nimport java.util.LinkedList;\nimport java.util.List;\n\nimport javax.xml.stream.XMLInputFactory;\nimport javax.xml.stream.XMLStreamConstants;\nimport javax.xml.stream.XMLStreamException;\nimport javax.xml.stream.XMLStreamReader;\n\npublic class Solution {\n\n    public static void main(String[] args)  {\n        List<Question> quiz = getQuiz(\"inputFile.xml\");\n\n        printQuiz(quiz);\n    }\n\n    public static List<Question> getQuiz(String fileName) {\n        List<Question> quiz = null;\n\n        try {\n            // parser instantiation\n            InputStream in = new FileInputStream(fileName);\n            XMLInputFactory factory = XMLInputFactory.newInstance();\n            XMLStreamReader parser = factory.createXMLStreamReader(in);\n\n            String currentData = null, currentCategory = null, currentQuestion = null, currentRightAnswer = null;\n            quiz = new LinkedList<>();\n            List<String> badAnswers = new LinkedList<>();   // first instantiation of badAnswers list\n            for (int event = parser.next(); event != XMLStreamConstants.END_DOCUMENT; event = parser.next()) {\n\n                switch (event) {\n                    case XMLStreamConstants.START_ELEMENT:\n                        break;\n\n                    case XMLStreamConstants.END_ELEMENT:\n                        if (parser.getLocalName().equals(\"questionReponse\")) {\n                            Question question = new Question(currentCategory, currentQuestion, currentRightAnswer, badAnswers);\n                            quiz.add(question);\n                            badAnswers = new LinkedList<>();    // Renew badAnswers after each Question entry insert\n                        }               \n                        if (parser.getLocalName().equals(\"categorie\")) {\n                            currentCategory = currentData;\n                        }\n                        if (parser.getLocalName().equals(\"question\")) {\n                            currentQuestion = currentData;\n                        }\n                        if (parser.getLocalName().equals(\"reponse\")) {\n                            currentRightAnswer = currentData;\n                        }\n                        if (parser.getLocalName().equals(\"mauvaiseReponse\")) {\n                            badAnswers.add(currentData);\n                        }\n                        break;\n\n                    case XMLStreamConstants.CHARACTERS:\n                        currentData = parser.getText();\n                        break;\n                }\n            }   // end of for loop\n            parser.close();\n\n        } catch (FileNotFoundException | XMLStreamException e) {\n            e.printStackTrace();\n        }\n\n        return quiz;\n    }\n\n    public static void printQuiz(List<Question> quiz) {\n        int i = 1;\n        for(Question q : quiz) {\n            System.out.println(\"Question    : \" + i++);\n            System.out.printf(\"\\tCategory   : %s\\n\" , q.getCurrentCategory());\n            System.out.printf(\"\\tQuestion   : %s\\n\" , q.getCurrentQuestion());\n            System.out.printf(\"\\tAnswer     : %s\\n\" , q.getCurrentRightAnswer());\n            System.out.printf(\"\\tBad Answers: %s\\n\" , q.getBadAnswers());\n            System.out.println(\"***********************\\n\");\n        }\n    }\n\n}\n\nclass Question {\n\n    private String currentCategory;\n    private String currentQuestion;\n    private String currentRightAnswer;\n    private List<String> badAnswers;\n\n    public Question(String currentCategory, String currentQuestion, String currentRightAnswer, List<String> badAnswers) {\n        this.currentCategory = currentCategory;\n        this.currentQuestion = currentQuestion;\n        this.currentRightAnswer = currentRightAnswer;\n        this.badAnswers = badAnswers;\n    }\n\n    public String getCurrentCategory() {\n        return currentCategory;\n    }\n\n    public String getCurrentQuestion() {\n        return currentQuestion;\n    }\n\n    public String getCurrentRightAnswer() {\n        return currentRightAnswer;\n    }\n\n    public List<String> getBadAnswers() {\n        return badAnswers;\n    }\n\n}\n\nDemo Output\nQuestion    : 1\n    Category   : Biologie\n    Question   : Question 1\n    Answer     : reponse correcte 1\n    Bad Answers: [reponse fausse 1.1, reponse fausse 1.2, reponse fausse 1.3]\n***********************\n\nQuestion    : 2\n    Category   : Chimie\n    Question   : Question 2\n    Answer     : reponse correcte 2\n    Bad Answers: [reponse fausse 2.1, reponse fausse 2.2, reponse fausse 2.3]\n***********************\n\nQuestion    : 3\n    Category   : CultureG\n    Question   : Question 3\n    Answer     : reponse correcte 3\n    Bad Answers: [reponse fausse 3.1, reponse fausse 3.2, reponse fausse 3.3]\n***********************\n\n", "meta": {"pile_set_name": "StackExchange"}}
{"text": "For the Democratic Party, a pliant and friendly news media is both a blessing and a curse.\n\nOn the one hand, the corporate press's eagerness to rehabilitate Democratic officials after even the most shameful and despicable acts has made it possible for some of the party\u2019s worst actors to maintain political power with relative ease. Then again, the news media\u2019s reflexively and reliably soft coverage of left-wing lawmakers has made the chief benefactors of this cozy relationship both soft and complacent. Democratic officials and candidates have been lulled into a false sense of security, ignoring or forgetting the benefits that come with being tempered by a thorough, brutal vetting.\n\nThe downside to the corporate media\u2019s mostly hands-off approach to covering Democratically aligned lawmakers was never clearer than it was during the Feb. 19 primary debate in Las Vegas, Nevada.\n\nFormer New York City Mayor Michael Bloomberg, who spent much of the evening having his entrails ripped out by his 2020 opponents and paraded around the stage, managed to get in one good blow against Sen. Bernie Sanders, going after the Vermont lawmaker for his conspicuous wealth.\n\n\u201cWhat a wonderful country we have,\u201d said the former mayor. \u201cThe best-known socialist in the country happens to be a millionaire with three houses. What did I miss here?\u201d\n\n\u201cWell,\u201d an irate Sanders said, \u201cYou'll miss that I work in Washington, house one. \u201d\n\nBloomberg interjected, \u201cThat's the first problem.\u201d\n\n\u201cLive in Burlington, house two,\u201d the senator continued.\n\nThe former mayor interrupted again, \u201cThat's good.\u201d\n\n\u201cAnd like thousands of other Vermonters, I do have a summer camp. Forgive me for that. Where is your home? Which tax haven do you have your home?\u201d Sanders demanded, hopelessly losing the exchange.\n\n\u201cNew York City, thank you very much,\u201d Bloomberg said to applause, \u201cand I pay all my taxes.\u201d\n\nThe most remarkable thing about the exchange is not that Sanders was so easily baited by Bloomberg into making a sloppy, blindly angry defense but that it marked the first time in the 2020 campaign season that anyone, Democrat, reporter, or debate moderator, pressed the 2020 Democratic primary front-runner to reconcile his own considerable fortune with his core message of confiscating wealth from business owners.\n\nHow did Sanders make it through nine debates without a fellow Democrat or debate moderator asking him to respond to the most obvious criticism he will face should he go up against Trump? The 2016 election was a \u201ctakers versus makers\u201d election. It is astonishing, then, that it took for a 2020 Democratic primary candidate who is not even on the ballot in Nevada or South Carolina to ask the millionaire socialist senator about his three houses. I guess that is what happens when you schedule all your primary debates with only friendly news networks.\n\nThis gets to the precise problem of the too-friendly relationship between the Democratic Party and the corporate media. It is a double-edged sword that allows terrible men to weather what should be career-ending scandals and missteps but also leads to their entire party getting lazy and soft. Not having to worry about a tough, combative press is how you get incidents such as the 2020 Democratic front-runner being totally unprepared to answer the most obvious criticism of his campaign.\n\nIf Sanders's disastrous handling of Bloomberg's no-brainer broadside is a portent of things to come, the general election meat grinder will be a straight-up bloodbath for Democrats.", "meta": {"pile_set_name": "OpenWebText2"}}
{"text": "\nFacebook has hired the Patriot Act's co-author as a general counsel - Jerry2\nhttps://boingboing.net/2019/04/22/mass-surveillance-r-us.html\n======\njavagram\n\u201cJennifer Newstead helped craft the Patriot Act, a cowardly work of treasonous\nlegislation foisted on the American people in the wake of the 9/11 attacks;\u201d\n\nSource seems a little biased. Treasonous? That\u2019s gotta require a lot of\ncortortion around the definition of treason.\n\nPatriot Act provisions have been repeatedly reauthorized by the democratically\nelected legislature since it was originally passed. This isn\u2019t a case of\nfoisting anything upon the people, the people are perfectly happy to vote in\nsupporters of the Patriot Act.\n[https://en.wikipedia.org/wiki/Patriot_Act#Reauthorizations](https://en.wikipedia.org/wiki/Patriot_Act#Reauthorizations)\n\n~~~\nthundergolfer\nIt's well known that many members of congress passed through the act _without\nhaving read it_. Given the enormity of the act's effects on the country, this\nis quite a problematic thing.\n\nI don't it was democracy that saw that bill through. It was crisis politics.\nDemocracy requires a well-informed public, and capable representatives. With\nthe USA PATRIOT act there was neither.\n\n~~~\nfoxyv\nWith the current state of campaign finance, congress is essentially two\ncorporations with congressmen/women as employees. If you don't vote the party\nline or you don't secure funding for the party you get defunded on your next\nelection. Surprising they don't bother to read the bills they are told to\npass.\n\n------\ncanada_dry\nA perfect fit really.\n\nThis guy figures it's ok to allow personal records like telephone, e-mail,\nfinancial, and business records to be surreptitiously captured without full\ndue process/transparency.\n\nFacebook would love to push the (no-)privacy envelope much further: a complete\ndata free-for-all for their commercial gain.\n\n------\nJerry2\nIt's unfortunate that mods decided sink this story. Any explanation as to why?\n\n------\ntuxxy\nWhat exactly... do they think is going to happen when news outlets hear this?\n\n~~~\njoshmn\nThe 30 minute news cycle we've had for the last 3 years of course.\n\n~~~\nisoskeles\nYeah unlike when the Patriot Act passed, and the news media spoke truth to\npower or whatever, and saved us all from that treasonous law.\n\nApologies for the snark but it\u2019s been like this for more than 20 years.\n\n~~~\nthundergolfer\nTo add to your comment. _Manufacturing Consent_ came out in 1988, 31 years\nago. That book manfully built the case that this stuff has been going on for\nwell over a century, but that it really kicked up in the post WW2 era with the\nerosion of labour-class news media.\n\nToday 6 US media companies control 90% of US media, and any hope one has of\nthe internet disarming them dims more than a little at the sight of a\nP.A.T.R.I.O.T act author crossing over into the arms of a tech giant.\n\n", "meta": {"pile_set_name": "HackerNews"}}
{"text": "Da den fynske optiker Finn Juncker tog til Senegal for at v\u00e6re med til at uddele brugte briller til befolkningen, var han opfyldt af idealisme og entusiasme. Fem \u00e5r senere m\u00e5tte han sande, hvor vanskeligt det kan v\u00e6re at hj\u00e6lpe andre.\n\nFinn Juncker har et freelance-optikerfirma. Med udgangspunkt i F\u00e5borg arbejder han ogs\u00e5 i Albertslund, i Malaga og i Gr\u00f8nland, og i perioder har han arbejdet i Senegal. Det sidste for egen regning.\n\nDet afrikanske eventyr begyndte, da han s\u00e5 en annonce i bladet Optikeren, hvor man s\u00f8gte optikere til et projekt om brugte briller til befolkningen i Senegal. Projektet gik ud p\u00e5, at indsamle brugte briller i Danmark. Brillerne blev renoveret og repareret af tidligere alkoholikere og narkomaner p\u00e5 et behandlingshjem i Nyk\u00f8bing Falster og herefter sendt til Senegal.\n\nBag projektet stod en dansk sygeplejerske. Hun s\u00f8gte to optikere, en sygeplejerske mere og en medhj\u00e6lper. I 1998 rejste disse fire, inklusive Finn Juncker, til Senegal. De skulle selv betale rejsen og opholdet, og de m\u00e5tte bruge deres sommerferie p\u00e5 det.\n\n- Vi boede i lerhytter hos de lokale og sov p\u00e5 gulvet, og vores tre daglige m\u00e5ltider bestod af ris, som vi selv skulle betale for. Vi havde ogs\u00e5 udgifter til chauff\u00f8r og benzin. Vi var der knap tre uger, og vi foretog 200 synspr\u00f8ver og udleverede 150 par briller hver dag. Folk var kommet g\u00e5ende flere dagsmarcher for at f\u00e5 briller. Desv\u00e6rre kom der ogs\u00e5 mange blinde og folk med gr\u00e5 st\u00e6r, som h\u00e5bede, at vi kunne kurere dem. Det var h\u00e5rdt at v\u00e6re vidne til. Men de mange, vi kunne hj\u00e6lpe, var hele rejsen v\u00e6rd, fort\u00e6ller Finn Juncker.\n\nKort efter projektets start s\u00f8gte den ledende sygeplejerske om midler hos Danida. Omkring en halv million kr. blev bevilget til de tre \u00e5r, projektet skulle l\u00f8be. Det var nu et Danida-projekt.\n\nNogle af pengene gik til at f\u00e5 senegalesere til Danmark, hvor Finn Juncker opl\u00e6rte dem, s\u00e5 de kunne fungere som optikere hjemme og s\u00e5ledes overtage danskernes arbejde. Der gik tre \u00e5r p\u00e5 denne m\u00e5de. Finn Juncker brugte to-tre uger hvert \u00e5r af sin sommerferie p\u00e5 at arbejde som optiker i Senegal, og om vinteren opl\u00e6rte han senegalesere i Danmark. Men \u00f8konomien knirkede.\n\n- Der var et eller andet helt galt. Vi betalte alt for meget for den mad, vi spiste, dvs. ris, og alt for meget for benzin og til chauff\u00f8rens l\u00f8n. M\u00e5lt med lokale alen. F.eks. var det den danske stats kilometertakst, der blev anvendt, n\u00e5r vi skulle k\u00f8re ud og betjene befolkningen. Men brillerne blev leveret, og behovet var stort. S\u00e5 vi betalte, beretter Finn Juncker.\n\nDe var j\u00e6vnligt ude for en del ubehagelige hold-ups ved forskellige checkpoints af krigere med maskingev\u00e6rer. Omr\u00e5det var plaget af uro, og det var ikke ufarligt at bev\u00e6ge sig omkring dernede.\n\nDa projektet udl\u00f8b efter tre \u00e5r, opfordrede Finn Juncker tre optikere, han kendte som folk med hjertet p\u00e5 rette sted, til at tage med ham til Senegal i sommerferien og videref\u00f8re det p\u00e5begyndte arbejde.\n\nHan kontaktede folkene i Senegal og fortalte, at et hold p\u00e5 fire danske optikere med et l\u00e6s briller var klar til at tage af sted p\u00e5 egen h\u00e5nd. Det vil sige uden Danida-midler. Optikerne ville ikke kunne betale de samme summer til senegaleserne som hidtil for mad og transport. Da k\u00f8lnedes interessen m\u00e6rkbart hos senegaleserne, og de fire optikere kom aldrig af sted.\n\nMen Finn Juncker er gjort af st\u00e6digt stof. Han havde l\u00e6rt en gambianer at kende, som var indehaver af en brillebutik i Gambia, men som ikke var uddannet optiker. De to indgik en forretningsaftale om kompagniskab.\n\nFinn Juncker skulle l\u00e6re ham op og hj\u00e6lpe ham i gang som partner i foretagenet. Det gik ogs\u00e5 fint. Finn Juncker uddannede gambianeren i hans butik og havde medbragt en hel del kostbare m\u00e5leinstrumenter til synspr\u00f8ver.\n\nMeningen var, at gambianeren skulle k\u00f8be m\u00e5leinstrumenterne for de penge, han solgte briller for, men han ville hellere k\u00f8be biler. Da Finn Juncker forklarede ham, at han gerne ville have sine m\u00e5leinstrumenter tilbage, tilkaldte gambianeren politiet og bildte betjentene ind, at Finn Juncker havde for\u00e6ret ham instrumenterne.\n\nFinn Juncker m\u00e5tte opgive at f\u00e5 sine instrumenter igen.\n\nEn ekstra bitter kr\u00f8lle p\u00e5 det eventyr var, at Finn Juncker i Danmark forg\u00e6ves k\u00e6mpede med skattev\u00e6snet, der ikke ville anerkende hans rejse som forretning og udgifterne i den forbindelse som fradragsberettiget.\n\n- Jeg inds\u00e5, at det var slut. Min indsats og mine penge var tabt. De senegalesere, vi havde l\u00e6rt op som optikere her i Danmark, har aldrig f\u00e5et lov at praktisere i Senegal. Jeg m\u00e5 sige, at jeg har f\u00e5et et temmelig desillusioneret syn p\u00e5 ulandsst\u00f8tte. Pengene g\u00e5r i de forkerte lommer. Og vores projekt er desv\u00e6rre ikke enest\u00e5ende. Det er kendetegnende for en r\u00e6kke afrikanske lande, at nogle f\u00e5 magtfulde h\u00f8vdinge sidder p\u00e5 alt, og de er villige til at g\u00e5 langt for at f\u00e5 del i st\u00f8ttemidlerne. De bruger pengene til deres egen familie, til at sende deres b\u00f8rn p\u00e5 dyre skoler, til rejser og luksus. Det var situationen omkring brilleprojektet, og det var grunden til, at vi skulle betale s\u00e5 meget for mad og k\u00f8rsel. Tilbage st\u00e5r tusindvis af fattige og syge, som kunne have v\u00e6ret hjulpet ofte for et forholdsvis beskedent bel\u00f8b, siger Finn Juncker.\n\nHan har ikke fortrudt sin indsats i Afrika, men han er skuffet og \u00e6rgerlig. Sin trang til at g\u00f8re nytte og hj\u00e6lpe andre f\u00e5r han s\u00e5 udl\u00f8b for i Gr\u00f8nland.", "meta": {"pile_set_name": "OpenWebText2"}}
{"text": "1. Field of the Invention\nThe present invention relates to a motor drive apparatus which is, for example, used for driving an X-Y table of a monolithic wire bonder or a die bonder serving as one of IC manufacturing apparatus, and a method of controlling the same.\n2. Description of the Related Art\nThere is known a method of accurately stopping a motor at a target position, as disclosed in Unexamined Japanese Patent Application No. 55-77384/1980. In this prior art, after the motor passes through the target position, an error extreme point is obtained in order to determine a current value to be supplied to the motor to correct the error. Then, a rectangular current is supplied to the motor so as to eliminate the error and stop the motor at the target position.\nHereinafter, a background technology of the present invention will be explained. FIG. 10 is a block diagram showing one example of a motor drive apparatus controlling a typical three-phase synchronous motor. FIG. 11 is a detailed view showing a motor 1 of FIG. 10. FIG. 12 is a view showing inductive voltages of the motor 1 of FIG. 10. FIG. 13 is a view showing output signals from an encoder 2 shown in FIG. 10. FIG. 14 is a view showing an operation of a pulse converter 3 shown in FIG. 10. And, FIG. 15 is a detailed view showing a magnetic pole detector 4 of FIG. 10.\nIn FIG. 10, a reference numeral 1 represents a three-phase synchronous motor equipped with 9 slots and 6 poles. More specifically, as shown in FIG. 11, this three-phase synchronous motor comprises a stator 5 and a rotor 6. The stator 5 is associated with three coils of U-phase 7, V-phase 8, and W-phase 9 windings. This motor 1 has nine slots 10 disposed on an inside surface of the stator 5 which are spaced at intervals of 40 degrees. These nine slots 10 are wound by the coil windings in the order of U-phase, V-phase, and W-phase repetitively so as to form a star connection. On the other hand, the rotor 6 has six permanent magnet poles 11 disposed on the outer circumferential surface thereof.\nAn operational principle of the motor 1 will be explained below. The rotor 8 causes a magnetic field corresponding to its rotational position, which interacts with three, U-phase 7, V-phase 8, and W-phase 9, windings on the stator 5. Therefore, these three windings 7, 8, and 9 generate voltages due to Lorentz's force. Namely, three, U-phase 12, V-phase 13, and W-phase 14, inductive voltages of sine waveform are generated at intervals of 120 degrees as shown in FIG. 12 because a magnetic field to each winding is cyclically increased and decreased in response to spatial positioning of the permanent magnet 11 which cyclically approaches to and departs from each winding during one complete revolution of the rotor 6.\nIf sine-wave currents being in-phase with these inductive voltages of FIG. 12 are supplied to the U-phase 7, V-phase 8, and W-phase 9 windings, respectively, the rotor 6 generates a torque in a clockwise (abbreviated as CW) direction due to Fleming's left-hand rule. The magnitude of the torque generated is proportional to an amplitude of the current supplied. Moreover, if the above currents are further multiplied with -1 and delayed 180 degrees in phase before being supplied to respective windings, the rotor 6 generates a torque in a counterclockwise (abbreviated as CCW) direction.\nIn FIG. 10, a reference numeral 2 represents an optical encoder having three channels and installed on a rotor shaft of the motor 1. When the motor i rotates in the clockwise (CW) direction, the encoder 2 generates an A-phase signal 15 and a B-phase signal 18 having a mutual phase difference of 90 degrees therebetween as shown in FIG. 12, together with a Z-phase pulse signal 17 corresponding to one of zero-crossing 20 points of the U-phase inductive voltage 12. If the motor 1 rotates in the counterclockwise (CCW) direction, the phase relationship between the A-phase signal 15 and B-phase signal 16 are reversed. Therefore, the rotational direction of the motor 1 is easily judged by checking the phase relationship between the A-phase signal 15 and the B-phase signal 18.\nA reference numeral 3 represents a pulse converter connected to the encoder 2. This pulse converter 3 converts the A-phase and B-phase signals 15 and 18 into a CW pulse signal 18 as shown in FIG. 14 when the motor 1 rotates in the clockwise direction. On the contrary, this pulse converter 3 converts the A-phase and B-phase signals 15 and 16 into a CCW pulse signal 19 as shown in FIG. 14 when the motor 1 rotates in the counterclockwise direction. A reference numeral 4 represents a magnetic pole detector comprising a counter 20, a U-phase current phase command table 21, and a W-phase current phase command table 22. As shown in FIG. 15, the counter 20 receives the signals fed from the pulse converter 3 so as to effect its count-up and count-down operations in response to the CW pulse 18 and the CCW pulse 19, respectively. Furthermore, the counter 20 is connected to the encoder 2 so as to effect its clear operation in response to the Z-phase signal 17. The U-phase current phase command table 21 memorizes the phase of the U-phase inductive voltage 12 with respect to the Z-phase signal 17 of the encoder 2. The W-phase current phase command table 22 memorizes the phase of the W-phase inductive voltage 14 with respect to the Z-phase signal 17.\nAn operation of the magnetic pole detector 4 will be explained below. The counter 20 is cleared at the zero-cross point of the U-phase inductive voltage 12 in response to the Z-phase signal 17 fed from the encoder 2. When the motor 1 rotates, a rotational displacement or shift amount from the above zero-cross point of the U-phase inductive voltage 12 is counted by the counter 20. The counted value becomes a pointer 23 of the U-phase current phase command table 21 for outputting a phase value of the U-phase inductive voltage 12 corresponding to the present rotational position of the motor 1. In the same manner, the counted value of the counter 20 becomes a pointer 23 of the W-phase current phase command table 22 for outputting a phase value of the W-phase inductive voltage 14 corresponding to the present rotational position of the motor 1.\nThe magnetic pole detector 4 is connected to two multipliers 24U, 24W so that the phase values of the U-phase and W-phase inductive voltages 12 and 14 can be multiplied with an output of a speed control calculator 25. The speed control calculator 25 outputs a torque command value, i.e. a current amplitude command value. The multipliers 24U, 24W, therefore, multiply the current amplitude command value with the U-phase and W-phase current phase command values. The resultant two outputs from respective multipliers 24U, 24W are, then, fed to two D/A converters 28U, 28W so as to generate U-phase and W-phase current commands, respectively. These U-phase and W-phase current commands are, subsequently, fed to current amplifiers 27U, 27W in which drive currents to be supplied to the U-phase winding 7 and the W-phase winding 9 are generated in response to the U-phase and W-phase current commands, respectively.\nThe U-phase winding 7, the V-phase winding 8, and the W-phase winding 9 are connected with each other so as to constitute a star connection; therefore, the sum of currents flowing through these three-phase windings 7, 8, and 9 becomes 0. A current command for the V-phase winding 8 is, accordingly, identical with -(U-phase current command +W-phase current command). A subtracter 28 is therefore provided to obtain a V-phase current command equal to -(U-phase current command +W-phase current command). Thus obtained V-phase current command is, thereafter, fed to another current amplifier 27V in which a drive current to be supplied to the V-phase winding 8 is generated in response to the V-phase current command.\nA reference numeral 29 represents a speed detector connected to the pulse converter 3. This speed detector 29 detects the speed of the motor 1 by counting the number of pulses generated during a time measured by a timer 38 when the motor 1 rotates at a high speed and measuring an interval between successive pulses generated when the motor 1 rotates at a low speed. Reference numerals 31 and 32 represent a positive-direction position command pulse and a negative-direction position command pulse, respectively, fed from an external device. Reference numerals 33 and 34 represent subtracters.\nA reference numeral 35 represents a positional deviation reading sampler which is open-or-close controlled at predetermined intervals in response to an output signal from a timer 37. A reference numeral 38 represents a speed deviation reading sampler which is open-or-close controlled at predetermined intervals in response to an output signal from the timer 38. If these samplers 35 and 38 are closed, the speed control calculator 25, the magnetic pole detector 4, the multipliers 24U, 24W, and the D/A converters 28U, 28W are activated to renew the current commands to be supplied to the current amplifiers 27U, 27W.\nThe subtracter 34, constituted by an up-down counter, is counted up in response to the positive-direction position command pulse S1 and is counted down in response to the negative-direction position command pulse 32. The subtracter 34 is further counted down in response to the CW pulse 18 fed from the pulse converter S and is counted up in response to the CCW pulse 19. The subtracter 34 calculates a positional deviation through these count-up and count-down operations.\nA reference numeral 39 represents a position control calculator which amplifies the positional deviation obtained. The speed control calculator 25 amplifies a value supplied from the speed deviation reading sampler 38 to obtain a torque command, i.e. a current amplitude command.\nAn operation of the above-described motor drive apparatus will be explained below.\nFirst of all, the subtracter 34, constituted by an up-down counter, is counted up in response to the positive-direction position command pulse 31 and counted down in response to the negative-direction position command pulse 32, and is further counted down in response to the CW pulse 18 fed from the pulse converter 3 and counted up in response to the CCW pulse 19, in order to obtain the positional deviation. Furthermore, the position control calculator 39 inputs the positional deviation through the positional deviation reading sampler 35 being open-or-close controlled by the timer 37. The position control calculator 39 amplitudes this positional deviation and outputs a speed command so as to reduce the positional deviation.\nNext, the subtracter 33 subtracts this speed command by a feedback speed obtained from the speed detector 29 to generate a speed deviation. The speed control calculator 25 inputs the speed deviation through the speed deviation reading sampler 36 being-open-or-close controlled by the timer 38. The speed control calculator 25 amplitudes this speed deviation and generates a torque command, i.e. a current amplitude command.\nOn the other hand, when the motor 1 rotates in the clockwise (CW) direction, the encoder 2 generates the A-phase signal 15 and the B-phase signal 16 having a mutual phase difference of 90 degrees therebetween as shown in FIG. 12, together with the Z-phase pulse signal 17 corresponding to one of zero-crossing points of the U-phase inductive voltage 12. This A-phase signal 15 and B-phase signal 16 are, then, inputted into the pulse converter 3. These A-phase signal 15 and B-phase signal 16 are converted into the CW pulse 18 when the motor 1 rotates in the clockwise (CW) direction, and are converted into the CCW pulse 19 when the motor 1 rotates in the counterclockwise (CCW) direction.\nNext, the CW pulse signal 18 and the CCW pulse signal 19 outputted from the pulse converter 3, and the Z-phase signal 17 outputted from the encoder 2 are supplied to the magnetic pole detector 4. The counter 20 shown in FIG. 15 is counted up by the CW pulse signal 18 and counted down by the CCW pulse signal 19. Furthermore, the counter 20 is cleared by the Z-phase signal 17 fed from the encoder 2 to be 0. Namely, an arrival of the designated zero-cross point of the U-phase inductive voltage 12 is known by checking the Z-phase signal 17. And, a displacement or shift amount of the motor 1 from the designated zero-cross point of the U-phase inductive voltage 12 is known from the count value of the counter 20. The count value of the counter 20 becomes the pointer 23 of the U-phase current phase command table 21 for outputting the phase value of the U-phase inductive voltage 12 corresponding to the present rotational position of the motor 1. Moreover, the count value of the counter 20 becomes the pointer 23 of the W-phase current phase command table 22 for outputting the phase value of the W-phase inductive voltage 14 corresponding to the present rotational position of the motor 1.\nIn the multipliers 24U, 24W, the phase values of the U-phase and W-phase inductive voltages 12 and 14 are multiplied with the torque command outputted from the speed control calculator 25. Namely, the multipliers 24U, 24W multiply the current amplitude command value with the U-phase and W-phase current phase command values, respectively. The resultant two outputs from respective multipliers 24U, 24W are, then, fed to two D/A converters 26U, 26W so as to generate U-phase and W-phase current commands, respectively. These U-phase and W-phase current commands are, subsequently, fed to current amplifiers 27U, 27W in which the drive currents to be supplied to the U-phase winding 7 and the W-phase winding 9 are generated in response to the U-phase and W-phase current commands, respectively.\nOn the other hand, the subtracter 28 obtains the current command for the V-phase winding 8 by calculating the value identical with -(U-phase current command +W-phase current command). Thus obtained V-phase current command is, thereafter, fed to the current amplifier 27V in which the drive current to be supplied to the V-phase winding 8 is generated in response to the V-phase current command.\nIf the torque command is a positive value, the motor 1 generates a torque in the clockwise (CW) direction. On the contrary, if the torque command is a negative value, the motor 1 generates a torque in the counterclockwise (CCW) direction because the multipliers 24U and 24W generate U-phase and W-phase current commands having 180-degree phase difference with respect to respective U-phase and W-phase current phase commands. Thus, the speed deviation is decreased. In accordance with the reduction of the speed deviation, the positional deviation becomes small.\nFIG. 9(A) shows a sampling interval of the speed deviation reading sampler 36 applied to both moving and stationary conditions of the motor 1. FIG. 9(B) shows a sampling interval of the positional deviation reading sampler 35 applied to both moving and stationary conditions of the motor 1.\nWhen the motor 1 is in a moving condition, in order to stabilize the motor drive operation by the above-described motor drive apparatus, the speed control must be performed by using three times or more sampling with respect to the calculated speed command as shown in FIG. 9. The reason why three times or more sampling are required when the motor 1 is in a moving condition is as follows.\nIf the speed command sampling interval is identical with the control sampling interval in the speed control operation, the motor 1 will not be able to sufficiently follow up the speed command because, even if the speed of the motor 1 is controlled to coincide with the speed command value, the speed command value itself may vary at the next coming control sampling timing. Thus, the speed of the motor 1 cannot be stabilized. Especially, as the positional command varies widely when the motor 1 is in a moving condition, the speed command will correspondingly cause wide variation. Hence, three times or more sampling are required for allowing the motor 1 to follow up the speed command. For this reason, the speed of the timer 37 is set 1/3 or less compared with that of the timer 38.\nIn accordance with the above motor drive apparatus, the sampling interval of the positional deviation reading sampler 35 will be sufficiently extended or elongated so as to stabilize the motor speed control during the moving condition of the motor. However, when the motor 1 is in a stationary condition, the sampling interval of the positional deviation reading sampler 35 will be too long to accurately detect a small positional deviation if this small positional deviation varies at a period smaller than that of the positional deviation reading sampler 35. Consequently, there is a problem that the positioning control cannot be accurately and responsively performed when the motor is in a stationary condition.", "meta": {"pile_set_name": "USPTO Backgrounds"}}
{"text": "Q:\n\nCan a existing mapreduce program be made to run from a specified offset of input file\n\nIs there any way to run an existing mapreduce program so that it processes only from a given offset of the input file?\nEg:\nIf given offset is 500, the mapreduce program should start processing input file from 500th byte.\n\nA:\n\nIt is possible, but will require Java coding and creating a custom InputFormat. For example you can subclass FileInputFormat and override methods public List getSplits(JobContext job) and protected FileSplit makeSplit(Path file, long start, long length, String[] hosts).\nTo pass the starting offset you can use Configuration parameters accessible via job.getConfiguration().getInt(YOUR_PARAM_NAME, 0)\n\n", "meta": {"pile_set_name": "StackExchange"}}
{"text": "Allele-specific wild-type blocker quantitative PCR for highly sensitive detection of rare JAK2 p.V617F point mutation in primary myelofibrosis as an appropriate tool for the monitoring of molecular remission following therapy.\nScreening of JAK2 V617F point mutation becomes more and more important in monitoring of JAK2 positive MPN following stem cell transplantation. In an attempt to achieve the required high sensitivity (1:10(5)), specifity and robustness we created an approach applicable on bone marrow biopsies where we adapted the principle of wild-type blocker PCR with allele-specific Q-PCR. The significance of the assay was demonstrated on a retrospective series of sequential bone marrow biopsies as diagnosis of molecular relapse now preceded the diagnosis of clinical relapse by far. This method offers the urgently needed tool for a systematic molecular analysis of sequential biopsies in the course of stem cell transplantation to develop guidelines for the management of these patients.", "meta": {"pile_set_name": "PubMed Abstracts"}}
{"text": "///\n/// Copyright (c) 2016 Dropbox, Inc. All rights reserved.\n///\n/// Auto-generated by Stone, do not modify.\n///\n\n#import <Foundation/Foundation.h>\n\n#import \"DBSerializableProtocol.h\"\n\n@class DBTEAMPOLICIESSharedFolderJoinPolicy;\n\nNS_ASSUME_NONNULL_BEGIN\n\n#pragma mark - API Object\n\n///\n/// The `SharedFolderJoinPolicy` union.\n///\n/// Policy governing which shared folders a team member can join.\n///\n/// This class implements the `DBSerializable` protocol (serialize and\n/// deserialize instance methods), which is required for all Obj-C SDK API route\n/// objects.\n///\n@interface DBTEAMPOLICIESSharedFolderJoinPolicy : NSObject <DBSerializable, NSCopying>\n\n#pragma mark - Instance fields\n\n/// The `DBTEAMPOLICIESSharedFolderJoinPolicyTag` enum type represents the\n/// possible tag states with which the `DBTEAMPOLICIESSharedFolderJoinPolicy`\n/// union can exist.\ntypedef NS_CLOSED_ENUM(NSInteger, DBTEAMPOLICIESSharedFolderJoinPolicyTag){\n    /// Team members can only join folders shared by teammates.\n    DBTEAMPOLICIESSharedFolderJoinPolicyFromTeamOnly,\n\n    /// Team members can join any shared folder, including those shared by users\n    /// outside the team.\n    DBTEAMPOLICIESSharedFolderJoinPolicyFromAnyone,\n\n    /// (no description).\n    DBTEAMPOLICIESSharedFolderJoinPolicyOther,\n\n};\n\n/// Represents the union's current tag state.\n@property (nonatomic, readonly) DBTEAMPOLICIESSharedFolderJoinPolicyTag tag;\n\n#pragma mark - Constructors\n\n///\n/// Initializes union class with tag state of \"from_team_only\".\n///\n/// Description of the \"from_team_only\" tag state: Team members can only join\n/// folders shared by teammates.\n///\n/// @return An initialized instance.\n///\n- (instancetype)initWithFromTeamOnly;\n\n///\n/// Initializes union class with tag state of \"from_anyone\".\n///\n/// Description of the \"from_anyone\" tag state: Team members can join any shared\n/// folder, including those shared by users outside the team.\n///\n/// @return An initialized instance.\n///\n- (instancetype)initWithFromAnyone;\n\n///\n/// Initializes union class with tag state of \"other\".\n///\n/// @return An initialized instance.\n///\n- (instancetype)initWithOther;\n\n- (instancetype)init NS_UNAVAILABLE;\n\n#pragma mark - Tag state methods\n\n///\n/// Retrieves whether the union's current tag state has value \"from_team_only\".\n///\n/// @return Whether the union's current tag state has value \"from_team_only\".\n///\n- (BOOL)isFromTeamOnly;\n\n///\n/// Retrieves whether the union's current tag state has value \"from_anyone\".\n///\n/// @return Whether the union's current tag state has value \"from_anyone\".\n///\n- (BOOL)isFromAnyone;\n\n///\n/// Retrieves whether the union's current tag state has value \"other\".\n///\n/// @return Whether the union's current tag state has value \"other\".\n///\n- (BOOL)isOther;\n\n///\n/// Retrieves string value of union's current tag state.\n///\n/// @return A human-readable string representing the union's current tag state.\n///\n- (NSString *)tagName;\n\n@end\n\n#pragma mark - Serializer Object\n\n///\n/// The serialization class for the `DBTEAMPOLICIESSharedFolderJoinPolicy`\n/// union.\n///\n@interface DBTEAMPOLICIESSharedFolderJoinPolicySerializer : NSObject\n\n///\n/// Serializes `DBTEAMPOLICIESSharedFolderJoinPolicy` instances.\n///\n/// @param instance An instance of the `DBTEAMPOLICIESSharedFolderJoinPolicy`\n/// API object.\n///\n/// @return A json-compatible dictionary representation of the\n/// `DBTEAMPOLICIESSharedFolderJoinPolicy` API object.\n///\n+ (nullable NSDictionary<NSString *, id> *)serialize:(DBTEAMPOLICIESSharedFolderJoinPolicy *)instance;\n\n///\n/// Deserializes `DBTEAMPOLICIESSharedFolderJoinPolicy` instances.\n///\n/// @param dict A json-compatible dictionary representation of the\n/// `DBTEAMPOLICIESSharedFolderJoinPolicy` API object.\n///\n/// @return An instantiation of the `DBTEAMPOLICIESSharedFolderJoinPolicy`\n/// object.\n///\n+ (DBTEAMPOLICIESSharedFolderJoinPolicy *)deserialize:(NSDictionary<NSString *, id> *)dict;\n\n@end\n\nNS_ASSUME_NONNULL_END\n", "meta": {"pile_set_name": "Github"}}
{"text": "Introduction\n\n\n\nMark J. Terrill/Associated Press\n\nThough some have argued that the crowded G.O.P. primary debates would improve if they were more, and not less, of a circus, many critics have lamented the lack of substantive policy discussion by presidential candidates. What changes could be made to the debate formats to make them more substantive?", "meta": {"pile_set_name": "OpenWebText2"}}
{"text": "477 F.2d 598\nZukowskiv.State Bar Grievance Board, State Bar ofMichigan\n73-1072\nUNITED STATES COURT OF APPEALS Sixth Circuit\n4/18/73\n\n1\nE.D.Mich.\n\nAFFIRMED\n", "meta": {"pile_set_name": "FreeLaw"}}
{"text": "Primary care for women. Comprehensive assessment and management of common mental health problems.\nThis article emphasizes the importance of the role of the certified nurse-midwife (CNM) in the primary care assessment of, and appropriate referral for women with mental health problems, especially in cases of psychiatric emergencies. Essential aspects of assessment, diagnosis, and treatment of the more common psychiatric problems are included, and the treatment modalities that are considered when referral results in psychiatric intervention are reviewed. In addition, the overall prevalence of mental health problems in women, the frequency with which primary care providers may encounter mental health problems, and issues of mental health care utilization are discussed.", "meta": {"pile_set_name": "PubMed Abstracts"}}
{"text": "When Rudy Gay left the game with a left knee injury late in the first quarter, memories of the Sacramento Kings\u2019 (16-22) recent poor play minus a star resurfaced. The thought came to fruition as DeMarcus Cousins joined him on the sidelines in the waning seconds of regulation, and the short-handed Kings fell to the visiting Dallas Mavericks (27-12), 108-104.\n\nThe Kings are currently 2-2 on their six-game home stand and return to action on Friday in a contest against the Miami Heat. Join Cowbell Kingdom\u2019sJames Ham as he recaps the action from the floor of Sleep Train Arena.\n\nGolden State Warriors Projected Starters (31-22)\n\nWhat to watch\n\n1. Can the Kings win without DeMarcus Cousins?\n\nThe Kings are 0-7 without their starting center and it looks like Cousins will miss another game on Wednesday with a strained left hip flexor. Andrew Bogut is questionable for the Warrior with left shoulder inflammation, as is reserve Jermaine O\u2019Neal (sore back). This game might turn into a track meet, which doesn\u2019t bode well for Sacramento.\n\n2. Can the Kings defend the 3-point line?\n\nSacramento ranks 28th in the league against the long ball. The Warriors starting backcourt of Curry and Thompson have already shot close to 800 3-pointers on the season. If the Kings don\u2019t stay with Golden State\u2019s shooters, they have very little chance of pulling off the upset.\n\n3. How do the Kings players handle the trade rumors?\n\nThe trade deadline is 12pm PST on Thursday and the rumors are swirling. Do the Kings players crumble under the pressure or do they come out swinging in what might be their last game in Sacramento?\n\nAccording to an NBA source, Sacramento Kings point guard Isaiah Thomas underwent an MRI earlier Tuesday on his left wrist. Counter to other media reports, the results of the tests were negative and Thomas is not expected to miss any time with the injury.\n\nSince taking over the starting position 35 games ago, Thomas is averaging 21.5 points, 6.9 assists and 1.3 steals per game in 37.5 minutes. But rumors that he was having some discomfort in his wrist began a few weeks back.\n\nRecently, his shooting numbers have taken a dramatic dip, beginning in January when he shot just 41.2 percent from the field and 32.7 percent from long range. Thomas\u2019s overall field goal percentage has bounced back in the month of February, but his 3-point percentage for the seven games this month is 24.1 percent.\n\nThomas and rookie guard Ben McLemore were the subject of a trade rumor on Monday, but coach Michael Malone and general manager Pete D\u2019Alessandro refuted the reports following practice on Tuesday afternoon.\n\n\u201cThe report that was, I think on Yahoo!, about our offer to Boston was so erroneous and I don\u2019t know where it came from,\u201d Malone told reporters on Tuesday. \u201cWe dispel the rumors that are out there that we know are not true, but at the same time, this is a business and you have no idea what can happen up until trade deadline. I think all of our players realize that.\u201d\n\nWith injuries and possible trade rumors swirling, it should be a wild couple of days in Sacramento.\n\nDeMarcus Cousins Injury Update\n\nThomas wasn\u2019t the only Kings player to undergo an MRI today. For the second straight day, center DeMarcus Cousins made a trip to the doctors office for testing. Results of the first MRI were inconclusive, but a second test confirmed the Kings medical staff\u2019s earlier diagnosis of a strained left hip flexor.\n\nCousins has been unable to participate in practice since returning from the All-Star break. He is listed as day-to-day, but considered doubtful for Wednesday\u2019s match-up against the Golden State Warriors.\n\nHamady Ndiaye out of Rutgers and DeQuan Jones out of Florida are the only late additions. Ndiaye was in camp last season with Sacramento and left a solid impression. After being waived by the Kings, the 26-year old center spent last season playing for Tianjin Ronggang Golden Lions of the Chinese Basketball Association.\n\nJones played in 63 games last season with the Orlando Magic, including 17 starts. He averaged 3.7 points per game in a little under 13 minutes a game.\n\nLast season it was high ropes courses in Colorado Springs, Co. This year, the Sacramento Kings open training camp away from home again, but instead of the Team USA practice facility in Colorado, it will be on the sandy beaches of Santa Barbara, CA. Camp will run from Oct. 1-6 at the Pavilion Gym on the University of California, Santa Barbara campus.\n\nThe team will head back to Northern California for their pre-season opener on the road against the Golden State Warriors on October 7, before heading to Las Vegas to take on the Lakers on Oct. 10.\n\nAfter the initial week away, the Kings will continue camp in Sacramento at the team\u2019s practice facility in Natomas.\n\nCowbell Kingdom has grown exponentially since its founding in 2009 and we want to make sure we know our audience. The information you provide in this brief survey will be used to help us better serve you. For your participation, you will be automatically entered into a contest to win a copy of the 2013-14 Sacramento Kings Dancers calendar and a \u201cBlackout\u201d t-shirt commemorating last season\u2019s first home game.\n\nBut there\u2019s probably no other player more overlooked and underrated on this season\u2019s roster than the fourth-year guard. Just look no further than ESPN.com\u2019s annual NBA Rank, which appraises the value of the league\u2019s top 500 players. The 25-year-old guard moved up just five spots (no. 136 in 2011 to no. 131 in 2012) in this year\u2019s rankings. These were the five players ranked just ahead of Thornton in the 2012 forecast:\n\nSuch is life on a bad team with little to no national exposure. However, those who follow the Kings closely know just how valuable Thornton is, especially his competition.\n\n\u201cHe\u2019s become an outstanding scorer in this league,\u201d said Dallas Mavericks guard Darren Collisonback in January of his former New Orleans Hornets teammate. \u201cHe\u2019s definitely made a niche in this league as far as (being) a big time scorer.\n\n\u201cHe can shoot the ball extremely well and he can do a lot of different things off the pick and roll,\u201d added Collison. \u201cAnd he\u2019s exceptionally quick too.\u201d\n\nIn their rookie year, Collison and Thornton formed an explosive and exciting young backcourt for the Hornets. Though they\u2019ve since gone their separate ways, the two remain close. Thornton worked out last offseason with Collison in Los Angeles during the lockout.\n\nThe fourth-year guard out of UCLA thinks Sacramento is a good fit for his old teammate. He believes Thornton will only continue to improve with the Kings\u2019 green nucleus.\n\n\u201cThis is a young team that\u2019s going to be good in the near future,\u201d Collison said. \u201cHe has a starting role here, so anytime you have a starting role, it\u2019s always a good fit. And he\u2019s one of their best scorers, too.\u201d\n\nAveraging 18.7 points per game, Thornton led the Kings in scoring last season and usually found himself as their go-to-guy in clutch situations. The next step for Thornton, according to another former teammate, is becoming an accomplished defender.\n\n\u201cHe\u2019s always been a capable scorer,\u201d said Indiana Pacers big man David West. \u201cKey for him has always been for him to play as hard defensively as he does offensively.\u201d\n\nAs explosive as he is with the ball, Thornton could stand to see some improvement on the defensive end. The Louisiana native finished in the bottom three among his 15 teammates in defensive rating.\n\n\u201cWe would challenge him to do the same thing on the defensive end,\u201d said West of his days with Thornton in New Orleans. \u201cMake him more of a complete ball player.\u201d\n\nHowever like Collison, West thinks Thornton will continue to find success in the league.\n\n\u201cHe\u2019s a strong-minded, tough-minded kid,\u201d West said. \u201cI knew that once he got an opportunity to just get in a system that worked for him and bring out his best skills, he\u2019d do well.\u201d\n\nThe Kings may not belong to Marcus Thornton. But his importance to their success isn\u2019t an understatement.\n\nTwenty-five years ago today, Sacramento Kings Head Coach Keith Smart hit a shot that changed his life forever.\n\nNo matter where I go, people talk about it. Once they recognize me or see a nametag on my bag or something like that, they start talking about \u201cThe Shot\u201d. So it\u2019s a great moment and I\u2019m glad it went in, but wasn\u2019t just something for me.\n\nWe just had our 25 year championship reunion. And we all got together and it wasn\u2019t so much what we all did in the tournament and our careers. It was a friendship and a relationship that we have now that that moment brings us all together.\n\nDiehard Sacramento Kings fan Kevin Fippin wanted to propose to his long-time girlfriend Lydia Nicolaisen. So before he popped the question on New Year\u2019s Eve, he recruited the services of a Sacramento Kings fan favorite.", "meta": {"pile_set_name": "Pile-CC"}}
{"text": "Three-dimensional structures of H-ras p21 mutants: molecular basis for their inability to function as signal switch molecules.\nThe X-ray structures of the guanine nucleotide binding domains (amino acids 1-166) of five mutants of the H-ras oncogene product p21 were determined. The mutations described are Gly-12----Arg, Gly-12----Val, Gln-61----His, Gln-61----Leu, which are all oncogenic, and the effector region mutant Asp-38----Glu. The resolutions of the crystal structures range from 2.0 to 2.6 A. Cellular and mutant p21 proteins are almost identical, and the only significant differences are seen in loop L4 and in the vicinity of the gamma-phosphate. For the Gly-12 mutants the larger side chains interfere with GTP binding and/or hydrolysis. Gln-61 in cellular p21 adopts a conformation where it is able to catalyze GTP hydrolysis. This conformation has not been found for the mutants of Gln-61. Furthermore, Leu-61 cannot activate the nucleophilic water because of the chemical nature of its side chain. The D38E mutation preserves its ability to bind GAP.", "meta": {"pile_set_name": "PubMed Abstracts"}}
{"text": "Autosomal dominant polycystic kidney disease (ADPKD) is a common monoallelic disorder associated with progressive cyst development and resulting in end stage renal failure (ESRD) in 50% of patients by 60y. However, there is considerable phenotypic variability, extending from in utero onset to patients with adequate renal function into old age. Autosomal dominant polycystic liver disease (ADPLD), as traditionally defined, results in PLD with minimal renal cysts. Classically there have been considered two ADPKD genes, PKD1 and PKD2, encoding PC1 and PC2, and two ADPLD genes, PRKCSH and SEC63, but in the past few years greater genetic heterogeneity has been described, with nine genes now implicated overall. Recent data also indicates an overlap in etiology and pathogenesis associated with ADPKD and ADPLD, with the efficient biogenesis and localization of the PC-complex central to both disorders. During the last funding period we identified a novel gene, GANAB, which is associated with both disorders, where the encoded protein, GII?? is involved in the maturation and trafficking of PC1. In this proposal we will take advantage of advances in next generation sequencing (NGS) methodologies, and large populations of ADPKD and ADPLD patients that have been assembled and screened for the classic genes, to hunt for novel genes for these disorders (Aim 1). The phenotype associated with these genes will be characterized (Aim 3) along with their mechanism of action (Aim 2). NGS methods will be perfected to screen the segmentally duplicated locus, PKD1, and to identify missed mutations at the known loci, including those present in just some cells due to mosaicism (Aim 1). The significance of many PKD1 nontruncating variants has been difficult to evaluate (classed as variants of unknown significance; VUS), but recently evidence that some are incompletely penetrant alleles partially explains phenotypic variability in PKD1 populations. In Aim 2 improved in silico predictions, in combination with machine learning, will improve the understanding of the pathogenicity and penetrance of VUS. A cellular assay of the biogenesis and trafficking of this PC-complex will also be employed to quantify the penetrance of VUS. The mechanism of pathogenesis will be explored in animal models with ultralow penetrant (ULP) Pkd1 or Pkd2 alleles. Employing the large clinically, imaging, and genetically well-defined populations phenotypic groupings of patients will be defined that will then be compared to the genic and PKD1 allelic groups (Aim 3). This iterative process will allow the Variant Score (VS) associated with each PKD1 VUS to be refined. In a separate population the revised VS, alone and in combination with clinical, functional, and imaging data, will be employed to generate a comprehensive, predictive algorithm for ADPKD (Aim 3). Disease modifiers to severe disease, via biallelic ADPKD, and due to alleles at other loci will also be identified and characterized in the cellular assay and in vivo in combination with the Pkd1 hypomorphic, RC model. The final aim will exploit the newly identified information that some PKD1 and PKD2 VUS are rescuable, folding mutations that in a maturation-fostering environment can traffic and function appropriately. A screening scheme based on the level of cell surface PC1 will be improved and new chaperone drugs specific for the PC complex will be sought in collaboration with Sanford Burnham Prebys. A second mutation group that will be explored therapeutically are nonsense mutations. A cellular assay for readthrough efficiency is being developed and will be used for screening. Identified chaperone or readthrough drugs will be tested in available mouse models. Overall this proposal will better explain the etiology and the genetic causes of phenotypic variability in ADPKD/ADPLD, develop better prognostic tools for individual selection of patients for treatment that are now becoming available, and explore allele based treatments for ADPKD.", "meta": {"pile_set_name": "NIH ExPorter"}}
{"text": "Q:\n\nA japanese saying \"\u4e00\u3092\u3044\u3046\u3068\u5341\u8fd4\u3063\u3066\u304f\u308b\"\n\nI'm currently trying to read a japanese novel and I found this expression : \n\n\u4e00\u3092\u3044\u3046\u3068\u5341\u8fd4\u3063\u3066\u304f\u308b\n\nIt was meant to qualify a character, but I just don't get it. At first I thought it could mean \"tell one and give back ten\", so I thought it meant this character tends to do more than he was actually asked or intended to do...?\nHowever, I tried searching on japanese sites and it seems it's a saying to qualify a very proud person...? Still I would like to have a more precise idea of what it could really mean and where it does come from, because I'm very interested by japanese idioms.\nDoes anyone have a more precise idea ?\nThank you very much.\n\nA:\n\n\u300c[\u4e00]{\u3044\u3061}\u3092\u3044\u3046\u3068[\u5341\u8fd4]{\u3058\u3085\u3046\u304b\u3048}\u3063\u3066\u304f\u308b\u300d\n\nThe meaning and nuance of this phrase can be quite different depending on the context or the speaker's intention.\nPositive:\nSomeone is always willing to give a full explanation.  You ask one simple question and he will not only answer that question but also give you so much more related information.\nNegative:\nSomeone always talks back to you.  Tell him one thing and he will give back a long session of objection, refutation, etc. \n(Possibly) more important:\nI explained the phrase in terms of \"speaking words\" above, but the phrase does not always have to be about \"ten times as many words\".  It can also be about someone's tendency in taking non-verbal actions if he just is the type to do much more than the bare minimum.  \n\n", "meta": {"pile_set_name": "StackExchange"}}
{"text": "Michele Orecchia\n\nMichele Orecchia (26 December 1903 \u2013 11 December 1981) was an Italian professional road bicycle racer, who won one stage in the 1932 Tour de France. He also competed in the individual and team road race events at the 1928 Summer Olympics.\n\nMajor results\n\n1927\nGiro del Sestriere\n1929\nGiro d'Italia:\n9th place overall classification\n1932\nTour de France:\nWinner stage 8\n\nReferences\n\nExternal links\n\nOfficial Tour de France results for Michele Orecchia\n\nCategory:1903 births\nCategory:1981 deaths\nCategory:Italian male cyclists\nCategory:Italian Tour de France stage winners\nCategory:Sportspeople from Marseille\nCategory:Olympic cyclists of Italy\nCategory:Cyclists at the 1928 Summer Olympics\nCategory:Tour de France cyclists\nCategory:French male cyclists", "meta": {"pile_set_name": "Wikipedia (en)"}}
{"text": "A VISUALLY STUNNING architectural biography of Minnesota\u2019s most influential architect of the twentieth century. Architect, artist, furniture designer, and educator, Ralph Rapson has played a leading role in the development and practice of modern architecture and design, both nationally and internationally.\n\n\u201cRalph Rapson is now a legend in the history of modern architecture.\u201d\n\u2014Cesar Pelli, FAIA\n\nREVIEW:\n\nBarbara Flanagan/The New York Times\n\nRalph Rapson is best known as the designer of the Gutherie, Minneapolis\u2019s landmark of theater design, but because he worked, taught and competed with most of the world\u2019s first modernists\u2013Wright, Mies, Corbusier, Saarinen\u2013his elder son and biographer calls him \u201cthe Forest Gump of architecture.\u201d\n\nRalph Rapson: Sixty Years of Modern Design, by Rip Rapson, Jane King Hession and Bruce N. Wright, documents the architect\u2019s vast career and uncanny associations.\n\nRapson believed design should be reflect the moment\u2013furniture, houses, cities\u2013but his take on modernism was never pompous. He perpetuated endless ideas\u2013still fresh\u2013vibrant drawings and youthful pranks. (He had his students hoist famous visitors upside down, including the stocky Buckminister Fuller, and footprint the ceiling with their bare soles.) The book shows how one can be talented, influential and happy, all the while remaining internationally obscure. It also tells, discreetly, how one man can achieve all this single-handedly: with his right forearm amputated at birth, Ralph Rapson drew with his left hand.", "meta": {"pile_set_name": "Pile-CC"}}
{"text": "Q:\n\nDoctrine2 entity default value for ManyToOne relation property\n\nI've got a Doctrine2 Entity called \"Order\", which has several status properties. The allowed status' are stored in a different Entity, so there is a ManyToOne relation defined for those entities.\n/**\n * @ORM\\Entity()\n */\nclass Order extends AbstractEntity {\n    // ...\n    /**\n     * @ORM\\ManyToOne(targetEntity=\"Status\")\n     * @ORM\\JoinColumn(onDelete=\"NO ACTION\", nullable=false)\n     */\n    protected $status;\n\n    /** @ORM\\Column(nullable=true) */\n    protected $stringProperty = \"default value\";\n\n}\n\nI need to set this status property to a default value when creating a new instance of the order object.\nFor a \"non-relation\" property I can simply set it like the $stringProperty above. But how to do it for relations?\n\nI cannot set the value to the id of the related record, as Doctrine2 will complain.\nIt's fine if the configured default is a \"Reference\" to the status entity. The available status' are fixed and won't change (often).\n\nHow do I configure the entity to have a proper default relation configured.\nPreferably not in a listener when persisting, as the status may be requested before that.\n\nA:\n\nThere are several approaches but I would suggest using the OrderRepository as a factory for creating new orders.\nclass OrderRepository\n{\n    public function create()\n    {\n        $order = new Order();\n        $status = $this->_em->find('Status','default'); // or getReference\n        $order->setStatus($status);\n        return $order;\n    }\n}\n\n// In a controller\n$orderRepository = $this->container->get('order_repository');\n$order = $orderRepository->create();\n\nBy going with a repository you can initialize complex entity graphs that will be ready for persisting.\n==========================================================================\nPlan B would be to do this sort of thing within the order object and then use listeners to \"fix things up\" before persisting or updating.\nclass Order\n{\n    public function __construct()\n    {\n        $this->status = new Status('Default');\n    }\n}\n\nThe problem of course is that a default status object already exists in the database so when you flush you will get a error.  So you need to hang an onFlush(http://docs.doctrine-project.org/projects/doctrine-orm/en/latest/reference/events.html#onflush) listener on the entity manager, check to see if the status object is being managed by the entity manager and, if not, replace it with a managed object fetched via the entity manager.\nThis approach lets you deal with more \"pure\" domain models without worrying as much about the persistence layer.  On the other hand, dealing with the flush can be tricky.  On the gripping hand, once you get it working then it does open up some major possibilities.\n========================================================\nThere is also the question of what exactly the status entity does.  If all it contains is some sort of status state ('entered',processed') etc.  Then you might consider just having it be a string.  Sort of like the ROLE_USER objects.\n\n", "meta": {"pile_set_name": "StackExchange"}}
{"text": "Q:\n\nReact typescript ref return null in conditional rendering\n\nI want to use React refs, it works fine in static rendering, e.g:   \n<footer ref=\"ftr\"></footer>\n\nBut, not in conditional rendering, e.g:\n{footer ?\n    <footer ref=\"ftr\"></footer>\n: null}\n\nWhen I called ReactDOM.findDOMNode(this.refs.ftr);, the first way returned the element (fine) but the second returned me undefined.\nHow to do the right way in conditional rendering? Any answer would be appreciated.\n\nA:\n\nYou should not use string refs as written in the docs:\n\nWe advise against it because string refs have some issues, are\n  considered legacy, and are likely to be removed in one of the future\n  releases\n\nYou can do this:\nlet footerElement: HTMLElement | null = null;\n...\n{footer ?\n    <footer ref={ el => footerElement = el }></footer>\n: null}\n...\nif (footerElement != null) {\n    ...\n}\n\n", "meta": {"pile_set_name": "StackExchange"}}
{"text": "Q:\n\nNot populating tableview with structure array\n\nI need to populate my tableView with an array of a structure. The first property of the structure is the name. This is what I tried...\nvar menuArray:[Restaurant] = [Restaurant]()\n override func viewDidLoad() {\n    super.viewDidLoad()\nlet shake = Item(name: \"Shake\", carbs: 20)\n    let fries = Item(name: \"Fries\", carbs: 30)\n\n    let beverages = Category(name: \"Beverages\", items: [shake])\n    let chips_fries = Category(name: \"Chips & Fries\", items: [fries])\n    let desserts = Category(name: \"Desserts\", items: [])\n    let other = Category(name: \"Other Menu Items\", items: [])\n    let sandwiches_burgers = Category(name: \"Sandwiches & Burgers\", items: [])\n    let sides = Category(name: \"Sides\", items: [])\n\n    a_w = Restaurant(name: \"A&W\", categories: [beverages, chips_fries, desserts, other, sandwiches_burgers, sides])\n\n    let menuArray = [a_w]\n\n}\n\noverride func tableView(_ tableView: UITableView, cellForRowAt indexPath: IndexPath) -> UITableViewCell {\n    let currentCell = tableView.dequeueReusableCell(withIdentifier: \"cell\")\n    let currentRestaurant = menuArray[indexPath.row]\n    currentCell?.textLabel!.text = currentRestaurant.name\n    return currentCell!\n}\noverride func tableView(_ tableView: UITableView, numberOfRowsInSection section: Int) -> Int {\n\n    return menuArray.count\n}\n\nWhy won't it populate my tableView\nHere is my class also...\nimport Foundation\n\nstruct Item {\n    let name: String\n    let carbs: Int\n}\n\nstruct Category {\n    let name: String\n    let items: [Item]\n}\n\nstruct Restaurant {\n    let name: String\n    let categories: [Category]\n\n}\n\nA:\n\nIn this line\nlet menuArray = [a_w]\n\nyou are creating a local variable menuArray which is different from the property with the same name representing the data source array.\nOmit let\nmenuArray = [a_w]\n\nPS: Please use more descriptive variable names than a_w.\n\n", "meta": {"pile_set_name": "StackExchange"}}
{"text": "The Harper government is looking for security experts to help harden federal buildings in the Ottawa area against threats, including possible terror-related attacks.\n\nPublic Works posted a tender Wednesday asking for professionals to conduct so-called threat risk assessments \u201cto identify employees and assets that need protection, analyze threats against them, assess the current risk, and recommend safeguards.\u201d\n\nThe review will cover all federally owned or leased buildings in the Ottawa area and may include bridges, dams and other structures, says the document.\n\nThe posting follows the Oct. 22 shootings at Parliament Hill, which exposed numerous security gaps, as well as the government\u2019s recent claims that Canada is a target for ISIS and related groups based in the Middle East.\n\nGrade every deficiency\n\nThe list of potential risks cited in the material includes terrorism, demonstrations, environmental threats and others, and the tender requires inspections of all elements of buildings, including the siting of washrooms and how the exteriors of buildings are illuminated.\n\nThe consultants are to grade every deficiency up to the highest level, described as a \u201ccondition of vulnerability which exists which may be exploited by opportunistic person(s) or organizations with hostile objectives.\u201d\n\nA lone gunman managed to penetrate deep into the Centre Block of the House of Commons on Oct. 22 before being gunned down in a hallway metres from the prime minister and dozens of other politicians.\n\nRCMP called in the Ontario Provincial Police to review the security failings exposed by the incident, and their report is expected to be handed down shortly.", "meta": {"pile_set_name": "OpenWebText2"}}
{"text": "It was a Pink Burn-out YO!PS - anyone else see the creator pot-hole on lane 2 there...You can fall in there and they'll never find you!", "meta": {"pile_set_name": "OpenWebText2"}}
{"text": "Q:\n\nHow to Compile and Debug C++ in Notepad++ using Turbo C++ Compiler\n\nI have installed NppExecute plugin in notepad++. I am not able to figure out next step to compile and debug C,C++ programs in Notepad++.\nSystem Details: (a) Turbo C directory C:\\TC (b) OS Windows 7\nPlease provide complete details on how to set Environment Variable and Scripts for Compiling and Debugging.  \n\nA:\n\nI wondering why somone wants to use turbo C++.If you run Windows, just use Visual Studio Express, or Dev-C++.If you still want to use Turbo C you will run into several problems with compatibility of this ancient software.\n\nA:\n\nNotepad++ has the run feature, but as far as I know it's unable to help you debugging (e.g. stepping through code, watching variables, etc.).\nYour best bet would be using a simple batch file to compile the code and run your debug commands, but as far as I know you can't include everything into Notepad++ (i.e. it's no real C/C++ IDE).\nOnly option you've got is adding the created batch file as the program to be run by NppExecute.\nEdit:\nOverall, as rkosegi suggested, if possible, use a more up-to-date toolchain.\nMicrosoft's Visual C++ Express Edition can be downloaded for free and used for private or commercial projects.\nIf you target cross platform code, it might be easier to use MinGW to use GCC/G++ under Windows.\n\n", "meta": {"pile_set_name": "StackExchange"}}
{"text": "All Studio Posts\n\nThe upcoming AES 54th International Conferencem focusing on audio forensics, is set to take place June 12-14, 2014, at the Holiday Inn Bloomsbury in London. Dedicated to exploring techniques, technologies and advancements in the field of audio forensics, the conference will provide a platform for sharing research related to the forensic application of speech/signal processing, acoustical analyses, audio authentication and the examination of methodologies and best practices. Chairpersons for this conference are Mark Huckvale and Jeff M. Smith. This marks\u2026\nView this post\n\nFrom the archives of the late, great Recording Engineer/Producer (RE/P) magazine, enjoy this in-depth discussion with engineer/ producer Val Garay, conducted by Robert Carr. This article dates back to the October 1983 issue. As a natural extension to his career as a musician during the early Sixties, Val Garay\u2019s love for music lead him to pursue the art and science of audio engineering. Starting in 1969, he apprenticed at the Sound Factory, Hollywood, under rock-recording legend Dave Hassinger (Rolling Stones,\u2026\nView this post\n\nStudio Technologies recently became Audinate\u2019s 100th Dante licensee and is embracing the audio-over-Ethernet movement by developing a line of Dante-enabled products. \u201cStudio Technologies prides itself on developing specialized solutions for its customers,\u201d says Studio Technologies president Gordon Kapes. \u201cOur users rely on us to deliver products that will enhance their workflow in both fixed and mobile broadcast applications. Dante has proven its technological excellence, and we are convinced that it is the correct, progressive solution for adding networking technology to\u2026\nView this post\n\nSoftware company Plugin Alliance has announced the availability of bx_refinement and bx_saturator V2, two new native plug-ins from German software developer Brainworx. bx_refinement is the brainchild of mastering engineer Gebre Waddell of Stonebridge Mastering, who designed the original prototype as a tool to remove harshness, a problem he was encountering more and more in his work due to the transition to digital and the prevalence of over-compressed mixes. \u201cHarsh recordings are one of the most common problems mixing and mastering\u2026\nView this post\n\nLocated outside Dallas, Cool Pony Media is a record label and artist development company that works with various music genres, as well as score-to-picture work. Brothers and co-founders, Mark and Mike Stitts, recently did an upgrade in part of their studio with help from API, and as a result, the team now uses THE BOX console on a daily basis for writing, tracking, creating stems, and mixing. \u201cWe\u2019re amazed,\u201d says Mark Stitts. \u201cWe have quite a bit of other API\u2026\nView this post\n\nArticle provided by Home Studio Corner. If you\u2019ve been mixing for any length of time, you know how valuable the high-pass filter (HPF) can be. It removes excess low end from your non-bass-heavy tracks, allowing you to clean up the low frequencies, making room for the kick and bass. But then there\u2019s this thing called a low frequency shelf. What\u2019s that all about? In the picture below you can see both a high-pass filter and a low-frequency shelf. A\u2026\nView this post\n\nRadial Engineering has announced that it has taken on the global sales, marketing and distribution of the Jensen Iso-Max range of products. Iso-Max is a range of isolators that provide ground isolation and noise abatement for audio and video in broadcast, home theater and commercial AV integration. Radial has a long history with Jensen. According to company president Peter Janis: \u201cWhen Radial was founded in 1992, we started life as a distributor. One of our first product lines was Jensen.\u2026\nView this post\n\nDPA Microphones has announced the appointment of Direct Imports as its distributor in New Zealand, signaling the company\u2019s continued commitment toward growth and customer service in the country. From its headquarters in Hastings, Hawkes Bay, Direct Imports will carry a full stock of DPA products for live, recording and broadcast applications. \u201cWe are delighted to have been appointed the New Zealand distributor for DPA Microphones and honored to have this outstanding brand join our portfolio and complement our current range\u2026\nView this post\n\nRecord Factory Music Academy, a music production education facility in downtown Seoul, South Korea, delivers real-world recording experience to students, which is now aided with the addition of a Solid State Logic AWS 924 hybrid console/controller in its newly built studios. More than 1,000 students have gained an education since Record Factory Music Academy was established. Through hands-on workshops covering everything from MIDI production to in-studio engineering and music video creation, the facility is gaining a reputation for its advanced\u2026\nView this post", "meta": {"pile_set_name": "Pile-CC"}}
{"text": "From the mid-1960's until the close of that decade, automobiles became lighter, more compact, and more powerful. Auto manufacturers continued to compete against one another for drag-strip supremacy. As government regulations and safety concerns increased, the muscle car era began to decline rapidly.\n\nMany of these ultimate high-performance muscle cars were built to satisfy homologation requirements. Others were built just to have the fastest machine on the road. The Plymouth Hemi 'Cuda is an example of one of the fiercest and most powerful vehicle ever constructed for the roadway. It was derived from the lesser Barracuda's which began in the mid-1960's. It was built atop the 'E' body platform and was restyled in 1970 by John Herlitz, making it longer, wider, and lower. The 426 cubic-inch Hemi V8 was capable of producing an astonishing 425 horsepower. Matted to a four-speed manual 833 transmission, this was the ultimate muscle car of its day.\n\nThis 1971 Plymouth Hemi 'Cuda Convertible with black paint and orange billboards was offered for sale at the 2006 RM Auction in Monterey, CA where it was expected to sell between $180,000-$220,000. It came equipped from the factory with power windows, power brakes, power steering, Rally instrument cluster, rim blow steering wheel, bucket seats, AM/FM cassette radio, and driving lights. It has a Dana '60' rear end and the 426 cu in engine. It is one of just 374 'Cda Convertibles built in 1971. On auction day bidding reached $165,000 which was not high enough to satisfy reserve. The vehicle was left unsold.By Daniel Vaughan | Dec 2006\n\nThis 'Cuda Convertible was given a show-quality restoration to original specifications and is one of just 374 examples originally produced for the 1971 model year. It is believed to be one of just 87 383-powered convertibles produced for the last year of 'Cuda convertible production in 1971. The 383 cubic-inch V8 has four-barrel carburetors and is capable of producing 300 horsepower. There is a TorqueFlite three-speed automatic gearbox and four-wheel hydraulic brakes.\n\nThe car is finished in Tawny Gold, with a white interior and a white power-operated convertible top. Features include dual chrome-tipped exhaust outlets, floor console, hood pins, power brakes, power steering, Rallye wheels, a 'Slap Stik' shifter and a 'Tuff' steering wheel.\n\nIn 2010, this 'Cuda Convertible was offered for sale at the Vintage Motor Cars of Meadow Brook presented by RM Auctions. The car was estimated to sell for $60,000 - $70,000. As bidding came to a close, the car had been sold for the sum of $44,000 including buyer's premium.By Daniel Vaughan | Aug 2010\n\nV8 Cuda Convertible\n\nThe 3rd generation Barracuda ran from 1970 through 1974; the previous generations were A-body Valiant based which began in 1964. Designed by John E. Herlitz on the 108-inch wheelbase, unibody, E-platform, a shorter and wider version of the existing B-body. This example has the non-Hemi 340 cubic-inch V8 with automatic and it is a stock example. 1971 was the only year for four headlamps. Somehow, this model series didn't sell to expectation and production slowed over the years, making the cars quite rare today. An unaltered car is even more rare.\n\nV8 Cuda Hard Top Coupe\n\nThe writing was on the wall by 1971 for the muscle car enthusiast. With rising gas prices and skyrocketing insurance rates, the days of the overpowered and often low priced performance automobile were numbered. For the big three, it seems that the decision was made to go out with a bang, and some of the rarest and most desirable muscle cars ever to come out of the Motor City were produced.\n\nAmong the hottest is the Hemi 'Cuda, produced for a mere two model years. In 1970, it is believed that Plymouth produced just 696 Hemi 'Cuda hardtops and for 1971, a mere 118 would leave the line.\n\nWild colors would survive for the 1971 model year and Chrysler would lead the pack with their Hi-Impact color palate. Several eye popping colors were offered, including Sassy Grass Green as seen on this example, which is one of the rarest offerings.\n\nWhen it comes to American Muscle, the Plymouth hemi 'Cuda is always at the top of the list. And when it comes to rarity and desirability, nothing compares to a 1971 Hemi ' Cuda.\n\nNo matter what make or model you may prefer, there is no disputing the visual impact of the 426 Street Hemi engine. With the massive valve covers and the huge dual quad carbs, it certainly takes top honors when it comes to intimidation. To add the outrageous FC7 in Violet, (aka Plum Crazy) paint to the mix is to take things a step beyond.\n\nThis 1971 Hemi 'Cuda exemplifies what Mopar Performance was all about in the final years of the original Muscle Car era. With a mere 107 leaving the Hamtramck, Michigan assembly plant with the Hemi engine under the shaker hood, these cars were rare even when new. This car is one of just 48 equipped with the Torqueflite automatic transmission and it also features the rare leather interior, elastomeric color keyed bumpers, power steering and power front disc brakes, a center console, the AM radio with the Dictaphone cassette recorder, tinted glass, dual color keyed mirrors and more, making it one of the highest option 1971 Hemi 'Cuda's in existence.\n\nOf course, when new these cars were flogged not only on the street, but at the tracks throughout the country, making this example among the most sought after and valuable American muscle cars ever built.\n\nThe first series of the Barracuda was produced from 1964 through 1969, distinguished by its A-body construction. From 1970 through 1974 the second series was produced using an E-body construction.\n\nIn 1964, Plymouth offered the Barracuda as an option of the Valiant model line, meaning it wore both the Valiant and Barracuda emblems. The base offering was a 225 cubic-inch six-cylinder engine that produced with 180 horsepower. An optional Commando 273 cubic-inch eight-cylinder engine was available with a four-barrel carburetor, high-compression heads and revised cams. The vehicle was outfitted with a live rear axle and semi-elliptic springs. Unfortunately, the Barracuda was introduced at the same time, separated by only two weeks, as the Ford Mustang. The Mustang proved to be the more popular car outselling the Valiant Barracuda by a ratio of 8 to 1.\n\nThe interior was given a floor-shifter, vinyl semi-bucket seats, and rear seating. The rear seats folded down allowing ample space for cargo.\n\nBy 1967, Plymouth redesigned the Barracuda and added a coupe and convertible to the model line-up. To accommodate larger engines, the engine bay was enlarged. There were multiple engine offerings that ranged in configuration and horsepower ratings. The 225 cubic-inch six-cylinder was the base engine while the 383 cubic-inch 8-cylinder was the top-of-the-line producing 280 horsepower. That was impressive, especially considering the horsepower to weight ratio. Many chose the 340 cubic-inch eight-cylinder because the 383 and Hemi were reported to make the Barracuda nose-heavy while the 340 offered optimal handling.\n\nIn 1968 Plymouth offered a Super Stock 426 Hemi package. The lightweight body and race-tuned Hemi were perfect for the drag racing circuit. Glass was replaced with lexan, non-essential items were removed, and lightweight seats with aluminum brackets replaced the factory bench, and were given a sticker that indicated the car was not to be driven on public highways but for supervised acceleration trials. The result was a car that could run the quarter mile in the ten-second range.\n\nFor 1969 a limited number of 440 Barracudas were produced, giving the vehicle a zero-to-sixty time of around 5.6 seconds.\n\nIn 1970 the Barracuda were restyled but shared similarities to the 1967 through 1969 models. The Barracuda was available in convertible and hardtop configuration; the fastback was no longer offered. Sales were strong in 1970 but declined in the years that followed. The muscle car era was coming to a close due to the rising government safety and emission regulations and insurance premiums. Manufacturers were forced to detune their engines. The market segment was slowly shifting from muscle-cars to luxury automobiles. 1974 was the final year Plymouth offered the Barracuda.By Daniel Vaughan | Aug 2010\n\n\u25feDodge Charger and Durango 'most loved' in their respective segments for second consecutive year\n\u25feJeep\u00ae Renegade leads Entry SUV segment in 2015 Most Loved Vehicles in America survey by Strategic Vision\n\u25feFIAT captures most segment wins among small cars with 500 and 500e\n\u25feFCA US ranked highest overall in Strategic Vision's 20th annual Total Quality Index\u2122 this past July\nNovember 24, 2015 , Auburn Hills, Mich. - Strategic Vision has named five FCA US LLC vehicles to its 'Most Loved Ve...[Read more...]\n\nScottsdale, Arizona (July 18th, 2015) \u2013 Thomas Scott is an accountant and entrepreneur from Athens, Georgia who has had a love for all things automotive for as long as he can remember. He possesses a lifetime of passion for buying, selling and working on classic American cars.\n'I started out with the muscle cars \u2014 the Mopars, the Cobra Jet Mustang, the Chevelle,' Scott says. 'Those are cars that everybody recognizes \u2014 they're widely popular and very tradeable.' However, as S...[Read more...]\n\nScottsdale, Arizona (December 1st, 2014) \u2013 For Enthusiasts \u2013 By Enthusiasts. \u2122 This is far more than a tagline at Russo and Steele Collector Automobile Auctions. It's a lifestyle, and we are gearing up to deliver that singular passion to the High Desert of sunny Scottsdale, Arizona for our annual flagship event during the world renowned collector car week. Additionally, Scottsdale marks the kick-off of the year-long celebration of our 15th anniversary. Held over five thrilling a...[Read more...]", "meta": {"pile_set_name": "Pile-CC"}}
{"text": "\ufeff/***********************************************************************\n!!!!!! DO NOT MODIFY !!!!!!\n\nGacGen.exe Resource.xml\n\nThis file is generated by Workflow compiler\nhttps://github.com/vczh-libraries\n***********************************************************************/\n\n#ifndef VCZH_WORKFLOW_COMPILER_GENERATED_DEMOREFLECTION\n#define VCZH_WORKFLOW_COMPILER_GENERATED_DEMOREFLECTION\n\n#include \"Demo.h\"\n#ifndef VCZH_DEBUG_NO_REFLECTION\n#include \"GacUIReflection.h\"\n#endif\n\n#if defined( _MSC_VER)\n#pragma warning(push)\n#pragma warning(disable:4250)\n#elif defined(__GNUC__)\n#pragma GCC diagnostic push\n#pragma GCC diagnostic ignored \"-Wparentheses-equality\"\n#elif defined(__clang__)\n#pragma clang diagnostic push\n#pragma clang diagnostic ignored \"-Wparentheses-equality\"\n#endif\n\n/***********************************************************************\nReflection\n***********************************************************************/\n\nnamespace vl\n{\n\tnamespace reflection\n\t{\n\t\tnamespace description\n\t\t{\n#ifndef VCZH_DEBUG_NO_REFLECTION\n\t\t\tDECL_TYPE_INFO(::demo::MainWindow)\n\t\t\tDECL_TYPE_INFO(::demo::MainWindowConstructor)\n#endif\n\n\t\t\textern bool LoadDemoTypes();\n\t\t}\n\t}\n}\n\n#if defined( _MSC_VER)\n#pragma warning(pop)\n#elif defined(__GNUC__)\n#pragma GCC diagnostic pop\n#elif defined(__clang__)\n#pragma clang diagnostic pop\n#endif\n\n#endif\n", "meta": {"pile_set_name": "Github"}}
{"text": "Purdy was chatting to her bezzie mate who works at Colchester Hospital last night, and was impressed to hear that the Hospital wants more people to car share! Her mate, inspired by all the money she knows Purdy is saving, [...]\n\nLoveurcar\n\nThe Loveurcar campaign is brought to you by the Colchester Travel Plan Club, Colchester Borough Council Air Quality Team and V102 as part of a Defra funded project to encourage more sustainable driving for those journeys that have to be made by car.", "meta": {"pile_set_name": "Pile-CC"}}
{"text": "Q:\n\nbootstrap.min.css sets transparency where not wanted\n\nI have a small chatbox at the bottom of my page which seems to be inheriting CSS style from bootstrap.min.css and that chatbox is transparent which is a nuisance because the underlying text on the page shows through and what is worse, is that hyperlinks on the page are over-riding clickable areas in the chatbox for opening, closing and submitting messages.\nI have tried adding CSS style to the chatbox for opacity and rgba. Even tried adding a background image but to no effect.\nI have since modified the chatbox to display an iFrame from a different site that does not use bootstrap.min.css.\nBut even the iFrame page is affected by transparency. I can remove the transparency setting in bootstrap.min.css but that will not solve my bigger problem... I am intending to use this chatbox on several sites and may not have control of the site's CSS.\nSo I need a way to override the parent site's CSS just for the chatbox. \nIf that is impossible, then I can  weed out the transparency from bootstrap.min.css that is used on my own sites. However I do wonder what is the point of such transparency when it is useless here...\n\nA:\n\nIt's a z-index problem which is common when integrating iframes, apply z-index: 2000; (or whatever number as long as it comes on top) on your chatbox div so your chatbox will still stay upfront.\n\n", "meta": {"pile_set_name": "StackExchange"}}
{"text": "Q:\n\nWhere to get flight dynamics for a flight sim model?\n\nOnce, a while ago, I tried to create a Flight Simulator X model for an aircraft that I wanted a model of, but was soon overwhelmed by having to guess so much of the flight dynamics. Is there somewhere where I could get detailed information about the flight dynamics of aircraft without contacting the manufacturer, a pilot, or having the plane itself to run tests on? I mean for things like drag at different mach, drag coefficient created by the landing gear, lift coefficient created by the flaps, detailed stuff about the engines, etc.\n\nA:\n\nUnfortunately I have no experience with how FSX models aircraft, but at a guess, it's model requires extensive experimental data from a real aircraft to truly get the right parameters.\nAnd that's something no hobbyist is likely to be able to do. For that matter, it's pretty difficult for a pilot to do, since actually recording the relevant data is difficult, and some of what you need to know requires doing things with the aircraft you probably shouldn't do in most circumstances.\nX-Plane's flight model and aircraft creation tool is far more forgiving. You still end up having to guess a lot of parameters, but they are generally less critical to basic handling.\nAll you really need to get a decent flight model out of X-Plane is a good set of reverence pictures, an eye for detail (so your model matches the geometry properly), and ideally the correct airfoil profiles and engine specifications.\n(Primarily the thrust and power)\nFor the most part, good reference models and diagrams, and the information you'd find in the Pilot's operating handbook is enough to create a decent flight model in X-Plane.\nIt certainly won't be perfect, and you'll probably have to tune it, but it's a much easier task than getting that data needed for an FSX model.\nI have the good fortune of being a student pilot, and as such I decided to attempt a model in X-Plane, and found that while it was far from perfect, (and needs a lot of improvement to be a 'good') model, it's behaviour was much closer to the real aircraft that I fly regularly than I was ever expecting given how much I had to guess.\nI had to guess everything from the aileron deflection angles to the propeller geometry, wing airfoil choices and more, and still the resulting model was only slightly off from the real thing insofar as I know how the real aircraft flies.\nI guess that's not an overly helpful answer in a direct sense for an FSX flight model, but I fear it just isn't going to be at all easy to find the information you need to make a flight model that isn't fundamentally broken in FSX, let alone accurate.\nX-Plane is just far simpler to work with when you don't have a lot of information...\nWhether that's worth the downsides of X-Plane (especially the consequences of switching if you already have a heavy investment in FSX), I don't know.\nBut it's worth keeping in mind if you are particularly fond of amateur aircraft design.\n(It's even plausible to create fictional designs in x-plane for which no real-world data could ever exist in theory, and still get a good idea of how such a design likely would fly if it did exist.)\nAs for FSX potentially having better flight models in some cases? Maybe. But this is likely going to be the flight models of expensive add-on aircraft models that were made with the help of the manufacturer and pilots qualified to fly the real aircraft.\nThat's not going to help you any if you don't have access to those kinds of resources.\nA hand-tuned model matched to exact real-world data may well work better than a physics based model if you have good source data.\nBut if your source data is lousy (as it is for most of us unfortunately), then the physics based model will be much more reliable most of the time...\n\nA:\n\nDecent aerodynamic (wind tunnel) data is available courtesy of NASA / NTRS.\nWindtunnel derived aerodynamic data sources is where I have collected together detailed data for the B747, F-14 and F-15.\nB747 Aerodynamic data\n\nNASA CR-1756 The Simulation of a Large Jet Transport Aircraft Volume I: Mathematical Model, C. Rodney Hanke\nMarch 1971 \nD6-30643 THE SIMULATION OF A JUMBO JET TRANSPORT AIRCRAFT - VOLUME 11: MODELING DATA, C. Rodney Hanke and Donald R. Nordwall September 1970\n\nF-14 Aerodynamic data\nThese are the data sources for my F-14 for FlightGear\n\nF-14A Aerodata plots F-14A Aerodata plots from AFWAL-TR-80-3141. These are in the TR; and don't reflect the JSBSim model as that has more data; this is just what I made for reference whilst modelling.\nRichard Harrison\nAFWAL-TR-80-3141, Part I Investigation of High-Angle-of-Attack Maneuver-limiting factors, Part I: Anaylsis and simulation\nDonald E. Johnston, David G. Mitchell, Thomas T. Myers\n1980\nAFWAL-TR-80-3141, Part III: Investigation of High-Angle-of-Attack Maneuver-limiting factors, Part III: Appendices aerodynamic models\nDonald E. Johnston, David G. Mitchell, Thomas T. Myers\n1980\nNASA TN D-6909 DYNAMIC STABILITY DERIVATIVES AT ANGLES OF ATTACK FROM -5deg TO 90deg FOR A VARIABLE-SWEEP FIGHTER CONFIGURATION WITH TWIN VERTICAL TAILS\nSue B. Grafton and Ernie L. Anglin\n1972\nNASA-TM-101717 Flutter clearance to the F-14A Variable-Sweep Transition Flight Expirement Airplane - Phase 2\nLawrence C. Freudinger and Michael W. Kehoe\nJuly 1990\nN89 - 20931 APPLIED TRANSONICS AT GRUMMAN\nW. H. Davis\n\nF-15 Aerodynamic data sources\nThese are the data sources / references for F-15 for FlightGear. The FDM is based on the windtunnel derived aerodynamic data found in (AFIT/GAE/ENY/90D-16).\n\nRichard Harrison, rjh@zaretto.com: F-15 Aerodynamic data from (AFIT/GAE/ENY/90D-16); CG 25.65%, ZDAT/AED/2014/12-2, December, 2014: F-15 Aerodynamic data extracted from AFIT/GAE/ENY/90D-16\nRobert J. McDonnell, B.S., Captain, USAF: INVESTIGATION OF THE HIGH ANGLE OF ATTACK DYNAMICS OF THE F-15B USING BIFURCATION ANALYSIS, AFIT/GAE/ENY/90D-16, December 1990: ADA230462.pdf\nRichard L. Bennet, Major, USAF: ANALYSIS OF THE EFFECTS OF REMOVING NOSE BALLAST FROM THE F-15 EAGLE, AFIT/GA/ENY/91D-1, December 1991: ADA244044.pdf\nDR. J. R. LUMMUS, G. T. JOYCE, O C. D. O MALLEY: ANALYSIS OF WIND TUNNEL TEST RESULTS FOR A 9.39-PER CENT SCALE MODEL OF A VSTOL FIGHTER/ATTACK AIRCRAFT : VOLUME I - STUDY OVERVIEW, NASA CR-152391-VOL-1 Figure 3-2 p54, October 1980: 19810014497.pdf\nFrank W. Burcham, Jr., Trindel A. Maine, C. Gordon Fullerton, and Lannie Dean Webb: Development and Flight Evaluation of an Emergency Digital Flight Control System Using Only Engine Thrust on an F-15 Airplane, NASA TP-3627, September 1996: 88414main_H-2048.pdf\nThomas R. Sisk and Neil W. Matheny: Precision Controllability of the F-15 Airplane, NASA-TM-72861, May 1979 87906main_H-1073.pdf\nAircraft handling data\n\nNT-a3A, F-104A, F-4C, X-15, HL-10, Jetstar, CV-880M, B-747, C-5A, and XB-70A.\n\nRobert K. Heffley and Wayne F. Jewell, NASA CR-2144 AIRCRAFT HANDLING QUALITIES DATA,\nDecember 1972\n\nJSBSim implementations of the aerodynamics models can be viewed in my GitHub repository F-14 and F-15. These are both useful references in how to implement an aerodynamic model using JSBSim.\nWhere no such data is available OpenVSP using VSPAero is a useful tool for generating coefficients from geometry.\nAny computational method (including OpenVSP and X-Plane) will not be able to attain the accuracy gained from windtunnel measurements, especially as you reach the edge of the flight envelope. All FAA Level D simulators use wind tunnel derived aerodyanmic data packages for this reason.\n\n", "meta": {"pile_set_name": "StackExchange"}}
{"text": "Dietary sodium chloride intake independently predicts the degree of hyperchloremic metabolic acidosis in healthy humans consuming a net acid-producing diet.\nWe previously demonstrated that typical American net acid-producing diets predict a low-grade metabolic acidosis of severity proportional to the diet net acid load as indexed by the steady-state renal net acid excretion rate (NAE). We now investigate whether a sodium (Na) chloride (Cl) containing diet likewise associates with a low-grade metabolic acidosis of severity proportional to the sodium chloride content of the diet as indexed by the steady-state Na and Cl excretion rates. In the steady-state preintervention periods of our previously reported studies comprising 77 healthy subjects, we averaged in each subject three to six values of blood hydrogen ion concentration ([H]b), plasma bicarbonate concentration ([HCO(3)(-)]p), the partial pressure of carbon dioxide (Pco(2)), the urinary excretion rates of Na, Cl, NAE, and renal function as measured by creatinine clearance (CrCl), and performed multivariate analyses. Dietary Cl strongly correlated positively with dietary Na (P < 0.001) and was an independent negative predictor of [HCO(3)(-)]p after adjustment for diet net acid load, Pco(2) and CrCl, and positive and negative predictors, respectively, of [H]b and [HCO(3)(-)]p after adjustment for diet acid load and Pco(2). These data provide the first evidence that, in healthy humans, the diet loads of NaCl and net acid independently predict systemic acid-base status, with increasing degrees of low-grade hyperchloremic metabolic acidosis as the loads increase. Assuming a causal relationship, over their respective ranges of variation, NaCl has approximately 50-100% of the acidosis-producing effect of the diet net acid load.", "meta": {"pile_set_name": "PubMed Abstracts"}}
{"text": "Stefan Priebe\n\nStefan Priebe  is a psychologist and psychiatrist of German and British nationality. He grew up in West-Berlin, studied in Hamburg, and was Head of the Department of Social Psychiatry at the Free University Berlin until 1997. He is Professor of Social and Community Psychiatry at Queen Mary, University of London, and Director of a World Health Organization collaborating centre, the only one specifically for Mental Health Services Development. He heads a research group in social psychiatry and has published  more than 600 peer-reviewed scientific papers.\n\nReferences\n\nExternal links \n \n \n\nCategory:1953 births\nCategory:Living people\nCategory:Place of birth missing (living people)\nCategory:German psychologists\nCategory:German psychiatrists\nCategory:British psychologists\nCategory:British psychiatrists\nCategory:Free University of Berlin faculty\nCategory:Academics of Queen Mary University of London\nCategory:People from Berlin", "meta": {"pile_set_name": "Wikipedia (en)"}}
{"text": "MANILA (Reuters) - Philippine security forces on Saturday killed a foreign national and his female companion who were suspected of being connected to a militant group supporting Islamic State, police officials said, two days after the group\u2019s leader was also killed.\n\nThe foreigner, believed to be Pakistani and identified as Abu Naila, resisted arrest and attempted to throw a grenade while a police and military team was conducting a manhunt in Sarangani province, Chief Superintendent Cedrick Train, a police regional director, said.\n\nThey were conducting an operation against members of the militant Ansar Al-Khilafah Philippines (AKP), one of a handful of small groups that have pledged allegiance to Islamic State and blamed for years of unrest in the Philippine south.\n\nOn Thursday, police chief Ronald dela Rosa said security forces had effectively broken the backbone of AKP with the killing of its leader, Mohammad Jaafar Maguid, and the arrest of his three AKP colleagues.\n\nHe has warned of \u201cretaliation\u201d by other AKP members and said security forces were on full alert as Filipino Catholics are set to celebrate the feast of the Black Nazarene, with millions of devotees expected to join processions on Monday in several parts of the country, including Manila.\n\nAuthorities have linked Maguid\u2019s group to several crimes ranging from arson and murder to bombings.\n\nRegional police spokesman Romeo Galgo said they were still verifying the nationality of the foreigner killed on Saturday.\n\n\u201cOfficers were forced to fire at the suspects when the grenade was lobbed at them,\u201d Train said.\n\nPresident Rodrigo Duterte has warned against Islamic State taking root in the southeast Asian country, saying it needed to avoid \u201ccontamination\u201d.", "meta": {"pile_set_name": "OpenWebText2"}}
{"text": "1. Field of the Invention\nThe present invention relates to particularly an optical coherence tomography apparatus including an interference optical system which is used in the medical field, an optical coherence tomography method, an ophthalmic apparatus, a method of controlling the ophthalmic apparatus, and a storage medium.\n2. Description of the Related Art\nCurrently, various types of ophthalmic apparatuses using optical devices are used. Such apparatuses include, for example, an anterior ocular segment imaging apparatus, a fundus camera, and a scanning laser ophthalmoscope (SLO). Among them all, an optical coherence tomography (OCT) apparatus (to be referred to as an \u201cOCT apparatus\u201d hereinafter) is an apparatus capable of obtaining a high-resolution tomogram of an object to be examined. This OCT apparatus has been becoming an indispensable apparatus for dedicated retinal outpatient clinics.\nFor example, the OCT apparatus disclosed in Japanese Patent Laid-Open No. 11-325849 uses low-coherent light as a light source. Light from the light source is split into measurement light and reference light through a splitting optical path such as a beam splitter. Measurement light is light to irradiate an object to be examined such as the eye through a measurement light path. Return light of this light is guided to a detection position through a detection light path. Note that return light is reflected light or scattered light containing information associated with an interface relative to the irradiation direction of light on the object. On the other hand, reference light is light to be guided to the detection position through a reference light path by being reflected by a reference mirror or the like. It is possible to obtain a tomogram of an object to be examined by causing interference between this return light and reference light, collectively acquiring wavelength spectra by using a spectrometer or the like, and performing Fourier transform of the acquired spectra. An OCT apparatus which collectively measures wavelength spectra is generally called a spectral domain OCT apparatus (SD-OCT apparatus).\nIn an SD-OCT apparatus, a measurement depth Lmax is represented, as an optical distance Lmax, by a pixel count N of the image sensor of a spectrometer and a spectrum width \u0394K of the frequency detected by the spectrometer according to equation (1). Note that the spectrum width \u0394K is represented by a maximum wavelength \u03bbmax and a minimum wavelength \u03bbmin. The pixel count N is often an even number, and is generally the factorial of 2, that is 1024 or 2048.\n                                                                                          L                  max                                =                                  \u00b1                                      N                                          4                      \u2062                                                                                          \u2062                      \u0394                      \u2062                                                                                          \u2062                      K                                                                                                                                                                \u0394                  \u2062                                                                          \u2062                  K                                =                                                      1                                          \u03bb                      min                                                        -                                      1                                          \u03bb                      max                                                                                                          }                            (        1        )            \nIf, for example, a central wavelength of 840 nm, a band of 50 nm, and a pixel count of 1024 are set, \u03bbmax=840+50/2=840+25=865 nm, \u03bbmin=840\u221250/2=840\u221225=815 nm, and N=1024. In this case, optical distance Lmax=3.6 mm. That is, it is possible to perform measurement up to about 3.6 mm on the plus side relative to the coherence gate. The coherence gate is the point at which a reference light path coincides with an optical distance in a measurement light path. When a desired region (a distance in the depth direction) is sufficiently smaller than 3.6 mm (for example, 1 mm or less), the measurement depth can be reduced by decreasing the pixel count of the spectrometer. Decreasing the pixel count is important in order to speed up processing and reduce the data amount. This is because, when measuring a three-dimensional image of the retina, it takes much measurement time and produces a large amount of data. When an object to be examined is a moving object like the eye, in particular, it is required to further shorten the measurement time.\nOn the other hand, changing the pixel count of a spectrometer is equivalent to changing the resolution of the spectrometer. A problem in this case will be described with reference to FIG. 1. FIG. 1 is a graph obtained by plotting, for each spectrometer resolution, the light intensity measurement results obtained when the position of the coherence gate is moved while a mirror is located at the position of an object to be examined. The ordinate corresponds to the light intensity, and the abscissa to the distance. With an increase in distance from the coherence gate, light intensity attenuation called Roll-Off occurs. The degree of attenuation of a light intensity Int mainly depends on the resolution of a spectrometer and the pixel count of an image sensor. Letting x be a distance variable and a be a coefficient proportional to the resolution of the spectrometer, the degree of attenuation is proportional to a sinc function given by\n                    Int        \u221d                              sin            \u2062                                                  \u2062            2            \u2062                                                  \u2062            \u03c0            \u2062                                                  \u2062            x            \u2062                                                  \u2062            \u03b1                                \u03c0            \u2062                                                  \u2062            x                                              (        2        )            \nAs is obvious from FIG. 1, as a value indicating a resolution increases (from 0.1 nm to 0.2 nm, 0.5 nm, and 1.0 nm), the cycle in which plotted points approach zero is shortened. As described above, images formed from spectrum data from spectrometers having different resolutions differ in light intensity in the depth direction. Differences in light intensity are differences in image contrast. This makes images in the same region look different. That is, with spectrometers having different resolutions, obtained images look different.\nIn consideration of the above problems, the present invention provides a technique of correcting the contrast differences between images which are caused when wavelength resolutions differ (spectrometers differ in resolution in the case of an SD-OCT) in an FD-OCT apparatus such as an SD-OCT apparatus.", "meta": {"pile_set_name": "USPTO Backgrounds"}}
{"text": "Sen. Bernie Sanders (I-VT) regained his previously held second place position, according to an Economist/YouGov poll released Wednesday, amplifying the ongoing battle between the Vermont senator and Sen. Elizabeth Warren (D-MA), who remain neck and neck.\n\nEconomist/YouGov surveyed 1,500 U.S. citizens (1,111 of whom are registered voters) August 17\u201320 and asked Democrat primary voters, \u201cIf the Democratic presidential primary or caucus in your state were held today, who would you vote for?\u201d\n\nOf the Democrat primary voters surveyed, 22 percent chose Joe Biden (D), with Sanders falling just three points behind with 19 percent support. Warren fell to third place with 17 percent support, a significant contrast from last week\u2019s poll, which showed the Massachusetts senator in a statistical tie for first place with Biden:\n\nNational Democratic Primary: Biden 21 (-1 in a week)\n\nWarren 20 (+4)\n\nSanders 16 (+3)\n\nHarris 8 (-)\n\nO'Rourke 5 (+3)\n\nButtigieg 5 (-3)\n\nBooker 2 (+1)\n\nGabbard 2 (-1)\n\nBennet 1\n\nCastro 1\n\nGillibrand 1\n\nKlobuchar 1\n\nSteyer 1\n\nWilliamson 1\n\nYang 1@TheEconomist /@YouGov https://t.co/WbnJkHHkG7 \u2014 Political Polls (@PpollingNumbers) August 14, 2019\n\nThis week\u2019s poll showed Sen. Kamala Harris (D-CA) in fourth place with eight percent support, followed by Mayor Pete Buttigieg (D) and Beto O\u2019Rourke (D) with seven percent and three percent, respectively. The remaining candidates garnered two percent support or less. Twelve percent of voters said they are \u201cnot sure\u201d who they will vote for. The poll\u2019s margin of error is+/- 2.6 percent when adjusted for weighting and +/- 3 percent for registered voters.\n\nMore good news comes for Sanders in terms of the perception of his electability. While most Democrats \u2013 65 percent \u2013 view Biden as the most electable candidate, Sanders saw a bump from last week\u2019s poll, jumping from 52 percent to 59 percent. Warren maintained her status, with 57 percent of respondents saying she could \u201cprobably beat\u201d President Trump.\n\nThis poll echoes the Morning Consult poll released Monday, showing Sanders in second place with 20 percent support.\n\nAs Breitbart News reported:\n\nA Morning Consult poll \u2013 stemming from interviews with 17,115 Democrat-leaning registered voters August 12\u201318 \u2013 shows Sanders reclaiming his previously held second place position with 20 percent support. While he is still 11 points behind Biden, who has 31 percent support, the Vermont senator is still five points ahead of his closest challenger Warren, who garnered 15 percent support. The survey affirms the storyline of Sen. Kamala Harris\u2019s (D-CA) freefall from the first tier, garnering nine percent support. She is followed by Mayor Pete Buttigieg (D) who has five percent support, and Sen. Cory Booker (D-NJ), Beto O\u2019Rourke (D), and Andrew Yang (D), who all received three percent support. The remaining candidates garnered one percent support or less. The margin of error is +/- one percent.\n\nThe current Real Clear Politics average shows Biden in first place with 28.8 percent support, followed by Sanders in second place with 16 percent support, and Warren in third with 15.4 percent support.", "meta": {"pile_set_name": "OpenWebText2"}}
{"text": "Q:\n\nIs it ok to ask questions on Stack Overflow to improve my coding skills?\n\nI have some questions I want to ask to other (experienced) programmers on Stack\u00a0Overflow.\nThe goal of those questions is gaining knowledge to become a better programmer.\nI think it's a great idea to ask an experienced programmer I know to take a look at my code. But mostly experienced programmers don't have time for this. \nSo can I ask such questions on Stack Overflow?\n\nA:\n\nSo can I ask such questions on Stack Overflow?\n\nNo.\nThis is\n\nopinion based \nnot about a specific programming problem \ntoo broad\n\nRegarding improvement of working code you may ask at Code Review, instead.\nFor questions about \"creating, delivering, and maintaining software responsibly\", you can ask them at Software Engineering Stack Exchange (previously named \"Programmers Stack Exchange\").\n\nA:\n\nSuch questions are not strictly disallowed here (I think), they are asked and answered from time to time, if they ask about a very specific part of some code. When it's just a huge code dump, asking how to improve it, your question will quickly gather downvotes and close votes.\nThere is a site specifically created for this, however: Code Review Stack Exchange\nTake a look at What topics can I ask about here? for details on the kind of questions you can ask on Code Review. Below is a summary, taken from that page:\n\nI'm confused! What questions are on-topic for this site?\nSimply ask yourself the following questions. To be on-topic the answer\n  must be \"yes\" to all questions:\n\nIs code included directly in my question? (See Make sure you include your code in your question below.)\nAm I an owner or maintainer of the code?\nIs it actual code from a project rather than pseudo-code or example code?\nDo I want the code to be good code? (i.e. not code-golfing, obfuscation, or similar)\nTo the best of my knowledge, does the code work as intended?\nDo I want feedback about any or all facets of the code?\n\nIf you answered \"yes\" to all the above questions, your question is\n  on-topic for Code Review.\n\nA:\n\nAlthough you shouldn't just ask on Stack\u00a0Overflow to have your code looked at, you can use Stack\u00a0Overflow to improve your coding skills. I do it all the time, by answering questions (or just by trying to), about things that I don't quite know how to do but would like to. It's a great way to find out about language features, techniques and technologies you didn't know about. \nA surprising number of questions (or perhaps it's not at all surprising) can be answered with a bit of googling, persistence and experimentation. And if I get it wrong, a swift handful of downvotes will set me straight. :-)\n\n", "meta": {"pile_set_name": "StackExchange"}}
{"text": "cask \"font-cormorant-sc\" do\n  version :latest\n  sha256 :no_check\n\n  # github.com/google/fonts/ was verified as official when first introduced to the cask\n  url \"https://github.com/google/fonts/trunk/ofl/cormorantsc\",\n      using:      :svn,\n      trust_cert: true\n  name \"Cormorant SC\"\n  homepage \"https://fonts.google.com/specimen/Cormorant+SC\"\n\n  font \"CormorantSC-Bold.ttf\"\n  font \"CormorantSC-Light.ttf\"\n  font \"CormorantSC-Medium.ttf\"\n  font \"CormorantSC-Regular.ttf\"\n  font \"CormorantSC-SemiBold.ttf\"\nend\n", "meta": {"pile_set_name": "Github"}}
{"text": "Molly Henderson\n\nMolly Henderson (born September 14, 1953) is a former Commissioner of Lancaster County, Pennsylvania.\n\nThe Commissioners are the chief executive and legislative officials of the County, which has 500,000 residents spread over  and an annual County budget of $300 million. \n Henderson was elected in 2003 to a four-year term \nand was the lone Democrat on the Board of Commissioners in a County where Republicans outnumber Democrats two to one.\n\nHenderson was previously Head of Public Health for the City of Lancaster, Pennsylvania, the County seat. \n\nHenderson was not re-elected as Lancaster County Commissioner on November 7, 2007.  Henderson was succeeded by Craig Lehman as the minority Commissioner.\n\nOther careers\nShe is a former high school and college teacher, holding a doctorate degree from Temple University, a master's degree from West Chester University and her B.S. from James Madison University. Henderson is also a Respiratory Therapist and worked at Lancaster General Hospital prior to her teaching and government careers.\n\nHenderson\u2019s book Pressed: Public Money, Private Profit - A Cautionary Tale tells the story of the development, building, and financing of the Lancaster County Convention Center and Marriott Hotel in downtown Lancaster. The highly controversial \u201cconvention center project,\u201d as it was known to those in Lancaster County (pop. 510,000), was originally proposed in 1999 as a $75 million \u201cpublic-private\u201d partnership. The project included a publicly-owned convention center ($30 million) and a privately-owned hotel ($45 million). By the time the convention center and hotel opened in 2009, the project\u2019s cost had ballooned to more than $170 million, with more than 90% of the total cost of both the convention center and hotel borne by Pennsylvania taxpayers.\n\nPolitical views\nHenderson is a notable opponent of the Lancaster County Convention Center Authority's controversial $170 million hotel/convention center in downtown Lancaster on the site of the former Watt & Shand building.\n The project's supporters believe it would promote the revitalization of the city's center. Its opponents, however, feel it poses an unacceptable risk to taxpayers.\nThe hotel portion of the project is owned 50% by Lancaster Newspapers, Inc. which have been accused of using their monopoly print position in the County to promote the project and stifle opposition. Henderson has been referenced in more than 2,200 newspaper articles, over 700 of which concern the Lancaster County Convention Center project, many of them attacking her position.\n\nPersonal life\nHenderson is married to Alex Henderson and has two children, Alexander \"Ander\" Henderson and Leslie Henderson.\n\nSee also\n Lancaster County\n Lancaster City\n Lancaster Newspapers\n\nReferences\n\nExternal links\n\n Official Lancaster County Site\n Campaign Site\n\nCategory:1953 births\nCategory:Living people\nCategory:County commissioners in Pennsylvania\nCategory:Temple University alumni\nCategory:Politicians from Lancaster, Pennsylvania\nCategory:People from Cumberland, Maryland\nCategory:West Chester University alumni\nCategory:James Madison University alumni\nCategory:Women in Pennsylvania politics\nCategory:Pennsylvania Democrats", "meta": {"pile_set_name": "Wikipedia (en)"}}
{"text": "I got a wake up call, I got to make this workCause if we don\u00b4t we\u00b4re left with nothing and that\u00b4s what hurtsWe\u00b4re so close to giving up but something keeps us here\n\nI can\u00b4t see what\u00b4s yet to comeBut I have imagined life without you and it feels wrongI want to know where love begins, not where it ends\n\nCause we don\u00b4t know what we\u00b4re doingWe\u00b4re just built this wayWe\u00b4re careless but we\u00b4re tryingCause we both make mistakesAnd I don\u00b4t want to keep on runningIf we\u00b4re only gonna fall behindWe\u00b4ve almost got it rightBut almost wasn\u00b4t what I had in mind\n\nWe want it all and deserve no lessBut all we seem to give each other is second bestWe\u00b4re still reaching out for something that we can\u00b4t touch\n\nCause we don\u00b4t know what we\u00b4re doingWe\u00b4re just built this wayWe\u00b4re careless but we\u00b4re tryingCause we both make mistakesAnd I don\u00b4t want to keep on runningIf we\u00b4re only gonna fall behindWe\u00b4ve almost got it rightBut almost wasn\u00b4t what I had in mind\n\nYou know there\u00b4s nothing like this loveSo we don\u00b4t want to let it go\n\nCause we don\u00b4t know what we\u00b4re doingWe\u00b4re just built this wayWe\u00b4re careless but we\u00b4re tryingCause we both make mistakesAnd I don\u00b4t want to keep on runningIf we\u00b4re only gonna fall behindWe\u00b4ve almost it got rightBut almost wasn\u00b4t what I had in mind", "meta": {"pile_set_name": "Pile-CC"}}
{"text": "British scientists have identified a way in which Salmonella, the bacteria that cause typhoid fever and gastroenteritis, inactivate immune defenses in human cells.\n\nOne way in which human cells fight off infections is by engulfing the smaller bacterial cells and then attacking them with toxic enzymes contained in small packets called lysosomes. Lysosomes constantly need to be replenished with fresh enzymes that are generated from a factory within human cells. These enzymes are carried from the factory along a dedicated transport pathway. After dropping off new enzymes at lysosomes, the transport carriers are sent back to the factory to pick up new enzymes.\n\nA study, published in the journal Science, shows that Salmonella protects itself from this attack by depleting the supply of toxic enzymes. The researchers found that after Salmonella bacteria have been engulfed by the cell, but before they are killed, Salmonella injects a protein that prevents the cell from recycling the transport carriers between the factory and the lysosome.\n\nThis means that Salmonella effectively cuts off the supply line of the enzymes that would otherwise kill it. As a result, the enzymes get re-routed out of the cell and the lysosomes lose their potency. Salmonella is then able to exploit the disarmed lysosomes by feeding off the nutrients they contain.\n\n\u201cThis seems to be a very effective way for these harmful bacteria to interfere with our cell\u2019s defense mechanisms, and then exploit the defective lysosomes to their own benefit,\u201d explained Prof David Holden of the Imperial College London\u2019s Department of Medicine and MRC Center for Molecular Bacteriology and Infection, senior author of the study.\n\n\u201cOur challenge now is to understand in greater detail how the injected Salmonella protein works at the molecular level, and to exploit our findings to develop more effective vaccines. This is especially important since many Salmonella strains are now resistant to antibiotics,\u201d Prof Holden concluded.\n\n_______\n\nBibliographic information: Kieran McGourty et al. Salmonella Inhibits Retrograde Trafficking of Mannose-6-Phosphate Receptors and Lysosome Function. Science, vol. 338, no. 6109, pp. 963-967; doi: 10.1126/science.1227037", "meta": {"pile_set_name": "OpenWebText2"}}
``````{ end_of_file="data/pile_demo.jsonl" }

``````{ path="pattern_lens/frontend/index.html"  }
<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <!-- <meta name="viewport" content="width=device-width, initial-scale=1.0"> -->
    <title>Attention Pattern Analysis</title>

    <link rel="icon" type="image/svg+xml"
        href='data:image/svg+xml,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 100 100"><rect width="100" height="100" fill="%23000" stroke="%23333" stroke-width="1"/><path d="M0,0 L100,100 L0,100 Z" fill="rgba(0,255,255,0.2)"/><path d="M0,0 L15,15 L0,15 Z" fill="rgba(255,255,255,0.3)"/><path d="M15,15 L35,35 L15,35 Z" fill="rgba(255,255,255,0.3)"/><path d="M35,35 L60,60 L35,60 Z" fill="rgba(255,255,255,0.3)"/><path d="M60,60 L100,100 L60,100 Z" fill="rgba(255,255,255,0.3)"/></svg>'>

    <!--
    #### ##     ## ########   #######  ########  ########  ######
     ##  ###   ### ##     ## ##     ## ##     ##    ##    ##    ##
     ##  #### #### ##     ## ##     ## ##     ##    ##    ##
     ##  ## ### ## ########  ##     ## ########     ##     ######
     ##  ##     ## ##        ##     ## ##   ##      ##          ##
     ##  ##     ## ##        ##     ## ##    ##     ##    ##    ##
    #### ##     ## ##         #######  ##     ##    ##     ######
    -->

    <script src="https://cdnjs.cloudflare.com/ajax/libs/vue/3.2.31/vue.global.min.js"></script>
    <!-- Include lodash library for utility functions -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/lodash.js/4.17.21/lodash.min.js"></script>
    <!-- Include pako library for decompressing SVGZ files -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/pako/2.0.4/pako.min.js"></script>
    <!-- For decompressing SVGZ files -->
    <!-- Include ag-Grid library for prompts table -->
    <!-- <script src="https://cdnjs.cloudflare.com/ajax/libs/ag-grid/32.1.0/ag-grid-community.min.js"></script> -->
    <script src="https://cdn.jsdelivr.net/npm/ag-grid-community@32.2.0/dist/ag-grid-community.min.js"></script>


    <!--
     ######   ######   ######
    ##    ## ##    ## ##    ##
    ##       ##       ##
    ##        ######   ######
    ##             ##       ##
    ##    ## ##    ## ##    ##
     ######   ######   ######
    -->
    <style>
        /* CSS Variables */
        :root {
            /* Colors */
            --primary: #007bff;
            --primary-hover: #0056b3;
            --secondary: #6c757d;
            --secondary-hover: #545b62;
            --success: #28a745;
            --border: #ccc;
            --text-muted: #666;
            --bg-light: #f0f0f0;
            --bg-white: #fff;
            --shadow: rgba(0, 0, 0, 0.1);
            --text-color: #000;

            /* Dark mode colors */
            --dark-bg: #1a1a1a;
            --dark-text: #ffffff;
            --dark-border: #444;
            --dark-bg-light: #2d2d2d;
            --dark-shadow: rgba(0, 0, 0, 0.3);

            /* Spacing */
            --space-xs: 3px;
            --space-sm: 5px;
            --space-md: 10px;
            --space-lg: 20px;

            /* Layout */
            --border-radius: 4px;
            --container-max-width: 1200px;
            --checkbox-size: 12px;
        }

        /* Base Styles */
        body {
            font-family: Arial, sans-serif;
            line-height: 1.4;
            margin: 0;
            padding: var(--space-md);
        }

        .container {
            max-width: var(--container-max-width);
            margin: 0 auto;
        }

        /* Header Styles */
        .header-container {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 1rem;
        }

        .header-title {
            margin: 0;
        }

        .header-controls {
            display: flex;
            gap: 1rem;
            align-items: center;
        }

        /* Layout Components */
        .main-selection-content {
            display: flex;
            flex-direction: column;
            border: 2px solid var(--border);
            height: 800px;
            min-height: 400px;
            resize: vertical;
            overflow: hidden;
        }

        .top-filters {
            display: flex;
            gap: var(--space-md);
            height: 350px;
            border-bottom: 1px solid var(--border);
            min-height: 100px;
            max-height: 80vh;
            padding: var(--space-md);
            resize: vertical;
            position: relative;
            overflow: auto;
        }

        /* Functions Filter */
        .functions-filter {
            width: 200px;
            min-width: 100px;
            max-width: 500px;
            display: flex;
            flex-direction: column;
            border: 1px solid var(--border);
            padding: var(--space-md);
            border-radius: var(--border-radius);
            flex-shrink: 0;
        }

        /* Filter Components */
        .filter-item {
            margin-bottom: var(--space-sm);
            border: 1px solid var(--border);
            padding: var(--space-sm);
            border-radius: var(--border-radius);
        }

        .filter-label {
            display: flex;
            align-items: center;
            justify-content: space-between;
            margin-bottom: var(--space-xs);
        }

        /* Checkbox Lists */
        .checkbox-list {
            border: 1px solid var(--border);
            padding: var(--space-xs);
            flex: 1;
            overflow-y: auto;
            overflow-x: visible;
        }

        .checkbox-item {
            position: relative;
            display: flex;
            align-items: center;
            margin-bottom: 1px;
            line-height: 1;
            width: 100%;
        }

        .checkbox-item label {
            display: flex;
            align-items: center;
            justify-content: space-between;
            width: 100%;
            margin-left: 4px;
        }

        .function-name {
            flex-grow: 1;
            margin-right: 8px;
        }

        input[type="checkbox"] {
            margin: 0 0.2em 0 0;
            width: var(--checkbox-size);
            height: var(--checkbox-size);
            vertical-align: middle;
        }

        /* Head Grid */
        .head-grid {
            display: flex;
            gap: 1px;
            margin: 0 8px;
            height: 100%;
            align-items: center;
        }

        .headsGrid-col {
            display: flex;
            flex-direction: column;
            gap: 1px;
            height: 100%;
            justify-content: center;
        }

        .headsGrid-cell {
            width: 5px;
            height: 5px;
            margin: 0.5px;
            transition: background-color 0.2s ease;
        }

        .headsGrid-cell-selected {
            background-color: #2a1fee;
        }

        .headsGrid-cell-empty {
            background-color: #ac9a9a;
        }

        /* Model Grid */
        #modelGrid {
            flex: 1;
            min-width: 200px;
            overflow: auto;
        }

        /* Prompt Table */
        .prompt-table {
            flex: 1;
            min-height: 200px;
            display: flex;
            flex-direction: column;
            overflow: hidden;
            position: relative;
        }

        .prompts-info {
            border: 1px solid var(--border);
            padding: var(--space-sm);
            border-radius: var(--border-radius);
        }

        .prompt-counter {
            display: flex;
            align-items: center;
            justify-content: space-between;
        }

        .prompt-text-cell {
            cursor: pointer;
        }

        /* ag-Grid Customization */
        .ag-theme-alpine {
            height: calc(100% - 3em) !important;
            width: 100% !important;
        }

        .ag-cell-edit-input {
            height: 100% !important;
            line-height: normal !important;
            padding: 0 8px !important;
        }

        .ag-cell:not(.invalid-selection) {
            background-color: transparent !important;
        }

        .ag-cell.invalid-selection {
            background-color: #ffeaea !important;
        }

        /* Dataset List */
        .dataset-list-container {
            position: absolute;
            right: var(--space-md);
            top: 0.5em;
        }

        .dataset-list {
            position: relative;
            cursor: pointer;
            border: 1px solid var(--border);
            padding: 1px;
            border-radius: var(--border-radius);
            background-color: #f9f9f9;
        }

        .dataset-list-content {
            display: none;
            position: absolute;
            right: 0;
            top: 100%;
            background-color: var(--bg-white);
            border: 1px solid var(--border);
            padding: var(--space-xs) var(--space-lg) var(--space-xs) var(--space-xs);
            font-family: monospace;
            box-shadow: 0 4px 8px var(--shadow);
            z-index: 1000;
        }

        .dataset-list:hover .dataset-list-content {
            display: block;
        }

        /* Image Controls and Display */
        .image-controls-container {
            margin: var(--space-lg) 0;
        }

        .image-controls {
            display: flex;
            align-items: center;
            justify-content: space-between;
            padding: var(--space-md);
            background-color: var(--bg-light);
            border-radius: 8px;
            box-shadow: 0 2px 4px var(--shadow);
        }

        .image-controls-display,
        .image-controls-size {
            display: flex;
            align-items: center;
            width: 50%;
        }

        .image-controls-size {
            justify-content: flex-end;
        }

        .resize-slider {
            width: 250px;
            margin: 0 var(--space-md);
        }

        .resize-input {
            width: 75px;
            padding: 2px var(--space-sm);
        }

        /* Image Grid */
        .images {
            display: grid;
            gap: var(--space-sm);
            margin-top: var(--space-md);
        }

        .image-container {
            text-align: center;
        }

        .image-info {
            font-size: 0.8em;
            margin: 2em 0 -1em;
        }

        .img-container svg,
        .img-container img {
            width: 100%;
            height: 100%;
            object-fit: contain;
            image-rendering: pixelated;
            -ms-interpolation-mode: nearest-neighbor;
        }

        /* Buttons */
        .btn {
            margin: 5px;
            padding: 8px 16px;
            font-size: 14px;
            font-weight: bold;
            border: none;
            border-radius: var(--border-radius);
            cursor: pointer;
            transition: background-color 0.3s ease;
        }

        .btn-primary {
            background-color: var(--primary);
            color: white;
        }

        .btn-primary:hover {
            background-color: var(--primary-hover);
        }

        .btn-secondary,
        .btn-header,
        .btn-dark-mode {
            background-color: var(--secondary);
            color: white;
        }

        .btn-secondary:hover,
        .btn-header:hover,
        .btn-dark-mode:hover {
            background-color: var(--secondary-hover);
        }

        /* Progress Bar */
        .progress-bar {
            height: 12px;
            width: 200px;
            background: #ddd;
            border-radius: 6px;
            overflow: hidden;
        }

        .progress-bar-fill {
            height: 100%;
            transition: width 0.3s ease;
        }

        .progress-bar-fill.loading {
            background-color: var(--primary);
        }

        .progress-bar-fill.complete {
            background-color: var(--success);
        }

        .progress-wrapper {
            padding-left: 1rem;
        }

        /* Function Info Tooltip */
        .function-info {
            position: relative;
            cursor: help;
            display: flex;
            align-items: center;
            margin-left: auto;
        }

        .function-tooltip {
            display: none;
            position: fixed;
            background-color: #eee;
            border: 1px solid #ccc;
            padding: 8px;
            width: 250px;
            z-index: 9999999;
            border-radius: 4px;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.2);
        }

        .function-info:hover .function-tooltip {
            display: block;
        }

        /* Dark Mode Styles */
        .dark-mode {
            background-color: var(--dark-bg);
            color: var(--dark-text);
        }

        .dark-mode .container {
            background-color: var(--dark-bg);
        }

        .dark-mode .functions-filter,
        .dark-mode .filter-item,
        .dark-mode .checkbox-list {
            background-color: var(--dark-bg-light);
            border-color: var(--dark-border);
        }

        .dark-mode .ag-theme-alpine {
            --ag-background-color: var(--dark-bg-light);
            --ag-header-background-color: var(--dark-bg);
            --ag-odd-row-background-color: var(--dark-bg);
            --ag-header-foreground-color: var(--dark-text);
            --ag-foreground-color: var(--dark-text);
            --ag-border-color: var(--dark-border);
        }

        .dark-mode .top-controls {
            background-color: var(--dark-bg-light);
        }

        .dark-mode .dataset-list,
        .dark-mode .dataset-list-content {
            background-color: var(--dark-bg-light);
            border-color: var(--dark-border);
            color: var(--dark-text);
        }

        .dark-mode .dataset-list-content ul {
            margin: 0;
            padding: 0.5em 1em;
            list-style-type: none;
        }

        .dark-mode .dataset-list-content li {
            color: var(--dark-text);
            padding: 0.2em 0;
        }

        .dark-mode .image-controls-container {
            background-color: transparent;
        }

        .dark-mode .image-controls {
            background-color: var(--dark-bg-light);
            border-color: var(--dark-border);
            box-shadow: 0 2px 4px var(--dark-shadow);
        }

        .dark-mode .resize-slider,
        .dark-mode .resize-input {
            background-color: var(--dark-bg);
            border-color: var(--dark-border);
        }

        .dark-mode .resize-input {
            color: var(--dark-text);
        }

        .dark-mode .image-controls label {
            color: var(--dark-text);
        }

        .dark-mode .progress-bar {
            background-color: var(--dark-bg);
            border: 1px solid var(--dark-border);
        }

        .dark-mode .progress-status {
            color: var(--dark-text);
        }

        .dark-mode .function-tooltip {
            background-color: var(--dark-bg-light);
            border-color: var(--dark-border);
            color: var(--dark-text);
        }

        /* Utility Classes */
        .loading,
        .error {
            text-align: center;
            padding: var(--space-md);
        }

        .counter {
            font-size: 0.8em;
            color: var(--text-muted);
            margin-left: auto;
        }

        /* Dark Mode Toggle */
        .dark-mode-toggle {
            position: relative;
            width: 60px;
            height: 30px;
            border-radius: 15px;
            background-color: #e2e8f0;
            cursor: pointer;
            transition: background-color 0.3s ease;
            border: none;
            padding: 0;
            overflow: hidden;
        }

        .dark-mode-toggle::before {
            content: "";
            position: absolute;
            top: 3px;
            left: 3px;
            width: 24px;
            height: 24px;
            border-radius: 50%;
            background-color: white;
            transition: transform 0.3s ease;
            z-index: 1;
        }

        .dark-mode .dark-mode-toggle {
            background-color: #4a5568;
        }

        .dark-mode .dark-mode-toggle::before {
            transform: translateX(30px);
        }

        .dark-mode-icon {
            position: absolute;
            top: 50%;
            transform: translateY(-50%);
            font-size: 14px;
            pointer-events: none;
            line-height: 1;
            display: flex;
            align-items: center;
            justify-content: center;
            width: 24px;
            height: 24px;
        }

        .sun-icon {
            left: 8px;
            opacity: 1;
        }

        .moon-icon {
            right: 8px;
            opacity: 1;
        }

        .dark-mode-button {
            display: flex;
            align-items: center;
            gap: 8px;
            cursor: pointer;
            color: inherit;
        }
    </style>
</head>

<body>
    <!--
    ##     ## ######## ##     ## ##
    ##     ##    ##    ###   ### ##
    ##     ##    ##    #### #### ##
    #########    ##    ## ### ## ##
    ##     ##    ##    ##     ## ##
    ##     ##    ##    ##     ## ##
    ##     ##    ##    ##     ## ########
    -->
    <!-- Root element for Vue app -->
    <div id="app" class="container" :class="{ 'dark-mode': isDarkMode }">
        <div class="header-container">
            <h1 class="header-title">Attention Pattern Analysis</h1>
            <a href="https://github.com/mivanit/pattern-lens/">built with pattern-lens v$$PATTERN_LENS_VERSION$$</a>
            <div class="header-controls">
                <button class="btn btn-header dark-mode-button" @click="toggleDarkMode">
                    <span>Dark Mode</span>
                    <div class="dark-mode-toggle">
                        <div class="dark-mode-icon" style="left: 4px">☀️</div>
                        <div class="dark-mode-icon" style="right: 4px">🌙</div>
                    </div>
                </button>
                <button class="btn btn-header" @click="clearAllSelections">
                    🗑️ Clear All Selections
                </button>
            </div>
        </div>

        <div class="main-selection-content">
            <!-- Top section with functions and models side by side -->
            <div class="top-filters">
                <!-- Functions Filter -->
                <div class="functions-filter">
                    <div class="filter-label">
                        <input type="checkbox" id="select-all-functions"
                            :indeterminate.prop="isIndeterminate('functions')" :checked="isChecked('functions')"
                            @change="toggleSelectAll('functions', $event)">
                        <label for="select-all-functions">Functions:</label>
                        <span class="counter">
                            {{ filters.selected.functions.length }} / {{ Object.keys(filters.available.functions).length
                            }}
                        </span>
                    </div>
                    <div class="checkbox-list">
                        <div v-for="(func, name) in filters.available.functions" :key="name" class="checkbox-item">
                            <input type="checkbox" :id="'func-' + name" :value="name"
                                v-model="filters.selected.functions">
                            <label :for="'func-' + name">
                                <span class="function-name">{{ name }}</span>
                                <span class="function-info">ℹ️
                                    <div class="function-tooltip">
                                        <div v-if="func.figure_save_fmt"><strong>Format:</strong> {{
                                            func.figure_save_fmt }}</div>
                                        <div v-if="func.source"><strong>Source:</strong> {{ func.source }}</div>
                                        <div v-if="func.doc"> {{ func.doc }} </div>
                                    </div>
                                </span>
                            </label>
                        </div>
                    </div>
                </div>

                <!-- Model Selection -->
                <div id="modelGrid" class="ag-theme-alpine" style="height: 300px; width: 100%;"></div>
            </div>

            <!-- Prompts Table (full width) -->
            <div class="prompt-table">
                <div class="prompts-info">
                    <div class="prompt-counter">
                        Selected Prompts: {{ prompts.selected.length }} / {{ Object.keys(prompts.all).length }}
                    </div>
                    <div class="dataset-list-container">
                        <div class="dataset-list">
                            Hover here to see unique datasets
                            <div class="dataset-list-content">
                                <ul>
                                    <li v-for="dataset in uniqueDatasets" :key="dataset">{{ dataset }}</li>
                                </ul>
                            </div>
                        </div>
                    </div>
                </div>
                <div id="promptGrid" class="ag-theme-alpine"></div>
            </div>
        </div>

        <!-- image display button and size controls -->
        <div class="image-controls-container">
            <div class="image-controls">
                <div class="image-controls-display">
                    <button class="btn" :class="{ 'btn-primary': !images.upToDate, 'btn-secondary': images.upToDate }"
                        @click="displayImages">
                        {{ images.upToDate ? 'Images Up to Date' : 'Display Images' }}
                    </button>
                    <div class="progress-wrapper">
                        <span class="progress-status" v-if="images.expected > 0"> {{ images.visible.length || 'N/A' }} /
                            {{ images.expected }} images</span>
                        <div class="progress-bar" v-if="loading || images.visible.length > 0">
                            <div class="progress-bar-fill" :class="{ 'loading': loading, 'complete': !loading }"
                                :style="{ width: `${(images.visible.length / images.expected) * 100}%` }">
                            </div>
                        </div>
                    </div>
                </div>
                <div class="image-controls-size" v-if="images.visible.length > 0">
                    <label for="resizeSlider">Images per row:</label>
                    <input type="range" id="resizeSlider" class="resize-slider" v-model.number="images.perRow" min="1"
                        max="16" step="1">
                    <input type="number" class="resize-input" v-model.number="images.perRow" min="1" max="64">
                </div>
            </div>
        </div>

        <!-- images are loading -->
        <div v-if="loading" class="loading">Loading...</div>

        <!-- actual images display -->
        <div v-else-if="images.visible.length > 0" class="images"
            :style="{ 'grid-template-columns': `repeat(${images.perRow}, 1fr)` }">
            <div v-for="image in images.visible" class="image-container">
                <p v-if="images.perRow <= 4" class="image-info">
                    <a :href="getSinglePropertyFilterUrl('models', image.model)">{{ image.model }}</a> -
                    <a :href="getSinglePropertyFilterUrl('functions', image.function)">{{ image.function }}</a> -
                    <a :href="getSinglePropertyFilterUrl('layers', image.layer)">L{{ image.layer }}</a> -
                    <a :href="getSinglePropertyFilterUrl('heads', image.head)">H{{ image.head }}</a> -
                    <a :href="getSinglePropertyFilterUrl('prompts', image.promptHash)">{{ image.promptHash }}</a>
                </p>
                <a :href="getImageUrl(image)" class="img-container" v-html="image.content"
                    :title="images.perRow > 4 ? image.name : ''">
                </a>
            </div>
        </div>

        <!-- no images found -->
        <div v-else-if="images.requested" class="error">No images found for the selected criteria.</div>

    </div>

    <script>
        // Utility functions for file and directory operations
        //  ######   #######  ##    ##  ######  ########  ######
        // ##    ## ##     ## ###   ## ##    ##    ##    ##    ##
        // ##       ##     ## ####  ## ##          ##    ##
        // ##       ##     ## ## ## ##  ######     ##     ######
        // ##       ##     ## ##  ####       ##    ##          ##
        // ##    ## ##     ## ##   ### ##    ##    ##    ##    ##
        //  ######   #######  ##    ##  ######     ##     ######
        const DATA_DIR = '.';
        const FIGURE_FORMATS = ['svg', 'svgz', 'png'];
        const URL_HEAD_PREFIX = 'heads-';
        const fileOps = {
            async getDirectoryContents(path) {
                const response = await fetch(`${path}/index.txt`);
                const text = await response.text();
                return text.trim().split('\n');
            },
            async fileExists(path) {
                const response = await fetch(path, { method: 'HEAD' });
                return response.ok;
            },
            async fetchJson(path) {
                const response = await fetch(path);
                return response.json();
            },
            async fetchJsonL(path) {
                const response = await fetch(path);
                const text = await response.text();
                // allow for the last line being incomplete
                const text_split = text.trim().split('\n');
                let output = text_split.slice(0, -1).map(JSON.parse);
                try {
                    output.push(JSON.parse(text_split[text_split.length - 1]));
                } catch (error) {
                    console.error('Error parsing last line of JSONL:', error);
                }
                return output;
            },
            async fetchAndDecompressSvgz(path) {
                // returns null if file does not exist
                const response = await fetch(path);
                if (!response.ok) {
                    return null;
                } else {
                    const arrayBuffer = await response.arrayBuffer();
                    const uint8Array = new Uint8Array(arrayBuffer);
                    return pako.inflate(uint8Array, { to: 'string' });
                }
            },
            async figureExists(path) {
                for (const format of FIGURE_FORMATS) {
                    fig_path = `${path}.${format}`;
                    if (await this.fileExists(fig_path)) {
                        return format;
                    }
                }
                return null;
            }
        };
        // Create a new Vue.js application
        const app = Vue.createApp({

            // ########     ###    ########    ###
            // ##     ##   ## ##      ##      ## ##
            // ##     ##  ##   ##     ##     ##   ##
            // ##     ## ##     ##    ##    ##     ##
            // ##     ## #########    ##    #########
            // ##     ## ##     ##    ##    ##     ##
            // ########  ##     ##    ##    ##     ##

            data() {
                return {
                    isDarkMode: false,
                    prompts: {
                        all: {},        // hash -> prompt mapping
                        selected: [],   // selected from table
                        grid: {
                            api: null,
                            isReady: false
                        },
                    },
                    loading: false,
                    images: {
                        visible: [],
                        expected: 0,
                        requested: false,
                        upToDate: false,
                        perRow: 4,
                    },
                    models: {
                        configs: {},    // model -> config mapping
                        grid: {
                            api: null,
                        },
                    },
                    filters: {
                        available: {    // all available options
                            models: [],
                            functions: [],
                            layers: [],
                            heads: [],
                        },
                        selected: {     // currently selected options
                            models: [],
                            functions: [],
                            layers: [],
                            heads: [],
                        },
                    },
                    head_selections_str: {}, // model -> selection string mapping
                };
            },

            methods: {

                // ##     ## ########    ###    ########   ######
                // ##     ## ##         ## ##   ##     ## ##    ##
                // ##     ## ##        ##   ##  ##     ## ##
                // ######### ######   ##     ## ##     ##  ######
                // ##     ## ##       ######### ##     ##       ##
                // ##     ## ##       ##     ## ##     ## ##    ##
                // ##     ## ######## ##     ## ########   ######

                // Parse head selection string and return a 2D array of booleans
                parseHeadString(str, maxLayer, maxHead) {
                    try {
                        const result = Array(maxLayer).fill().map(() => Array(maxHead).fill(false));
                        if (!str || str.trim() === '') return result;

                        const selections = str.replaceAll("x", "*").split(',').map(s => s.trim());

                        for (const selection of selections) {
                            const match = selection.match(/^L(\d+|\d+-\d+|\*)(H\d+|H\*|Hx)?$/);
                            if (!match) return null;

                            const layerPart = match[1];
                            let headPart = match[2];

                            // If the user typed only "L8" (no head specification), default to H*
                            if (!headPart) {
                                headPart = 'H*';
                            }

                            let layers = [];
                            if (layerPart === '*') {
                                layers = Array.from({ length: maxLayer }, (_, i) => i);
                            } else if (layerPart.includes('-')) {
                                const [start, end] = layerPart.split('-').map(Number);
                                if (start > end || end >= maxLayer) return null;
                                layers = Array.from({ length: end - start + 1 }, (_, i) => start + i);
                            } else {
                                const layer = Number(layerPart);
                                if (layer >= maxLayer) return null;
                                layers = [layer];
                            }

                            const headStr = headPart.substring(1);
                            if (headStr === '*' || headStr === 'x') {
                                for (const layer of layers) {
                                    result[layer].fill(true);
                                }
                            } else {
                                const head = Number(headStr);
                                if (head >= maxHead) return null;
                                for (const layer of layers) {
                                    result[layer][head] = true;
                                }
                            }
                        }

                        return result;
                    } catch (e) {
                        console.error('Error parsing head string:', e);
                        return null;
                    }
                },

                isHeadSelected(model, layer, head) {
                    // First check if we have parsed selections for this model
                    if (!this.head_selections_arr[model]) {
                        console.warn(`No parsed head selections found for model: ${model}`);
                        return false;
                    }

                    try {
                        // Verify layer and head are within bounds
                        const parsedSelections = this.head_selections_arr[model];
                        if (!Array.isArray(parsedSelections) ||
                            !Array.isArray(parsedSelections[layer]) ||
                            typeof parsedSelections[layer][head] === 'undefined') {
                            console.warn(
                                `Invalid layer/head combination for ${model}: L${layer}H${head}`,
                                `Max bounds: L${parsedSelections.length - 1}H${parsedSelections[0]?.length - 1}`
                            );
                            return false;
                        }

                        return parsedSelections[layer][head];
                    } catch (e) {
                        console.error('Error checking head selection:', e);
                        console.log('Model:', model, 'Layer:', layer, 'Head:', head);
                        return false;
                    }
                },

                isValidHeadSelection(model) {
                    return this.head_selections_arr[model] !== null;
                },
                // ##     ## ########  ##
                // ##     ## ##     ## ##
                // ##     ## ##     ## ##
                // ##     ## ########  ##
                // ##     ## ##   ##   ##
                // ##     ## ##    ##  ##
                //  #######  ##     ## ########

                // Modified URL handling
                updateURL() {
                    const params = new URLSearchParams();

                    if (this.filters.selected.functions.length > 0) {
                        params.set('functions', this.filters.selected.functions.join('~'));
                    }

                    if (this.prompts.selected.length > 0) {
                        params.set('prompts', this.prompts.selected.join('~'));
                    }

                    if (this.filters.selected.models.length > 0) {
                        params.set('models', this.filters.selected.models.join('~'));
                    }

                    if (this.filters.selected.models.length > 0) {
                        for (const model of Object.keys(this.head_selections_str)) {
                            params.set(
                                `${URL_HEAD_PREFIX}${model}`,
                                this.head_selections_str[model].replaceAll("*", "x").replaceAll(" ", "").split(',').join('~')
                            );
                        }
                    }

                    const newURL = `${window.location.pathname}?${params.toString()}`;
                    history.replaceState(null, '', newURL);
                },

                readURL() {
                    const params = new URLSearchParams(window.location.search);

                    this.filters.selected.functions = params.get('functions')?.split('~') || [];

                    this.prompts.selected = params.get('prompts')?.split('~') || [];

                    this.filters.selected.models = params.get('models')?.split('~') || [];

                    try {
                        this.head_selections_str = {};
                        for (const [key, value] of params) {
                            if (key.startsWith(URL_HEAD_PREFIX)) {
                                const model = key.substring(URL_HEAD_PREFIX.length);
                                this.head_selections_str[model] = value.split('~').join(', ');
                            }
                        }
                    } catch (e) {
                        console.error('Error parsing head selections from URL:', e);
                    }
                },
                selectPromptsFromURL() {
                    if (!this.isGridReady || this.prompts.selected.length === 0) return;

                    const promptSet = new Set(this.prompts.selected);
                    this.prompts.grid.api.forEachNode((node) => {
                        if (promptSet.has(node.data.hash)) {
                            node.setSelected(true);
                        }
                    });
                },
                getImageUrl(image) {
                    return this.getFilterUrl('all', [image.model], [image.promptHash], [image.layer], [image.head], [image.function]);
                },

                getSinglePropertyFilterUrl(type, value) {
                    const params = new URLSearchParams(window.location.search);
                    params.set(type, value); // This preserves other params while updating just this one
                    return `${window.location.pathname}?${params.toString()}`;
                },

                getFilterUrl(type, ...values) {
                    const params = new URLSearchParams(window.location.search);

                    if (type === 'all') {
                        params.set('models', values[0].join('~'));
                        params.set('prompts', values[1].join('~'));
                        params.set('layers', values[2].join('~'));
                        params.set('heads', values[3].join('~'));
                        params.set('functions', values[4].join('~'));
                    } else {
                        params.set(type, values.flat().join('~'));
                    }

                    return `${window.location.pathname}?${params.toString()}`;
                },

                // ##     ## ######## ##       ########  ######## ########
                // ##     ## ##       ##       ##     ## ##       ##     ##
                // ##     ## ##       ##       ##     ## ##       ##     ##
                // ######### ######   ##       ########  ######   ########
                // ##     ## ##       ##       ##        ##       ##   ##
                // ##     ## ##       ##       ##        ##       ##    ##
                // ##     ## ######## ######## ##        ######## ##     ##

                toggleDarkMode() {
                    console.log('Toggling dark mode');  // Add this debug line
                    this.isDarkMode = !this.isDarkMode;
                    localStorage.setItem('darkMode', this.isDarkMode);
                    // Force a DOM update
                    this.$nextTick(() => {
                        document.documentElement.classList.toggle('dark-mode', this.isDarkMode);
                    });
                },
                clearAllSelections() {
                    // Clear prompts selection
                    if (this.prompts.grid.api) {
                        this.prompts.grid.api.deselectAll();
                    }

                    // Clear models selection
                    if (this.models.grid.api) {
                        this.models.grid.api.deselectAll();
                    }

                    // Clear function selections
                    this.filters.selected.functions = [];

                    // Reset head selections
                    this.head_selections_str = {};

                    // Update URL to reflect cleared state
                    this.updateURL();
                },
                isIndeterminate(category) {
                    const items = this.filters.available[category];
                    const selectedItems = this.filters.selected[category];
                    return selectedItems.length > 0 && selectedItems.length < items.length;
                },
                isChecked(category) {
                    const items = this.filters.available[category];
                    const selectedItems = this.filters.selected[category];
                    return selectedItems.length === items.length && items.length > 0;
                },
                toggleSelectAll(category, event) {
                    const checked = event.target.checked;
                    this.filters.selected[category] = checked ? [...this.filters.available[category]] : [];
                },
                async loadData() {
                    try {
                        await this.loadModels();
                        await Promise.all([
                            this.loadAllPrompts(),
                            this.loadFunctions()
                        ]);

                        this.updateLayersAndHeads();
                    } catch (error) {
                        console.error('Error loading data:', error);
                    }
                },
                async loadModels() {
                    this.loading = true;
                    console.log('Loading models...');
                    const models = await fileOps.fetchJsonL(`${DATA_DIR}/models.jsonl`);
                    this.models.configs = {};
                    for (const model of models) {
                        this.models.configs[model["model_name"]] = model;
                    }
                    this.filters.available.models = Object.keys(this.models.configs);
                    console.log('Models:', this.filters.available.models);
                    this.loading = false;

                    // After loading models, initialize head selections
                    this.filters.selected.models.forEach(model => {
                        if (!this.head_selections_str[model]) {
                            this.head_selections_str[model] = 'L*H*';
                        }
                    });
                },
                async loadFunctions() {
                    const functions = await fileOps.fetchJsonL(`${DATA_DIR}/figures.jsonl`);
                    console.log('Functions:', functions);
                    this.filters.available.functions = functions.reduce(
                        (acc, item) => {
                            acc[item.name] = item;
                            return acc;
                        },
                        {},
                    );
                    console.log('this.filters.available.functions:', this.filters.available.functions);
                },
                onFirstDataRendered(params) {
                    this.selectPromptsFromURL();
                },
                // Handle selection change in ag-Grid
                onSelectionChanged() {
                    const selectedNodes = this.prompts.grid.api.getSelectedRows();
                    this.prompts.selected = selectedNodes.map(node => node.hash);
                    this.updateURL();
                },
                // Update layers and heads based on selected models
                updateLayersAndHeads() {
                    // get all layer and head counts
                    let mdl_n_layers = [];
                    let mdl_n_heads = [];
                    for (const model of this.filters.selected.models) {
                        const config = this.models.configs[model];
                        if (config) {
                            mdl_n_layers.push(config.n_layers);
                            mdl_n_heads.push(config.n_heads);
                        }
                    }
                    // get the max layer and head counts, generate lists
                    this.filters.available.layers = [];
                    this.filters.available.heads = [];

                    for (let i = 0; i < _.max(mdl_n_layers); i++) {
                        this.filters.available.layers.push(i.toString());
                    }
                    for (let i = 0; i < _.max(mdl_n_heads); i++) {
                        this.filters.available.heads.push(i.toString());
                    }
                },

                // ##     ##  #######  ########  ######## ##        ######
                // ###   ### ##     ## ##     ## ##       ##       ##    ##
                // #### #### ##     ## ##     ## ##       ##       ##
                // ## ### ## ##     ## ##     ## ######   ##        ######
                // ##     ## ##     ## ##     ## ##       ##             ##
                // ##     ## ##     ## ##     ## ##       ##       ##    ##
                // ##     ##  #######  ########  ######## ########  ######
                getHeadSelectionCount(model) {
                    const parsed = this.head_selections_arr[model];
                    if (!parsed) return 0;
                    return parsed.reduce((acc, layer) =>
                        acc + layer.reduce((sum, isSelected) => sum + (isSelected ? 1 : 0), 0), 0);
                },
                getTotalHeads(model) {
                    const config = this.models.configs[model];
                    return config ? config.n_layers * config.n_heads : 0;
                },
                setupModelTable() {
                    const columnDefs = [
                        {
                            headerName: 'Model',
                            field: 'model_name',
                            sort: 'asc',
                            width: 150
                        },
                        {
                            headerName: 'd_model',
                            field: 'd_model',
                            width: 90,
                            filter: 'agNumberColumnFilter'
                        },
                        {
                            headerName: 'n_layers',
                            field: 'n_layers',
                            width: 90,
                            filter: 'agNumberColumnFilter'
                        },
                        {
                            headerName: 'n_heads',
                            field: 'n_heads',
                            width: 90,
                            filter: 'agNumberColumnFilter'
                        },
                        {
                            headerName: 'Selected',
                            valueGetter: (params) => {
                                return `${this.getHeadSelectionCount(params.data.model_name)} / ${this.getTotalHeads(params.data.model_name)}`;
                            },
                            width: 100
                        },
                        {
                            headerName: 'Head Grid',
                            field: 'head_grid',
                            width: 150,
                            cellRenderer: (params) => {
                                const model = params.data.model_name;
                                const div = document.createElement('div');
                                div.className = 'head-grid';
                                div.setAttribute('data-model', model); // Add data attribute for updates

                                const n_heads = params.data.n_heads;
                                const n_layers = params.data.n_layers;

                                for (let h = 0; h < n_heads; h++) {
                                    const layerDiv = document.createElement('div');
                                    layerDiv.className = 'headsGrid-col';

                                    for (let l = 0; l < n_layers; l++) {
                                        const cell = document.createElement('div');
                                        cell.className = `headsGrid-cell ${this.isHeadSelected(model, l, h) ? 'headsGrid-cell-selected' : 'headsGrid-cell-empty'}`;
                                        cell.setAttribute('data-layer', l);
                                        cell.setAttribute('data-head', h);
                                        layerDiv.appendChild(cell);
                                    }

                                    div.appendChild(layerDiv);
                                }

                                return div;
                            }
                        },
                        {
                            headerName: 'Head Selection',
                            field: 'head_selection',
                            editable: true,
                            width: 200,
                            cellEditor: 'agTextCellEditor',
                            cellEditorParams: {
                                maxLength: 50
                            },
                            valueSetter: params => {
                                const newValue = params.newValue;
                                const model = params.data.model_name;

                                // Update the head selection in Vue's data
                                params.context.componentParent.head_selections_str[model] = newValue;

                                // Update the cell class for validation styling
                                const isValid = params.context.componentParent.isValidHeadSelection(model);
                                const cell = params.api.getCellRendererInstances({
                                    rowNodes: [params.node],
                                    columns: [params.column]
                                })[0];

                                if (cell) {
                                    const element = cell.getGui();
                                    if (isValid) {
                                        element.classList.remove('invalid-selection');
                                    } else {
                                        element.classList.add('invalid-selection');
                                    }
                                }

                                // Force refresh of the head grid cell
                                const gridCol = params.api.getColumnDef('head_grid');
                                if (gridCol) {
                                    params.api.refreshCells({
                                        rowNodes: [params.node],
                                        columns: ['head_grid'],
                                        force: true
                                    });
                                }

                                return true;
                            },
                            valueGetter: params => {
                                return params.context.componentParent.head_selections_str[params.data.model_name] || 'L*H*';
                            },
                            cellClass: params => {
                                const isValid = params.context.componentParent.isValidHeadSelection(params.data.model_name);
                                return isValid ? '' : 'invalid-selection';
                            }
                        },
                    ];

                    const modelGrid_options = {
                        columnDefs: columnDefs,
                        rowData: Object.values(this.models.configs),
                        selection: {
                            headerCheckbox: true,
                            selectAll: 'filtered',
                            checkboxes: true,
                            mode: 'multiRow',
                            enableClickSelection: true,
                        },
                        defaultColDef: {
                            sortable: true,
                            filter: true,
                            resizable: true,
                            floatingFilter: true,
                            suppressKeyboardEvent: params => {
                                // Allow all keyboard events in edit mode
                                if (params.editing) {
                                    return false;
                                }
                                // Prevent default grid behavior for typing when not in edit mode
                                if (params.event.key.length === 1 && !params.event.ctrlKey && !params.event.metaKey) {
                                    return false;
                                }
                                return true;
                            },
                        },
                        context: {
                            componentParent: this
                        },
                        onSelectionChanged: (event) => {
                            const selectedRows = event.api.getSelectedRows();
                            this.filters.selected.models = selectedRows.map(row => row.model_name);
                        },
                        onGridReady: (params) => {
                            this.models.grid.api = params.api;
                            // Select models from URL
                            if (this.filters.selected.models.length > 0) {
                                params.api.forEachNode(node => {
                                    if (this.filters.selected.models.includes(node.data.model_name)) {
                                        node.setSelected(true);
                                    }
                                });
                            }
                        },
                    };

                    const modelGrid_div = document.querySelector('#modelGrid');
                    this.models.grid.api = agGrid.createGrid(modelGrid_div, modelGrid_options);
                },
                refreshHeadGrids() {
                    if (this.models.grid.api) {
                        this.models.grid.api.refreshCells({
                            columns: ['head_grid'],
                            force: true
                        });
                    }
                },
                // ########  ########   #######  ##     ## ########  ########
                // ##     ## ##     ## ##     ## ###   ### ##     ##    ##   
                // ##     ## ##     ## ##     ## #### #### ##     ##    ##   
                // ########  ########  ##     ## ## ### ## ########     ##   
                // ##        ##   ##   ##     ## ##     ## ##           ##    
                // ##        ##    ##  ##     ## ##     ## ##           ##    
                // ##        ##     ##  #######  ##     ## ##           ##    

                async loadAllPrompts() {
                    this.loading = true;
                    console.log('Loading prompts...');
                    this.prompts.all = {};

                    for (const model of this.filters.available.models) {
                        try {
                            const modelPrompts = await fileOps.fetchJsonL(`${DATA_DIR}/${model}/prompts.jsonl`);
                            for (const prompt of modelPrompts) {
                                if (prompt.hash in this.prompts.all) {
                                    this.prompts.all[prompt.hash].models.push(model);
                                } else {
                                    this.prompts.all[prompt.hash] = { ...prompt, models: [model] };
                                }
                            }
                        } catch (error) {
                            console.error(`Error loading prompts for model ${model}:`, error);
                        }
                    }
                    console.log('loaded number of prompts:', Object.keys(this.prompts.all).length);
                    this.loading = false;
                },
                // Initialize the ag-Grid table
                setupPromptTable() {
                    const columnDefs = [
                        {
                            headerName: 'Prompt Text',
                            field: 'text',
                            sortable: true,
                            filter: true,
                            flex: 2,
                            cellRenderer: (params) => {
                                const eGui = document.createElement('div');
                                // Replace tabs and newlines with spaces for display
                                eGui.innerText = params.value.replace(/\s+/g, ' ');
                                eGui.classList.add('prompt-text-cell');
                                eGui.addEventListener('click', () => {
                                    navigator.clipboard.writeText(params.value);
                                });

                                eGui.addEventListener('contextmenu', (event) => {
                                    event.preventDefault();
                                    const newWindow = window.open();
                                    newWindow.document.write(`<pre>${params.value}</pre>`);
                                    newWindow.document.close();
                                    newWindow.document.title = `Prompt '${params.data.hash}'`;
                                });

                                return eGui;
                            },
                        },
                        {
                            headerName: 'Models', field: 'models', sortable: true, filter: true, width: 150,
                            valueFormatter: (params) => params.value.join(', '),
                        },
                        { headerName: 'Hash', field: 'hash', sortable: true, filter: true, width: 100 },
                        { headerName: 'Tokens', field: 'n_tokens', sortable: true, filter: 'agNumberColumnFilter', width: 80 },
                        { headerName: 'Dataset', field: 'meta.pile_set_name', sortable: true, filter: true, width: 150 },
                    ];

                    // Grid options
                    const promptGrid_options = {
                        columnDefs: columnDefs,
                        rowData: Object.values(this.prompts.all),
                        pagination: true,
                        enableCellTextSelection: true,
                        paginationPageSize: 20,
                        paginationPageSizeSelector: [5, 10, 20, 50, 100, 500],
                        selection: {
                            headerCheckbox: true,
                            selectAll: 'filtered',
                            checkboxes: true,
                            mode: 'multiRow',
                            enableClickSelection: true,
                        },

                        defaultColDef: {
                            sortable: true,
                            filter: true,
                            resizable: true,
                            floatingFilter: true
                        },
                        onSelectionChanged: this.onSelectionChanged.bind(this),
                        onFirstDataRendered: this.onFirstDataRendered.bind(this),
                        onGridReady: (params) => {
                            this.prompts.grid.api = params.api;
                            this.isGridReady = true;
                            this.selectPromptsFromURL();
                        },
                    };

                    const promptGrid_div = document.querySelector('#promptGrid');
                    this.prompts.grid.api = agGrid.createGrid(promptGrid_div, promptGrid_options);
                },

                // ########  ####  ######  ########  ##          ###    ##    ##
                // ##     ##  ##  ##    ## ##     ## ##         ## ##    ##  ##
                // ##     ##  ##  ##       ##     ## ##        ##   ##    ####
                // ##     ##  ##   ######  ########  ##       ##     ##    ##
                // ##     ##  ##        ## ##        ##       #########    ##
                // ##     ##  ##  ##    ## ##        ##       ##     ##    ##
                // ########  ####  ######  ##        ######## ##     ##    ##

                // Display images based on selected criteria
                async displayImages() {
                    this.loading = true;
                    this.images.requested = true;
                    this.images.visible = [];

                    // Calculate total images based on parsed head selections
                    let totalImages = 0;
                    for (const model of this.filters.selected.models) {
                        totalImages += this.getHeadSelectionCount(model) * this.prompts.selected.length * this.filters.selected.functions.length;
                    }
                    this.images.expected = totalImages;

                    // Load images based on parsed head selections
                    for (const model of this.filters.selected.models) {
                        const config = this.models.configs[model];
                        const rawString = this.head_selections_str[model] || 'L*H*';
                        const parsedHeads = this.parseHeadString(rawString, config.n_layers, config.n_heads);
                        if (!parsedHeads) {
                            console.warn(`Invalid head selection for ${model}: "${rawString}"`);
                            continue;
                        }

                        // Iterate over all layers and heads
                        for (let layer = 0; layer < config.n_layers; layer++) {
                            for (let head = 0; head < config.n_heads; head++) {
                                if (!parsedHeads[layer][head]) {
                                    continue;
                                }
                                // Now for each selected prompt and function:
                                for (const promptHash of this.prompts.selected) {
                                    for (
                                        const func_name of
                                        this.filters.selected.functions
                                    ) {
                                        let func = this.filters.available.functions[func_name];
                                        if (!func) {
                                            console.warn(`Function not found ${func_name}`, typeof func_name, JSON.stringify(func_name), func_name, this.filters.available.functions);
                                        }
                                        const basePath = `${DATA_DIR}/${model}/prompts/${promptHash}/L${layer}/H${head}`;

                                        // get the figure format from metadata
                                        let figure_format = func.figure_save_fmt;
                                        if (!figure_format) {
                                            // as a fallback, look for all valid formats
                                            figure_format = await fileOps.figureExists(`${basePath}/${func_name}`);
                                            console.log('could not find figure format for func name', func_name, 'found', figure_format);
                                        }

                                        if (figure_format) {
                                            // Create figure entry
                                            const figure_meta = {
                                                name: `${model} - Prompt ${promptHash} - L${layer}H${head} - ${func_name}`,
                                                model: model,
                                                promptHash: promptHash,
                                                layer: layer,
                                                head: head,
                                                function: func_name,
                                                figure_format: figure_format,
                                            };

                                            if (figure_format === 'svgz') {
                                                const svgText = await fileOps.fetchAndDecompressSvgz(`${basePath}/${func_name}.svgz`);
                                                if (svgText) {
                                                    this.images.visible.push({
                                                        content: svgText,
                                                        ...figure_meta,
                                                    });
                                                }
                                            } else {
                                                const imglink = `<img src="${basePath}/${func_name}.${figure_format}" alt="${figure_meta.name}">`;
                                                this.images.visible.push({
                                                    content: imglink,
                                                    ...figure_meta,
                                                });
                                            }
                                        }
                                    }
                                }
                            }
                        }
                    }

                    this.images.upToDate = true;
                    this.loading = false;
                },
                openMetadata(func) {
                    const newWindow = window.open('', '_blank');
                    let content = `<div style="font-family: sans-serif; line-height:1.4;">`;
                    if (func.doc) {
                        content += `<p><strong>Description:</strong> ${func.doc}</p>`;
                    }
                    if (func.figure_save_fmt) {
                        content += `<p><strong>Format:</strong> ${func.figure_save_fmt}</p>`;
                    }
                    if (func.source) {
                        content += `<p><strong>Source:</strong> ${func.source}</p>`;
                    }
                    content += `</div>`;
                    newWindow.document.write(content);
                    newWindow.document.close();
                    newWindow.document.title = `Metadata for ${func.name}`;
                },
            },


            //  ######   #######  ##     ## ########  ##     ## ######## ######## ########
            // ##    ## ##     ## ###   ### ##     ## ##     ##    ##    ##       ##     ##
            // ##       ##     ## #### #### ##     ## ##     ##    ##    ##       ##     ##
            // ##       ##     ## ## ### ## ########  ##     ##    ##    ######   ##     ##
            // ##       ##     ## ##     ## ##        ##     ##    ##    ##       ##     ##
            // ##    ## ##     ## ##     ## ##        ##     ##    ##    ##       ##     ##
            //  ######   #######  ##     ## ##         #######     ##    ######## ########

            computed: {
                uniqueDatasets() {
                    return [
                        ...new Set(
                            Object.values(this.prompts.all).map(prompt => prompt.meta.pile_set_name).filter(Boolean)
                        )
                    ];
                },
                head_selections_arr() {
                    // model -> boolean[][] mapping for efficient lookup
                    let parsed = {};

                    for (const model in this.head_selections_str) {
                        const config = this.models.configs[model];
                        if (!config) {
                            console.warn(`No config found for model: ${model}`);
                            parsed[model] = null;
                            continue;
                        }

                        const parsedHeads = this.parseHeadString(
                            this.head_selections_str[model] || 'L*H*',
                            config.n_layers,
                            config.n_heads
                        );

                        if (!parsedHeads) {
                            console.warn(
                                `Invalid head selection for ${model}: "${this.head_selections_str[model]}"`
                            );
                        }

                        parsed[model] = parsedHeads;
                    }

                    return parsed;
                }
            },


            // ##      ##    ###    ########  ######  ##     ##
            // ##  ##  ##   ## ##      ##    ##    ## ##     ##
            // ##  ##  ##  ##   ##     ##    ##       ##     ##
            // ##  ##  ## ##     ##    ##    ##       #########
            // ##  ##  ## #########    ##    ##       ##     ##
            // ##  ##  ## ##     ##    ##    ##    ## ##     ##
            //  ###  ###  ##     ##    ##     ######  ##     ##

            // Watch for changes in selected models to load prompts and update layers and heads
            watch: {
                'filters.selected': {
                    deep: true,
                    handler() {
                        this.images.upToDate = false;
                        this.updateURL();
                    }
                },
                'prompts.selected': {
                    handler() {
                        this.images.upToDate = false;
                    }
                },
                'head_selections_str': {
                    deep: true,
                    handler(newValue) {
                        Object.keys(newValue).forEach(model => {
                            if (!this.models.configs[model]) {
                                console.warn(`Attempting to update head selections for unknown model: ${model}`);
                                return;
                            }
                        });
                        this.images.upToDate = false;
                        this.updateURL();
                        this.refreshHeadGrids();
                    }
                },
                'filters.selected.models': {
                    deep: true,
                    handler(newModels) {
                        // Initialize head selections for new models
                        newModels.forEach(model => {
                            if (!this.head_selections_str[model]) {
                                this.head_selections_str[model] = 'L*H*';
                            }
                        });
                        this.updateURL();
                    }
                },
            },

            // Lifecycle hook when component is mounted
            async mounted() {
                console.log('Mounting app:', this);
                const savedDarkMode = localStorage.getItem('darkMode');
                if (savedDarkMode !== null) {
                    this.isDarkMode = savedDarkMode === 'true';
                }
                if (this.isDarkMode) {
                    document.documentElement.classList.add('dark-mode');
                }
                this.readURL(); // Read filters from URL first
                await this.loadData(); // Load models, prompts, and functions
                this.setupModelTable(); // Initialize the model grid
                this.setupPromptTable(); // Initialize the prompts grid
                console.log('Mounted app:', this);
            }
        });

        // Mount the Vue app to the DOM element with id="app"
        app.mount('#app');
    </script>
</body>

</html>
``````{ end_of_file="pattern_lens/frontend/index.html" }

``````{ path="pattern_lens/__init__.py"  }
""".. include:: ../README.md"""

__all__ = [
	"activations",
	"attn_figure_funcs",
	"consts",
	"figure_util",
	"figures",
	"indexes",
	"load_activations",
	"prompts",
	"server",
]

``````{ end_of_file="pattern_lens/__init__.py" }

``````{ path="pattern_lens/activations.py"  }
"""computing and saving activations given a model and prompts

# Usage:

from the command line:

```bash
python -m pattern_lens.activations --model <model_name> --prompts <prompts_path> --save-path <save_path> --min-chars <min_chars> --max-chars <max_chars> --n-samples <n_samples>
```

from a script:

```python
from pattern_lens.activations import activations_main
activations_main(
	model_name="gpt2",
	save_path="demo/"
	prompts_path="data/pile_1k.jsonl",
)
```

"""

import argparse
import functools
import json
import re
from collections.abc import Callable
from dataclasses import asdict
from pathlib import Path
from typing import Literal, overload

import numpy as np
import torch
import tqdm
from jaxtyping import Float
from muutils.json_serialize import json_serialize
from muutils.misc.numerical import shorten_numerical_to_str

# custom utils
from muutils.spinner import SpinnerContext
from transformer_lens import (  # type: ignore[import-untyped]
	ActivationCache,
	HookedTransformer,
	HookedTransformerConfig,
)

# pattern_lens
from pattern_lens.consts import (
	ATTN_PATTERN_REGEX,
	DATA_DIR,
	DIVIDER_S1,
	DIVIDER_S2,
	SPINNER_KWARGS,
	ActivationCacheNp,
	ReturnCache,
)
from pattern_lens.indexes import (
	generate_models_jsonl,
	generate_prompts_jsonl,
	write_html_index,
)
from pattern_lens.load_activations import (
	ActivationsMissingError,
	augment_prompt_with_hash,
	load_activations,
)
from pattern_lens.prompts import load_text_data


# return nothing, but `stack_heads` still affects how we save the activations
@overload
def compute_activations(
	prompt: dict,
	model: HookedTransformer | None = None,
	save_path: Path = Path(DATA_DIR),
	names_filter: Callable[[str], bool] | re.Pattern = ATTN_PATTERN_REGEX,
	return_cache: Literal[None] = None,
	stack_heads: bool = False,
) -> tuple[Path, None]: ...
# return stacked heads in numpy or torch form
@overload
def compute_activations(
	prompt: dict,
	model: HookedTransformer | None = None,
	save_path: Path = Path(DATA_DIR),
	names_filter: Callable[[str], bool] | re.Pattern = ATTN_PATTERN_REGEX,
	return_cache: Literal["torch"] = "torch",
	stack_heads: Literal[True] = True,
) -> tuple[Path, Float[torch.Tensor, "n_layers n_heads n_ctx n_ctx"]]: ...
@overload
def compute_activations(
	prompt: dict,
	model: HookedTransformer | None = None,
	save_path: Path = Path(DATA_DIR),
	names_filter: Callable[[str], bool] | re.Pattern = ATTN_PATTERN_REGEX,
	return_cache: Literal["numpy"] = "numpy",
	stack_heads: Literal[True] = True,
) -> tuple[Path, Float[np.ndarray, "n_layers n_heads n_ctx n_ctx"]]: ...
# return dicts in numpy or torch form
@overload
def compute_activations(
	prompt: dict,
	model: HookedTransformer | None = None,
	save_path: Path = Path(DATA_DIR),
	names_filter: Callable[[str], bool] | re.Pattern = ATTN_PATTERN_REGEX,
	return_cache: Literal["numpy"] = "numpy",
	stack_heads: Literal[False] = False,
) -> tuple[Path, ActivationCacheNp]: ...
@overload
def compute_activations(
	prompt: dict,
	model: HookedTransformer | None = None,
	save_path: Path = Path(DATA_DIR),
	names_filter: Callable[[str], bool] | re.Pattern = ATTN_PATTERN_REGEX,
	return_cache: Literal["torch"] = "torch",
	stack_heads: Literal[False] = False,
) -> tuple[Path, ActivationCache]: ...
# actual function body
def compute_activations(  # noqa: PLR0915
	prompt: dict,
	model: HookedTransformer | None = None,
	save_path: Path = Path(DATA_DIR),
	names_filter: Callable[[str], bool] | re.Pattern = ATTN_PATTERN_REGEX,
	return_cache: ReturnCache = "torch",
	stack_heads: bool = False,
) -> tuple[
	Path,
	ActivationCacheNp
	| ActivationCache
	| Float[np.ndarray, "n_layers n_heads n_ctx n_ctx"]
	| Float[torch.Tensor, "n_layers n_heads n_ctx n_ctx"]
	| None,
]:
	"""get activations for a given model and prompt, possibly from a cache

	if from a cache, prompt_meta must be passed and contain the prompt hash

	# Parameters:
	- `prompt : dict | None`
		(defaults to `None`)
	- `model : HookedTransformer`
	- `save_path : Path`
		(defaults to `Path(DATA_DIR)`)
	- `names_filter : Callable[[str], bool]|re.Pattern`
		a filter for the names of the activations to return. if an `re.Pattern`, will use `lambda key: names_filter.match(key) is not None`
		(defaults to `ATTN_PATTERN_REGEX`)
	- `return_cache : Literal[None, "numpy", "torch"]`
		will return `None` as the second element if `None`, otherwise will return the cache in the specified tensor format. `stack_heads` still affects whether it will be a dict (False) or a single tensor (True)
		(defaults to `None`)
	- `stack_heads : bool`
		whether the heads should be stacked in the output. this causes a number of changes:
	- `npy` file with a single `(n_layers, n_heads, n_ctx, n_ctx)` tensor saved for each prompt instead of `npz` file with dict by layer
	- `cache` will be a single `(n_layers, n_heads, n_ctx, n_ctx)` tensor instead of a dict by layer if `return_cache` is `True`
		will assert that everything in the activation cache is only attention patterns, and is all of the attention patterns. raises an exception if not.

	# Returns:
	```
	tuple[
		Path,
		Union[
			None,
			ActivationCacheNp, ActivationCache,
			Float[np.ndarray, "n_layers n_heads n_ctx n_ctx"], Float[torch.Tensor, "n_layers n_heads n_ctx n_ctx"],
		]
	]
	```
	"""
	# check inputs
	assert model is not None, "model must be passed"
	assert "text" in prompt, "prompt must contain 'text' key"
	prompt_str: str = prompt["text"]

	# compute or get prompt metadata
	prompt_tokenized: list[str] = prompt.get(
		"tokens",
		model.tokenizer.tokenize(prompt_str),
	)
	prompt.update(
		dict(
			n_tokens=len(prompt_tokenized),
			tokens=prompt_tokenized,
		),
	)

	# save metadata
	prompt_dir: Path = save_path / model.cfg.model_name / "prompts" / prompt["hash"]
	prompt_dir.mkdir(parents=True, exist_ok=True)
	with open(prompt_dir / "prompt.json", "w") as f:
		json.dump(prompt, f)

	# set up names filter
	names_filter_fn: Callable[[str], bool]
	if isinstance(names_filter, re.Pattern):
		names_filter_fn = lambda key: names_filter.match(key) is not None  # noqa: E731
	else:
		names_filter_fn = names_filter

	# compute activations
	cache_torch: ActivationCache
	with torch.no_grad():
		model.eval()
		# TODO: batching?
		_, cache_torch = model.run_with_cache(
			prompt_str,
			names_filter=names_filter_fn,
			return_type=None,
		)

	activations_path: Path
	# saving and returning
	if stack_heads:
		n_layers: int = model.cfg.n_layers
		key_pattern: str = "blocks.{i}.attn.hook_pattern"
		# NOTE: this only works for stacking heads at the moment
		# activations_specifier: str = key_pattern.format(i=f'0-{n_layers}')
		activations_specifier: str = key_pattern.format(i="-")
		activations_path = prompt_dir / f"activations-{activations_specifier}.npy"

		# check the keys are only attention heads
		head_keys: list[str] = [key_pattern.format(i=i) for i in range(n_layers)]
		cache_torch_keys_set: set[str] = set(cache_torch.keys())
		assert cache_torch_keys_set == set(head_keys), (
			f"unexpected keys!\n{set(head_keys).symmetric_difference(cache_torch_keys_set) = }\n{cache_torch_keys_set} != {set(head_keys)}"
		)

		# stack heads
		patterns_stacked: Float[torch.Tensor, "n_layers n_heads n_ctx n_ctx"] = (
			torch.stack([cache_torch[k] for k in head_keys], dim=1)
		)
		# check shape
		pattern_shape_no_ctx: tuple[int, ...] = tuple(patterns_stacked.shape[:3])
		assert pattern_shape_no_ctx == (1, n_layers, model.cfg.n_heads), (
			f"unexpected shape: {patterns_stacked.shape[:3] = } ({pattern_shape_no_ctx = }), expected {(1, n_layers, model.cfg.n_heads) = }"
		)

		patterns_stacked_np: Float[np.ndarray, "n_layers n_heads n_ctx n_ctx"] = (
			patterns_stacked.cpu().numpy()
		)

		# save
		np.save(activations_path, patterns_stacked_np)

		# return
		match return_cache:
			case "numpy":
				return activations_path, patterns_stacked_np
			case "torch":
				return activations_path, patterns_stacked
			case None:
				return activations_path, None
			case _:
				msg = f"invalid return_cache: {return_cache = }"
				raise ValueError(msg)
	else:
		activations_path = prompt_dir / "activations.npz"

		# save
		cache_np: ActivationCacheNp = {
			k: v.detach().cpu().numpy() for k, v in cache_torch.items()
		}

		np.savez_compressed(
			activations_path,
			**cache_np,
		)

		# return
		match return_cache:
			case "numpy":
				return activations_path, cache_np
			case "torch":
				return activations_path, cache_torch
			case None:
				return activations_path, None
			case _:
				msg = f"invalid return_cache: {return_cache = }"
				raise ValueError(msg)


@overload
def get_activations(
	prompt: dict,
	model: HookedTransformer | str,
	save_path: Path = Path(DATA_DIR),
	allow_disk_cache: bool = True,
	return_cache: Literal[None] = None,
) -> tuple[Path, None]: ...
@overload
def get_activations(
	prompt: dict,
	model: HookedTransformer | str,
	save_path: Path = Path(DATA_DIR),
	allow_disk_cache: bool = True,
	return_cache: Literal["torch"] = "torch",
) -> tuple[Path, ActivationCache]: ...
@overload
def get_activations(
	prompt: dict,
	model: HookedTransformer | str,
	save_path: Path = Path(DATA_DIR),
	allow_disk_cache: bool = True,
	return_cache: Literal["numpy"] = "numpy",
) -> tuple[Path, ActivationCacheNp]: ...
def get_activations(
	prompt: dict,
	model: HookedTransformer | str,
	save_path: Path = Path(DATA_DIR),
	allow_disk_cache: bool = True,
	return_cache: ReturnCache = "numpy",
) -> tuple[Path, ActivationCacheNp | ActivationCache | None]:
	"""given a prompt and a model, save or load activations

	# Parameters:
	- `prompt : dict`
		expected to contain the 'text' key
	- `model : HookedTransformer | str`
		either a `HookedTransformer` or a string model name, to be loaded with `HookedTransformer.from_pretrained`
	- `save_path : Path`
		path to save the activations to (and load from)
		(defaults to `Path(DATA_DIR)`)
	- `allow_disk_cache : bool`
		whether to allow loading from disk cache
		(defaults to `True`)
	- `return_cache : Literal[None, "numpy", "torch"]`
		whether to return the cache, and in what format
		(defaults to `"numpy"`)

	# Returns:
	- `tuple[Path, ActivationCacheNp | ActivationCache | None]`
		the path to the activations and the cache if `return_cache is not None`

	"""
	# add hash to prompt
	augment_prompt_with_hash(prompt)

	# get the model
	model_name: str = (
		model.cfg.model_name if isinstance(model, HookedTransformer) else model
	)

	# from cache
	if allow_disk_cache:
		try:
			path, cache = load_activations(
				model_name=model_name,
				prompt=prompt,
				save_path=save_path,
			)
			if return_cache:
				return path, cache
			else:
				# TODO: this basically does nothing, since we load the activations and then immediately get rid of them.
				# maybe refactor this so that load_activations can take a parameter to simply assert that the cache exists?
				# this will let us avoid loading it, which slows things down
				return path, None
		except ActivationsMissingError:
			pass

	# compute them
	if isinstance(model, str):
		model = HookedTransformer.from_pretrained(model_name)

	return compute_activations(
		prompt=prompt,
		model=model,
		save_path=save_path,
		return_cache=return_cache,
	)


DEFAULT_DEVICE: torch.device = torch.device(
	"cuda" if torch.cuda.is_available() else "cpu",
)


def activations_main(
	model_name: str,
	save_path: str,
	prompts_path: str,
	raw_prompts: bool,
	min_chars: int,
	max_chars: int,
	force: bool,
	n_samples: int,
	no_index_html: bool,
	shuffle: bool = False,
	stacked_heads: bool = False,
	device: str | torch.device = DEFAULT_DEVICE,
) -> None:
	"""main function for computing activations

	# Parameters:
	- `model_name : str`
		name of a model to load with `HookedTransformer.from_pretrained`
	- `save_path : str`
		path to save the activations to
	- `prompts_path : str`
		path to the prompts file
	- `raw_prompts : bool`
		whether the prompts are raw, not filtered by length. `load_text_data` will be called if `True`, otherwise just load the "text" field from each line in `prompts_path`
	- `min_chars : int`
		minimum number of characters for a prompt
	- `max_chars : int`
		maximum number of characters for a prompt
	- `force : bool`
		whether to overwrite existing files
	- `n_samples : int`
		maximum number of samples to process
	- `no_index_html : bool`
		whether to write an index.html file
	- `shuffle : bool`
		whether to shuffle the prompts
		(defaults to `False`)
	- `stacked_heads : bool`
		whether	to stack the heads in the output tensor. will save as `.npy` instead of `.npz` if `True`
		(defaults to `False`)
	- `device : str | torch.device`
		the device to use. if a string, will be passed to `torch.device`
	"""
	# figure out the device to use
	device_: torch.device
	if isinstance(device, torch.device):
		device_ = device
	elif isinstance(device, str):
		device_ = torch.device(device)
	else:
		msg = f"invalid device: {device}"
		raise TypeError(msg)

	print(f"using device: {device_}")

	with SpinnerContext(message="loading model", **SPINNER_KWARGS):
		model: HookedTransformer = HookedTransformer.from_pretrained(
			model_name,
			device=device_,
		)
		model.model_name = model_name
		model.cfg.model_name = model_name
		n_params: int = sum(p.numel() for p in model.parameters())
	print(
		f"loaded {model_name} with {shorten_numerical_to_str(n_params)} ({n_params}) parameters",
	)
	print(f"\tmodel devices: { {p.device for p in model.parameters()} }")

	save_path_p: Path = Path(save_path)
	save_path_p.mkdir(parents=True, exist_ok=True)
	model_path: Path = save_path_p / model_name
	with SpinnerContext(
		message=f"saving model info to {model_path.as_posix()}",
		**SPINNER_KWARGS,
	):
		model_cfg: HookedTransformerConfig
		model_cfg = model.cfg
		model_path.mkdir(parents=True, exist_ok=True)
		with open(model_path / "model_cfg.json", "w") as f:
			json.dump(json_serialize(asdict(model_cfg)), f)

	# load prompts
	with SpinnerContext(
		message=f"loading prompts from {prompts_path = }",
		**SPINNER_KWARGS,
	):
		prompts: list[dict]
		if raw_prompts:
			prompts = load_text_data(
				Path(prompts_path),
				min_chars=min_chars,
				max_chars=max_chars,
				shuffle=shuffle,
			)
		else:
			with open(model_path / "prompts.jsonl", "r") as f:
				prompts = [json.loads(line) for line in f.readlines()]
		# truncate to n_samples
		prompts = prompts[:n_samples]

	print(f"{len(prompts)} prompts loaded")

	# write index.html
	with SpinnerContext(message="writing index.html", **SPINNER_KWARGS):
		if not no_index_html:
			write_html_index(save_path_p)

	# TODO: not implemented yet
	if stacked_heads:
		raise NotImplementedError("stacked_heads not implemented yet")

	# get activations
	list(
		tqdm.tqdm(
			map(
				functools.partial(
					get_activations,
					model=model,
					save_path=save_path_p,
					allow_disk_cache=not force,
					return_cache=None,
					# stacked_heads=stacked_heads,
				),
				prompts,
			),
			total=len(prompts),
			desc="Computing activations",
			unit="prompt",
		),
	)

	with SpinnerContext(
		message="updating jsonl metadata for models and prompts",
		**SPINNER_KWARGS,
	):
		generate_models_jsonl(save_path_p)
		generate_prompts_jsonl(save_path_p / model_name)


def main() -> None:
	"generate attention pattern activations for a model and prompts"
	print(DIVIDER_S1)
	with SpinnerContext(message="parsing args", **SPINNER_KWARGS):
		arg_parser: argparse.ArgumentParser = argparse.ArgumentParser()
		# input and output
		arg_parser.add_argument(
			"--model",
			"-m",
			type=str,
			required=True,
			help="The model name(s) to use. comma separated with no whitespace if multiple",
		)

		arg_parser.add_argument(
			"--prompts",
			"-p",
			type=str,
			required=False,
			help="The path to the prompts file (jsonl with 'text' key on each line). If `None`, expects that `--figures` is passed and will generate figures for all prompts in the model directory",
			default=None,
		)

		arg_parser.add_argument(
			"--save-path",
			"-s",
			type=str,
			required=False,
			help="The path to save the attention patterns",
			default=DATA_DIR,
		)

		# min and max prompt lengths
		arg_parser.add_argument(
			"--min-chars",
			type=int,
			required=False,
			help="The minimum number of characters for a prompt",
			default=100,
		)
		arg_parser.add_argument(
			"--max-chars",
			type=int,
			required=False,
			help="The maximum number of characters for a prompt",
			default=1000,
		)

		# number of samples
		arg_parser.add_argument(
			"--n-samples",
			"-n",
			type=int,
			required=False,
			help="The max number of samples to process, do all in the file if None",
			default=None,
		)

		# force overwrite
		arg_parser.add_argument(
			"--force",
			"-f",
			action="store_true",
			help="If passed, will overwrite existing files",
		)

		# no index html
		arg_parser.add_argument(
			"--no-index-html",
			action="store_true",
			help="If passed, will not write an index.html file for the model",
		)

		# raw prompts
		arg_parser.add_argument(
			"--raw-prompts",
			"-r",
			action="store_true",
			help="pass if the prompts have not been split and tokenized (still needs keys 'text' and 'meta' for each item)",
		)

		# shuffle
		arg_parser.add_argument(
			"--shuffle",
			action="store_true",
			help="If passed, will shuffle the prompts",
		)

		# stack heads
		arg_parser.add_argument(
			"--stacked-heads",
			action="store_true",
			help="If passed, will stack the heads in the output tensor",
		)

		# device
		arg_parser.add_argument(
			"--device",
			type=str,
			required=False,
			help="The device to use for the model",
			default="cuda" if torch.cuda.is_available() else "cpu",
		)

		args: argparse.Namespace = arg_parser.parse_args()

	print(f"args parsed: {args}")

	models: list[str]
	if "," in args.model:
		models = args.model.split(",")
	else:
		models = [args.model]

	n_models: int = len(models)
	for idx, model in enumerate(models):
		print(DIVIDER_S2)
		print(f"processing model {idx + 1} / {n_models}: {model}")
		print(DIVIDER_S2)

		activations_main(
			model_name=model,
			save_path=args.save_path,
			prompts_path=args.prompts,
			raw_prompts=args.raw_prompts,
			min_chars=args.min_chars,
			max_chars=args.max_chars,
			force=args.force,
			n_samples=args.n_samples,
			no_index_html=args.no_index_html,
			shuffle=args.shuffle,
			stacked_heads=args.stacked_heads,
			device=args.device,
		)
		del model

	print(DIVIDER_S1)


if __name__ == "__main__":
	main()

``````{ end_of_file="pattern_lens/activations.py" }

``````{ path="pattern_lens/attn_figure_funcs.py"  }
"""default figure functions

- If you are making a PR, add your new figure function here.
- if you are using this as a library, then you can see examples here


note that for `pattern_lens.figures` to recognize your function, you need to use the `register_attn_figure_func` decorator
which adds your function to `ATTENTION_MATRIX_FIGURE_FUNCS`

"""

import itertools
from collections.abc import Callable, Sequence

from pattern_lens.consts import AttentionMatrix
from pattern_lens.figure_util import (
	AttentionMatrixFigureFunc,
	Matrix2D,
	save_matrix_wrapper,
)

_FIGURE_NAMES_KEY: str = "_figure_names"

ATTENTION_MATRIX_FIGURE_FUNCS: list[AttentionMatrixFigureFunc] = list()


def get_all_figure_names() -> list[str]:
	"""get all figure names"""
	return list(
		itertools.chain.from_iterable(
			getattr(
				func,
				_FIGURE_NAMES_KEY,
				[func.__name__],
			)
			for func in ATTENTION_MATRIX_FIGURE_FUNCS
		),
	)


def register_attn_figure_func(
	func: AttentionMatrixFigureFunc,
) -> AttentionMatrixFigureFunc:
	"""decorator for registering attention matrix figure function

	if you want to add a new figure function, you should use this decorator

	# Parameters:
	- `func : AttentionMatrixFigureFunc`
		your function, which should take an attention matrix and path

	# Returns:
	- `AttentionMatrixFigureFunc`
		your function, after we add it to `ATTENTION_MATRIX_FIGURE_FUNCS`

	# Usage:
	```python
	@register_attn_figure_func
	def my_new_figure_func(attn_matrix: AttentionMatrix, path: Path) -> None:
		fig, ax = plt.subplots(figsize=(10, 10))
		ax.matshow(attn_matrix, cmap="viridis")
		ax.set_title("My New Figure Function")
		ax.axis("off")
		plt.savefig(path / "my_new_figure_func", format="svgz")
		plt.close(fig)
	```

	"""
	setattr(func, _FIGURE_NAMES_KEY, (func.__name__,))
	global ATTENTION_MATRIX_FIGURE_FUNCS  # noqa: PLW0602
	ATTENTION_MATRIX_FIGURE_FUNCS.append(func)

	return func


def register_attn_figure_multifunc(
	names: Sequence[str],
) -> Callable[[AttentionMatrixFigureFunc], AttentionMatrixFigureFunc]:
	"decorator which registers a function as a multi-figure function"

	def decorator(func: AttentionMatrixFigureFunc) -> AttentionMatrixFigureFunc:
		setattr(
			func,
			_FIGURE_NAMES_KEY,
			tuple([f"{func.__name__}.{name}" for name in names]),
		)
		global ATTENTION_MATRIX_FIGURE_FUNCS  # noqa: PLW0602
		ATTENTION_MATRIX_FIGURE_FUNCS.append(func)
		return func

	return decorator


@register_attn_figure_func
@save_matrix_wrapper(fmt="png")
def raw(attn_matrix: AttentionMatrix) -> Matrix2D:
	"raw attention matrix"
	return attn_matrix


# some more examples:

# @register_attn_figure_func
# @matplotlib_figure_saver
# def raw(attn_matrix: AttentionMatrix, ax: plt.Axes) -> None:
#     ax.matshow(attn_matrix, cmap="viridis")
#     ax.set_title("Raw Attention Pattern")
#     ax.axis("off")

# @register_attn_figure_func
# @save_matrix_wrapper(fmt="svg")
# def raw_svg(attn_matrix: AttentionMatrix) -> Matrix2D:
#     return attn_matrix

# @register_attn_figure_func
# @save_matrix_wrapper(fmt="svgz")
# def raw_svgz(attn_matrix: AttentionMatrix) -> Matrix2D:
#     return attn_matrix

``````{ end_of_file="pattern_lens/attn_figure_funcs.py" }

``````{ path="pattern_lens/consts.py"  }
"""implements some constants and types"""

import re
from typing import Literal

import numpy as np
import torch
from jaxtyping import Float

AttentionMatrix = Float[np.ndarray, "n_ctx n_ctx"]
"type alias for attention matrix"

ActivationCacheNp = dict[str, np.ndarray]
"type alias for a cache of activations, like a transformer_lens.ActivationCache"

ActivationCacheTorch = dict[str, torch.Tensor]
"type alias for a cache of activations, like a transformer_lens.ActivationCache but without the extras. useful for when loading from an npz file"

DATA_DIR: str = "attn_data"
"default directory for attention data"

ATTN_PATTERN_REGEX: re.Pattern = re.compile(r"blocks\.(\d+)\.attn\.hook_pattern")
"regex for finding attention patterns in model state dicts"

SPINNER_KWARGS: dict = dict(
	config=dict(success="✔️ "),
)
"default kwargs for `muutils.spinner.Spinner`"

DIVIDER_S1: str = "=" * 70
"divider string for separating sections"

DIVIDER_S2: str = "-" * 50
"divider string for separating subsections"

ReturnCache = Literal[None, "numpy", "torch"]
"return type for a cache of activations"

``````{ end_of_file="pattern_lens/consts.py" }

``````{ path="pattern_lens/figure_util.py"  }
"""implements a bunch of types, default values, and templates which are useful for figure functions

notably, you can use the decorators `matplotlib_figure_saver`, `save_matrix_wrapper` to make your functions save figures
"""

import base64
import functools
import gzip
import io
from collections.abc import Callable, Sequence
from pathlib import Path
from typing import Literal, overload

import matplotlib as mpl
import matplotlib.pyplot as plt
import numpy as np
from jaxtyping import Float, UInt8
from matplotlib.colors import Colormap
from PIL import Image

from pattern_lens.consts import AttentionMatrix

AttentionMatrixFigureFunc = Callable[[AttentionMatrix, Path], None]
"Type alias for a function that, given an attention matrix, saves one or more figures"

Matrix2D = Float[np.ndarray, "n m"]
"Type alias for a 2D matrix (plottable)"

Matrix2Drgb = UInt8[np.ndarray, "n m rgb=3"]
"Type alias for a 2D matrix with 3 channels (RGB)"

AttentionMatrixToMatrixFunc = Callable[[AttentionMatrix], Matrix2D]
"Type alias for a function that, given an attention matrix, returns a 2D matrix"

MATPLOTLIB_FIGURE_FMT: str = "svgz"
"format for saving matplotlib figures"

MatrixSaveFormat = Literal["png", "svg", "svgz"]
"Type alias for the format to save a matrix as when saving raw matrix, not matplotlib figure"

MATRIX_SAVE_NORMALIZE: bool = False
"default for whether to normalize the matrix to range [0, 1]"

MATRIX_SAVE_CMAP: str = "viridis"
"default colormap for saving matrices"

MATRIX_SAVE_FMT: MatrixSaveFormat = "svgz"
"default format for saving matrices"

MATRIX_SAVE_SVG_TEMPLATE: str = """<svg xmlns="http://www.w3.org/2000/svg" width="{m}" height="{n}" viewBox="0 0 {m} {n}" image-rendering="pixelated"> <image href="data:image/png;base64,{png_base64}" width="{m}" height="{n}" /> </svg>"""
"template for saving an `n` by `m` matrix as an svg/svgz"


# TYPING: mypy hates it when we dont pass func=None or None as the first arg
@overload  # without keyword arguments, returns decorated function
def matplotlib_figure_saver(
	func: Callable[[AttentionMatrix, plt.Axes], None],
) -> AttentionMatrixFigureFunc: ...
@overload  # with keyword arguments, returns decorator
def matplotlib_figure_saver(
	func: None = None,
	fmt: str = MATPLOTLIB_FIGURE_FMT,
) -> Callable[
	[Callable[[AttentionMatrix, plt.Axes], None], str],
	AttentionMatrixFigureFunc,
]: ...
def matplotlib_figure_saver(
	func: Callable[[AttentionMatrix, plt.Axes], None] | None = None,
	fmt: str = MATPLOTLIB_FIGURE_FMT,
) -> (
	AttentionMatrixFigureFunc
	| Callable[
		[Callable[[AttentionMatrix, plt.Axes], None], str],
		AttentionMatrixFigureFunc,
	]
):
	"""decorator for functions which take an attention matrix and predefined `ax` object, making it save a figure

	# Parameters:
	- `func : Callable[[AttentionMatrix, plt.Axes], None]`
		your function, which should take an attention matrix and predefined `ax` object
	- `fmt : str`
		format for saving matplotlib figures
		(defaults to `MATPLOTLIB_FIGURE_FMT`)

	# Returns:
	- `AttentionMatrixFigureFunc`
		your function, after we wrap it to save a figure

	# Usage:
	```python
	@register_attn_figure_func
	@matplotlib_figure_saver
	def raw(attn_matrix: AttentionMatrix, ax: plt.Axes) -> None:
		ax.matshow(attn_matrix, cmap="viridis")
		ax.set_title("Raw Attention Pattern")
		ax.axis("off")
	```

	"""

	def decorator(
		func: Callable[[AttentionMatrix, plt.Axes], None],
		fmt: str = fmt,
	) -> AttentionMatrixFigureFunc:
		@functools.wraps(func)
		def wrapped(attn_matrix: AttentionMatrix, save_dir: Path) -> None:
			fig_path: Path = save_dir / f"{func.__name__}.{fmt}"

			fig, ax = plt.subplots(figsize=(10, 10))
			func(attn_matrix, ax)
			plt.tight_layout()
			plt.savefig(fig_path)
			plt.close(fig)

		wrapped.figure_save_fmt = fmt  # type: ignore[attr-defined]

		return wrapped

	if callable(func):
		# Handle no-arguments case
		return decorator(func)
	else:
		# Handle arguments case
		return decorator


def matplotlib_multifigure_saver(
	names: Sequence[str],
	fmt: str = MATPLOTLIB_FIGURE_FMT,
) -> Callable[
	# decorator takes in function
	# which takes a matrix and a dictionary of axes corresponding to the names
	[Callable[[AttentionMatrix, dict[str, plt.Axes]], None]],
	# returns the decorated function
	AttentionMatrixFigureFunc,
]:
	"""decorate a function such that it saves multiple figures, one for each name in `names`

	# Parameters:
	- `names : Sequence[str]`
		the names of the figures to save
	- `fmt : str`
		format for saving matplotlib figures
		(defaults to `MATPLOTLIB_FIGURE_FMT`)

	# Returns:
	- `Callable[[Callable[[AttentionMatrix, dict[str, plt.Axes]], None], AttentionMatrixFigureFunc]`
		the decorator, which will then be applied to the function
		we expect the decorated function to take an attention pattern, and a dict of axes corresponding to the names

	"""

	def decorator(
		func: Callable[[AttentionMatrix, dict[str, plt.Axes]], None],
	) -> AttentionMatrixFigureFunc:
		func_name: str = func.__name__

		@functools.wraps(func)
		def wrapped(attn_matrix: AttentionMatrix, save_dir: Path) -> None:
			# set up axes and corresponding figures
			axes_dict: dict[str, plt.Axes] = {}
			figs_dict: dict[str, plt.Figure] = {}

			# Create all figures and axes
			for name in names:
				fig, ax = plt.subplots(figsize=(10, 10))
				axes_dict[name] = ax
				figs_dict[name] = fig

			try:
				# Run the function to make plots
				func(attn_matrix, axes_dict)

				# Save each figure
				for name, fig_ in figs_dict.items():
					fig_path: Path = save_dir / f"{func_name}.{name}.{fmt}"
					# TYPING: error: Item "SubFigure" of "Figure | SubFigure" has no attribute "tight_layout"  [union-attr]
					fig_.tight_layout()  # type: ignore[union-attr]
					# TYPING: error: Item "SubFigure" of "Figure | SubFigure" has no attribute "savefig"  [union-attr]
					fig_.savefig(fig_path)  # type: ignore[union-attr]
			finally:
				# Always clean up figures, even if an error occurred
				for fig in figs_dict.values():
					# TYPING: error: Argument 1 to "close" has incompatible type "Figure | SubFigure"; expected "int | str | Figure | Literal['all'] | None"  [arg-type]
					plt.close(fig)  # type: ignore[arg-type]

		# it doesn't normally have this attribute, but we're adding it
		wrapped.figure_save_fmt = fmt  # type: ignore[attr-defined]

		return wrapped

	return decorator


def matrix_to_image_preprocess(
	matrix: Matrix2D,
	normalize: bool = False,
	cmap: str | Colormap = "viridis",
	diverging_colormap: bool = False,
	normalize_min: float | None = None,
) -> Matrix2Drgb:
	"""preprocess a 2D matrix into a plottable heatmap image

	# Parameters:
	- `matrix : Matrix2D`
		input matrix
	- `normalize : bool`
		whether to normalize the matrix to range [0, 1]
		(defaults to `MATRIX_SAVE_NORMALIZE`)
	- `cmap : str|Colormap`
		the colormap to use for the matrix
		(defaults to `MATRIX_SAVE_CMAP`)
	- `diverging_colormap : bool`
		if True and using a diverging colormap, ensures 0 values map to the center of the colormap
		(defaults to False)
	- `normalize_min : float|None`
		if a float, then for `normalize=True` and `diverging_colormap=False`, the minimum value to normalize to (generally set this to zero?).
		if `None`, then the minimum value of the matrix is used.
		if `diverging_colormap=True` OR `normalize=False`, this **must** be `None`.
		(defaults to `None`)

	# Returns:
	- `Matrix2Drgb`
	"""
	# check dims (2 is not that magic of a value here, hence noqa)
	assert matrix.ndim == 2, f"Matrix must be 2D, got {matrix.ndim = }"  # noqa: PLR2004

	# check matrix is not empty
	assert matrix.size > 0, "Matrix cannot be empty"

	if normalize_min is not None:
		assert not diverging_colormap, (
			"normalize_min cannot be used with diverging_colormap=True"
		)
		assert normalize, "normalize_min cannot be used with normalize=False"

	# Normalize the matrix to range [0, 1]
	normalized_matrix: Matrix2D
	if normalize:
		if diverging_colormap:
			# For diverging colormaps, we want to center around 0
			max_abs: float = max(abs(matrix.max()), abs(matrix.min()))
			normalized_matrix = (matrix / (2 * max_abs)) + 0.5
		else:
			max_val: float = matrix.max()
			min_val: float
			if normalize_min is not None:
				min_val = normalize_min
				assert min_val < max_val, "normalize_min must be less than matrix max"
				assert min_val >= matrix.min(), (
					"normalize_min must less than matrix min"
				)
			else:
				min_val = matrix.min()

			normalized_matrix = (matrix - min_val) / (max_val - min_val)
	else:
		if diverging_colormap:
			assert matrix.min() >= -1 and matrix.max() <= 1, (  # noqa: PT018
				"For diverging colormaps without normalization, matrix values must be in range [-1, 1]"
			)
			normalized_matrix = matrix
		else:
			assert matrix.min() >= 0 and matrix.max() <= 1, (  # noqa: PT018
				"Matrix values must be in range [0, 1], or normalize must be True"
			)
			normalized_matrix = matrix

	# get the colormap
	cmap_: Colormap
	if isinstance(cmap, str):
		cmap_ = mpl.colormaps[cmap]
	elif isinstance(cmap, Colormap):
		cmap_ = cmap
	else:
		msg = f"Invalid type for {cmap = }, {type(cmap) = }, must be str or Colormap"
		raise TypeError(
			msg,
		)

	# Apply the colormap
	rgb_matrix: Float[np.ndarray, "n m channels=3"] = (
		cmap_(normalized_matrix)[:, :, :3] * 255
	).astype(np.uint8)  # Drop alpha channel

	assert rgb_matrix.shape == (
		matrix.shape[0],
		matrix.shape[1],
		3,
	), f"Matrix after colormap must have 3 channels, got {rgb_matrix.shape = }"

	return rgb_matrix


@overload
def matrix2drgb_to_png_bytes(matrix: Matrix2Drgb, buffer: None = None) -> bytes: ...
@overload
def matrix2drgb_to_png_bytes(matrix: Matrix2Drgb, buffer: io.BytesIO) -> None: ...
def matrix2drgb_to_png_bytes(
	matrix: Matrix2Drgb,
	buffer: io.BytesIO | None = None,
) -> bytes | None:
	"""Convert a `Matrix2Drgb` to valid PNG bytes via PIL

	- if `buffer` is provided, it will write the PNG bytes to the buffer and return `None`
	- if `buffer` is not provided, it will return the PNG bytes

	# Parameters:
	- `matrix : Matrix2Drgb`
	- `buffer : io.BytesIO | None`
		(defaults to `None`, in which case it will return the PNG bytes)

	# Returns:
	- `bytes|None`
		`bytes` if `buffer` is `None`, otherwise `None`
	"""
	pil_img: Image.Image = Image.fromarray(matrix, mode="RGB")
	if buffer is None:
		buffer = io.BytesIO()
		pil_img.save(buffer, format="PNG")
		buffer.seek(0)
		return buffer.read()
	else:
		pil_img.save(buffer, format="PNG")
		return None


def matrix_as_svg(
	matrix: Matrix2D,
	normalize: bool = MATRIX_SAVE_NORMALIZE,
	cmap: str | Colormap = MATRIX_SAVE_CMAP,
	diverging_colormap: bool = False,
	normalize_min: float | None = None,
) -> str:
	"""quickly convert a 2D matrix to an SVG image, without matplotlib

	# Parameters:
	- `matrix : Float[np.ndarray, 'n m']`
		a 2D matrix to convert to an SVG image
	- `normalize : bool`
		whether to normalize the matrix to range [0, 1]. if it's not in the range [0, 1], this must be `True` or it will raise an `AssertionError`
		(defaults to `False`)
	- `cmap : str`
		the colormap to use for the matrix -- will look up in `matplotlib.colormaps` if it's a string
		(defaults to `"viridis"`)
	- `diverging_colormap : bool`
		if True and using a diverging colormap, ensures 0 values map to the center of the colormap
		(defaults to False)
	- `normalize_min : float|None`
		if a float, then for `normalize=True` and `diverging_colormap=False`, the minimum value to normalize to (generally set this to zero?)
		if `None`, then the minimum value of the matrix is used
		if `diverging_colormap=True` OR `normalize=False`, this **must** be `None`
		(defaults to `None`)


	# Returns:
	- `str`
		the SVG content for the matrix
	"""
	# Get the dimensions of the matrix
	assert matrix.ndim == 2, f"Matrix must be 2D, got {matrix.shape = }"  # noqa: PLR2004
	m, n = matrix.shape

	# Preprocess the matrix into an RGB image
	matrix_rgb: Matrix2Drgb = matrix_to_image_preprocess(
		matrix,
		normalize=normalize,
		cmap=cmap,
		diverging_colormap=diverging_colormap,
		normalize_min=normalize_min,
	)

	# Convert the RGB image to PNG bytes
	image_data: bytes = matrix2drgb_to_png_bytes(matrix_rgb)

	# Encode the PNG bytes as base64
	png_base64: str = base64.b64encode(image_data).decode("utf-8")

	# Generate the SVG content
	svg_content: str = MATRIX_SAVE_SVG_TEMPLATE.format(m=m, n=n, png_base64=png_base64)

	return svg_content


@overload  # with keyword arguments, returns decorator
def save_matrix_wrapper(
	func: None = None,
	*args: tuple[()],
	fmt: MatrixSaveFormat = MATRIX_SAVE_FMT,
	normalize: bool = MATRIX_SAVE_NORMALIZE,
	cmap: str | Colormap = MATRIX_SAVE_CMAP,
	diverging_colormap: bool = False,
	normalize_min: float | None = None,
) -> Callable[[AttentionMatrixToMatrixFunc], AttentionMatrixFigureFunc]: ...
@overload  # without keyword arguments, returns decorated function
def save_matrix_wrapper(
	func: AttentionMatrixToMatrixFunc,
	*args: tuple[()],
	fmt: MatrixSaveFormat = MATRIX_SAVE_FMT,
	normalize: bool = MATRIX_SAVE_NORMALIZE,
	cmap: str | Colormap = MATRIX_SAVE_CMAP,
	diverging_colormap: bool = False,
	normalize_min: float | None = None,
) -> AttentionMatrixFigureFunc: ...
def save_matrix_wrapper(
	func: AttentionMatrixToMatrixFunc | None = None,
	*args,
	fmt: MatrixSaveFormat = MATRIX_SAVE_FMT,
	normalize: bool = MATRIX_SAVE_NORMALIZE,
	cmap: str | Colormap = MATRIX_SAVE_CMAP,
	diverging_colormap: bool = False,
	normalize_min: float | None = None,
) -> (
	AttentionMatrixFigureFunc
	| Callable[[AttentionMatrixToMatrixFunc], AttentionMatrixFigureFunc]
):
	"""Decorator for functions that process an attention matrix and save it as an SVGZ image.

	Can handle both argumentless usage and with arguments.

	# Parameters:

	- `func : AttentionMatrixToMatrixFunc|None`
		Either the function to decorate (in the no-arguments case) or `None` when used with arguments.
	- `fmt : MatrixSaveFormat, keyword-only`
		The format to save the matrix as. Defaults to `MATRIX_SAVE_FMT`.
	- `normalize : bool, keyword-only`
		Whether to normalize the matrix to range [0, 1]. Defaults to `False`.
	- `cmap : str, keyword-only`
		The colormap to use for the matrix. Defaults to `MATRIX_SVG_CMAP`.
	- `diverging_colormap : bool`
		if True and using a diverging colormap, ensures 0 values map to the center of the colormap
		(defaults to False)
	- `normalize_min : float|None`
		if a float, then for `normalize=True` and `diverging_colormap=False`, the minimum value to normalize to (generally set this to zero?)
		if `None`, then the minimum value of the matrix is used
		if `diverging_colormap=True` OR `normalize=False`, this **must** be `None`
		(defaults to `None`)

	# Returns:

	`AttentionMatrixFigureFunc|Callable[[AttentionMatrixToMatrixFunc], AttentionMatrixFigureFunc]`

	- `AttentionMatrixFigureFunc` if `func` is `AttentionMatrixToMatrixFunc` (no arguments case)
	- `Callable[[AttentionMatrixToMatrixFunc], AttentionMatrixFigureFunc]` if `func` is `None` -- returns the decorator which will then be applied to the  (with arguments case)

	# Usage:

	```python
	@save_matrix_wrapper
	def identity_matrix(matrix):
		return matrix

	@save_matrix_wrapper(normalize=True, fmt="png")
	def scale_matrix(matrix):
		return matrix * 2

	@save_matrix_wrapper(normalize=True, cmap="plasma")
	def scale_matrix(matrix):
		return matrix * 2
	```

	"""
	assert len(args) == 0, "This decorator only supports keyword arguments"

	assert (
		fmt in MatrixSaveFormat.__args__  # type: ignore[attr-defined]
	), f"Invalid format {fmt = }, must be one of {MatrixSaveFormat.__args__}"  # type: ignore[attr-defined]

	def decorator(
		func: Callable[[AttentionMatrix], Matrix2D],
	) -> AttentionMatrixFigureFunc:
		@functools.wraps(func)
		def wrapped(attn_matrix: AttentionMatrix, save_dir: Path) -> None:
			fig_path: Path = save_dir / f"{func.__name__}.{fmt}"
			processed_matrix: Matrix2D = func(attn_matrix)

			if fmt == "png":
				processed_matrix_rgb: Matrix2Drgb = matrix_to_image_preprocess(
					processed_matrix,
					normalize=normalize,
					cmap=cmap,
					diverging_colormap=diverging_colormap,
					normalize_min=normalize_min,
				)
				image_data: bytes = matrix2drgb_to_png_bytes(processed_matrix_rgb)
				fig_path.write_bytes(image_data)

			else:
				svg_content: str = matrix_as_svg(
					processed_matrix,
					normalize=normalize,
					cmap=cmap,
					diverging_colormap=diverging_colormap,
					normalize_min=normalize_min,
				)

				if fmt == "svgz":
					with gzip.open(fig_path, "wt") as f:
						f.write(svg_content)

				else:
					fig_path.write_text(svg_content, encoding="utf-8")

		wrapped.figure_save_fmt = fmt  # type: ignore[attr-defined]

		return wrapped

	if callable(func):
		# Handle no-arguments case
		return decorator(func)
	else:
		# Handle arguments case
		return decorator

``````{ end_of_file="pattern_lens/figure_util.py" }

``````{ path="pattern_lens/figures.py"  }
"""code for generating figures from attention patterns, using the functions decorated with `register_attn_figure_func`"""

import argparse
import functools
import itertools
import json
import warnings
from collections import defaultdict
from pathlib import Path

import numpy as np
from jaxtyping import Float

# custom utils
from muutils.json_serialize import json_serialize
from muutils.parallel import run_maybe_parallel
from muutils.spinner import SpinnerContext

# pattern_lens
from pattern_lens.attn_figure_funcs import ATTENTION_MATRIX_FIGURE_FUNCS
from pattern_lens.consts import (
	DATA_DIR,
	DIVIDER_S1,
	DIVIDER_S2,
	SPINNER_KWARGS,
	ActivationCacheNp,
	AttentionMatrix,
)
from pattern_lens.indexes import (
	generate_functions_jsonl,
	generate_models_jsonl,
	generate_prompts_jsonl,
)
from pattern_lens.load_activations import load_activations


class HTConfigMock:
	"""Mock of `transformer_lens.HookedTransformerConfig` for type hinting and loading config json

	can be initialized with any kwargs, and will update its `__dict__` with them. does, however, require the following attributes:
	- `n_layers: int`
	- `n_heads: int`
	- `model_name: str`

	we do this to avoid having to import `torch` and `transformer_lens`, since this would have to be done for each process in the parallelization and probably slows things down significantly
	"""

	def __init__(self, **kwargs: dict[str, str | int]) -> None:
		"will pass all kwargs to `__dict__`"
		self.n_layers: int
		self.n_heads: int
		self.model_name: str
		self.__dict__.update(kwargs)

	def serialize(self) -> dict:
		"""serialize the config to json. values which aren't serializable will be converted via `muutils.json_serialize.json_serialize`"""
		# its fine, we know its a dict
		return json_serialize(self.__dict__)  # type: ignore[return-value]

	@classmethod
	def load(cls, data: dict) -> "HTConfigMock":
		"try to load a config from a dict, using the `__init__` method"
		return cls(**data)


def process_single_head(
	layer_idx: int,
	head_idx: int,
	attn_pattern: AttentionMatrix,
	save_dir: Path,
	force_overwrite: bool = False,
) -> dict[str, bool | Exception]:
	"""process a single head's attention pattern, running all the functions in `ATTENTION_MATRIX_FIGURE_FUNCS` on the attention pattern

	> [gotcha:] if `force_overwrite` is `False`, and we used a multi-figure function,
	> it will skip all figures for that function if any are already saved
	> and it assumes a format of `{func_name}.{figure_name}.{fmt}` for the saved figures

	# Parameters:
	- `layer_idx : int`
	- `head_idx : int`
	- `attn_pattern : AttentionMatrix`
		attention pattern for the head
	- `save_dir : Path`
		directory to save the figures to
	- `force_overwrite : bool`
		whether to overwrite existing figures. if `False`, will skip any functions which have already saved a figure
		(defaults to `False`)

	# Returns:
	- `dict[str, bool | Exception]`
		a dictionary of the status of each function, with the function name as the key and the status as the value
	"""
	funcs_status: dict[str, bool | Exception] = dict()

	for func in ATTENTION_MATRIX_FIGURE_FUNCS:
		func_name: str = func.__name__
		fig_path: list[Path] = list(save_dir.glob(f"{func_name}.*"))

		if not force_overwrite and len(fig_path) > 0:
			funcs_status[func_name] = True
			continue

		try:
			func(attn_pattern, save_dir)
			funcs_status[func_name] = True

		# bling catch any exception
		except Exception as e:  # noqa: BLE001
			error_file = save_dir / f"{func.__name__}.error.txt"
			error_file.write_text(str(e))
			warnings.warn(
				f"Error in {func.__name__} for L{layer_idx}H{head_idx}: {e!s}",
				stacklevel=2,
			)
			funcs_status[func_name] = e

	return funcs_status


def compute_and_save_figures(
	model_cfg: "HookedTransformerConfig|HTConfigMock",  # type: ignore[name-defined] # noqa: F821
	activations_path: Path,
	cache: ActivationCacheNp | Float[np.ndarray, "n_layers n_heads n_ctx n_ctx"],
	save_path: Path = Path(DATA_DIR),
	force_overwrite: bool = False,
	track_results: bool = False,
) -> None:
	"""compute and save figures for all heads in the model, using the functions in `ATTENTION_MATRIX_FIGURE_FUNCS`

	# Parameters:
	- `model_cfg : HookedTransformerConfig|HTConfigMock`
	- `cache : ActivationCacheNp | Float[np.ndarray, "n_layers n_heads n_ctx n_ctx"]`
	- `save_path : Path`
		(defaults to `Path(DATA_DIR)`)
	- `force_overwrite : bool`
		force overwrite of existing figures. if `False`, will skip any functions which have already saved a figure
		(defaults to `False`)
	- `track_results : bool`
		whether to track the results of each function for each head. Isn't used for anything yet, but this is a TODO
		(defaults to `False`)
	"""
	prompt_dir: Path = activations_path.parent

	if track_results:
		results: defaultdict[
			str,  # func name
			dict[
				tuple[int, int],  # layer, head
				bool | Exception,  # success or exception
			],
		] = defaultdict(dict)

	for layer_idx, head_idx in itertools.product(
		range(model_cfg.n_layers),
		range(model_cfg.n_heads),
	):
		attn_pattern: AttentionMatrix
		if isinstance(cache, dict):
			attn_pattern = cache[f"blocks.{layer_idx}.attn.hook_pattern"][0, head_idx]
		elif isinstance(cache, np.ndarray):
			attn_pattern = cache[layer_idx, head_idx]
		else:
			msg = (
				f"cache must be a dict or np.ndarray, not {type(cache) = }\n{cache = }"
			)
			raise TypeError(
				msg,
			)

		save_dir: Path = prompt_dir / f"L{layer_idx}" / f"H{head_idx}"
		save_dir.mkdir(parents=True, exist_ok=True)
		head_res: dict[str, bool | Exception] = process_single_head(
			layer_idx=layer_idx,
			head_idx=head_idx,
			attn_pattern=attn_pattern,
			save_dir=save_dir,
			force_overwrite=force_overwrite,
		)

		if track_results:
			for func_name, status in head_res.items():
				results[func_name][(layer_idx, head_idx)] = status

	# TODO: do something with results

	generate_prompts_jsonl(save_path / model_cfg.model_name)


def process_prompt(
	prompt: dict,
	model_cfg: "HookedTransformerConfig|HTConfigMock",  # type: ignore[name-defined] # noqa: F821
	save_path: Path,
	force_overwrite: bool = False,
) -> None:
	"""process a single prompt, loading the activations and computing and saving the figures

	basically just calls `load_activations` and then `compute_and_save_figures`

	# Parameters:
	- `prompt : dict`
	- `model_cfg : HookedTransformerConfig|HTConfigMock`
	- `force_overwrite : bool`
		(defaults to `False`)
	"""
	activations_path: Path
	cache: ActivationCacheNp | Float[np.ndarray, "n_layers n_heads n_ctx n_ctx"]
	activations_path, cache = load_activations(
		model_name=model_cfg.model_name,
		prompt=prompt,
		save_path=save_path,
		return_fmt="numpy",
	)

	compute_and_save_figures(
		model_cfg=model_cfg,
		activations_path=activations_path,
		cache=cache,
		save_path=save_path,
		force_overwrite=force_overwrite,
	)


def figures_main(
	model_name: str,
	save_path: str,
	n_samples: int,
	force: bool,
	parallel: bool | int = True,
) -> None:
	"""main function for generating figures from attention patterns, using the functions in `ATTENTION_MATRIX_FIGURE_FUNCS`

	# Parameters:
	- `model_name : str`
		model name to use, used for loading the model config, prompts, activations, and saving the figures
	- `save_path : str`
		base path to look in
	- `n_samples : int`
		max number of samples to process
	- `force : bool`
		force overwrite of existing figures. if `False`, will skip any functions which have already saved a figure
	- `parallel : bool | int`
		whether to run in parallel. if `True`, will use all available cores. if `False`, will run in serial. if an int, will try to use that many cores
		(defaults to `True`)
	"""
	with SpinnerContext(message="setting up paths", **SPINNER_KWARGS):
		# save model info or check if it exists
		save_path_p: Path = Path(save_path)
		model_path: Path = save_path_p / model_name
		with open(model_path / "model_cfg.json", "r") as f:
			model_cfg = HTConfigMock.load(json.load(f))

	with SpinnerContext(message="loading prompts", **SPINNER_KWARGS):
		# load prompts
		with open(model_path / "prompts.jsonl", "r") as f:
			prompts: list[dict] = [json.loads(line) for line in f.readlines()]
		# truncate to n_samples
		prompts = prompts[:n_samples]

	print(f"{len(prompts)} prompts loaded")

	print(f"{len(ATTENTION_MATRIX_FIGURE_FUNCS)} figure functions loaded")
	print("\t" + ", ".join([func.__name__ for func in ATTENTION_MATRIX_FIGURE_FUNCS]))

	list(
		run_maybe_parallel(
			func=functools.partial(
				process_prompt,
				model_cfg=model_cfg,
				save_path=save_path_p,
				force_overwrite=force,
			),
			iterable=prompts,
			parallel=parallel,
			pbar="tqdm",
			pbar_kwargs=dict(
				desc="Making figures",
				unit="prompt",
			),
		),
	)

	with SpinnerContext(
		message="updating jsonl metadata for models and functions",
		**SPINNER_KWARGS,
	):
		generate_models_jsonl(save_path_p)
		generate_functions_jsonl(save_path_p)


def main() -> None:
	"generates figures from the activations using the functions decorated with `register_attn_figure_func`"
	print(DIVIDER_S1)
	with SpinnerContext(message="parsing args", **SPINNER_KWARGS):
		arg_parser: argparse.ArgumentParser = argparse.ArgumentParser()
		# input and output
		arg_parser.add_argument(
			"--model",
			"-m",
			type=str,
			required=True,
			help="The model name(s) to use. comma separated with no whitespace if multiple",
		)
		arg_parser.add_argument(
			"--save-path",
			"-s",
			type=str,
			required=False,
			help="The path to save the attention patterns",
			default=DATA_DIR,
		)
		# number of samples
		arg_parser.add_argument(
			"--n-samples",
			"-n",
			type=int,
			required=False,
			help="The max number of samples to process, do all in the file if None",
			default=None,
		)
		# force overwrite of existing figures
		arg_parser.add_argument(
			"--force",
			"-f",
			type=bool,
			required=False,
			help="Force overwrite of existing figures",
			default=False,
		)

		args: argparse.Namespace = arg_parser.parse_args()

	print(f"args parsed: {args}")

	models: list[str]
	if "," in args.model:
		models = args.model.split(",")
	else:
		models = [args.model]

	n_models: int = len(models)
	for idx, model in enumerate(models):
		print(DIVIDER_S2)
		print(f"processing model {idx + 1} / {n_models}: {model}")
		print(DIVIDER_S2)
		figures_main(
			model_name=model,
			save_path=args.save_path,
			n_samples=args.n_samples,
			force=args.force,
		)

	print(DIVIDER_S1)


if __name__ == "__main__":
	main()

``````{ end_of_file="pattern_lens/figures.py" }

``````{ path="pattern_lens/indexes.py"  }
"""writes indexes to the model directory for the frontend to use or for record keeping"""

import importlib.metadata
import importlib.resources
import inspect
import itertools
import json
from collections.abc import Callable
from pathlib import Path

import pattern_lens
from pattern_lens.attn_figure_funcs import (
	_FIGURE_NAMES_KEY,
	ATTENTION_MATRIX_FIGURE_FUNCS,
)


def generate_prompts_jsonl(model_dir: Path) -> None:
	"""creates a `prompts.jsonl` file with all the prompts in the model directory

	looks in all directories in `{model_dir}/prompts` for a `prompt.json` file
	"""
	prompts: list[dict] = list()
	for prompt_dir in (model_dir / "prompts").iterdir():
		prompt_file: Path = prompt_dir / "prompt.json"
		if prompt_file.exists():
			with open(prompt_file, "r") as f:
				prompt_data: dict = json.load(f)
				prompts.append(prompt_data)

	with open(model_dir / "prompts.jsonl", "w") as f:
		for prompt in prompts:
			f.write(json.dumps(prompt))
			f.write("\n")


def generate_models_jsonl(path: Path) -> None:
	"""creates a `models.jsonl` file with all the models"""
	models: list[dict] = list()
	for model_dir in (path).iterdir():
		model_cfg_path: Path = model_dir / "model_cfg.json"
		if model_cfg_path.exists():
			with open(model_cfg_path, "r") as f:
				model_cfg: dict = json.load(f)
				models.append(model_cfg)

	with open(path / "models.jsonl", "w") as f:
		for model in models:
			f.write(json.dumps(model))
			f.write("\n")


def get_func_metadata(func: Callable) -> list[dict[str, str | None]]:
	"""get metadata for a function

	# Parameters:
	- `func : Callable` which has a `_FIGURE_NAMES_KEY` (by default `_figure_names`) attribute

	# Returns:

	`list[dict[str, str | None]]`
	each dictionary is for a function, containing:

	- `name : str` : the name of the figure
	- `func_name : str`
		the name of the function. if not a multi-figure function, this is identical to `name`
		if it is a multi-figure function, then `name` is `{func_name}.{figure_name}`
	- `doc : str` : the docstring of the function
	- `figure_save_fmt : str | None` : the format of the figure that the function saves, using the `figure_save_fmt` attribute of the function. `None` if the attribute does not exist
	- `source : str | None` : the source file of the function
	- `code : str | None` : the source code of the function, split by line. `None` if the source file cannot be read

	"""
	source_file: str | None = inspect.getsourcefile(func)
	output: dict[str, str | None] = dict(
		func_name=func.__name__,
		doc=func.__doc__,
		figure_save_fmt=getattr(func, "figure_save_fmt", None),
		source=Path(source_file).as_posix() if source_file else None,
	)

	try:
		output["code"] = inspect.getsource(func)
	except OSError:
		output["code"] = None

	fig_names: list[str] | None = getattr(func, _FIGURE_NAMES_KEY, None)
	if fig_names:
		return [
			{
				"name": func_name,
				**output,
			}
			for func_name in fig_names
		]
	else:
		return [
			{
				"name": func.__name__,
				**output,
			},
		]


def generate_functions_jsonl(path: Path) -> None:
	"unions all functions from `figures.jsonl` and `ATTENTION_MATRIX_FIGURE_FUNCS` into the file"
	figures_file: Path = path / "figures.jsonl"
	existing_figures: dict[str, dict] = dict()

	if figures_file.exists():
		with open(figures_file, "r") as f:
			for line in f:
				func_data: dict = json.loads(line)
				existing_figures[func_data["name"]] = func_data

	# Add any new functions from ALL_FUNCTIONS
	new_functions_lst: list[dict] = list(
		itertools.chain.from_iterable(
			get_func_metadata(func) for func in ATTENTION_MATRIX_FIGURE_FUNCS
		),
	)
	new_functions: dict[str, dict] = {func["name"]: func for func in new_functions_lst}

	all_functions: list[dict] = list(
		{
			**existing_figures,
			**new_functions,
		}.values(),
	)

	with open(figures_file, "w") as f:
		for func_meta in sorted(all_functions, key=lambda x: x["name"]):
			json.dump(func_meta, f)
			f.write("\n")


def write_html_index(path: Path) -> None:
	"""writes an index.html file to the path"""
	html_index: str = (
		importlib.resources.files(pattern_lens)
		.joinpath("frontend/index.html")
		.read_text(encoding="utf-8")
	)
	pattern_lens_version: str = importlib.metadata.version("pattern-lens")
	html_index = html_index.replace("$$PATTERN_LENS_VERSION$$", pattern_lens_version)
	with open(path / "index.html", "w", encoding="utf-8") as f:
		f.write(html_index)

``````{ end_of_file="pattern_lens/indexes.py" }

``````{ path="pattern_lens/load_activations.py"  }
"loading activations from .npz on disk. implements some custom Exception classes"

import base64
import hashlib
import json
from pathlib import Path
from typing import Literal, overload

import numpy as np

from pattern_lens.consts import ReturnCache


class GetActivationsError(ValueError):
	"""base class for errors in getting activations"""

	pass


class ActivationsMissingError(GetActivationsError, FileNotFoundError):
	"""error for missing activations -- can't find the activations file"""

	pass


class ActivationsMismatchError(GetActivationsError):
	"""error for mismatched activations -- the prompt text or hash do not match

	raised by `compare_prompt_to_loaded`
	"""

	pass


class InvalidPromptError(GetActivationsError):
	"""error for invalid prompt -- the prompt does not have fields "hash" or "text"

	raised by `augment_prompt_with_hash`
	"""

	pass


def compare_prompt_to_loaded(prompt: dict, prompt_loaded: dict) -> None:
	"""compare a prompt to a loaded prompt, raise an error if they do not match

	# Parameters:
	- `prompt : dict`
	- `prompt_loaded : dict`

	# Returns:
	- `None`

	# Raises:
	- `ActivationsMismatchError` : if the prompt text or hash do not match
	"""
	for key in ("text", "hash"):
		if prompt[key] != prompt_loaded[key]:
			msg = f"Prompt file does not match prompt at key {key}:\n{prompt}\n{prompt_loaded}"
			raise ActivationsMismatchError(
				msg,
			)


def augment_prompt_with_hash(prompt: dict) -> dict:
	"""if a prompt does not have a hash, add one

	not having a "text" field is allowed, but only if "hash" is present

	# Parameters:
	- `prompt : dict`

	# Returns:
	- `dict`

	# Modifies:
	the input `prompt` dictionary, if it does not have a `"hash"` key
	"""
	if "hash" not in prompt:
		if "text" not in prompt:
			msg = f"Prompt does not have 'text' field or 'hash' field: {prompt}"
			raise InvalidPromptError(
				msg,
			)
		prompt_str: str = prompt["text"]
		prompt_hash: str = (
			# we don't need this to be a secure hash
			base64.urlsafe_b64encode(hashlib.md5(prompt_str.encode()).digest())  # noqa: S324
			.decode()
			.rstrip("=")
		)
		prompt.update(hash=prompt_hash)
	return prompt


@overload
def load_activations(
	model_name: str,
	prompt: dict,
	save_path: Path,
	return_fmt: Literal["torch"] = "torch",
) -> "tuple[Path, dict[str, torch.Tensor]]":  # type: ignore[name-defined] # noqa: F821
	...
@overload
def load_activations(
	model_name: str,
	prompt: dict,
	save_path: Path,
	return_fmt: Literal["numpy"] = "numpy",
) -> "tuple[Path, dict[str, np.ndarray]]": ...
def load_activations(
	model_name: str,
	prompt: dict,
	save_path: Path,
	return_fmt: ReturnCache = "torch",
) -> "tuple[Path, dict[str, torch.Tensor]|dict[str, np.ndarray]]":  # type: ignore[name-defined] # noqa: F821
	"""load activations for a prompt and model, from an npz file

	# Parameters:
	- `model_name : str`
	- `prompt : dict`
	- `save_path : Path`
	- `return_fmt : Literal["torch", "numpy"]`
		(defaults to `"torch"`)

	# Returns:
	- `tuple[Path, dict[str, torch.Tensor]|dict[str, np.ndarray]]`
		the path to the activations file and the activations as a dictionary
		of numpy arrays or torch tensors, depending on `return_fmt`

	# Raises:
	- `ActivationsMissingError` : if the activations file is missing
	- `ValueError` : if `return_fmt` is not `"torch"` or `"numpy"`
	"""
	if return_fmt not in ("torch", "numpy"):
		msg = f"Invalid return_fmt: {return_fmt}, expected 'torch' or 'numpy'"
		raise ValueError(
			msg,
		)
	if return_fmt == "torch":
		import torch

	augment_prompt_with_hash(prompt)

	prompt_dir: Path = save_path / model_name / "prompts" / prompt["hash"]
	prompt_file: Path = prompt_dir / "prompt.json"
	if not prompt_file.exists():
		msg = f"Prompt file {prompt_file} does not exist"
		raise ActivationsMissingError(msg)
	with open(prompt_dir / "prompt.json", "r") as f:
		prompt_loaded: dict = json.load(f)
		compare_prompt_to_loaded(prompt, prompt_loaded)

	activations_path: Path = prompt_dir / "activations.npz"

	cache: dict

	with np.load(activations_path) as npz_data:
		if return_fmt == "numpy":
			cache = dict(npz_data.items())
		elif return_fmt == "torch":
			cache = {k: torch.from_numpy(v) for k, v in npz_data.items()}

	return activations_path, cache


# def load_activations_stacked()

``````{ end_of_file="pattern_lens/load_activations.py" }

``````{ path="pattern_lens/prompts.py"  }
"implements `load_text_data` for loading prompts"

import json
import random
from pathlib import Path


def load_text_data(
	fname: Path,
	min_chars: int | None = None,
	max_chars: int | None = None,
	shuffle: bool = False,
) -> list[dict]:
	"""given `fname`, the path to a jsonl file, split prompts up into more reasonable sizes

	# Parameters:
	- `fname : Path`
		jsonl file with prompts. Expects a list of dicts with a "text" key
	- `min_chars : int | None`
		(defaults to `None`)
	- `max_chars : int | None`
		(defaults to `None`)
	- `shuffle : bool`
		(defaults to `False`)

	# Returns:
	- `list[dict]`
		processed list of prompts. Each prompt has a "text" key w/ a string value and some metadata.
		this is not guaranteed to be the same length as the input list!
	"""
	# read raw data
	with open(fname, "r") as f:
		data_raw: list[dict] = [json.loads(d) for d in f.readlines()]

	# add fname metadata
	for d in data_raw:
		d["source_fname"] = fname.as_posix()

	# trim too-short samples
	if min_chars is not None:
		data_raw = list(
			filter(
				lambda x: len(x["text"]) >= min_chars,
				data_raw,
			),
		)

	# split up too-long samples
	if max_chars is not None:
		data_new: list[dict] = []
		for d in data_raw:
			d_text: str = d["text"]
			while len(d_text) > max_chars:
				data_new.append(
					{
						**d,
						"text": d_text[:max_chars],
					},
				)
				d_text = d_text[max_chars:]
			data_new.append(
				{
					**d,
					"text": d_text,
				},
			)
		data_raw = data_new

	# trim too-short samples again
	if min_chars is not None:
		data_raw = list(
			filter(
				lambda x: len(x["text"]) >= min_chars,
				data_raw,
			),
		)

	# shuffle
	if shuffle:
		random.shuffle(data_raw)

	return data_raw

``````{ end_of_file="pattern_lens/prompts.py" }

``````{ path="pattern_lens/py.typed"  }

``````{ end_of_file="pattern_lens/py.typed" }

``````{ path="pattern_lens/server.py"  }
"""cli for starting the server to show the web ui.

can also run with --rewrite-index to update the index.html file.
this is useful for working on the ui.
"""

import argparse
import http.server
import os
import socketserver
import sys
from pathlib import Path

from pattern_lens.indexes import write_html_index


def main(path: str | None = None, port: int = 8000) -> None:
	"move to the given path and start the server"
	if path is not None:
		os.chdir(path)
	try:
		with socketserver.TCPServer(
			("", port),
			http.server.SimpleHTTPRequestHandler,
		) as httpd:
			print(f"Serving at http://localhost:{port}")
			httpd.serve_forever()
	except KeyboardInterrupt:
		print("Server stopped")
		sys.exit(0)


if __name__ == "__main__":
	arg_parser: argparse.ArgumentParser = argparse.ArgumentParser()
	arg_parser.add_argument(
		"--path",
		type=str,
		required=False,
		help="The path to serve, defaults to the current directory",
		default=None,
	)
	arg_parser.add_argument(
		"--port",
		type=int,
		required=False,
		help="The port to serve on, defaults to 8000",
		default=8000,
	)
	arg_parser.add_argument(
		"--rewrite-index",
		action="store_true",
		help="Whether to write the latest index.html file",
	)
	args: argparse.Namespace = arg_parser.parse_args()

	if args.rewrite_index:
		write_html_index(path=Path(args.path))

	main(path=args.path, port=args.port)

``````{ end_of_file="pattern_lens/server.py" }

``````{ path="tests/integration/test_clis.py"  }
import sys
from unittest import mock

import pytest

from pattern_lens.activations import main as activations_main
from pattern_lens.figures import main as figures_main
from pattern_lens.server import main as server_main


def test_activations_cli():
	"""Test the activations command line interface."""
	test_args = [
		"pattern_lens.activations",
		"--model",
		"gpt2",
		"--prompts",
		"test_prompts.jsonl",
		"--save-path",
		"test_data",
		"--min-chars",
		"100",
		"--max-chars",
		"1000",
		"--n-samples",
		"5",
		"--force",
		"--raw-prompts",
		"--shuffle",
		"--device",
		"cpu",
	]

	with (
		mock.patch.object(sys, "argv", test_args),
		mock.patch(
			"pattern_lens.activations.activations_main",
		) as mock_activations_main,
	):
		# Mock SpinnerContext to prevent actual spinner during tests
		with mock.patch("pattern_lens.activations.SpinnerContext"):
			activations_main()

		# Check that activations_main was called with the right arguments
		mock_activations_main.assert_called_once()
		args, kwargs = mock_activations_main.call_args

		assert kwargs["model_name"] == "gpt2"
		assert kwargs["prompts_path"] == "test_prompts.jsonl"
		assert kwargs["save_path"] == "test_data"
		assert kwargs["min_chars"] == 100
		assert kwargs["max_chars"] == 1000
		assert kwargs["n_samples"] == 5
		assert kwargs["force"] is True
		assert kwargs["raw_prompts"] is True
		assert kwargs["shuffle"] is True
		assert kwargs["device"] == "cpu"


def test_figures_cli():
	"""Test the figures command line interface."""
	test_args = [
		"pattern_lens.figures",
		"--model",
		"gpt2",
		"--save-path",
		"test_data",
		"--n-samples",
		"5",
		"--force",
		"True",
	]

	with (
		mock.patch.object(sys, "argv", test_args),
		mock.patch("pattern_lens.figures.figures_main") as mock_figures_main,
	):
		# Mock SpinnerContext to prevent actual spinner during tests
		with mock.patch("pattern_lens.figures.SpinnerContext"):
			figures_main()

		# Check that figures_main was called with the right arguments
		mock_figures_main.assert_called_once()
		args, kwargs = mock_figures_main.call_args

		assert kwargs["model_name"] == "gpt2"
		assert kwargs["save_path"] == "test_data"
		assert kwargs["n_samples"] == 5
		assert kwargs["force"] is True


def test_figures_cli_with_multiple_models():
	"""Test the figures command line interface with multiple models."""
	test_args = [
		"pattern_lens.figures",
		"--model",
		"gpt2,pythia-70m",
		"--save-path",
		"test_data",
	]

	with (
		mock.patch.object(sys, "argv", test_args),
		mock.patch("pattern_lens.figures.figures_main") as mock_figures_main,
	):
		# Mock SpinnerContext to prevent actual spinner during tests
		with mock.patch("pattern_lens.figures.SpinnerContext"):
			figures_main()

		# Check that figures_main was called for each model
		assert mock_figures_main.call_count == 2

		# First call should be for gpt2
		args1, kwargs1 = mock_figures_main.call_args_list[0]
		assert kwargs1["model_name"] == "gpt2"

		# Second call should be for pythia-70m
		args2, kwargs2 = mock_figures_main.call_args_list[1]
		assert kwargs2["model_name"] == "pythia-70m"


def test_server_cli():
	"""Test the server command line interface."""
	test_args = [
		"pattern_lens.server",
		"--port",
		"8080",
		# "--path",
		# "test_path",
		"--rewrite-index",
	]

	with (
		mock.patch.object(sys, "argv", test_args),
		mock.patch("socketserver.TCPServer") as mock_server,
		# mock.patch("pattern_lens.server.write_html_index") as mock_write_html,
		# mock.patch("os.chdir") as mock_chdir,
	):
		# Set up the mock server to raise KeyboardInterrupt when serve_forever is called
		mock_server_instance = mock_server.return_value.__enter__.return_value
		mock_server_instance.serve_forever.side_effect = KeyboardInterrupt()

		# Call server_main
		with pytest.raises(SystemExit):
			server_main()

		# TODO: make these mock checks work -- I have no idea how to use mock properly
		# # Check that write_html_index was called
		# mock_write_html.assert_called_once()

		# # Check that chdir was called with the right path
		# mock_chdir.assert_called_once_with("test_path")

		# Check that server was started with the right port
		# mock_server.assert_called_once_with(("", 8080), mock.ANY)

		# Check that serve_forever was called
		# mock_server_instance.serve_forever.assert_called_once()

``````{ end_of_file="tests/integration/test_clis.py" }

``````{ path="tests/integration/test_pipeline.py"  }
import pytest

from pattern_lens.activations import activations_main
from pattern_lens.figures import figures_main

SAVE_PATH_BASE: str = "tests/_temp/pipeline"
PROMPTS_PATH: str = "data/pile_100.jsonl"
N_SAMPLES: int = 3
MIN_CHARS: int = 32
MAX_CHARS: int = 128
FORCE: bool = True
NO_INDEX_HTML: bool = False
FIGURES_PARALLEL: bool = False


@pytest.mark.parametrize(
	"model_name",
	["pythia-14m", "tiny-stories-1M"],
)
def test_pipeline(model_name: str):
	activations_main(
		model_name=model_name,
		save_path=SAVE_PATH_BASE,
		prompts_path=PROMPTS_PATH,
		raw_prompts=True,
		min_chars=MIN_CHARS,
		max_chars=MAX_CHARS,
		force=FORCE,
		n_samples=N_SAMPLES,
		no_index_html=NO_INDEX_HTML,
	)
	figures_main(
		model_name=model_name,
		save_path=SAVE_PATH_BASE,
		n_samples=N_SAMPLES,
		force=FORCE,
		parallel=FIGURES_PARALLEL,
	)

``````{ end_of_file="tests/integration/test_pipeline.py" }

``````{ path="tests/unit/test_activations.py"  }
from pathlib import Path
from unittest import mock

import numpy as np
import torch
from transformer_lens import HookedTransformer  # type: ignore[import-untyped]

from pattern_lens.activations import compute_activations, get_activations
from pattern_lens.load_activations import ActivationsMissingError

TEMP_DIR: Path = Path("tests/_temp")


class MockHookedTransformer:
	"""Mock of HookedTransformer for testing compute_activations and get_activations."""

	def __init__(self, model_name="test-model", n_layers=2, n_heads=2):
		self.model_name = model_name
		self.cfg = mock.MagicMock()
		self.cfg.n_layers = n_layers
		self.cfg.n_heads = n_heads
		self.tokenizer = mock.MagicMock()
		self.tokenizer.tokenize.return_value = ["test", "tokens"]

	def eval(self):
		return self

	def run_with_cache(self, prompt_str, names_filter=None, return_type=None):  # noqa: ARG002
		"""Mock run_with_cache to return fake attention patterns."""
		# Create a mock activation cache with appropriately shaped attention patterns
		cache: dict[str, torch.Tensor] = {}
		for i in range(self.cfg.n_layers):
			# [1, n_heads, n_ctx, n_ctx] tensor, where n_ctx is len(prompt_str)
			n_ctx: int = len(prompt_str)
			attn_pattern: torch.Tensor = torch.rand(
				1,
				self.cfg.n_heads,
				n_ctx,
				n_ctx,
			).float()
			cache[f"blocks.{i}.attn.hook_pattern"] = attn_pattern

		return None, cache


def test_compute_activations_stack_heads():
	"""Test compute_activations with stack_heads=True."""
	# Setup
	temp_dir: Path = TEMP_DIR / "test_compute_activations_stack_heads"
	model: HookedTransformer = HookedTransformer.from_pretrained("pythia-14m")
	prompt: dict[str, str] = {"text": "test prompt", "hash": "testhash123"}

	# Test with return_cache=None
	path, result = compute_activations(
		prompt=prompt,
		model=model,
		save_path=temp_dir,
		return_cache=None,
		stack_heads=True,
	)

	# Check return values
	assert (
		path
		== temp_dir
		/ model.cfg.model_name
		/ "prompts"
		/ prompt["hash"]
		/ "activations-blocks.-.attn.hook_pattern.npy"
	)
	assert result is None

	# Check the file was created and has correct shape
	assert path.exists()
	loaded = np.load(path)
	assert loaded.shape[:3] == (
		1,
		model.cfg.n_layers,
		model.cfg.n_heads,
	)
	assert loaded.shape[3] == loaded.shape[4]

	# Test with return_cache="numpy"
	path, result = compute_activations(
		prompt=prompt,
		model=model,
		save_path=temp_dir,
		return_cache="numpy",
		stack_heads=True,
	)

	# Check return values
	assert isinstance(result, np.ndarray)
	assert result.shape[:3] == (
		1,
		model.cfg.n_layers,
		model.cfg.n_heads,
	)
	assert result.shape[3] == result.shape[4]


def test_compute_activations_no_stack():
	"""Test compute_activations with stack_heads=False."""
	# Setup
	temp_dir = TEMP_DIR / "test_compute_activations_no_stack"
	model = HookedTransformer.from_pretrained("pythia-14m")
	prompt = {"text": "test prompt", "hash": "testhash123"}

	# Test with return_cache="numpy"
	path, result = compute_activations(
		prompt=prompt,
		model=model,
		save_path=temp_dir,
		return_cache="numpy",
		stack_heads=False,
	)

	# Check return values
	assert (
		path
		== temp_dir
		/ model.cfg.model_name
		/ "prompts"
		/ prompt["hash"]
		/ "activations.npz"
	)
	assert isinstance(result, dict)

	# Check that the keys have the expected form and values have the right shape
	for i in range(model.cfg.n_layers):
		key = f"blocks.{i}.attn.hook_pattern"
		assert key in result
		assert result[key].shape[:2] == (
			1,
			model.cfg.n_heads,
		)
		assert result[key].shape[2] == result[key].shape[3]


def test_get_activations_missing():
	"""Test get_activations when activations don't exist."""
	temp_dir = TEMP_DIR / "test_get_activations_missing"
	prompt = {"text": "test prompt", "hash": "testhash123"}

	# Patch the load_activations and compute_activations functions
	with (
		mock.patch("pattern_lens.activations.load_activations") as mock_load,
		mock.patch("pattern_lens.activations.compute_activations") as mock_compute,
	):
		# Set up load_activations to fail
		mock_load.side_effect = ActivationsMissingError("Not found")

		# Set up mock model and compute_activations
		model = HookedTransformer.from_pretrained("pythia-14m")
		mock_compute.return_value = (Path("mock/path"), {"mock": "cache"})

		# Call get_activations
		path, cache = get_activations(
			prompt=prompt,
			model=model,
			save_path=temp_dir,
			return_cache="numpy",
		)

		# Check that compute_activations was called with the right arguments
		mock_compute.assert_called_once()
		args, kwargs = mock_compute.call_args
		assert kwargs["prompt"] == prompt
		assert kwargs["save_path"] == temp_dir
		assert kwargs["return_cache"] == "numpy"

``````{ end_of_file="tests/unit/test_activations.py" }

``````{ path="tests/unit/test_activations_return.py"  }
# tests/unit/test_activations_return.py
from pathlib import Path
from unittest import mock

import pytest
import torch
from transformer_lens import HookedTransformer  # type: ignore[import-untyped]

from pattern_lens.activations import compute_activations, get_activations

TEMP_DIR: Path = Path("tests/_temp")


class MockHookedTransformer:
	"""Mock of HookedTransformer for testing compute_activations and get_activations."""

	def __init__(self, model_name="test-model", n_layers=2, n_heads=2):
		self.model_name = model_name
		self.cfg = mock.MagicMock()
		self.cfg.n_layers = n_layers
		self.cfg.n_heads = n_heads
		self.tokenizer = mock.MagicMock()
		self.tokenizer.tokenize.return_value = ["test", "tokens"]

	def eval(self):
		return self

	def run_with_cache(self, prompt_str, names_filter=None, return_type=None):  # noqa: ARG002
		"""Mock run_with_cache to return fake attention patterns."""
		# Create a mock activation cache with appropriately shaped attention patterns
		cache = {}
		for i in range(self.cfg.n_layers):
			# [1, n_heads, n_ctx, n_ctx] tensor, where n_ctx is len(prompt_str)
			n_ctx = len(prompt_str)
			attn_pattern = torch.rand(
				1,
				self.cfg.n_heads,
				n_ctx,
				n_ctx,
			).float()
			cache[f"blocks.{i}.attn.hook_pattern"] = attn_pattern

		return None, cache


def test_compute_activations_torch_return():
	"""Test compute_activations with return_cache="torch"."""
	# Setup
	temp_dir = TEMP_DIR / "test_compute_activations_torch_return"
	model = MockHookedTransformer(n_layers=3, n_heads=4)
	prompt = {"text": "test prompt", "hash": "testhash123"}

	# Test with stack_heads=True
	path, result = compute_activations(
		prompt=prompt,
		model=model,
		save_path=temp_dir,
		return_cache="torch",
		stack_heads=True,
	)

	# Check return values
	assert isinstance(result, torch.Tensor)
	assert result.shape == (
		1,
		model.cfg.n_layers,
		model.cfg.n_heads,
		len(prompt["text"]),
		len(prompt["text"]),
	)

	# Test with stack_heads=False
	path, result = compute_activations(
		prompt=prompt,
		model=model,
		save_path=temp_dir,
		return_cache="torch",
		stack_heads=False,
	)

	# Check return values
	assert isinstance(result, dict)
	for i in range(model.cfg.n_layers):
		key = f"blocks.{i}.attn.hook_pattern"
		assert key in result
		assert isinstance(result[key], torch.Tensor)


def test_compute_activations_invalid_return():
	"""Test compute_activations with an invalid return_cache value."""
	# Setup
	temp_dir = TEMP_DIR / "test_compute_activations_invalid_return"
	model = HookedTransformer.from_pretrained("pythia-14m")
	prompt = {"text": "test prompt", "hash": "testhash123"}

	# Test with an invalid return_cache value
	with pytest.raises(ValueError, match="invalid return_cache"):
		compute_activations(
			prompt=prompt,
			model=model,
			save_path=temp_dir,
			# intentionally invalid
			return_cache="invalid",  # type: ignore[call-overload]
			stack_heads=True,
		)


def test_get_activations_torch_return():
	"""Test get_activations with return_cache="torch" and mocked load_activations."""
	temp_dir = TEMP_DIR / "test_get_activations_torch_return"
	prompt = {"text": "test prompt", "hash": "testhash123"}
	model = MockHookedTransformer(model_name="test-model")

	# Create a mock for load_activations that returns torch tensors
	with mock.patch("pattern_lens.activations.load_activations") as mock_load:
		mock_cache = {
			"blocks.0.attn.hook_pattern": torch.rand(
				1,
				2,
				len(prompt["text"]),
				len(prompt["text"]),
			),
			"blocks.1.attn.hook_pattern": torch.rand(
				1,
				2,
				len(prompt["text"]),
				len(prompt["text"]),
			),
		}
		mock_load.return_value = (Path("mock/path"), mock_cache)

		# Call get_activations with torch return format
		path, cache = get_activations(
			prompt=prompt,
			model=model,
			save_path=temp_dir,
			return_cache="torch",
		)

		# Check that we got torch tensors back
		assert isinstance(cache, dict)
		for key, value in cache.items():
			assert isinstance(key, str)
			assert isinstance(value, torch.Tensor)


def test_get_activations_none_return():
	"""Test get_activations with return_cache=None."""
	temp_dir = TEMP_DIR / "test_get_activations_none_return"
	prompt = {"text": "test prompt", "hash": "testhash123"}
	model = MockHookedTransformer(model_name="test-model")

	# Create a mock for load_activations that returns a path but no cache
	with mock.patch("pattern_lens.activations.load_activations") as mock_load:
		mock_path = Path("mock/path")
		mock_load.return_value = (mock_path, {})  # Cache will be ignored

		# Call get_activations with None return format
		path, cache = get_activations(
			prompt=prompt,
			model=model,
			save_path=temp_dir,
			return_cache=None,
		)

		# Check that we got the path but no cache
		assert path == mock_path
		assert cache is None

``````{ end_of_file="tests/unit/test_activations_return.py" }

``````{ path="tests/unit/test_figure_util.py"  }
import base64
import gzip
import io
import re
from pathlib import Path

import jaxtyping
import matplotlib.pyplot as plt
import numpy as np
import pytest
from PIL import Image

from pattern_lens.figure_util import (
	MATPLOTLIB_FIGURE_FMT,
	matplotlib_figure_saver,
	matrix_as_svg,
	save_matrix_wrapper,
)

TEMP_DIR: Path = Path("tests/_temp")


def test_matplotlib_figure_saver():
	TEMP_DIR.mkdir(parents=True, exist_ok=True)

	@matplotlib_figure_saver
	def plot_matrix(attn_matrix, ax):
		ax.matshow(attn_matrix, cmap="viridis")
		ax.axis("off")

	attn_matrix = np.random.rand(10, 10).astype(np.float32)
	plot_matrix(attn_matrix, TEMP_DIR)

	saved_file = TEMP_DIR / f"plot_matrix.{MATPLOTLIB_FIGURE_FMT}"
	assert saved_file.exists(), "Matplotlib figure file was not saved"


def test_matplotlib_figure_saver_exception():
	TEMP_DIR.mkdir(parents=True, exist_ok=True)

	@matplotlib_figure_saver
	def faulty_plot(attn_matrix, ax):  # noqa: ARG001
		raise ValueError("Intentional failure for testing")

	attn_matrix = np.random.rand(10, 10).astype(np.float32)
	with pytest.raises(ValueError, match="Intentional failure for testing"):
		faulty_plot(attn_matrix, TEMP_DIR)


def test_matrix_as_svg_normalization():
	matrix = np.array([[2, 4], [6, 8]], dtype=np.float32)
	svg_content = matrix_as_svg(matrix, normalize=True)
	assert "image href=" in svg_content, "SVG content is malformed"
	assert "data:image/png;base64," in svg_content, "Base64 encoding is missing"


def test_matrix_as_svg_no_normalization():
	matrix = np.array([[0.1, 0.4], [0.6, 0.9]], dtype=np.float32)
	svg_content = matrix_as_svg(matrix, normalize=False)
	assert "image href=" in svg_content, "SVG content is malformed"
	assert "data:image/png;base64," in svg_content, "Base64 encoding is missing"


def test_matrix_as_svg_invalid_range():
	matrix = np.array([[-1, 2], [3, 4]], dtype=np.float32)
	with pytest.raises(
		AssertionError,
		match="Matrix values must be in range \\[0, 1\\], or normalize must be True",
	):
		matrix_as_svg(matrix, normalize=False)


def test_matrix_as_svg_invalid_dims():
	matrix = np.random.rand(5, 5, 5).astype(np.float32)
	with pytest.raises((AssertionError, jaxtyping.TypeCheckError)):
		matrix_as_svg(matrix, normalize=True)


def test_matrix_as_svg_invalid_cmap_fixed():
	matrix = np.array([[0.1, 0.4], [0.6, 0.9]], dtype=np.float32)
	with pytest.raises(KeyError, match="'invalid_cmap' is not a known colormap name"):
		matrix_as_svg(matrix, cmap="invalid_cmap")


# Test with no arguments
def test_save_matrix_as_svgz_wrapper_no_args():
	TEMP_DIR.mkdir(parents=True, exist_ok=True)

	@save_matrix_wrapper(fmt="svgz")
	def no_op(matrix):
		return matrix

	test_matrix = np.array([[0.1, 0.2], [0.3, 0.4]], dtype=np.float32)
	no_op(test_matrix, TEMP_DIR)

	saved_file = TEMP_DIR / "no_op.svgz"
	assert saved_file.exists(), "SVGZ file was not saved in no-args case"


# Test with keyword-only arguments
def test_save_matrix_as_svgz_wrapper_with_args():
	TEMP_DIR.mkdir(parents=True, exist_ok=True)

	@save_matrix_wrapper(normalize=True, cmap="plasma")
	def scale_matrix(matrix):
		return matrix * 2

	test_matrix = np.array([[0.5, 0.6], [0.7, 0.8]], dtype=np.float32)
	scale_matrix(test_matrix, TEMP_DIR)

	saved_file = TEMP_DIR / "scale_matrix.svgz"
	assert saved_file.exists(), "SVGZ file was not saved with keyword-only arguments"


# Test exception handling
def test_save_matrix_as_svgz_wrapper_exceptions():
	TEMP_DIR.mkdir(parents=True, exist_ok=True)

	@save_matrix_wrapper(normalize=False)
	def invalid_range(matrix):
		return matrix * 2

	test_matrix = np.array([[2, 3], [4, 5]], dtype=np.float32)
	with pytest.raises(
		AssertionError,
		match=r"Matrix values must be in range \[0, 1\], or normalize must be True.*",
	):
		invalid_range(test_matrix, TEMP_DIR)


# Test keyword-only arguments enforced
def test_save_matrix_as_svgz_wrapper_keyword_only():
	TEMP_DIR.mkdir(parents=True, exist_ok=True)

	@save_matrix_wrapper(normalize=True, cmap="plasma")
	def scale_matrix(matrix):
		return matrix * 2

	test_matrix = np.array([[0.5, 0.6], [0.7, 0.8]], dtype=np.float32)
	scale_matrix(test_matrix, TEMP_DIR)

	saved_file = TEMP_DIR / "scale_matrix.svgz"
	assert saved_file.exists(), "SVGZ file was not saved with keyword-only arguments"


# Test multiple calls to the decorator
def test_save_matrix_as_svgz_wrapper_multiple():
	TEMP_DIR.mkdir(parents=True, exist_ok=True)

	@save_matrix_wrapper(normalize=True)
	def scale_by_factor(matrix):
		return matrix * 3

	matrix_1 = np.array([[0.1, 0.5], [0.7, 0.9]], dtype=np.float32)
	matrix_2 = np.array([[0.2, 0.6], [0.8, 1.0]], dtype=np.float32)

	scale_by_factor(matrix_1, TEMP_DIR)
	scale_by_factor(matrix_2, TEMP_DIR)

	# Check the saved files
	saved_file = TEMP_DIR / "scale_by_factor.svgz"
	assert saved_file.exists(), "SVGZ file was not saved for multiple calls"


# Validate behavior when normalize is False and values are in range
def test_save_matrix_as_svgz_wrapper_no_normalization():
	TEMP_DIR.mkdir(parents=True, exist_ok=True)

	@save_matrix_wrapper(normalize=False)
	def pass_through(matrix):
		return matrix

	test_matrix = np.array([[0.1, 0.2], [0.3, 0.4]], dtype=np.float32)
	pass_through(test_matrix, TEMP_DIR)

	saved_file = TEMP_DIR / "pass_through.svgz"
	assert saved_file.exists(), (
		"SVGZ file was not saved when normalization was not applied"
	)


# Test with a complex matrix
def test_save_matrix_as_svgz_wrapper_complex_matrix():
	TEMP_DIR.mkdir(parents=True, exist_ok=True)

	@save_matrix_wrapper(normalize=True, cmap="viridis")
	def complex_processing(matrix):
		return np.sin(matrix)

	test_matrix = np.linspace(0, np.pi, 16).reshape(4, 4).astype(np.float32)
	complex_processing(test_matrix, TEMP_DIR)

	saved_file = TEMP_DIR / "complex_processing.svgz"
	assert saved_file.exists(), "SVGZ file was not saved for complex matrix processing"


def test_matrix_as_svg_dimensions():
	# Test different matrix shapes
	matrices = [
		np.random.rand(5, 10),  # Non-square
		np.random.rand(3, 3),  # Small square
		np.random.rand(100, 50),  # Large non-square
	]

	for matrix in matrices:
		m, n = matrix.shape
		svg_content = matrix_as_svg(matrix, normalize=True)
		assert f'width="{m}"' in svg_content
		assert f'height="{n}"' in svg_content
		assert f'viewBox="0 0 {m} {n}"' in svg_content


def test_save_matrix_as_svgz_wrapper_content():
	TEMP_DIR.mkdir(parents=True, exist_ok=True)

	@save_matrix_wrapper(normalize=True)
	def identity(matrix):
		return matrix

	test_matrix = np.array([[0.1, 0.2], [0.3, 0.4]], dtype=np.float32)
	identity(test_matrix, TEMP_DIR)

	saved_file = TEMP_DIR / "identity.svgz"
	with gzip.open(saved_file, "rt") as f:
		content = f.read()
		assert "svg" in content
		assert "image href=" in content
		assert "base64" in content


@pytest.mark.parametrize("fmt", ["png", "pdf", "svg"])
def test_matplotlib_figure_saver_formats(fmt):
	TEMP_DIR.mkdir(parents=True, exist_ok=True)

	# TYPING: error: Too few arguments  [call-arg]
	@matplotlib_figure_saver(None, fmt=fmt)  # type: ignore[call-arg]
	def plot_matrix(attn_matrix, ax):
		ax.matshow(attn_matrix)
		ax.axis("off")

	matrix = np.random.rand(5, 5)
	plot_matrix(matrix, TEMP_DIR)
	saved_file = TEMP_DIR / f"plot_matrix.{fmt}"
	assert saved_file.exists(), f"File not saved for format {fmt}"


def test_matrix_as_svg_empty():
	empty_matrix = np.array([[]], dtype=np.float32).reshape(0, 0)
	with pytest.raises(AssertionError, match="Matrix cannot be empty"):
		matrix_as_svg(empty_matrix)


def test_matplotlib_figure_saver_cleanup():
	TEMP_DIR.mkdir(parents=True, exist_ok=True)
	initial_figures = len(plt.get_fignums())

	@matplotlib_figure_saver
	def plot_matrix(attn_matrix, ax):
		ax.matshow(attn_matrix)

	matrix = np.random.rand(5, 5)
	plot_matrix(matrix, TEMP_DIR)

	# Check that no figure objects remain
	assert len(plt.get_fignums()) == initial_figures, "Figure not properly cleaned up"


def test_matrix_as_svg_non_numeric():
	matrix = np.array([["a", "b"], ["c", "d"]])
	with pytest.raises(TypeError):
		matrix_as_svg(matrix)


def test_matrix_as_svg_format():
	# create a small 2x2 matrix
	matrix = np.array([[0.0, 0.5], [1.0, 0.75]], dtype=float)

	svg_str = matrix_as_svg(matrix)

	# ensure it's got the correct SVG wrapper
	assert svg_str.startswith("<svg"), "SVG should start with <svg>"
	assert svg_str.endswith("</svg>"), "SVG should end with </svg>"

	# find the embedded base64 image data
	match = re.search(r'data:image/png;base64,([^"]+)', svg_str)
	assert match, "Expected an embedded PNG in data URI format"

	embedded_data = match.group(1)
	png_data = base64.b64decode(embedded_data)

	Image.open(io.BytesIO(png_data))

``````{ end_of_file="tests/unit/test_figure_util.py" }

``````{ path="tests/unit/test_figures.py"  }
# tests/unit/test_figures.py
from pathlib import Path
from unittest import mock

import numpy as np

from pattern_lens.figure_util import save_matrix_wrapper
from pattern_lens.figures import compute_and_save_figures, process_single_head

TEMP_DIR: Path = Path("tests/_temp")


def test_process_single_head():
	"""Test processing a single head's attention pattern."""
	# Setup
	temp_dir = TEMP_DIR / "test_process_single_head"
	head_dir = temp_dir / "L0" / "H0"
	head_dir.mkdir(parents=True)

	# Create a simple test attention matrix
	attn_pattern = np.random.rand(10, 10).astype(np.float32)

	# Create a simple test figure function
	@save_matrix_wrapper(fmt="svg")
	def test_fig_func(matrix):
		return matrix

	# Patch ATTENTION_MATRIX_FIGURE_FUNCS to use our test function
	with mock.patch(
		"pattern_lens.figures.ATTENTION_MATRIX_FIGURE_FUNCS",
		[test_fig_func],
	):
		# Call process_single_head
		result = process_single_head(
			layer_idx=0,
			head_idx=0,
			attn_pattern=attn_pattern,
			save_dir=head_dir,
			force_overwrite=True,
		)

		# Check that our function was called and succeeded
		assert "test_fig_func" in result
		assert result["test_fig_func"] is True

		# Check that the figure file was created
		assert (head_dir / "test_fig_func.svg").exists()


def test_process_single_head_error_handling():
	"""Test that process_single_head properly handles errors in figure functions."""
	# Setup
	temp_dir = TEMP_DIR / "test_process_single_head_error_handling"
	head_dir = temp_dir / "L0" / "H0"
	head_dir.mkdir(parents=True)

	# Create a simple test attention matrix
	attn_pattern = np.random.rand(10, 10).astype(np.float32)

	# Create a test figure function that raises an exception
	def error_fig_func(matrix, save_dir):  # noqa: ARG001
		raise ValueError("Test error")

	# Patch ATTENTION_MATRIX_FIGURE_FUNCS to use our test function
	with mock.patch(
		"pattern_lens.figures.ATTENTION_MATRIX_FIGURE_FUNCS",
		[error_fig_func],
	):
		# Call process_single_head
		result = process_single_head(
			layer_idx=0,
			head_idx=0,
			attn_pattern=attn_pattern,
			save_dir=head_dir,
			force_overwrite=True,
		)

		# Check that our function was called and failed
		assert "error_fig_func" in result
		assert isinstance(result["error_fig_func"], ValueError)

		# Check that an error file was created
		assert (head_dir / "error_fig_func.error.txt").exists()


def test_compute_and_save_figures():
	"""Test compute_and_save_figures with a mock model config and cache."""
	# Setup
	temp_dir = TEMP_DIR / "test_compute_and_save_figures"
	prompt_dir = temp_dir / "test-model" / "prompts" / "test-hash"
	prompt_dir.mkdir(parents=True)

	# Create a mock model config
	class MockConfig:
		def __init__(self):
			self.n_layers = 2
			self.n_heads = 2
			self.model_name = "test-model"

	# Create a simple test attention matrices dict
	cache_dict = {
		"blocks.0.attn.hook_pattern": np.random.rand(1, 2, 5, 5).astype(np.float32),
		"blocks.1.attn.hook_pattern": np.random.rand(1, 2, 5, 5).astype(np.float32),
	}

	# Create a simple test figure function
	@save_matrix_wrapper(fmt="png")
	def test_fig_func(matrix):
		return matrix

	# Patch ATTENTION_MATRIX_FIGURE_FUNCS and process_single_head
	with (
		mock.patch(
			"pattern_lens.figures.ATTENTION_MATRIX_FIGURE_FUNCS",
			[test_fig_func],
		),
		mock.patch("pattern_lens.figures.process_single_head") as mock_process_head,
		mock.patch("pattern_lens.figures.generate_prompts_jsonl") as mock_gen_prompts,
	):
		mock_process_head.return_value = {"test_fig_func": True}

		# Call compute_and_save_figures with dict cache
		compute_and_save_figures(
			model_cfg=MockConfig(),
			activations_path=prompt_dir / "activations.npz",
			cache=cache_dict,
			save_path=temp_dir,
			force_overwrite=True,
		)

		# Check that process_single_head was called for each layer and head
		assert mock_process_head.call_count == 4  # 2 layers * 2 heads

		# Check that generate_prompts_jsonl was called
		mock_gen_prompts.assert_called_once_with(temp_dir / "test-model")

		# Reset mocks and test with stacked array
		mock_process_head.reset_mock()
		mock_gen_prompts.reset_mock()

		# Create a stacked array of shape [n_layers, n_heads, n_ctx, n_ctx]
		cache_array = np.random.rand(2, 2, 5, 5).astype(np.float32)

		# Call compute_and_save_figures with array cache
		compute_and_save_figures(
			model_cfg=MockConfig(),
			activations_path=prompt_dir / "activations.npy",
			cache=cache_array,
			save_path=temp_dir,
			force_overwrite=True,
		)

		# Check that process_single_head was called for each layer and head
		assert mock_process_head.call_count == 4  # 2 layers * 2 heads

		# Check that generate_prompts_jsonl was called
		mock_gen_prompts.assert_called_once_with(temp_dir / "test-model")

``````{ end_of_file="tests/unit/test_figures.py" }

``````{ path="tests/unit/test_load_activations.py"  }
# tests/unit/test_load_activations.py
import json
from pathlib import Path
from unittest import mock

import numpy as np
import pytest

from pattern_lens.load_activations import (
	ActivationsMismatchError,
	ActivationsMissingError,
	InvalidPromptError,
	augment_prompt_with_hash,
	load_activations,
)

TEMP_DIR: Path = Path("tests/_temp")


def test_augment_prompt_with_hash():
	"""Test adding hash to prompt."""
	# Test with a prompt that doesn't have a hash
	prompt_no_hash = {"text": "test prompt"}
	result = augment_prompt_with_hash(prompt_no_hash)

	# Check that the hash was added and is deterministic
	assert "hash" in result
	assert isinstance(result["hash"], str)

	# Save the hash for comparison
	first_hash = result["hash"]

	# Test that calling it again doesn't change the hash
	result = augment_prompt_with_hash(prompt_no_hash)
	assert result["hash"] == first_hash

	# Test with a prompt that already has a hash
	prompt_with_hash = {"text": "test prompt", "hash": "existing-hash"}
	result = augment_prompt_with_hash(prompt_with_hash)

	# Check that the hash wasn't changed
	assert result["hash"] == "existing-hash"

	# Test with an invalid prompt (no text or hash)
	with pytest.raises(InvalidPromptError):
		augment_prompt_with_hash({"other_field": "value"})


def test_load_activations_success():
	"""Test successful loading of activations."""
	# Setup
	temp_dir = TEMP_DIR / "test_load_activations_success"
	model_name = "test-model"
	prompt = {"text": "test prompt", "hash": "testhash123"}

	# Create the necessary directory structure
	prompt_dir = temp_dir / model_name / "prompts" / prompt["hash"]
	prompt_dir.mkdir(parents=True)

	# Create a dummy prompt.json file
	with open(prompt_dir / "prompt.json", "w") as f:
		json.dump(prompt, f)

	# Create a dummy activations.npz file
	fake_activations = {
		"blocks.0.attn.hook_pattern": np.random.rand(1, 2, 10, 10).astype(np.float32),
	}
	np.savez(prompt_dir / "activations.npz", **fake_activations)

	# Test loading with numpy format
	with mock.patch(
		"pattern_lens.load_activations.compare_prompt_to_loaded",
	) as mock_compare:
		path, cache = load_activations(
			model_name=model_name,
			prompt=prompt,
			save_path=temp_dir,
			return_fmt="numpy",
		)

		# Check that the path is correct
		assert path == prompt_dir / "activations.npz"

		# Check that the cache has the right structure
		assert isinstance(cache, dict)
		assert "blocks.0.attn.hook_pattern" in cache
		assert cache["blocks.0.attn.hook_pattern"].shape == (1, 2, 10, 10)

		# Check that the prompt was compared
		mock_compare.assert_called_once_with(prompt, prompt)


def test_load_activations_errors():
	"""Test error handling in load_activations."""
	# Setup
	temp_dir = TEMP_DIR / "test_load_activations_errors"
	model_name = "test-model"
	prompt = {"text": "test prompt", "hash": "testhash123"}

	# Test with missing prompt file
	with pytest.raises(ActivationsMissingError):
		load_activations(
			model_name=model_name,
			prompt=prompt,
			save_path=temp_dir,
			return_fmt="numpy",
		)

	# Create the necessary directory structure
	prompt_dir = temp_dir / model_name / "prompts" / prompt["hash"]
	prompt_dir.mkdir(parents=True)

	# Create a prompt.json file with different content
	different_prompt = {"text": "different prompt", "hash": prompt["hash"]}
	with open(prompt_dir / "prompt.json", "w") as f:
		json.dump(different_prompt, f)

	# Test with mismatched prompt
	with pytest.raises(ActivationsMismatchError):
		load_activations(
			model_name=model_name,
			prompt=prompt,
			save_path=temp_dir,
			return_fmt="numpy",
		)

	# Fix the prompt file
	with open(prompt_dir / "prompt.json", "w") as f:
		json.dump(prompt, f)

	# Test with missing activations file
	with pytest.raises(FileNotFoundError):
		load_activations(
			model_name=model_name,
			prompt=prompt,
			save_path=temp_dir,
			return_fmt="numpy",
		)

``````{ end_of_file="tests/unit/test_load_activations.py" }

``````{ path="tests/unit/test_multifig.py"  }
from pathlib import Path

import matplotlib.pyplot as plt
import numpy as np

from pattern_lens.figure_util import matplotlib_multifigure_saver

TEMP_DIR: Path = Path("tests/_temp")


def test_matplotlib_multifigure_saver():
	"""Test the matplotlib_multifigure_saver decorator."""
	# Create a temporary directory for saving figures
	temp_dir = TEMP_DIR / "test_matplotlib_multifigure_saver"
	temp_dir.mkdir(parents=True, exist_ok=True)

	# Define a test function with the decorator
	@matplotlib_multifigure_saver(names=["hist", "heatmap"])
	def multi_plot(attn_matrix, axes_dict):
		# Plot histogram
		axes_dict["hist"].hist(attn_matrix.flatten(), bins=30)
		axes_dict["hist"].set_title("Attention Values Histogram")

		# Plot heatmap
		im = axes_dict["heatmap"].matshow(attn_matrix, cmap="viridis")  # noqa: F841
		axes_dict["heatmap"].set_title("Attention Heatmap")

	# Generate a test attention matrix
	attn_matrix = np.random.rand(10, 10).astype(np.float32)

	# Call the decorated function
	multi_plot(attn_matrix, temp_dir)

	# Check that both figures were saved
	hist_file = temp_dir / "multi_plot.hist.svgz"
	heatmap_file = temp_dir / "multi_plot.heatmap.svgz"

	assert hist_file.exists(), "Histogram figure file was not saved"
	assert heatmap_file.exists(), "Heatmap figure file was not saved"

	# Check that figure_save_fmt attribute was set correctly
	assert hasattr(multi_plot, "figure_save_fmt")
	assert multi_plot.figure_save_fmt == "svgz"


def test_matplotlib_multifigure_saver_custom_format():
	"""Test the matplotlib_multifigure_saver decorator with a custom format."""
	# Create a temporary directory for saving figures
	temp_dir = TEMP_DIR / "test_matplotlib_multifigure_saver_custom_format"
	temp_dir.mkdir(parents=True, exist_ok=True)

	# Define a test function with the decorator and custom format
	@matplotlib_multifigure_saver(names=["plot1", "plot2"], fmt="png")
	def multi_plot_png(attn_matrix, axes_dict):
		# Simple plots for each axis
		axes_dict["plot1"].plot(attn_matrix.mean(axis=0))
		axes_dict["plot1"].set_title("Mean by Column")

		axes_dict["plot2"].plot(attn_matrix.mean(axis=1))
		axes_dict["plot2"].set_title("Mean by Row")

	# Generate a test attention matrix
	attn_matrix = np.random.rand(10, 10).astype(np.float32)

	# Call the decorated function
	multi_plot_png(attn_matrix, temp_dir)

	# Check that both figures were saved with the custom format
	plot1_file = temp_dir / "multi_plot_png.plot1.png"
	plot2_file = temp_dir / "multi_plot_png.plot2.png"

	assert plot1_file.exists(), "Plot1 figure file was not saved"
	assert plot2_file.exists(), "Plot2 figure file was not saved"

	# Check that figure_save_fmt attribute was set correctly
	assert hasattr(multi_plot_png, "figure_save_fmt")
	assert multi_plot_png.figure_save_fmt == "png"


def test_matplotlib_multifigure_saver_error_handling():
	"""Test error handling in the matplotlib_multifigure_saver decorator."""
	# Create a temporary directory for saving figures
	temp_dir = TEMP_DIR / "test_matplotlib_multifigure_saver_error_handling"
	temp_dir.mkdir(parents=True, exist_ok=True)

	# Define a test function that raises an error for one of the plots
	@matplotlib_multifigure_saver(names=["good_plot", "error_plot"])
	def plot_with_error(attn_matrix, axes_dict):
		# This plot should work fine
		axes_dict["good_plot"].matshow(attn_matrix)

		# This plot will raise an error
		axes_dict["error_plot"].plot(1 / 0)  # Division by zero

	# Generate a test attention matrix
	attn_matrix = np.random.rand(10, 10).astype(np.float32)

	# Call the decorated function and expect an error
	try:
		plot_with_error(attn_matrix, temp_dir)
		raise AssertionError("Expected ZeroDivisionError but no exception was raised")
	except ZeroDivisionError:
		# Check that the first figure was saved before the error
		good_plot_file = temp_dir / "plot_with_error.good_plot.svgz"
		assert not good_plot_file.exists(), "Good plot file was saved before the error"


def test_matplotlib_multifigure_saver_cleanup():
	"""Test that matplotlib_multifigure_saver properly closes figures."""
	# Create a temporary directory for saving figures
	temp_dir = TEMP_DIR / "test_matplotlib_multifigure_saver_cleanup"
	temp_dir.mkdir(parents=True, exist_ok=True)

	# Count the number of open figures before the test
	initial_figures = len(plt.get_fignums())

	# Define a test function with the decorator
	@matplotlib_multifigure_saver(names=["plot1", "plot2"])
	def multi_plot_cleanup(attn_matrix, axes_dict):
		axes_dict["plot1"].plot(attn_matrix[0])
		axes_dict["plot2"].plot(attn_matrix[1])

	# Generate a test attention matrix
	attn_matrix = np.random.rand(10, 10).astype(np.float32)

	# Call the decorated function
	multi_plot_cleanup(attn_matrix, temp_dir)

	# Check that no new figures remain open
	assert len(plt.get_fignums()) == initial_figures, "Figures were not properly closed"

``````{ end_of_file="tests/unit/test_multifig.py" }

``````{ path="tests/unit/test_server.py"  }
# tests/unit/test_server.py
from unittest import mock

from pattern_lens.server import main as server_main


def test_server_main():
	"""Test the server main function."""
	# Mock the TCPServer and other components
	with (
		mock.patch("pattern_lens.server.socketserver.TCPServer") as mock_server,
		mock.patch(
			"pattern_lens.server.http.server.SimpleHTTPRequestHandler",
		) as mock_handler,
		mock.patch("pattern_lens.server.os.chdir") as mock_chdir,
		mock.patch("pattern_lens.server.sys.exit") as mock_exit,
	):
		# Setup the server to raise KeyboardInterrupt after being called
		mock_server_instance = mock_server.return_value.__enter__.return_value
		mock_server_instance.serve_forever.side_effect = KeyboardInterrupt()

		# Call the server main function
		server_main("test_path", 8080)

		# Check that the function changed to the right directory
		mock_chdir.assert_called_once_with("test_path")

		# Check that the server was initialized with the right parameters
		mock_server.assert_called_once_with(("", 8080), mock_handler)

		# Check that serve_forever was called
		mock_server_instance.serve_forever.assert_called_once()

		# Check that sys.exit was called with 0 (clean exit)
		mock_exit.assert_called_once_with(0)

``````{ end_of_file="tests/unit/test_server.py" }

``````{ path="README.md"  }
[![PyPI](https://img.shields.io/pypi/v/pattern-lens)](https://pypi.org/project/pattern-lens/)
![PyPI - Downloads](https://img.shields.io/pypi/dm/pattern-lens)
[![docs](https://img.shields.io/badge/docs-latest-blue)](https://miv.name/pattern-lens)
[![Checks](https://github.com/mivanit/pattern-lens/actions/workflows/checks.yml/badge.svg)](https://github.com/mivanit/pattern-lens/actions/workflows/checks.yml)

[![Coverage](docs/coverage/coverage.svg)](docs/coverage/html/)
![GitHub commits](https://img.shields.io/github/commit-activity/t/mivanit/pattern-lens)
![GitHub commit activity](https://img.shields.io/github/commit-activity/m/mivanit/pattern-lens)
![GitHub closed pull requests](https://img.shields.io/github/issues-pr-closed/mivanit/pattern-lens)
![code size, bytes](https://img.shields.io/github/languages/code-size/mivanit/pattern-lens)

# pattern-lens

visualization of LLM attention patterns and things computed about them

`pattern-lens` makes it easy to:

- Generate visualizations of attention patterns, or figures computed from attention patterns, from models supported by [TransformerLens](https://github.com/TransformerLensOrg/TransformerLens)
- Compare generated figures across models, layers, and heads in an [interactive web interface](https://miv.name/pattern-lens/demo/)

# Installation

```bash
pip install pattern-lens
```


# Usage

The pipeline is as follows:

- Generate attention patterns using `pattern_lens.activations.acitvations_main()`, saving them in `npz` files
- Generate visualizations using `pattern_lens.figures.figures_main()` -- read the `npz` files, pass each attention pattern to each visualization function, and save the resulting figures
- Serve the web interface using `pattern_lens.server` -- web interface reads metadata in json/jsonl files, then lets the user select figures to show


## Basic CLI

Generate attention patterns and default visualizations:

```bash
# generate activations
python -m pattern_lens.activations --model gpt2 --prompts data/pile_1k.jsonl --save-path attn_data
# create visualizations
python -m pattern_lens.figures --model gpt2 --save-path attn_data
```

serve the web UI:

```bash
python -m pattern_lens.server --path attn_data
```


## Web UI

View a demo of the web UI at [miv.name/pattern-lens/demo](https://miv.name/pattern-lens/demo/).

## Custom Figures

Add custom visualization functions by decorating them with `@register_attn_figure_func`. You should still generate the activations first:
```
python -m pattern_lens.activations --model gpt2 --prompts data/pile_1k.jsonl --save-path attn_data
```

and then write+run a script/notebook that looks something like this:

```python
import numpy as np
import matplotlib.pyplot as plt
from scipy.linalg import svd

# these functions simplify writing a function which saves a figure
from pattern_lens.figure_util import matplotlib_figure_saver, save_matrix_wrapper
# decorator to register your function, such that it will be run by `figures_main`
from pattern_lens.attn_figure_funcs import register_attn_figure_func
# runs the actual figure generation pipeline
from pattern_lens.figures import figures_main

# define your own functions
# this one uses `matplotlib_figure_saver` -- define a function that takes matrix and `plt.Axes`, modify the axes
@register_attn_figure_func
@matplotlib_figure_saver(fmt="svgz")
def svd_spectra(attn_matrix: np.ndarray, ax: plt.Axes) -> None:
    # Perform SVD
    U, s, Vh = svd(attn_matrix)

    # Plot singular values
    ax.plot(s, "o-")
    ax.set_yscale("log")
    ax.set_xlabel("Singular Value Index")
    ax.set_ylabel("Singular Value")
    ax.set_title("Singular Value Spectrum of Attention Matrix")


# run the figures pipelne
# run the pipeline
figures_main(
	model_name="pythia-14m",
	save_path=Path("docs/demo/"),
	n_samples=5,
	force=False,
)
```

see `demo.ipynb` for a full example
``````{ end_of_file="README.md" }

``````{ path="demo.ipynb" processed_with="ipynb_to_md" }
```python
from pathlib import Path

import matplotlib.pyplot as plt
import numpy as np
from scipy.linalg import svd

from pattern_lens.attn_figure_funcs import register_attn_figure_func
from pattern_lens.figure_util import matplotlib_figure_saver, save_matrix_wrapper
from pattern_lens.figures import figures_main
```

```python
# define and register your own functions
# don't take these too seriously, they're just examples


# using matplotlib_figure_saver -- define a function that takes matrix and `plt.Axes`, modify the axes
@register_attn_figure_func
@matplotlib_figure_saver(fmt="svgz")
def svd_spectra(attn_matrix: np.ndarray, ax: plt.Axes) -> None:
	# Perform SVD
	U, s, Vh = svd(attn_matrix)

	# Plot singular values
	ax.plot(s, "o-")
	ax.set_yscale("log")
	ax.set_xlabel("Singular Value Index")
	ax.set_ylabel("Singular Value")
	ax.set_title("Singular Value Spectrum of Attention Matrix")


# manually creating and saving a figure
@register_attn_figure_func
def attention_flow(attn_matrix: np.ndarray, path: Path) -> None:
	"""Visualize attention as flows between tokens.

	Creates a simplified Sankey-style diagram where line thickness and color
	intensity represent attention strength.
	"""
	fig, ax = plt.subplots(figsize=(6, 6))
	n_tokens: int = attn_matrix.shape[0]

	# Create positions for tokens on left and right
	left_pos: np.ndarray = np.arange(n_tokens)
	right_pos: np.ndarray = np.arange(n_tokens)

	# Plot flows
	for i in range(n_tokens):
		for j in range(n_tokens):
			weight = attn_matrix[i, j]
			if weight > 0.05:  # Only plot stronger connections
				ax.plot(
					[0, 1],
					[left_pos[i], right_pos[j]],
					alpha=weight,
					linewidth=weight * 5,
					color="blue",
				)

	ax.set_xlim(-0.1, 1.1)
	ax.set_ylim(-1, n_tokens)
	ax.axis("off")
	ax.set_title("Attention Flow Between Positions")

	# be sure to save the figure as `function_name.format` in the given location
	fig.savefig(path / "attention_flow.svgz", format="svgz")


@register_attn_figure_func
@save_matrix_wrapper(fmt="svgz")
def gram_matrix(attn_matrix: np.ndarray) -> np.ndarray:
	return attn_matrix @ attn_matrix.T
```

```python
# run the pipeline
figures_main(
	model_name="pythia-14m",
	save_path=Path("docs/demo/"),
	n_samples=5,
	force=False,
)
```


``````{ end_of_file="demo.ipynb" }

``````{ path="makefile" processed_with="makefile_recipes" }
# first/default target is help
.PHONY: default
default: help
	...

# this recipe is weird. we need it because:
# - a one liner for getting the version with toml is unwieldy, and using regex is fragile
# - using $$SCRIPT_GET_VERSION within $(shell ...) doesn't work because of escaping issues
# - trying to write to the file inside the `gen-version-info` recipe doesn't work, 
# 	shell eval happens before our `python -c ...` gets run and `cat` doesn't see the new file
.PHONY: write-proj-version
write-proj-version:
	...

# gets version info from $(PYPROJECT), last version from $(LAST_VERSION_FILE), and python version
# uses just `python` for everything except getting the python version. no echo here, because this is "private"
.PHONY: gen-version-info
gen-version-info: write-proj-version
	...

# getting commit log since the tag specified in $(LAST_VERSION_FILE)
# will write to $(COMMIT_LOG_FILE)
# when publishing, the contents of $(COMMIT_LOG_FILE) will be used as the tag description (but can be edited during the process)
# no echo here, because this is "private"
.PHONY: gen-commit-log
gen-commit-log: gen-version-info
	...

# force the version info to be read, printing it out
# also force the commit log to be generated, and cat it out
.PHONY: version
version: gen-commit-log
	@echo "Current version is $(PROJ_VERSION), last auto-uploaded version is $(LAST_VERSION)"
	...

.PHONY: setup
setup: dep-check
	@echo "install and update via uv"
	...

.PHONY: dep-check-torch
dep-check-torch:
	@echo "see if torch is installed, and which CUDA version and devices it sees"
	...

.PHONY: dep
dep:
	@echo "Exporting dependencies as per $(PYPROJECT) section 'tool.uv-exports.exports'"
	...

.PHONY: dep-check
dep-check:
	@echo "Checking that exported requirements are up to date"
	...

.PHONY: dep-clean
dep-clean:
	@echo "clean up lock files, .venv, and requirements files"
	...

# runs ruff to format the code
.PHONY: format
format:
	@echo "format the source code"
	...

# runs ruff and pycln to check if the code is formatted correctly
.PHONY: format-check
format-check:
	@echo "check if the source code is formatted correctly"
	...

# runs type checks with mypy
.PHONY: typing
typing: clean
	@echo "running type checks"
	...

# generates a report of the mypy output
.PHONY: typing-report
typing-report:
	@echo "generate a report of the type check output -- errors per file"
	...

.PHONY: test
test: clean
	@echo "running tests"
	...

.PHONY: check
check: clean format-check test typing
	@echo "run format checks, tests, and typing checks"
	...

# generates a whole tree of documentation in html format.
# see `$(MAKE_DOCS_SCRIPT_PATH)` and the templates in `$(DOCS_RESOURCES_DIR)/templates/html/` for more info
.PHONY: docs-html
docs-html:
	@echo "generate html docs"
	...

# instead of a whole website, generates a single markdown file with all docs using the templates in `$(DOCS_RESOURCES_DIR)/templates/markdown/`.
# this is useful if you want to have a copy that you can grep/search, but those docs are much messier.
# docs-combined will use pandoc to convert them to other formats.
.PHONY: docs-md
docs-md:
	@echo "generate combined (single-file) docs in markdown"
	...

# after running docs-md, this will convert the combined markdown file to other formats:
# gfm (github-flavored markdown), plain text, and html
# requires pandoc in path, pointed to by $(PANDOC)
# pdf output would be nice but requires other deps
.PHONY: docs-combined
docs-combined: docs-md
	@echo "generate combined (single-file) docs in markdown and convert to other formats"
	...

# generates coverage reports as html and text with `pytest-cov`, and a badge with `coverage-badge`
# if `.coverage` is not found, will run tests first
# also removes the `.gitignore` file that `coverage html` creates, since we count that as part of the docs
.PHONY: cov
cov:
	@echo "generate coverage reports"
	...

# runs the coverage report, then the docs, then the combined docs
.PHONY: docs
docs: cov docs-html docs-combined todo lmcat
	@echo "generate all documentation and coverage reports"
	...

# removed all generated documentation files, but leaves everything in `$DOCS_RESOURCES_DIR`
# and leaves things defined in `pyproject.toml:tool.makefile.docs.no_clean`
# (templates, svg, css, make_docs.py script)
# distinct from `make clean`
.PHONY: docs-clean
docs-clean:
	@echo "remove generated docs except resources"
	...

.PHONY: todo
todo:
	@echo "get all TODO's from the code"
	...

.PHONY: lmcat-tree
lmcat-tree:
	@echo "show in console the lmcat tree view"
	...

.PHONY: lmcat
lmcat:
	@echo "write the lmcat full output to pyproject.toml:[tool.lmcat.output]"
	...

# verifies that the current branch is $(PUBLISH_BRANCH) and that git is clean
# used before publishing
.PHONY: verify-git
verify-git: 
	@echo "checking git status"
	...

.PHONY: build
build: 
	@echo "build the package"
	...

# gets the commit log, checks everything, builds, and then publishes with twine
# will ask the user to confirm the new version number (and this allows for editing the tag info)
# will also print the contents of $(PYPI_TOKEN_FILE) to the console for the user to copy and paste in when prompted by twine
.PHONY: publish
publish: gen-commit-log check build verify-git version gen-version-info
	@echo "run all checks, build, and then publish"
	...

# cleans up temp files from formatter, type checking, tests, coverage
# removes all built files
# removes $(TESTS_TEMP_DIR) to remove temporary test files
# recursively removes all `__pycache__` directories and `*.pyc` or `*.pyo` files
# distinct from `make docs-clean`, which only removes generated documentation files
.PHONY: clean
clean:
	@echo "clean up temporary files"
	...

.PHONY: clean-all
clean-all: clean docs-clean dep-clean
	@echo "clean up all temporary files, dep files, venv, and generated docs"
	...

.PHONY: info
info: gen-version-info
	@echo "# makefile variables"
	...

.PHONY: info-long
info-long: info
	@echo "# other variables"
	...

# immediately print out the help targets, and then local variables (but those take a bit longer)
.PHONY: help
help: help-targets info
	@echo -n ""
	...

.PHONY: demo-clean
demo-clean:
	...

.PHONY: demo-activations
demo-activations:
	...

.PHONY: demo-figures
demo-figures:
	...

.PHONY: demo-server
demo-server:
	...

.PHONY: demo
demo: demo-clean demo-activations demo-figures demo-server
	@echo "generate demo"
	...

.PHONY: demo-docs
demo-docs: demo-clean demo-activations demo-figures
	@echo "generate demo for docs (no server)"
	...

.PHONY: summary
summary:
	@echo "write docs/summary.md using lmcat"
	...

``````{ end_of_file="makefile" }

``````{ path="pyproject.toml"  }
[project]
    name = "pattern_lens"
    version = "0.3.0"
    description = ""
    readme = "README.md"
    requires-python = ">=3.11"
    dependencies = [
        # standard
        "numpy>=1.26.1,<2.0.0",
        "torch>=2.5.1",
        "jaxtyping>=0.2.33",
        "tqdm>=4.66.5",
        "pandas>=2.2.2",
        "scipy>=1.14.1",
        # "scikit-learn>=1.3",
        "matplotlib>=3.8.0",
        "pillow>=11.0.0",
        # jupyter
        "ipykernel>=6.29.5",
        "ipywidgets>=8.1.5",
        # typing
        "beartype>=0.14.1",
        # custom utils
        "muutils>=0.6.19",
        "zanj>=0.3.1",
        # TL
        "transformer-lens>=2.10.0",
        # this TL dep not listed? is this in an extra?
        "typeguard>=4.4.1",
    ]

[dependency-groups]
    dev = [
        # lmcat
        "lmcat>=0.2.0; python_version >= '3.11'",
        # test
        "pytest>=8.2.2",
        # coverage
        "pytest-cov>=4.1.0",
        "coverage-badge>=1.1.0",
        # type checking
        "mypy>=1.0.1",
        "types-tqdm",
        # docs
        'pdoc>=14.6.0',
        "nbconvert>=7.16.4",
        # tomli since no tomlib in python < 3.11
        "tomli>=2.1.0; python_version < '3.11'",
        # lint
        "ruff>=0.4.8",
    ]

[tool.uv]
    package = true

[project.urls]
    Homepage = "https://miv.name/pattern-lens"
    Documentation = "https://miv.name/pattern-lens"
    Repository = "https://github.com/mivanit/pattern-lens"
    Issues = "https://github.com/mivanit/pattern-lens/issues"

[build-system]
    requires = ["hatchling"]
    build-backend = "hatchling.build"

# tools
[tool]
    [tool.hatch.build.targets.wheel]
        packages = ["pattern_lens"]

    # ruff config
    [tool.ruff]
        exclude = ["__pycache__"]

        [tool.ruff.lint]
            ignore = [
                "F722", # doesn't like jaxtyping
                "W191", # we like tabs
                "D400", # missing-trailing-period
                "D415", # missing-terminal-punctuation
                "E501", # line-too-long
                "S101", # assert is fine
                "D403", # first-word-uncapitalized
                "D206", # docstring-tab-indentation
                "ERA001", # commented-out-code
                "T201", # print is fine
                "C408", # calling dict() is fine
                "UP015", # we like specifying the mode even if it's the default
                "D300", # we like docstrings
                # boolean positional arguments are fine
                "FBT001", 
                "FBT002",
                "PTH123", # opening files is fine
                "RET505", # else return is fine
                "FIX002", # `make todo` will give us the TODO comments
                "PIE790", # be explicit about when we pass
                "EM101", # fine to have string literal exceptions
                "FURB129", # .readlines() is fine
                "SIM108", # ternary operators can be hard to read, choose on a case-by-case basis
                "PLR5501", # nested if else is fine, for readability
                "D203", # docstring right after the class
                "D213", # docstring on first line
                "NPY002", # legacy numpy generator is fine
                "D401", # don't care about imperative mood
                # todos:
                "TD002", # don't care about author
                "TD003", # `make todo` will give us a table where we can create issues
                "PLR0913", # sometimes you have to have a lot of args
            ]
            select = ["ALL"]
            # select = ["ICN001"]

            [tool.ruff.lint.per-file-ignores]
                "tests/*" = [
                    # don't need docstrings in test functions or modules
                    "D100",
                    "D102",
                    "D103", 
                    "D107",
                    # don't need __init__ either
                    "INP001",
                    "ANN204",
                    # don't need type annotations in test functions
                    "ANN001",
                    "ANN201", 
                    "ANN202",
                    "TRY003", # long exception messages in tests are fine
                    "PLR2004", # magic values fine in tests
                ]
                "docs/*" = ["ALL"] # not our problem
                "**/*.ipynb" = [
                    "D103", # don't need docstrings
                    "PLR2004", # magic variables are fine
                    "N806", # uppercase vars are fine
                ]

        [tool.ruff.format]
            indent-style = "tab"
            skip-magic-trailing-comma = false

    [tool.pytest.ini_options]
        adopts = "--jaxtyping-packages=pattern_lens,beartype.beartype"
        filterwarnings = [
            "ignore: PEP 484 type hint*:beartype.roar._roarwarn.BeartypeDecorHintPep585DeprecationWarning",
        ]

    [tool.mypy]
        check_untyped_defs = true

    # `make lmcat` depends on the lmcat and can be configured here
    [tool.lmcat]
        output = "docs/other/lmcat.txt" # changing this might mean it wont be accessible from the docs
        ignore_patterns = [
            "!docs/resources/make_docs.py",
            "docs/**",
            ".venv/**",
            ".git/**",
            ".meta/**",
            "uv.lock",
            "LICENSE",
        ]
        [tool.lmcat.glob_process]
            "[mM]akefile" = "makefile_recipes"
            "*.ipynb" = "ipynb_to_md"

# for configuring this tool (makefile, make_docs.py)
# ============================================================
[tool.makefile]

# documentation configuration, for `make docs` and `make docs-clean`
[tool.makefile.docs]
    output_dir = "docs"
    no_clean = [
        ".nojekyll",
        "demo",
    ]
    markdown_headings_increment = 2
    warnings_ignore = [
        ".*No docstring.*",
        ".*Private member.*",
    ]
    [tool.makefile.docs.notebooks]
        enabled = false
        source_path = "notebooks"
        output_path_relative = "notebooks"
        # [tool.makefile.docs.notebooks.descriptions]
        #     "example" = "Example notebook showing basic usage"
        #     "advanced" = "Advanced usage patterns and techniques"
        
        

# Custom export configurations
# affects `make dep` and related commands
[tool.makefile.uv-exports]
	args = [
		"--no-hashes"
	]
	exports = [
		# # all groups and extras
		{ name = "all", filename="requirements.txt", groups = true, extras=true },
		# # all groups and extras, a different way
		{ name = "all", groups = true, options = ["--all-extras"] },
	]

# configures `make todo`
[tool.makefile.inline-todo]
	search_dir = "."
	out_file_base = "docs/other/todo-inline.md"
	context_lines = 2
	extensions = ["py", "md"]
	tags = ["CRIT", "TODO", "FIXME", "HACK", "BUG", "DOC", "TYPING"]
	exclude = [
		"docs/**",
		".venv/**",
		"scripts/get_todos.py",
	]
	branch = "main"
    [tool.makefile.inline-todo.tag_label_map]
        "BUG" = "bug"
        "TODO" = "enhancement"
		"DOC" = "documentation"

# ============================================================
``````{ end_of_file="pyproject.toml" }