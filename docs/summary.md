# File Tree

```
pattern-lens
├── .github
│   ├── local
│   ├── requirements
│   │   ├── requirements-all.txt
│   │   ├── requirements-base.txt
│   │   └── requirements.txt
│   └── versions
│    └── .version
├── data
│   └── pile_5.jsonl
├── pattern_lens
│   ├── frontend
│   │   └── index.html
│   ├── __init__.py
│   ├── activations.py
│   ├── attn_figure_funcs.py
│   ├── consts.py
│   ├── figure_util.py
│   ├── figures.py
│   ├── indexes.py
│   ├── load_activations.py
│   ├── prompts.py
│   └── server.py
├── tests
│   ├── integration
│   │   └── test_pipeline.py
│   └── unit
│    └── test_figure_util.py
├── LICENSE
├── README.md
├── demo.ipynb
├── makefile
├── pyproject.toml
```

# File Contents

``````{ path: ".github/requirements/requirements-all.txt" }
# This file was autogenerated by uv via the following command:
#    uv export --no-hashes --group dev --all-extras
-e .
accelerate==1.2.1
aiohappyeyeballs==2.4.4
aiohttp==3.11.11
aiosignal==1.3.2
annotated-types==0.7.0
appnope==0.1.4 ; sys_platform == 'darwin'
asttokens==3.0.0
attrs==24.3.0
beartype==0.14.1
better-abc==0.0.3
bracex==2.5.post1
certifi==2024.12.14
cffi==1.17.1 ; implementation_name == 'pypy'
charset-normalizer==3.4.0
cli-exit-tools==1.2.7
click==8.1.7
colorama==0.4.6 ; sys_platform == 'win32'
comm==0.2.2
contourpy==1.3.1
coverage==7.6.9
coverage-badge==1.1.2
cycler==0.12.1
datasets==2.14.4
debugpy==1.8.11
decorator==5.1.1
dill==0.3.7
docker-pycreds==0.4.0
einops==0.8.0
executing==2.1.0
fancy-einsum==0.0.3
filelock==3.16.1
fonttools==4.55.3
frozenlist==1.5.0
fsspec==2024.10.0
gitdb==4.0.11
gitpython==3.1.43
huggingface-hub==0.27.0
idna==3.10
igittigitt==2.1.5
iniconfig==2.0.0
ipykernel==6.29.5
ipython==8.30.0
ipywidgets==8.1.5
jaxtyping==0.2.36
jedi==0.19.2
jinja2==3.1.4
jupyter-client==8.6.3
jupyter-core==5.7.2
jupyterlab-widgets==3.0.13
kiwisolver==1.4.7
lib-detect-testenv==2.0.8
libcst==1.5.1
lmcat==0.0.1
markdown-it-py==3.0.0
markupsafe==3.0.2
matplotlib==3.10.0
matplotlib-inline==0.1.7
mdurl==0.1.2
mpmath==1.3.0
multidict==6.1.0
multiprocess==0.70.15
muutils==0.6.19
mypy==1.13.0
mypy-extensions==1.0.0
nest-asyncio==1.6.0
networkx==3.4.2
numpy==1.26.4
nvidia-cublas-cu12==12.4.5.8 ; platform_machine == 'x86_64' and sys_platform == 'linux'
nvidia-cuda-cupti-cu12==12.4.127 ; platform_machine == 'x86_64' and sys_platform == 'linux'
nvidia-cuda-nvrtc-cu12==12.4.127 ; platform_machine == 'x86_64' and sys_platform == 'linux'
nvidia-cuda-runtime-cu12==12.4.127 ; platform_machine == 'x86_64' and sys_platform == 'linux'
nvidia-cudnn-cu12==9.1.0.70 ; platform_machine == 'x86_64' and sys_platform == 'linux'
nvidia-cufft-cu12==11.2.1.3 ; platform_machine == 'x86_64' and sys_platform == 'linux'
nvidia-curand-cu12==10.3.5.147 ; platform_machine == 'x86_64' and sys_platform == 'linux'
nvidia-cusolver-cu12==11.6.1.9 ; platform_machine == 'x86_64' and sys_platform == 'linux'
nvidia-cusparse-cu12==12.3.1.170 ; platform_machine == 'x86_64' and sys_platform == 'linux'
nvidia-nccl-cu12==2.21.5 ; platform_machine == 'x86_64' and sys_platform == 'linux'
nvidia-nvjitlink-cu12==12.4.127 ; platform_machine == 'x86_64' and sys_platform == 'linux'
nvidia-nvtx-cu12==12.4.127 ; platform_machine == 'x86_64' and sys_platform == 'linux'
packaging==24.2
pandas==2.2.3
parso==0.8.4
pathspec==0.12.1
pdoc==15.0.1
pexpect==4.9.0 ; sys_platform != 'emscripten' and sys_platform != 'win32'
pillow==11.0.0
platformdirs==4.3.6
pluggy==1.5.0
prompt-toolkit==3.0.48
propcache==0.2.1
protobuf==5.29.2
psutil==6.1.0
ptyprocess==0.7.0 ; sys_platform != 'emscripten' and sys_platform != 'win32'
pure-eval==0.2.3
pyarrow==18.1.0
pycln==2.4.0
pycparser==2.22 ; implementation_name == 'pypy'
pydantic==2.10.4
pydantic-core==2.27.2
pygments==2.18.0
pyparsing==3.2.0
pytest==8.3.4
pytest-cov==6.0.0
python-dateutil==2.9.0.post0
pytz==2024.2
pywin32==308 ; platform_python_implementation != 'PyPy' and sys_platform == 'win32'
pyyaml==6.0.2
pyzmq==26.2.0
regex==2024.11.6
requests==2.32.3
rich==13.9.4
ruff==0.8.3
safetensors==0.4.5
scipy==1.14.1
sentencepiece==0.2.0
sentry-sdk==2.19.2
setproctitle==1.3.4
setuptools==75.6.0
shellingham==1.5.4
six==1.17.0
smmap==5.0.1
stack-data==0.6.3
sympy==1.13.1
tokenizers==0.21.0
tomlkit==0.13.2
torch==2.5.1
tornado==6.4.2
tqdm==4.67.1
traitlets==5.14.3
transformer-lens==2.10.0
transformers==4.47.1
triton==3.1.0 ; python_full_version < '3.13' and platform_machine == 'x86_64' and sys_platform == 'linux'
typeguard==4.4.1
typer==0.15.1
types-requests==2.32.0.20241016
types-tqdm==4.67.0.20241221
typing-extensions==4.12.2
tzdata==2024.2
urllib3==2.2.3
wandb==0.19.1
wcmatch==10.0
wcwidth==0.2.13
widgetsnbextension==4.0.13
xxhash==3.5.0
yarl==1.18.3
zanj==0.3.1

``````{ end_of_file: ".github/requirements/requirements-all.txt" }

``````{ path: ".github/requirements/requirements-base.txt" }
# This file was autogenerated by uv via the following command:
#    uv export --no-hashes --no-group dev
-e .
accelerate==1.2.1
aiohappyeyeballs==2.4.4
aiohttp==3.11.11
aiosignal==1.3.2
annotated-types==0.7.0
appnope==0.1.4 ; sys_platform == 'darwin'
asttokens==3.0.0
attrs==24.3.0
beartype==0.14.1
better-abc==0.0.3
certifi==2024.12.14
cffi==1.17.1 ; implementation_name == 'pypy'
charset-normalizer==3.4.0
click==8.1.7
colorama==0.4.6 ; sys_platform == 'win32'
comm==0.2.2
contourpy==1.3.1
cycler==0.12.1
datasets==2.14.4
debugpy==1.8.11
decorator==5.1.1
dill==0.3.7
docker-pycreds==0.4.0
einops==0.8.0
executing==2.1.0
fancy-einsum==0.0.3
filelock==3.16.1
fonttools==4.55.3
frozenlist==1.5.0
fsspec==2024.10.0
gitdb==4.0.11
gitpython==3.1.43
huggingface-hub==0.27.0
idna==3.10
ipykernel==6.29.5
ipython==8.30.0
ipywidgets==8.1.5
jaxtyping==0.2.36
jedi==0.19.2
jinja2==3.1.4
jupyter-client==8.6.3
jupyter-core==5.7.2
jupyterlab-widgets==3.0.13
kiwisolver==1.4.7
markdown-it-py==3.0.0
markupsafe==3.0.2
matplotlib==3.10.0
matplotlib-inline==0.1.7
mdurl==0.1.2
mpmath==1.3.0
multidict==6.1.0
multiprocess==0.70.15
muutils==0.6.19
nest-asyncio==1.6.0
networkx==3.4.2
numpy==1.26.4
nvidia-cublas-cu12==12.4.5.8 ; platform_machine == 'x86_64' and sys_platform == 'linux'
nvidia-cuda-cupti-cu12==12.4.127 ; platform_machine == 'x86_64' and sys_platform == 'linux'
nvidia-cuda-nvrtc-cu12==12.4.127 ; platform_machine == 'x86_64' and sys_platform == 'linux'
nvidia-cuda-runtime-cu12==12.4.127 ; platform_machine == 'x86_64' and sys_platform == 'linux'
nvidia-cudnn-cu12==9.1.0.70 ; platform_machine == 'x86_64' and sys_platform == 'linux'
nvidia-cufft-cu12==11.2.1.3 ; platform_machine == 'x86_64' and sys_platform == 'linux'
nvidia-curand-cu12==10.3.5.147 ; platform_machine == 'x86_64' and sys_platform == 'linux'
nvidia-cusolver-cu12==11.6.1.9 ; platform_machine == 'x86_64' and sys_platform == 'linux'
nvidia-cusparse-cu12==12.3.1.170 ; platform_machine == 'x86_64' and sys_platform == 'linux'
nvidia-nccl-cu12==2.21.5 ; platform_machine == 'x86_64' and sys_platform == 'linux'
nvidia-nvjitlink-cu12==12.4.127 ; platform_machine == 'x86_64' and sys_platform == 'linux'
nvidia-nvtx-cu12==12.4.127 ; platform_machine == 'x86_64' and sys_platform == 'linux'
packaging==24.2
pandas==2.2.3
parso==0.8.4
pexpect==4.9.0 ; sys_platform != 'emscripten' and sys_platform != 'win32'
pillow==11.0.0
platformdirs==4.3.6
prompt-toolkit==3.0.48
propcache==0.2.1
protobuf==5.29.2
psutil==6.1.0
ptyprocess==0.7.0 ; sys_platform != 'emscripten' and sys_platform != 'win32'
pure-eval==0.2.3
pyarrow==18.1.0
pycparser==2.22 ; implementation_name == 'pypy'
pydantic==2.10.4
pydantic-core==2.27.2
pygments==2.18.0
pyparsing==3.2.0
python-dateutil==2.9.0.post0
pytz==2024.2
pywin32==308 ; platform_python_implementation != 'PyPy' and sys_platform == 'win32'
pyyaml==6.0.2
pyzmq==26.2.0
regex==2024.11.6
requests==2.32.3
rich==13.9.4
safetensors==0.4.5
scipy==1.14.1
sentencepiece==0.2.0
sentry-sdk==2.19.2
setproctitle==1.3.4
setuptools==75.6.0
six==1.17.0
smmap==5.0.1
stack-data==0.6.3
sympy==1.13.1
tokenizers==0.21.0
torch==2.5.1
tornado==6.4.2
tqdm==4.67.1
traitlets==5.14.3
transformer-lens==2.10.0
transformers==4.47.1
triton==3.1.0 ; python_full_version < '3.13' and platform_machine == 'x86_64' and sys_platform == 'linux'
typeguard==4.4.1
typing-extensions==4.12.2
tzdata==2024.2
urllib3==2.2.3
wandb==0.19.1
wcwidth==0.2.13
widgetsnbextension==4.0.13
xxhash==3.5.0
yarl==1.18.3
zanj==0.3.1

``````{ end_of_file: ".github/requirements/requirements-base.txt" }

``````{ path: ".github/requirements/requirements.txt" }
# This file was autogenerated by uv via the following command:
#    uv export --no-hashes --group dev
-e .
accelerate==1.2.1
aiohappyeyeballs==2.4.4
aiohttp==3.11.11
aiosignal==1.3.2
annotated-types==0.7.0
appnope==0.1.4 ; sys_platform == 'darwin'
asttokens==3.0.0
attrs==24.3.0
beartype==0.14.1
better-abc==0.0.3
bracex==2.5.post1
certifi==2024.12.14
cffi==1.17.1 ; implementation_name == 'pypy'
charset-normalizer==3.4.0
cli-exit-tools==1.2.7
click==8.1.7
colorama==0.4.6 ; sys_platform == 'win32'
comm==0.2.2
contourpy==1.3.1
coverage==7.6.9
coverage-badge==1.1.2
cycler==0.12.1
datasets==2.14.4
debugpy==1.8.11
decorator==5.1.1
dill==0.3.7
docker-pycreds==0.4.0
einops==0.8.0
executing==2.1.0
fancy-einsum==0.0.3
filelock==3.16.1
fonttools==4.55.3
frozenlist==1.5.0
fsspec==2024.10.0
gitdb==4.0.11
gitpython==3.1.43
huggingface-hub==0.27.0
idna==3.10
igittigitt==2.1.5
iniconfig==2.0.0
ipykernel==6.29.5
ipython==8.30.0
ipywidgets==8.1.5
jaxtyping==0.2.36
jedi==0.19.2
jinja2==3.1.4
jupyter-client==8.6.3
jupyter-core==5.7.2
jupyterlab-widgets==3.0.13
kiwisolver==1.4.7
lib-detect-testenv==2.0.8
libcst==1.5.1
lmcat==0.0.1
markdown-it-py==3.0.0
markupsafe==3.0.2
matplotlib==3.10.0
matplotlib-inline==0.1.7
mdurl==0.1.2
mpmath==1.3.0
multidict==6.1.0
multiprocess==0.70.15
muutils==0.6.19
mypy==1.13.0
mypy-extensions==1.0.0
nest-asyncio==1.6.0
networkx==3.4.2
numpy==1.26.4
nvidia-cublas-cu12==12.4.5.8 ; platform_machine == 'x86_64' and sys_platform == 'linux'
nvidia-cuda-cupti-cu12==12.4.127 ; platform_machine == 'x86_64' and sys_platform == 'linux'
nvidia-cuda-nvrtc-cu12==12.4.127 ; platform_machine == 'x86_64' and sys_platform == 'linux'
nvidia-cuda-runtime-cu12==12.4.127 ; platform_machine == 'x86_64' and sys_platform == 'linux'
nvidia-cudnn-cu12==9.1.0.70 ; platform_machine == 'x86_64' and sys_platform == 'linux'
nvidia-cufft-cu12==11.2.1.3 ; platform_machine == 'x86_64' and sys_platform == 'linux'
nvidia-curand-cu12==10.3.5.147 ; platform_machine == 'x86_64' and sys_platform == 'linux'
nvidia-cusolver-cu12==11.6.1.9 ; platform_machine == 'x86_64' and sys_platform == 'linux'
nvidia-cusparse-cu12==12.3.1.170 ; platform_machine == 'x86_64' and sys_platform == 'linux'
nvidia-nccl-cu12==2.21.5 ; platform_machine == 'x86_64' and sys_platform == 'linux'
nvidia-nvjitlink-cu12==12.4.127 ; platform_machine == 'x86_64' and sys_platform == 'linux'
nvidia-nvtx-cu12==12.4.127 ; platform_machine == 'x86_64' and sys_platform == 'linux'
packaging==24.2
pandas==2.2.3
parso==0.8.4
pathspec==0.12.1
pdoc==15.0.1
pexpect==4.9.0 ; sys_platform != 'emscripten' and sys_platform != 'win32'
pillow==11.0.0
platformdirs==4.3.6
pluggy==1.5.0
prompt-toolkit==3.0.48
propcache==0.2.1
protobuf==5.29.2
psutil==6.1.0
ptyprocess==0.7.0 ; sys_platform != 'emscripten' and sys_platform != 'win32'
pure-eval==0.2.3
pyarrow==18.1.0
pycln==2.4.0
pycparser==2.22 ; implementation_name == 'pypy'
pydantic==2.10.4
pydantic-core==2.27.2
pygments==2.18.0
pyparsing==3.2.0
pytest==8.3.4
pytest-cov==6.0.0
python-dateutil==2.9.0.post0
pytz==2024.2
pywin32==308 ; platform_python_implementation != 'PyPy' and sys_platform == 'win32'
pyyaml==6.0.2
pyzmq==26.2.0
regex==2024.11.6
requests==2.32.3
rich==13.9.4
ruff==0.8.3
safetensors==0.4.5
scipy==1.14.1
sentencepiece==0.2.0
sentry-sdk==2.19.2
setproctitle==1.3.4
setuptools==75.6.0
shellingham==1.5.4
six==1.17.0
smmap==5.0.1
stack-data==0.6.3
sympy==1.13.1
tokenizers==0.21.0
tomlkit==0.13.2
torch==2.5.1
tornado==6.4.2
tqdm==4.67.1
traitlets==5.14.3
transformer-lens==2.10.0
transformers==4.47.1
triton==3.1.0 ; python_full_version < '3.13' and platform_machine == 'x86_64' and sys_platform == 'linux'
typeguard==4.4.1
typer==0.15.1
types-requests==2.32.0.20241016
types-tqdm==4.67.0.20241221
typing-extensions==4.12.2
tzdata==2024.2
urllib3==2.2.3
wandb==0.19.1
wcmatch==10.0
wcwidth==0.2.13
widgetsnbextension==4.0.13
xxhash==3.5.0
yarl==1.18.3
zanj==0.3.1

``````{ end_of_file: ".github/requirements/requirements.txt" }

``````{ path: ".github/versions/.version" }
v0.1.0
``````{ end_of_file: ".github/versions/.version" }

``````{ path: "data/pile_5.jsonl" }
{"text": "It is done, and submitted. You can play \u201cSurvival of the Tastiest\u201d on Android, and on the web. Playing on the web works, but you have to simulate multi-touch for table moving and that can be a bit confusing.\n\nThere\u2019s a lot I\u2019d like to talk about. I\u2019ll go through every topic, insted of making the typical what went right/wrong list.\n\nConcept\n\nWorking over the theme was probably one of the hardest tasks I had to face.\n\nOriginally, I had an idea of what kind of game I wanted to develop, gameplay wise \u2013 something with lots of enemies/actors, simple graphics, maybe set in space, controlled from a top-down view. I was confident I could fit any theme around it.\n\nIn the end, the problem with a theme like \u201cEvolution\u201d in a game is that evolution is unassisted. It happens through several seemingly random mutations over time, with the most apt permutation surviving. This genetic car simulator is, in my opinion, a great example of actual evolution of a species facing a challenge. But is it a game?\n\nIn a game, you need to control something to reach an objective. That control goes against what evolution is supposed to be like. If you allow the user to pick how to evolve something, it\u2019s not evolution anymore \u2013 it\u2019s the equivalent of intelligent design, the fable invented by creationists to combat the very idea of evolution. Being agnostic and a Pastafarian, that\u2019s not something that rubbed me the right way.\n\nHence, my biggest dillema when deciding what to create was not with what I wanted to create, but with what I did not. I didn\u2019t want to create an \u201cintelligent design\u201d simulator and wrongly call it evolution.\n\nThis is a problem, of course, every other contestant also had to face. And judging by the entries submitted, not many managed to work around it. I\u2019d say the only real solution was through the use of artificial selection, somehow. So far, I haven\u2019t seen any entry using this at its core gameplay.\n\nAlas, this is just a fun competition and after a while I decided not to be as strict with the game idea, and allowed myself to pick whatever I thought would work out.\n\nMy initial idea was to create something where humanity tried to evolve to a next level but had some kind of foe trying to stop them from doing so. I kind of had this image of human souls flying in space towards a monolith or a space baby (all based in 2001: A Space Odyssey of course) but I couldn\u2019t think of compelling (read: serious) mechanics for that.\n\nBorgs were my next inspiration, as their whole hypothesis fit pretty well into the evolution theme. But how to make it work? Are you the borg, or fighting the Borg?\n\nThe third and final idea came to me through my girlfriend, who somehow gave me the idea of making something about the evolution of Pasta. The more I thought about it the more it sounded like it would work, so I decided to go with it.\n\nConversations with my inspiring co-worker Roushey (who also created the \u201cMechanical Underdogs\u201d signature logo for my intros) further matured the concept, as it involved into the idea of having individual pieces of pasta flying around and trying to evolve until they became all-powerful. A secondary idea here was that the game would work to explain how the Flying Spaghetti Monster came to exist \u2013 by evolving from a normal dinner table.\n\nSo the idea evolved more or less into this: you are sitting a table. You have your own plate, with is your \u201cbase\u201d. There are 5 other guests at the table, each with their own plate.\n\nYour plate can spawn little pieces of pasta. You do so by \u201cordering\u201d them through a menu. Some pastas are better than others; some are faster, some are stronger. They have varying costs, which are debited from your credits (you start with a number of credits).\n\nOnce spawned, your pastas start flying around. Their instinct is to fly to other plates, in order to conquer them (the objective of the game is having your pasta conquer all the plates on the table). But they are really autonomous, so after being spawned, you have no control over your pasta (think DotA or LoL creeps).\n\nYour pasta doesn\u2019t like other people\u2019s pasta, so if they meet, they shoot sauce at each other until one dies. You get credits for other pastas your own pasta kill.\n\nOnce a pasta is in the vicinity of a plate, it starts conquering it for its team. It takes around 10 seconds for a plate to be conquered; less if more pasta from the same team are around. If pasta from other team are around, though, they get locked down in their attempt, unable to conquer the plate, until one of them die (think Battlefield\u2019s standard \u201cConquest\u201d mode).\n\nYou get points every second for every plate you own.\n\nOver time, the concept also evolved to use an Italian bistro as its main scenario.\n\nCarlos, Carlos\u2019 Bistro\u2019s founder and owner\n\nSetup\n\nNo major changes were made from my work setup. I used FDT and Starling creating an Adobe AIR (ActionScript) project, all tools or frameworks I already had some knowledge with.\n\nOne big change for me was that I livestreamed my work through a twitch.tv account. This was a new thing for me. As recommended by Roushey, I used a program called XSplit and I got to say, it is pretty amazing. It made the livestream pretty effortless and the features are awesome, even for the free version. It was great to have some of my friends watch me, and then interact with them and random people through chat. It was also good knowing that I was also recording a local version of the files, so I could make a timelapse video later.\n\nKnowing the video was being recorded also made me a lot more self-conscious about my computer use, as if someone was watching over my shoulder. It made me realize that sometimes I spend too much time in seemingly inane tasks (I ended up wasting the longest time just to get some text alignment the way I wanted \u2013 it\u2019ll probably drive someone crazy if they watch it) and that I do way too many typos where writing code. I pretty much spend half of the time writing a line and the other half fixing the crazy characters in it.\n\nMy own stream was probably boring to watch since I was coding for the most time. But livestreaming is one of the cool things to do as a spectator too. It was great seeing other people working \u2013 I had a few tabs opened on my second monitor all the time. It\u2019s actually a bit sad, because if I could, I could have spent the whole weekend just watching other people working! But I had to do my own work, so I\u2019d only do it once in a while, when resting for a bit.\n\nDesign\n\nAlthough I wanted some simple, low-fi, high-contrast kind of design, I ended up going with somewhat realistic (vector) art. I think it worked very well, fitting the mood of the game, but I also went overboard.\n\nFor example: to know the state of a plate (who owns it, who\u2019s conquering it and how much time they have left before conquering it, which pasta units are in the queue, etc), you have to look at the plate\u2019s bill.\n\nThe problem I realized when doing some tests is that people never look at the bill! They think it\u2019s some kind of prop, so they never actually read its details.\n\nPlus, if you\u2019re zoomed out too much, you can\u2019t actually read it, so it\u2019s hard to know what\u2019s going on with the game until you zoom in to the area of a specific plate.\n\nOne other solution that didn\u2019t turn out to be as perfect as I thought was how to indicate who a plate base belongs to. In the game, that\u2019s indicated by the plate\u2019s decoration \u2013 its color denotes the team owner. But it\u2019s something that fits so well into the design that people never realized it, until they were told about it.\n\nIn the end, the idea of going with a full physical metaphor is one that should be done with care. Things that are very important risk becoming background noise, unless the player knows its importance.\n\nOriginally, I wanted to avoid any kind of heads-up display in my game. In the end, I ended up adding it at the bottom to indicate your credits and bases owned, as well as the hideous out-of-place-and-still-not-obvious \u201cCall Waiter\u201d button. But in hindsight, I should have gone with a simple HUD from the start, especially one that indicated each team\u2019s colors and general state of the game without the need for zooming in and out.\n\nDevelopment\n\nDevelopment went fast. But not fast enough.\n\nEven though I worked around 32+ hours for this Ludum Dare, the biggest problem I had to face in the end was overscoping. I had too much planned, and couldn\u2019t get it all done.\n\nContent-wise, I had several kinds of pasta planned (Wikipedia is just amazing in that regard), split into several different groups, from small Pastina to huge Pasta al forno. But because of time constraints, I ended up scratching most of them, and ended up with 5 different types of very small pasta \u2013 barely something to start when talking about the evolution of Pasta.\n\nPastas used in the game. Unfortunately, the macs where never used\n\nWhich is one of the saddest things about the project, really. It had the framework and the features to allow an endless number of elements in there, but I just didn\u2019t have time to draw the rest of the assets needed (something I loved to do, by the way).\n\nOther non-obvious features had to be dropped, too. For example, when ordering some pasta, you were supposed to select what kind of sauce you\u2019d like with your pasta, each with different attributes. Bolognese, for example, is very strong, but inaccurate; Pesto is very accurate and has great range, but it\u2019s weaker; and my favorite, Vodka, would triggers 10% loss of speed on the pasta hit by it.\n\nThe code for that is mostly in there. But in the end, I didn\u2019t have time to implement the sauce selection interface; all pasta ended up using bolognese sauce.\n\nTo-do list: lots of things were not done\n\nActual programming also took a toll in the development time. Having been programming for a while, I like to believe I got to a point where I know how to make things right, but at the expense of forgetting how to do things wrong in a seemingly good way. What I mean is that I had to take a lot of shortcuts in my code to save time (e.g. a lot of singletons references for cross-communication rather than events or observers, all-encompassing check loops, not fast enough) that left a very sour taste in my mouth. While I know I used to do those a few years ago and survive, I almost cannot accept the state my code is in right now.\n\nAt the same time, I do know it was the right thing to do given the timeframe.\n\nOne small thing that had some impact was using a somewhat new platform for me. That\u2019s Starling, the accelerated graphics framework I used in Flash. I had tested it before and I knew how to use it well \u2013 the API is very similar to Flash itself. However, there were some small details that had some impact during development, making me feel somewhat uneasy the whole time I was writing the game. It was, again, the right thing to do, but I should have used Starling more deeply before (which is the conundrum: I used it for Ludum Dare just so I could learn more about it).\n\nArgument and user experience\n\nOne final aspect of the game that I learned is that making the game obvious for your players goes a long way into making it fun. If you have to spend the longest time explaining things, your game is doing something wrong.\n\nAnd that\u2019s exactly the problem Survival of the Tastiest ultimately faced. It\u2019s very hard for people to understand what\u2019s going on with the game, why, and how. I did have some introductory text at the beginning, but that was a last-minute thing. More importantly, I should have had a better interface or simplified the whole concept so it would be easier for people to understand.\n\nThat doesn\u2019t mean the game itself should be simple. It just means that the experience and interface should be approachable and understandable.\n\nConclusion\n\nI\u2019m extremely happy with what I\u2019ve done and, especially given that this was my first Ludum Dare. However, I feel like I\u2019ve learned a lot of what not to do.\n\nThe biggest problem is overscoping. Like Eric Decker said, the biggest lesson we can learn with this is probably with scoping \u2013 deciding what to do beforehand in a way you can complete it without having to rush and do something half-assed.\n\nI\u2019m sure I will do more Ludum Dares in the future. But if there are any lessons I can take of it, they are to make it simple, to use frameworks and platforms you already have some absolute experience with (otherwise you\u2019ll spend too much time trying to solve easy questions), and to scope for a game that you can complete in one day only (that way, you can actually take two days and make it cool).\n\nThis entry was posted\non Monday, August 27th, 2012 at 10:54 am and is filed under LD #24.\nYou can follow any responses to this entry through the RSS 2.0 feed.\nYou can skip to the end and leave a response. Pinging is currently not allowed.\n\n3 Responses to \u201c\u201cSurvival of the Tastiest\u201d Post-mortem\u201d\n\ndarn it , knowing that I missed your livestream makes me a sad panda ;( but more to the point, the game is \u2026 well for a startup its original to say the least ;D it has some really neat ideas and more importantly its designed arround touch screens whitch by the looks of the submission is something rare ;o or that could be just me and my short memory -_-! awesum game, love et <3", "meta": {"pile_set_name": "Pile-CC"}}
{"text": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\r\n<segment>\r\n    <name>PD1</name>\r\n    <description>Patient Additional Demographic</description>\r\n    <elements>\r\n        <field minOccurs=\"0\" maxOccurs=\"0\">\r\n            <name>PD1.1</name>\r\n            <description>Living Dependency</description>\r\n            <datatype>IS</datatype>\r\n        </field>\r\n        <field minOccurs=\"0\" maxOccurs=\"0\">\r\n            <name>PD1.2</name>\r\n            <description>Living Arrangement</description>\r\n            <datatype>IS</datatype>\r\n        </field>\r\n        <field minOccurs=\"0\" maxOccurs=\"0\">\r\n            <name>PD1.3</name>\r\n            <description>Patient Primary Facility</description>\r\n            <datatype>XON</datatype>\r\n        </field>\r\n        <field minOccurs=\"0\" maxOccurs=\"0\">\r\n            <name>PD1.4</name>\r\n            <description>Patient Primary Care Provider Name &amp; ID No.</description>\r\n            <datatype>XCN</datatype>\r\n        </field>\r\n        <field minOccurs=\"0\" maxOccurs=\"0\">\r\n            <name>PD1.5</name>\r\n            <description>Student Indicator</description>\r\n            <datatype>IS</datatype>\r\n        </field>\r\n        <field minOccurs=\"0\" maxOccurs=\"0\">\r\n            <name>PD1.6</name>\r\n            <description>Handicap</description>\r\n            <datatype>IS</datatype>\r\n        </field>\r\n        <field minOccurs=\"0\" maxOccurs=\"0\">\r\n            <name>PD1.7</name>\r\n            <description>Living Will Code</description>\r\n            <datatype>IS</datatype>\r\n        </field>\r\n        <field minOccurs=\"0\" maxOccurs=\"0\">\r\n            <name>PD1.8</name>\r\n            <description>Organ Donor Code</description>\r\n            <datatype>IS</datatype>\r\n        </field>\r\n        <field minOccurs=\"0\" maxOccurs=\"0\">\r\n            <name>PD1.9</name>\r\n            <description>Separate Bill</description>\r\n            <datatype>ID</datatype>\r\n        </field>\r\n        <field minOccurs=\"0\" maxOccurs=\"0\">\r\n            <name>PD1.10</name>\r\n            <description>Duplicate Patient</description>\r\n            <datatype>CX</datatype>\r\n        </field>\r\n        <field minOccurs=\"0\" maxOccurs=\"0\">\r\n            <name>PD1.11</name>\r\n            <description>Publicity Code</description>\r\n            <datatype>CE</datatype>\r\n        </field>\r\n        <field minOccurs=\"0\" maxOccurs=\"0\">\r\n            <name>PD1.12</name>\r\n            <description>Protection Indicator</description>\r\n            <datatype>ID</datatype>\r\n        </field>\r\n        <field minOccurs=\"0\" maxOccurs=\"0\">\r\n            <name>PD1.13</name>\r\n            <description>Protection Indicator Effective Date</description>\r\n            <datatype>DT</datatype>\r\n        </field>\r\n        <field minOccurs=\"0\" maxOccurs=\"0\">\r\n            <name>PD1.14</name>\r\n            <description>Place of Worship</description>\r\n            <datatype>XON</datatype>\r\n        </field>\r\n        <field minOccurs=\"0\" maxOccurs=\"0\">\r\n            <name>PD1.15</name>\r\n            <description>Advance Directive Code</description>\r\n            <datatype>CE</datatype>\r\n        </field>\r\n        <field minOccurs=\"0\" maxOccurs=\"0\">\r\n            <name>PD1.16</name>\r\n            <description>Immunization Registry Status</description>\r\n            <datatype>IS</datatype>\r\n        </field>\r\n        <field minOccurs=\"0\" maxOccurs=\"0\">\r\n            <name>PD1.17</name>\r\n            <description>Immunization Registry Status Effective Date</description>\r\n            <datatype>DT</datatype>\r\n        </field>\r\n        <field minOccurs=\"0\" maxOccurs=\"0\">\r\n            <name>PD1.18</name>\r\n            <description>Publicity Code Effective Date</description>\r\n            <datatype>DT</datatype>\r\n        </field>\r\n        <field minOccurs=\"0\" maxOccurs=\"0\">\r\n            <name>PD1.19</name>\r\n            <description>Military Branch</description>\r\n            <datatype>IS</datatype>\r\n        </field>\r\n        <field minOccurs=\"0\" maxOccurs=\"0\">\r\n            <name>PD1.20</name>\r\n            <description>Military Rank/Grade</description>\r\n            <datatype>IS</datatype>\r\n        </field>\r\n        <field minOccurs=\"0\" maxOccurs=\"0\">\r\n            <name>PD1.21</name>\r\n            <description>Military Status</description>\r\n            <datatype>IS</datatype>\r\n        </field>\r\n    </elements>\r\n</segment>\r\n", "meta": {"pile_set_name": "Github"}}
{"text": "Article content\n\nHuman behavior has a tremendous impact on investing \u2014 more so than most realize \u2014 and one of our biggest weaknesses is the tendency to constantly compare and contrast ourselves to others.\n\n[np_storybar title=\u201dFollow Financial Post\u201d link=\u201d\u201d]\n\nWe apologize, but this video has failed to load.\n\ntap here to see other videos from our team. Try refreshing your browser, or Three signs bubbles are brewing again in the market \u2014 and one of them has wheels Back to video\n\n\u2022 Twitter\n\n\u2022 Facebook\n\n[/np_storybar]\n\nFor example, a 1995 study by the Harvard School of Public Health indicated that people will forgo a stronger income scenario in favour of a weaker one as long as it meant earning more than their neighbours.\n\nUnfortunately, many in the investment world are keenly aware of this and will structure their marketing efforts accordingly. As a result, you have a compounding of momentum or trends in the market as investors buy at or near market tops for fear of not doing as well as or better than others.\n\nFor the same reason, investors piled into technology stocks in 2000 with only the promise of earnings in some distant future, and into housing-related investments in 2007 that were backstopped by very low incomes.", "meta": {"pile_set_name": "OpenWebText2"}}
{"text": "Topic: reinvent midnight madness\n\nAmazon announced a new service at the AWS re:Invent Midnight Madness event. Amazon Sumerian is a solution that aims to make it easier for developers to build virtual reality, augmented reality, and 3D applications. It features a user friendly editor, which can be used to drag and drop 3D objects and characters into scenes. Amazon \u2026 continue reading", "meta": {"pile_set_name": "Pile-CC"}}
{"text": "About Grand Slam Fishing Charters\n\nAs a family owned business we know how important it is that your trip becomes the best memory of your vacation, we are proud of our islands, our waters and our crew and we are desperate show you the best possible time during your stay. We can not guarantee fish every time but we can guarantee you a great time! The biggest perk of our job is seeing so many of our customers become close friends\u201d\n\nA Great Way To Make New Friends!\n\nOur dockside parties are a great way to make new friends! Everyone is welcome!\n\nAndrea runs the whole operation, from discussing your initial needs by phone or email through to ensuring you have sufficient potato chips. Andrea has worked as concierge for many International resorts and fully understands the high expectations of international visitors.\n\n\u201cLife\u2019s A Game But Fishing Is Serious!\u201d\n\nUnlike many tour operators, our crew are highly valued and have been with us since day 1. Each have their own personalities and sense of humour and understand the importance of making your day perfect, for us the saying is true, \u201cLifes a game but fishing is serious!\u201d\n\nTRIP ADVISOR\n\nPlan Your Trip!\n\nAJ and Earl were excellent. My son and I did a half day deep sea trip and though the fish weren\u2019t too cooperative, they did everything to try to get something to bite. Very knowledgeable about the waters and my son was able to land a nice barracuda. The next day my wife, daughter, son [\u2026]\n\nWhen we arrived the crew made us feel right at home. They made us feel comfortable and answered all questions. The crew worked hard all day to put us on fish. We were successful in landing a nice size Wahoo even though the weather did not cooperate the entire day was enjoyable. I highly recommend [\u2026]", "meta": {"pile_set_name": "Pile-CC"}}
``````{ end_of_file: "data/pile_5.jsonl" }

``````{ path: "pattern_lens/frontend/index.html" }
<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <!-- <meta name="viewport" content="width=device-width, initial-scale=1.0"> -->
    <title>Attention Pattern Analysis</title>

    <link rel="icon" type="image/svg+xml"
        href='data:image/svg+xml,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 100 100"><rect width="100" height="100" fill="%23000" stroke="%23333" stroke-width="1"/><path d="M0,0 L100,100 L0,100 Z" fill="rgba(0,255,255,0.2)"/><path d="M0,0 L15,15 L0,15 Z" fill="rgba(255,255,255,0.3)"/><path d="M15,15 L35,35 L15,35 Z" fill="rgba(255,255,255,0.3)"/><path d="M35,35 L60,60 L35,60 Z" fill="rgba(255,255,255,0.3)"/><path d="M60,60 L100,100 L60,100 Z" fill="rgba(255,255,255,0.3)"/></svg>'>

    <!--
    #### ##     ## ########   #######  ########  ########  ######
     ##  ###   ### ##     ## ##     ## ##     ##    ##    ##    ##
     ##  #### #### ##     ## ##     ## ##     ##    ##    ##
     ##  ## ### ## ########  ##     ## ########     ##     ######
     ##  ##     ## ##        ##     ## ##   ##      ##          ##
     ##  ##     ## ##        ##     ## ##    ##     ##    ##    ##
    #### ##     ## ##         #######  ##     ##    ##     ######
    -->

    <script src="https://cdnjs.cloudflare.com/ajax/libs/vue/3.2.31/vue.global.min.js"></script>
    <!-- Include lodash library for utility functions -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/lodash.js/4.17.21/lodash.min.js"></script>
    <!-- Include pako library for decompressing SVGZ files -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/pako/2.0.4/pako.min.js"></script>
    <!-- For decompressing SVGZ files -->
    <!-- Include ag-Grid library for prompts table -->
    <!-- <script src="https://cdnjs.cloudflare.com/ajax/libs/ag-grid/32.1.0/ag-grid-community.min.js"></script> -->
    <script src="https://cdn.jsdelivr.net/npm/ag-grid-community@32.2.0/dist/ag-grid-community.min.js"></script>


    <!--
     ######   ######   ######
    ##    ## ##    ## ##    ##
    ##       ##       ##
    ##        ######   ######
    ##             ##       ##
    ##    ## ##    ## ##    ##
     ######   ######   ######
    -->
    <style>
        /* CSS Variables */
        :root {
            /* Colors */
            --primary: #007bff;
            --primary-hover: #0056b3;
            --secondary: #6c757d;
            --secondary-hover: #545b62;
            --success: #28a745;
            --border: #ccc;
            --text-muted: #666;
            --bg-light: #f0f0f0;
            --bg-white: #fff;
            --shadow: rgba(0, 0, 0, 0.1);
            --text-color: #000;

            /* Dark mode colors */
            --dark-bg: #1a1a1a;
            --dark-text: #ffffff;
            --dark-border: #444;
            --dark-bg-light: #2d2d2d;
            --dark-shadow: rgba(0, 0, 0, 0.3);

            /* Spacing */
            --space-xs: 3px;
            --space-sm: 5px;
            --space-md: 10px;
            --space-lg: 20px;

            /* Layout */
            --border-radius: 4px;
            --container-max-width: 1200px;
            --checkbox-size: 12px;
        }

        /* Base Styles */
        body {
            font-family: Arial, sans-serif;
            line-height: 1.4;
            margin: 0;
            padding: var(--space-md);
        }

        .container {
            max-width: var(--container-max-width);
            margin: 0 auto;
        }

        /* Header Styles */
        .header-container {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 1rem;
        }

        .header-title {
            margin: 0;
        }

        .header-controls {
            display: flex;
            gap: 1rem;
            align-items: center;
        }

        /* Layout Components */
        .main-selection-content {
            display: flex;
            flex-direction: column;
            border: 2px solid var(--border);
            height: 800px;
            min-height: 400px;
            resize: vertical;
            overflow: hidden;
        }

        .top-filters {
            display: flex;
            gap: var(--space-md);
            height: 350px;
            border-bottom: 1px solid var(--border);
            min-height: 100px;
            max-height: 80vh;
            padding: var(--space-md);
            resize: vertical;
            position: relative;
            overflow: auto;
        }

        /* Functions Filter */
        .functions-filter {
            width: 200px;
            min-width: 100px;
            max-width: 500px;
            display: flex;
            flex-direction: column;
            border: 1px solid var(--border);
            padding: var(--space-md);
            border-radius: var(--border-radius);
            flex-shrink: 0;
        }

        /* Filter Components */
        .filter-item {
            margin-bottom: var(--space-sm);
            border: 1px solid var(--border);
            padding: var(--space-sm);
            border-radius: var(--border-radius);
        }

        .filter-label {
            display: flex;
            align-items: center;
            justify-content: space-between;
            margin-bottom: var(--space-xs);
        }

        /* Checkbox Lists */
        .checkbox-list {
            border: 1px solid var(--border);
            padding: var(--space-xs);
            flex: 1;
            overflow-y: auto;
            overflow-x: visible;
        }

        .checkbox-item {
            position: relative;
            display: flex;
            align-items: center;
            margin-bottom: 1px;
            line-height: 1;
            width: 100%;
        }

        .checkbox-item label {
            display: flex;
            align-items: center;
            justify-content: space-between;
            width: 100%;
            margin-left: 4px;
        }

        .function-name {
            flex-grow: 1;
            margin-right: 8px;
        }

        input[type="checkbox"] {
            margin: 0 0.2em 0 0;
            width: var(--checkbox-size);
            height: var(--checkbox-size);
            vertical-align: middle;
        }

        /* Head Grid */
        .head-grid {
            display: flex;
            gap: 1px;
            margin: 0 8px;
            height: 100%;
            align-items: center;
        }

        .headsGrid-col {
            display: flex;
            flex-direction: column;
            gap: 1px;
            height: 100%;
            justify-content: center;
        }

        .headsGrid-cell {
            width: 5px;
            height: 5px;
            margin: 0.5px;
            transition: background-color 0.2s ease;
        }

        .headsGrid-cell-selected {
            background-color: #2a1fee;
        }

        .headsGrid-cell-empty {
            background-color: #ac9a9a;
        }

        /* Model Grid */
        #modelGrid {
            flex: 1;
            min-width: 200px;
            overflow: auto;
        }

        /* Prompt Table */
        .prompt-table {
            flex: 1;
            min-height: 200px;
            display: flex;
            flex-direction: column;
            overflow: hidden;
            position: relative;
        }

        .prompts-info {
            border: 1px solid var(--border);
            padding: var(--space-sm);
            border-radius: var(--border-radius);
        }

        .prompt-counter {
            display: flex;
            align-items: center;
            justify-content: space-between;
        }

        .prompt-text-cell {
            cursor: pointer;
        }

        /* ag-Grid Customization */
        .ag-theme-alpine {
            height: calc(100% - 3em) !important;
            width: 100% !important;
        }

        .ag-cell-edit-input {
            height: 100% !important;
            line-height: normal !important;
            padding: 0 8px !important;
        }

        .ag-cell:not(.invalid-selection) {
            background-color: transparent !important;
        }

        .ag-cell.invalid-selection {
            background-color: #ffeaea !important;
        }

        /* Dataset List */
        .dataset-list-container {
            position: absolute;
            right: var(--space-md);
            top: 0.5em;
        }

        .dataset-list {
            position: relative;
            cursor: pointer;
            border: 1px solid var(--border);
            padding: 1px;
            border-radius: var(--border-radius);
            background-color: #f9f9f9;
        }

        .dataset-list-content {
            display: none;
            position: absolute;
            right: 0;
            top: 100%;
            background-color: var(--bg-white);
            border: 1px solid var(--border);
            padding: var(--space-xs) var(--space-lg) var(--space-xs) var(--space-xs);
            font-family: monospace;
            box-shadow: 0 4px 8px var(--shadow);
            z-index: 1000;
        }

        .dataset-list:hover .dataset-list-content {
            display: block;
        }

        /* Image Controls and Display */
        .image-controls-container {
            margin: var(--space-lg) 0;
        }

        .image-controls {
            display: flex;
            align-items: center;
            justify-content: space-between;
            padding: var(--space-md);
            background-color: var(--bg-light);
            border-radius: 8px;
            box-shadow: 0 2px 4px var(--shadow);
        }

        .image-controls-display,
        .image-controls-size {
            display: flex;
            align-items: center;
            width: 50%;
        }

        .image-controls-size {
            justify-content: flex-end;
        }

        .resize-slider {
            width: 250px;
            margin: 0 var(--space-md);
        }

        .resize-input {
            width: 75px;
            padding: 2px var(--space-sm);
        }

        /* Image Grid */
        .images {
            display: grid;
            gap: var(--space-sm);
            margin-top: var(--space-md);
        }

        .image-container {
            text-align: center;
        }

        .image-info {
            font-size: 0.8em;
            margin: 2em 0 -1em;
        }

        .img-container svg,
        .img-container img {
            width: 100%;
            height: 100%;
            object-fit: contain;
            image-rendering: pixelated;
            -ms-interpolation-mode: nearest-neighbor;
        }

        /* Buttons */
        .btn {
            margin: 5px;
            padding: 8px 16px;
            font-size: 14px;
            font-weight: bold;
            border: none;
            border-radius: var(--border-radius);
            cursor: pointer;
            transition: background-color 0.3s ease;
        }

        .btn-primary {
            background-color: var(--primary);
            color: white;
        }

        .btn-primary:hover {
            background-color: var(--primary-hover);
        }

        .btn-secondary,
        .btn-header,
        .btn-dark-mode {
            background-color: var(--secondary);
            color: white;
        }

        .btn-secondary:hover,
        .btn-header:hover,
        .btn-dark-mode:hover {
            background-color: var(--secondary-hover);
        }

        /* Progress Bar */
        .progress-bar {
            height: 12px;
            width: 200px;
            background: #ddd;
            border-radius: 6px;
            overflow: hidden;
        }

        .progress-bar-fill {
            height: 100%;
            transition: width 0.3s ease;
        }

        .progress-bar-fill.loading {
            background-color: var(--primary);
        }

        .progress-bar-fill.complete {
            background-color: var(--success);
        }

        .progress-wrapper {
            padding-left: 1rem;
        }

        /* Function Info Tooltip */
        .function-info {
            position: relative;
            cursor: help;
            display: flex;
            align-items: center;
            margin-left: auto;
        }

        .function-tooltip {
            display: none;
            position: fixed;
            background-color: #eee;
            border: 1px solid #ccc;
            padding: 8px;
            width: 250px;
            z-index: 9999999;
            border-radius: 4px;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.2);
        }

        .function-info:hover .function-tooltip {
            display: block;
        }

        /* Dark Mode Styles */
        .dark-mode {
            background-color: var(--dark-bg);
            color: var(--dark-text);
        }

        .dark-mode .container {
            background-color: var(--dark-bg);
        }

        .dark-mode .functions-filter,
        .dark-mode .filter-item,
        .dark-mode .checkbox-list {
            background-color: var(--dark-bg-light);
            border-color: var(--dark-border);
        }

        .dark-mode .ag-theme-alpine {
            --ag-background-color: var(--dark-bg-light);
            --ag-header-background-color: var(--dark-bg);
            --ag-odd-row-background-color: var(--dark-bg);
            --ag-header-foreground-color: var(--dark-text);
            --ag-foreground-color: var(--dark-text);
            --ag-border-color: var(--dark-border);
        }

        .dark-mode .top-controls {
            background-color: var(--dark-bg-light);
        }

        .dark-mode .dataset-list,
        .dark-mode .dataset-list-content {
            background-color: var(--dark-bg-light);
            border-color: var(--dark-border);
            color: var(--dark-text);
        }

        .dark-mode .dataset-list-content ul {
            margin: 0;
            padding: 0.5em 1em;
            list-style-type: none;
        }

        .dark-mode .dataset-list-content li {
            color: var(--dark-text);
            padding: 0.2em 0;
        }

        .dark-mode .image-controls-container {
            background-color: transparent;
        }

        .dark-mode .image-controls {
            background-color: var(--dark-bg-light);
            border-color: var(--dark-border);
            box-shadow: 0 2px 4px var(--dark-shadow);
        }

        .dark-mode .resize-slider,
        .dark-mode .resize-input {
            background-color: var(--dark-bg);
            border-color: var(--dark-border);
        }

        .dark-mode .resize-input {
            color: var(--dark-text);
        }

        .dark-mode .image-controls label {
            color: var(--dark-text);
        }

        .dark-mode .progress-bar {
            background-color: var(--dark-bg);
            border: 1px solid var(--dark-border);
        }

        .dark-mode .progress-status {
            color: var(--dark-text);
        }

        .dark-mode .function-tooltip {
            background-color: var(--dark-bg-light);
            border-color: var(--dark-border);
            color: var(--dark-text);
        }

        /* Utility Classes */
        .loading,
        .error {
            text-align: center;
            padding: var(--space-md);
        }

        .counter {
            font-size: 0.8em;
            color: var(--text-muted);
            margin-left: auto;
        }

        /* Dark Mode Toggle */
        .dark-mode-toggle {
            position: relative;
            width: 60px;
            height: 30px;
            border-radius: 15px;
            background-color: #e2e8f0;
            cursor: pointer;
            transition: background-color 0.3s ease;
            border: none;
            padding: 0;
            overflow: hidden;
        }

        .dark-mode-toggle::before {
            content: "";
            position: absolute;
            top: 3px;
            left: 3px;
            width: 24px;
            height: 24px;
            border-radius: 50%;
            background-color: white;
            transition: transform 0.3s ease;
            z-index: 1;
        }

        .dark-mode .dark-mode-toggle {
            background-color: #4a5568;
        }

        .dark-mode .dark-mode-toggle::before {
            transform: translateX(30px);
        }

        .dark-mode-icon {
            position: absolute;
            top: 50%;
            transform: translateY(-50%);
            font-size: 14px;
            pointer-events: none;
            line-height: 1;
            display: flex;
            align-items: center;
            justify-content: center;
            width: 24px;
            height: 24px;
        }

        .sun-icon {
            left: 8px;
            opacity: 1;
        }

        .moon-icon {
            right: 8px;
            opacity: 1;
        }

        .dark-mode-button {
            display: flex;
            align-items: center;
            gap: 8px;
            cursor: pointer;
            color: inherit;
        }
    </style>
</head>

<body>
    <!--
    ##     ## ######## ##     ## ##
    ##     ##    ##    ###   ### ##
    ##     ##    ##    #### #### ##
    #########    ##    ## ### ## ##
    ##     ##    ##    ##     ## ##
    ##     ##    ##    ##     ## ##
    ##     ##    ##    ##     ## ########
    -->
    <!-- Root element for Vue app -->
    <div id="app" class="container" :class="{ 'dark-mode': isDarkMode }">
        <div class="header-container">
            <h1 class="header-title">Attention Pattern Analysis</h1>
            <div class="header-controls">
                <button class="btn btn-header dark-mode-button" @click="toggleDarkMode">
                    <span>Dark Mode</span>
                    <div class="dark-mode-toggle">
                        <div class="dark-mode-icon" style="left: 4px">☀️</div>
                        <div class="dark-mode-icon" style="right: 4px">🌙</div>
                    </div>
                </button>
                <button class="btn btn-header" @click="clearAllSelections">
                    🗑️ Clear All Selections
                </button>
            </div>
        </div>

        <div class="main-selection-content">
            <!-- Top section with functions and models side by side -->
            <div class="top-filters">
                <!-- Functions Filter -->
                <div class="functions-filter">
                    <div class="filter-label">
                        <input type="checkbox" id="select-all-functions"
                            :indeterminate.prop="isIndeterminate('functions')" :checked="isChecked('functions')"
                            @change="toggleSelectAll('functions', $event)">
                        <label for="select-all-functions">Functions:</label>
                        <span class="counter">
                            {{ filters.selected.functions.length }} / {{ Object.keys(filters.available.functions).length
                            }}
                        </span>
                    </div>
                    <div class="checkbox-list">
                        <div v-for="(func, name) in filters.available.functions" :key="name" class="checkbox-item">
                            <input type="checkbox" :id="'func-' + name" :value="name"
                                v-model="filters.selected.functions">
                            <label :for="'func-' + name">
                                <span class="function-name">{{ name }}</span>
                                <span class="function-info">ℹ️
                                    <div class="function-tooltip">
                                        <div v-if="func.doc"><strong>Description:</strong> {{ func.doc }}</div>
                                        <div v-if="func.figure_save_fmt"><strong>Format:</strong> {{
                                            func.figure_save_fmt }}</div>
                                        <div v-if="func.source"><strong>Source:</strong> {{ func.source }}</div>
                                    </div>
                                </span>
                            </label>
                        </div>
                    </div>
                </div>

                <!-- Model Selection -->
                <div id="modelGrid" class="ag-theme-alpine" style="height: 300px; width: 100%;"></div>
            </div>

            <!-- Prompts Table (full width) -->
            <div class="prompt-table">
                <div class="prompts-info">
                    <div class="prompt-counter">
                        Selected Prompts: {{ prompts.selected.length }} / {{ Object.keys(prompts.all).length }}
                    </div>
                    <div class="dataset-list-container">
                        <div class="dataset-list">
                            Hover here to see unique datasets
                            <div class="dataset-list-content">
                                <ul>
                                    <li v-for="dataset in uniqueDatasets" :key="dataset">{{ dataset }}</li>
                                </ul>
                            </div>
                        </div>
                    </div>
                </div>
                <div id="promptGrid" class="ag-theme-alpine"></div>
            </div>
        </div>

        <!-- image display button and size controls -->
        <div class="image-controls-container">
            <div class="image-controls">
                <div class="image-controls-display">
                    <button class="btn" :class="{ 'btn-primary': !images.upToDate, 'btn-secondary': images.upToDate }"
                        @click="displayImages">
                        {{ images.upToDate ? 'Images Up to Date' : 'Display Images' }}
                    </button>
                    <div class="progress-wrapper">
                        <span class="progress-status" v-if="images.expected > 0"> {{ images.visible.length || 'N/A' }} /
                            {{ images.expected }} images</span>
                        <div class="progress-bar" v-if="loading || images.visible.length > 0">
                            <div class="progress-bar-fill" :class="{ 'loading': loading, 'complete': !loading }"
                                :style="{ width: `${(images.visible.length / images.expected) * 100}%` }">
                            </div>
                        </div>
                    </div>
                </div>
                <div class="image-controls-size" v-if="images.visible.length > 0">
                    <label for="resizeSlider">Images per row:</label>
                    <input type="range" id="resizeSlider" class="resize-slider" v-model.number="images.perRow" min="1"
                        max="16" step="1">
                    <input type="number" class="resize-input" v-model.number="images.perRow" min="1" max="64">
                </div>
            </div>
        </div>

        <!-- images are loading -->
        <div v-if="loading" class="loading">Loading...</div>

        <!-- actual images display -->
        <div v-else-if="images.visible.length > 0" class="images"
            :style="{ 'grid-template-columns': `repeat(${images.perRow}, 1fr)` }">
            <div v-for="image in images.visible" class="image-container">
                <p v-if="images.perRow <= 4" class="image-info">
                    <a :href="getSinglePropertyFilterUrl('models', image.model)">{{ image.model }}</a> -
                    <a :href="getSinglePropertyFilterUrl('functions', image.function)">{{ image.function }}</a> -
                    <a :href="getSinglePropertyFilterUrl('layers', image.layer)">L{{ image.layer }}</a> -
                    <a :href="getSinglePropertyFilterUrl('heads', image.head)">H{{ image.head }}</a> -
                    <a :href="getSinglePropertyFilterUrl('prompts', image.promptHash)">{{ image.promptHash }}</a>
                </p>
                <a :href="getImageUrl(image)" class="img-container" v-html="image.content"
                    :title="images.perRow > 4 ? image.name : ''">
                </a>
            </div>
        </div>

        <!-- no images found -->
        <div v-else-if="images.requested" class="error">No images found for the selected criteria.</div>

    </div>

    <script>
        // Utility functions for file and directory operations
        //  ######   #######  ##    ##  ######  ########  ######
        // ##    ## ##     ## ###   ## ##    ##    ##    ##    ##
        // ##       ##     ## ####  ## ##          ##    ##
        // ##       ##     ## ## ## ##  ######     ##     ######
        // ##       ##     ## ##  ####       ##    ##          ##
        // ##    ## ##     ## ##   ### ##    ##    ##    ##    ##
        //  ######   #######  ##    ##  ######     ##     ######
        const DATA_DIR = '.';
        const FIGURE_FORMATS = ['svg', 'svgz', 'png'];
        const URL_HEAD_PREFIX = 'heads-';
        const fileOps = {
            async getDirectoryContents(path) {
                const response = await fetch(`${path}/index.txt`);
                const text = await response.text();
                return text.trim().split('\n');
            },
            async fileExists(path) {
                const response = await fetch(path, { method: 'HEAD' });
                return response.ok;
            },
            async fetchJson(path) {
                const response = await fetch(path);
                return response.json();
            },
            async fetchJsonL(path) {
                const response = await fetch(path);
                const text = await response.text();
                // allow for the last line being incomplete
                const text_split = text.trim().split('\n');
                let output = text_split.slice(0, -1).map(JSON.parse);
                try {
                    output.push(JSON.parse(text_split[text_split.length - 1]));
                } catch (error) {
                    console.error('Error parsing last line of JSONL:', error);
                }
                return output;
            },
            async fetchAndDecompressSvgz(path) {
                // returns null if file does not exist
                const response = await fetch(path);
                if (!response.ok) {
                    return null;
                } else {
                    const arrayBuffer = await response.arrayBuffer();
                    const uint8Array = new Uint8Array(arrayBuffer);
                    return pako.inflate(uint8Array, { to: 'string' });
                }
            },
            async figureExists(path) {
                for (const format of FIGURE_FORMATS) {
                    fig_path = `${path}.${format}`;
                    if (await this.fileExists(fig_path)) {
                        return format;
                    }
                }
                return null;
            }
        };
        // Create a new Vue.js application
        const app = Vue.createApp({

            // ########     ###    ########    ###
            // ##     ##   ## ##      ##      ## ##
            // ##     ##  ##   ##     ##     ##   ##
            // ##     ## ##     ##    ##    ##     ##
            // ##     ## #########    ##    #########
            // ##     ## ##     ##    ##    ##     ##
            // ########  ##     ##    ##    ##     ##

            data() {
                return {
                    isDarkMode: false,
                    prompts: {
                        all: {},        // hash -> prompt mapping
                        selected: [],   // selected from table
                        grid: {
                            api: null,
                            isReady: false
                        },
                    },
                    loading: false,
                    images: {
                        visible: [],
                        expected: 0,
                        requested: false,
                        upToDate: false,
                        perRow: 4,
                    },
                    models: {
                        configs: {},    // model -> config mapping
                        grid: {
                            api: null,
                        },
                    },
                    filters: {
                        available: {    // all available options
                            models: [],
                            functions: [],
                            layers: [],
                            heads: [],
                        },
                        selected: {     // currently selected options
                            models: [],
                            functions: [],
                            layers: [],
                            heads: [],
                        },
                    },
                    head_selections_str: {}, // model -> selection string mapping
                };
            },

            methods: {

                // ##     ## ########    ###    ########   ######
                // ##     ## ##         ## ##   ##     ## ##    ##
                // ##     ## ##        ##   ##  ##     ## ##
                // ######### ######   ##     ## ##     ##  ######
                // ##     ## ##       ######### ##     ##       ##
                // ##     ## ##       ##     ## ##     ## ##    ##
                // ##     ## ######## ##     ## ########   ######

                // Parse head selection string and return a 2D array of booleans
                parseHeadString(str, maxLayer, maxHead) {
                    try {
                        const result = Array(maxLayer).fill().map(() => Array(maxHead).fill(false));
                        if (!str || str.trim() === '') return result;

                        const selections = str.replaceAll("x", "*").split(',').map(s => s.trim());

                        for (const selection of selections) {
                            const match = selection.match(/^L(\d+|\d+-\d+|\*)(H\d+|H\*|Hx)?$/);
                            if (!match) return null;

                            const layerPart = match[1];
                            let headPart = match[2];

                            // If the user typed only "L8" (no head specification), default to H*
                            if (!headPart) {
                                headPart = 'H*';
                            }

                            let layers = [];
                            if (layerPart === '*') {
                                layers = Array.from({ length: maxLayer }, (_, i) => i);
                            } else if (layerPart.includes('-')) {
                                const [start, end] = layerPart.split('-').map(Number);
                                if (start > end || end >= maxLayer) return null;
                                layers = Array.from({ length: end - start + 1 }, (_, i) => start + i);
                            } else {
                                const layer = Number(layerPart);
                                if (layer >= maxLayer) return null;
                                layers = [layer];
                            }

                            const headStr = headPart.substring(1);
                            if (headStr === '*' || headStr === 'x') {
                                for (const layer of layers) {
                                    result[layer].fill(true);
                                }
                            } else {
                                const head = Number(headStr);
                                if (head >= maxHead) return null;
                                for (const layer of layers) {
                                    result[layer][head] = true;
                                }
                            }
                        }

                        return result;
                    } catch (e) {
                        console.error('Error parsing head string:', e);
                        return null;
                    }
                },

                isHeadSelected(model, layer, head) {
                    // First check if we have parsed selections for this model
                    if (!this.head_selections_arr[model]) {
                        console.warn(`No parsed head selections found for model: ${model}`);
                        return false;
                    }

                    try {
                        // Verify layer and head are within bounds
                        const parsedSelections = this.head_selections_arr[model];
                        if (!Array.isArray(parsedSelections) ||
                            !Array.isArray(parsedSelections[layer]) ||
                            typeof parsedSelections[layer][head] === 'undefined') {
                            console.warn(
                                `Invalid layer/head combination for ${model}: L${layer}H${head}`,
                                `Max bounds: L${parsedSelections.length - 1}H${parsedSelections[0]?.length - 1}`
                            );
                            return false;
                        }

                        return parsedSelections[layer][head];
                    } catch (e) {
                        console.error('Error checking head selection:', e);
                        console.log('Model:', model, 'Layer:', layer, 'Head:', head);
                        return false;
                    }
                },

                isValidHeadSelection(model) {
                    return this.head_selections_arr[model] !== null;
                },
                // ##     ## ########  ##
                // ##     ## ##     ## ##
                // ##     ## ##     ## ##
                // ##     ## ########  ##
                // ##     ## ##   ##   ##
                // ##     ## ##    ##  ##
                //  #######  ##     ## ########

                // Modified URL handling
                updateURL() {
                    const params = new URLSearchParams();

                    if (this.filters.selected.functions.length > 0) {
                        params.set('functions', this.filters.selected.functions.join('~'));
                    }

                    if (this.prompts.selected.length > 0) {
                        params.set('prompts', this.prompts.selected.join('~'));
                    }

                    if (this.filters.selected.models.length > 0) {
                        params.set('models', this.filters.selected.models.join('~'));
                    }

                    if (this.filters.selected.models.length > 0) {
                        for (const model of Object.keys(this.head_selections_str)) {
                            params.set(
                                `${URL_HEAD_PREFIX}${model}`,
                                this.head_selections_str[model].replaceAll("*", "x").replaceAll(" ", "").split(',').join('~')
                            );
                        }
                    }

                    const newURL = `${window.location.pathname}?${params.toString()}`;
                    history.replaceState(null, '', newURL);
                },

                readURL() {
                    const params = new URLSearchParams(window.location.search);

                    this.filters.selected.functions = params.get('functions')?.split('~') || [];

                    this.prompts.selected = params.get('prompts')?.split('~') || [];

                    this.filters.selected.models = params.get('models')?.split('~') || [];

                    try {
                        this.head_selections_str = {};
                        for (const [key, value] of params) {
                            if (key.startsWith(URL_HEAD_PREFIX)) {
                                const model = key.substring(URL_HEAD_PREFIX.length);
                                this.head_selections_str[model] = value.split('~').join(', ');
                            }
                        }
                    } catch (e) {
                        console.error('Error parsing head selections from URL:', e);
                    }
                },
                selectPromptsFromURL() {
                    if (!this.isGridReady || this.prompts.selected.length === 0) return;

                    const promptSet = new Set(this.prompts.selected);
                    this.prompts.grid.api.forEachNode((node) => {
                        if (promptSet.has(node.data.hash)) {
                            node.setSelected(true);
                        }
                    });
                },
                getImageUrl(image) {
                    return this.getFilterUrl('all', [image.model], [image.promptHash], [image.layer], [image.head], [image.function]);
                },

                getSinglePropertyFilterUrl(type, value) {
                    const params = new URLSearchParams(window.location.search);
                    params.set(type, value); // This preserves other params while updating just this one
                    return `${window.location.pathname}?${params.toString()}`;
                },

                getFilterUrl(type, ...values) {
                    const params = new URLSearchParams(window.location.search);

                    if (type === 'all') {
                        params.set('models', values[0].join('~'));
                        params.set('prompts', values[1].join('~'));
                        params.set('layers', values[2].join('~'));
                        params.set('heads', values[3].join('~'));
                        params.set('functions', values[4].join('~'));
                    } else {
                        params.set(type, values.flat().join('~'));
                    }

                    return `${window.location.pathname}?${params.toString()}`;
                },

                // ##     ## ######## ##       ########  ######## ########
                // ##     ## ##       ##       ##     ## ##       ##     ##
                // ##     ## ##       ##       ##     ## ##       ##     ##
                // ######### ######   ##       ########  ######   ########
                // ##     ## ##       ##       ##        ##       ##   ##
                // ##     ## ##       ##       ##        ##       ##    ##
                // ##     ## ######## ######## ##        ######## ##     ##

                toggleDarkMode() {
                    console.log('Toggling dark mode');  // Add this debug line
                    this.isDarkMode = !this.isDarkMode;
                    localStorage.setItem('darkMode', this.isDarkMode);
                    // Force a DOM update
                    this.$nextTick(() => {
                        document.documentElement.classList.toggle('dark-mode', this.isDarkMode);
                    });
                },
                clearAllSelections() {
                    // Clear prompts selection
                    if (this.prompts.grid.api) {
                        this.prompts.grid.api.deselectAll();
                    }

                    // Clear models selection
                    if (this.models.grid.api) {
                        this.models.grid.api.deselectAll();
                    }

                    // Clear function selections
                    this.filters.selected.functions = [];

                    // Reset head selections
                    this.head_selections_str = {};

                    // Update URL to reflect cleared state
                    this.updateURL();
                },
                isIndeterminate(category) {
                    const items = this.filters.available[category];
                    const selectedItems = this.filters.selected[category];
                    return selectedItems.length > 0 && selectedItems.length < items.length;
                },
                isChecked(category) {
                    const items = this.filters.available[category];
                    const selectedItems = this.filters.selected[category];
                    return selectedItems.length === items.length && items.length > 0;
                },
                toggleSelectAll(category, event) {
                    const checked = event.target.checked;
                    this.filters.selected[category] = checked ? [...this.filters.available[category]] : [];
                },
                async loadData() {
                    try {
                        await this.loadModels();
                        await Promise.all([
                            this.loadAllPrompts(),
                            this.loadFunctions()
                        ]);

                        this.updateLayersAndHeads();
                    } catch (error) {
                        console.error('Error loading data:', error);
                    }
                },
                async loadModels() {
                    this.loading = true;
                    console.log('Loading models...');
                    const models = await fileOps.fetchJsonL(`${DATA_DIR}/models.jsonl`);
                    this.models.configs = {};
                    for (const model of models) {
                        this.models.configs[model["model_name"]] = model;
                    }
                    this.filters.available.models = Object.keys(this.models.configs);
                    console.log('Models:', this.filters.available.models);
                    this.loading = false;

                    // After loading models, initialize head selections
                    this.filters.selected.models.forEach(model => {
                        if (!this.head_selections_str[model]) {
                            this.head_selections_str[model] = 'L*H*';
                        }
                    });
                },
                async loadFunctions() {
                    const functions = await fileOps.fetchJsonL(`${DATA_DIR}/functions.jsonl`);
                    console.log('Functions:', functions);
                    this.filters.available.functions = functions.reduce(
                        (acc, item) => {
                            acc[item.name] = item;
                            return acc;
                        },
                        {},
                    );
                    console.log('this.filters.available.functions:', this.filters.available.functions);
                },
                onFirstDataRendered(params) {
                    this.selectPromptsFromURL();
                },
                // Handle selection change in ag-Grid
                onSelectionChanged() {
                    const selectedNodes = this.prompts.grid.api.getSelectedRows();
                    this.prompts.selected = selectedNodes.map(node => node.hash);
                    this.updateURL();
                },
                // Update layers and heads based on selected models
                updateLayersAndHeads() {
                    // get all layer and head counts
                    let mdl_n_layers = [];
                    let mdl_n_heads = [];
                    for (const model of this.filters.selected.models) {
                        const config = this.models.configs[model];
                        if (config) {
                            mdl_n_layers.push(config.n_layers);
                            mdl_n_heads.push(config.n_heads);
                        }
                    }
                    // get the max layer and head counts, generate lists
                    this.filters.available.layers = [];
                    this.filters.available.heads = [];

                    for (let i = 0; i < _.max(mdl_n_layers); i++) {
                        this.filters.available.layers.push(i.toString());
                    }
                    for (let i = 0; i < _.max(mdl_n_heads); i++) {
                        this.filters.available.heads.push(i.toString());
                    }
                },

                // ##     ##  #######  ########  ######## ##        ######
                // ###   ### ##     ## ##     ## ##       ##       ##    ##
                // #### #### ##     ## ##     ## ##       ##       ##
                // ## ### ## ##     ## ##     ## ######   ##        ######
                // ##     ## ##     ## ##     ## ##       ##             ##
                // ##     ## ##     ## ##     ## ##       ##       ##    ##
                // ##     ##  #######  ########  ######## ########  ######
                getHeadSelectionCount(model) {
                    const parsed = this.head_selections_arr[model];
                    if (!parsed) return 0;
                    return parsed.reduce((acc, layer) =>
                        acc + layer.reduce((sum, isSelected) => sum + (isSelected ? 1 : 0), 0), 0);
                },
                getTotalHeads(model) {
                    const config = this.models.configs[model];
                    return config ? config.n_layers * config.n_heads : 0;
                },
                setupModelTable() {
                    const columnDefs = [
                        {
                            headerName: 'Model',
                            field: 'model_name',
                            sort: 'asc',
                            width: 150
                        },
                        {
                            headerName: 'd_model',
                            field: 'd_model',
                            width: 90,
                            filter: 'agNumberColumnFilter'
                        },
                        {
                            headerName: 'n_layers',
                            field: 'n_layers',
                            width: 90,
                            filter: 'agNumberColumnFilter'
                        },
                        {
                            headerName: 'n_heads',
                            field: 'n_heads',
                            width: 90,
                            filter: 'agNumberColumnFilter'
                        },
                        {
                            headerName: 'Selected',
                            valueGetter: (params) => {
                                return `${this.getHeadSelectionCount(params.data.model_name)} / ${this.getTotalHeads(params.data.model_name)}`;
                            },
                            width: 100
                        },
                        {
                            headerName: 'Head Grid',
                            field: 'head_grid',
                            width: 150,
                            cellRenderer: (params) => {
                                const model = params.data.model_name;
                                const div = document.createElement('div');
                                div.className = 'head-grid';
                                div.setAttribute('data-model', model); // Add data attribute for updates

                                const n_heads = params.data.n_heads;
                                const n_layers = params.data.n_layers;

                                for (let h = 0; h < n_heads; h++) {
                                    const layerDiv = document.createElement('div');
                                    layerDiv.className = 'headsGrid-col';

                                    for (let l = 0; l < n_layers; l++) {
                                        const cell = document.createElement('div');
                                        cell.className = `headsGrid-cell ${this.isHeadSelected(model, l, h) ? 'headsGrid-cell-selected' : 'headsGrid-cell-empty'}`;
                                        cell.setAttribute('data-layer', l);
                                        cell.setAttribute('data-head', h);
                                        layerDiv.appendChild(cell);
                                    }

                                    div.appendChild(layerDiv);
                                }

                                return div;
                            }
                        },
                        {
                            headerName: 'Head Selection',
                            field: 'head_selection',
                            editable: true,
                            width: 200,
                            cellEditor: 'agTextCellEditor',
                            cellEditorParams: {
                                maxLength: 50
                            },
                            valueSetter: params => {
                                const newValue = params.newValue;
                                const model = params.data.model_name;

                                // Update the head selection in Vue's data
                                params.context.componentParent.head_selections_str[model] = newValue;

                                // Update the cell class for validation styling
                                const isValid = params.context.componentParent.isValidHeadSelection(model);
                                const cell = params.api.getCellRendererInstances({
                                    rowNodes: [params.node],
                                    columns: [params.column]
                                })[0];

                                if (cell) {
                                    const element = cell.getGui();
                                    if (isValid) {
                                        element.classList.remove('invalid-selection');
                                    } else {
                                        element.classList.add('invalid-selection');
                                    }
                                }

                                // Force refresh of the head grid cell
                                const gridCol = params.api.getColumnDef('head_grid');
                                if (gridCol) {
                                    params.api.refreshCells({
                                        rowNodes: [params.node],
                                        columns: ['head_grid'],
                                        force: true
                                    });
                                }

                                return true;
                            },
                            valueGetter: params => {
                                return params.context.componentParent.head_selections_str[params.data.model_name] || 'L*H*';
                            },
                            cellClass: params => {
                                const isValid = params.context.componentParent.isValidHeadSelection(params.data.model_name);
                                return isValid ? '' : 'invalid-selection';
                            }
                        },
                    ];

                    const modelGrid_options = {
                        columnDefs: columnDefs,
                        rowData: Object.values(this.models.configs),
                        selection: {
                            headerCheckbox: true,
                            selectAll: 'filtered',
                            checkboxes: true,
                            mode: 'multiRow',
                            enableClickSelection: true,
                        },
                        defaultColDef: {
                            sortable: true,
                            filter: true,
                            resizable: true,
                            floatingFilter: true,
                            suppressKeyboardEvent: params => {
                                // Allow all keyboard events in edit mode
                                if (params.editing) {
                                    return false;
                                }
                                // Prevent default grid behavior for typing when not in edit mode
                                if (params.event.key.length === 1 && !params.event.ctrlKey && !params.event.metaKey) {
                                    return false;
                                }
                                return true;
                            },
                        },
                        context: {
                            componentParent: this
                        },
                        onSelectionChanged: (event) => {
                            const selectedRows = event.api.getSelectedRows();
                            this.filters.selected.models = selectedRows.map(row => row.model_name);
                        },
                        onGridReady: (params) => {
                            this.models.grid.api = params.api;
                            // Select models from URL
                            if (this.filters.selected.models.length > 0) {
                                params.api.forEachNode(node => {
                                    if (this.filters.selected.models.includes(node.data.model_name)) {
                                        node.setSelected(true);
                                    }
                                });
                            }
                        },
                    };

                    const modelGrid_div = document.querySelector('#modelGrid');
                    this.models.grid.api = agGrid.createGrid(modelGrid_div, modelGrid_options);
                },
                refreshHeadGrids() {
                    if (this.models.grid.api) {
                        this.models.grid.api.refreshCells({
                            columns: ['head_grid'],
                            force: true
                        });
                    }
                },
                // ########  ########   #######  ##     ## ########  ########
                // ##     ## ##     ## ##     ## ###   ### ##     ##    ##   
                // ##     ## ##     ## ##     ## #### #### ##     ##    ##   
                // ########  ########  ##     ## ## ### ## ########     ##   
                // ##        ##   ##   ##     ## ##     ## ##           ##    
                // ##        ##    ##  ##     ## ##     ## ##           ##    
                // ##        ##     ##  #######  ##     ## ##           ##    

                async loadAllPrompts() {
                    this.loading = true;
                    console.log('Loading prompts...');
                    this.prompts.all = {};

                    for (const model of this.filters.available.models) {
                        try {
                            const modelPrompts = await fileOps.fetchJsonL(`${DATA_DIR}/${model}/prompts.jsonl`);
                            for (const prompt of modelPrompts) {
                                if (prompt.hash in this.prompts.all) {
                                    this.prompts.all[prompt.hash].models.push(model);
                                } else {
                                    this.prompts.all[prompt.hash] = { ...prompt, models: [model] };
                                }
                            }
                        } catch (error) {
                            console.error(`Error loading prompts for model ${model}:`, error);
                        }
                    }
                    console.log('loaded number of prompts:', Object.keys(this.prompts.all).length);
                    this.loading = false;
                },
                // Initialize the ag-Grid table
                setupPromptTable() {
                    const columnDefs = [
                        {
                            headerName: 'Prompt Text',
                            field: 'text',
                            sortable: true,
                            filter: true,
                            flex: 2,
                            cellRenderer: (params) => {
                                const eGui = document.createElement('div');
                                // Replace tabs and newlines with spaces for display
                                eGui.innerText = params.value.replace(/\s+/g, ' ');
                                eGui.classList.add('prompt-text-cell');
                                eGui.addEventListener('click', () => {
                                    navigator.clipboard.writeText(params.value);
                                });

                                eGui.addEventListener('contextmenu', (event) => {
                                    event.preventDefault();
                                    const newWindow = window.open();
                                    newWindow.document.write(`<pre>${params.value}</pre>`);
                                    newWindow.document.close();
                                    newWindow.document.title = `Prompt '${params.data.hash}'`;
                                });

                                return eGui;
                            },
                        },
                        {
                            headerName: 'Models', field: 'models', sortable: true, filter: true, width: 150,
                            valueFormatter: (params) => params.value.join(', '),
                        },
                        { headerName: 'Hash', field: 'hash', sortable: true, filter: true, width: 100 },
                        { headerName: 'Tokens', field: 'n_tokens', sortable: true, filter: 'agNumberColumnFilter', width: 80 },
                        { headerName: 'Dataset', field: 'meta.pile_set_name', sortable: true, filter: true, width: 150 },
                    ];

                    // Grid options
                    const promptGrid_options = {
                        columnDefs: columnDefs,
                        rowData: Object.values(this.prompts.all),
                        pagination: true,
                        enableCellTextSelection: true,
                        paginationPageSize: 20,
                        paginationPageSizeSelector: [5, 10, 20, 50, 100, 500],
                        selection: {
                            headerCheckbox: true,
                            selectAll: 'filtered',
                            checkboxes: true,
                            mode: 'multiRow',
                            enableClickSelection: true,
                        },

                        defaultColDef: {
                            sortable: true,
                            filter: true,
                            resizable: true,
                            floatingFilter: true
                        },
                        onSelectionChanged: this.onSelectionChanged.bind(this),
                        onFirstDataRendered: this.onFirstDataRendered.bind(this),
                        onGridReady: (params) => {
                            this.prompts.grid.api = params.api;
                            this.isGridReady = true;
                            this.selectPromptsFromURL();
                        },
                    };

                    const promptGrid_div = document.querySelector('#promptGrid');
                    this.prompts.grid.api = agGrid.createGrid(promptGrid_div, promptGrid_options);
                },

                // ########  ####  ######  ########  ##          ###    ##    ##
                // ##     ##  ##  ##    ## ##     ## ##         ## ##    ##  ##
                // ##     ##  ##  ##       ##     ## ##        ##   ##    ####
                // ##     ##  ##   ######  ########  ##       ##     ##    ##
                // ##     ##  ##        ## ##        ##       #########    ##
                // ##     ##  ##  ##    ## ##        ##       ##     ##    ##
                // ########  ####  ######  ##        ######## ##     ##    ##

                // Display images based on selected criteria
                async displayImages() {
                    this.loading = true;
                    this.images.requested = true;
                    this.images.visible = [];

                    // Calculate total images based on parsed head selections
                    let totalImages = 0;
                    for (const model of this.filters.selected.models) {
                        totalImages += this.getHeadSelectionCount(model) * this.prompts.selected.length * this.filters.selected.functions.length;
                    }
                    this.images.expected = totalImages;

                    // Load images based on parsed head selections
                    for (const model of this.filters.selected.models) {
                        const config = this.models.configs[model];
                        const rawString = this.head_selections_str[model] || 'L*H*';
                        const parsedHeads = this.parseHeadString(rawString, config.n_layers, config.n_heads);
                        if (!parsedHeads) {
                            console.warn(`Invalid head selection for ${model}: "${rawString}"`);
                            continue;
                        }

                        // Iterate over all layers and heads
                        for (let layer = 0; layer < config.n_layers; layer++) {
                            for (let head = 0; head < config.n_heads; head++) {
                                if (!parsedHeads[layer][head]) {
                                    continue;
                                }
                                // Now for each selected prompt and function:
                                for (const promptHash of this.prompts.selected) {
                                    for (
                                        const func_name of
                                        this.filters.selected.functions
                                    ) {
                                        let func = this.filters.available.functions[func_name];
                                        if (!func) {
                                            console.warn(`Function not found ${func_name}`, typeof func_name, JSON.stringify(func_name), func_name, this.filters.available.functions);
                                        }
                                        const basePath = `${DATA_DIR}/${model}/prompts/${promptHash}/L${layer}/H${head}`;

                                        // get the figure format from metadata
                                        let figure_format = func.figure_save_fmt;
                                        if (!figure_format) {
                                            // as a fallback, look for all valid formats
                                            figure_format = await fileOps.figureExists(`${basePath}/${func_name}`);
                                            console.log('could not find figure format for func name', func_name, 'found', figure_format);
                                        }

                                        if (figure_format) {
                                            // Create figure entry
                                            const figure_meta = {
                                                name: `${model} - Prompt ${promptHash} - L${layer}H${head} - ${func_name}`,
                                                model: model,
                                                promptHash: promptHash,
                                                layer: layer,
                                                head: head,
                                                function: func_name,
                                                figure_format: figure_format,
                                            };

                                            if (figure_format === 'svgz') {
                                                const svgText = await fileOps.fetchAndDecompressSvgz(`${basePath}/${func_name}.svgz`);
                                                if (svgText) {
                                                    this.images.visible.push({
                                                        content: svgText,
                                                        ...figure_meta,
                                                    });
                                                }
                                            } else {
                                                const imglink = `<img src="${basePath}/${func_name}.${figure_format}" alt="${figure_meta.name}">`;
                                                this.images.visible.push({
                                                    content: imglink,
                                                    ...figure_meta,
                                                });
                                            }
                                        }
                                    }
                                }
                            }
                        }
                    }

                    this.images.upToDate = true;
                    this.loading = false;
                },
                openMetadata(func) {
                    const newWindow = window.open('', '_blank');
                    let content = `<div style="font-family: sans-serif; line-height:1.4;">`;
                    if (func.doc) {
                        content += `<p><strong>Description:</strong> ${func.doc}</p>`;
                    }
                    if (func.figure_save_fmt) {
                        content += `<p><strong>Format:</strong> ${func.figure_save_fmt}</p>`;
                    }
                    if (func.source) {
                        content += `<p><strong>Source:</strong> ${func.source}</p>`;
                    }
                    content += `</div>`;
                    newWindow.document.write(content);
                    newWindow.document.close();
                    newWindow.document.title = `Metadata for ${func.name}`;
                },
            },


            //  ######   #######  ##     ## ########  ##     ## ######## ######## ########
            // ##    ## ##     ## ###   ### ##     ## ##     ##    ##    ##       ##     ##
            // ##       ##     ## #### #### ##     ## ##     ##    ##    ##       ##     ##
            // ##       ##     ## ## ### ## ########  ##     ##    ##    ######   ##     ##
            // ##       ##     ## ##     ## ##        ##     ##    ##    ##       ##     ##
            // ##    ## ##     ## ##     ## ##        ##     ##    ##    ##       ##     ##
            //  ######   #######  ##     ## ##         #######     ##    ######## ########

            computed: {
                uniqueDatasets() {
                    return [
                        ...new Set(
                            Object.values(this.prompts.all).map(prompt => prompt.meta.pile_set_name).filter(Boolean)
                        )
                    ];
                },
                head_selections_arr() {
                    // model -> boolean[][] mapping for efficient lookup
                    let parsed = {};

                    for (const model in this.head_selections_str) {
                        const config = this.models.configs[model];
                        if (!config) {
                            console.warn(`No config found for model: ${model}`);
                            parsed[model] = null;
                            continue;
                        }

                        const parsedHeads = this.parseHeadString(
                            this.head_selections_str[model] || 'L*H*',
                            config.n_layers,
                            config.n_heads
                        );

                        if (!parsedHeads) {
                            console.warn(
                                `Invalid head selection for ${model}: "${this.head_selections_str[model]}"`
                            );
                        }

                        parsed[model] = parsedHeads;
                    }

                    return parsed;
                }
            },


            // ##      ##    ###    ########  ######  ##     ##
            // ##  ##  ##   ## ##      ##    ##    ## ##     ##
            // ##  ##  ##  ##   ##     ##    ##       ##     ##
            // ##  ##  ## ##     ##    ##    ##       #########
            // ##  ##  ## #########    ##    ##       ##     ##
            // ##  ##  ## ##     ##    ##    ##    ## ##     ##
            //  ###  ###  ##     ##    ##     ######  ##     ##

            // Watch for changes in selected models to load prompts and update layers and heads
            watch: {
                'filters.selected': {
                    deep: true,
                    handler() {
                        this.images.upToDate = false;
                        this.updateURL();
                    }
                },
                'prompts.selected': {
                    handler() {
                        this.images.upToDate = false;
                    }
                },
                'head_selections_str': {
                    deep: true,
                    handler(newValue) {
                        Object.keys(newValue).forEach(model => {
                            if (!this.models.configs[model]) {
                                console.warn(`Attempting to update head selections for unknown model: ${model}`);
                                return;
                            }
                        });
                        this.images.upToDate = false;
                        this.updateURL();
                        this.refreshHeadGrids();
                    }
                },
                'filters.selected.models': {
                    deep: true,
                    handler(newModels) {
                        // Initialize head selections for new models
                        newModels.forEach(model => {
                            if (!this.head_selections_str[model]) {
                                this.head_selections_str[model] = 'L*H*';
                            }
                        });
                        this.updateURL();
                    }
                },
            },

            // Lifecycle hook when component is mounted
            async mounted() {
                console.log('Mounting app:', this);
                const savedDarkMode = localStorage.getItem('darkMode');
                if (savedDarkMode !== null) {
                    this.isDarkMode = savedDarkMode === 'true';
                }
                if (this.isDarkMode) {
                    document.documentElement.classList.add('dark-mode');
                }
                this.readURL(); // Read filters from URL first
                await this.loadData(); // Load models, prompts, and functions
                this.setupModelTable(); // Initialize the model grid
                this.setupPromptTable(); // Initialize the prompts grid
                console.log('Mounted app:', this);
            }
        });

        // Mount the Vue app to the DOM element with id="app"
        app.mount('#app');
    </script>
</body>

</html>
``````{ end_of_file: "pattern_lens/frontend/index.html" }

``````{ path: "pattern_lens/__init__.py" }
"""
.. include:: ../README.md
"""

``````{ end_of_file: "pattern_lens/__init__.py" }

``````{ path: "pattern_lens/activations.py" }
"""computing and saving activations given a model and prompts


# Usage:

from the command line:

```bash
python -m pattern_lens.activations --model <model_name> --prompts <prompts_path> --save-path <save_path> --min-chars <min_chars> --max-chars <max_chars> --n-samples <n_samples>
```

from a script:

```python
from pattern_lens.activations import activations_main
activations_main(
    model_name="gpt2",
    save_path="demo/"
    prompts_path="data/pile_1k.jsonl",
)
```

"""

import argparse
import functools
import json
from dataclasses import asdict
from pathlib import Path
import re
from typing import Callable, Literal, overload

import numpy as np
import torch
import tqdm
from muutils.spinner import SpinnerContext
from muutils.misc.numerical import shorten_numerical_to_str
from muutils.json_serialize import json_serialize
from transformer_lens import HookedTransformer, HookedTransformerConfig  # type: ignore[import-untyped]

from pattern_lens.consts import (
    ATTN_PATTERN_REGEX,
    DATA_DIR,
    ActivationCacheNp,
    SPINNER_KWARGS,
    DIVIDER_S1,
    DIVIDER_S2,
)
from pattern_lens.indexes import (
    generate_models_jsonl,
    generate_prompts_jsonl,
    write_html_index,
)
from pattern_lens.load_activations import (
    ActivationsMissingError,
    augment_prompt_with_hash,
    load_activations,
)
from pattern_lens.prompts import load_text_data


def compute_activations(
    prompt: dict,
    model: HookedTransformer | None = None,
    save_path: Path = Path(DATA_DIR),
    return_cache: bool = True,
    names_filter: Callable[[str], bool] | re.Pattern = ATTN_PATTERN_REGEX,
) -> tuple[Path, ActivationCacheNp | None]:
    """get activations for a given model and prompt, possibly from a cache

    if from a cache, prompt_meta must be passed and contain the prompt hash

    # Parameters:
     - `prompt : dict | None`
       (defaults to `None`)
     - `model : HookedTransformer`
     - `save_path : Path`
       (defaults to `Path(DATA_DIR)`)
     - `return_cache : bool`
       will return `None` as the second element if `False`
       (defaults to `True`)
     - `names_filter : Callable[[str], bool]|re.Pattern`
       a filter for the names of the activations to return. if an `re.Pattern`, will use `lambda key: names_filter.match(key) is not None`
       (defaults to `ATTN_PATTERN_REGEX`)

    # Returns:
     - `tuple[Path, ActivationCacheNp|None]`
    """
    assert model is not None, "model must be passed"
    assert "text" in prompt, "prompt must contain 'text' key"
    prompt_str: str = prompt["text"]

    # compute or get prompt metadata
    prompt_tokenized: list[str] = prompt.get(
        "tokens",
        model.tokenizer.tokenize(prompt_str),
    )
    prompt.update(
        dict(
            n_tokens=len(prompt_tokenized),
            tokens=prompt_tokenized,
        )
    )

    # save metadata
    prompt_dir: Path = save_path / model.model_name / "prompts" / prompt["hash"]
    prompt_dir.mkdir(parents=True, exist_ok=True)
    with open(prompt_dir / "prompt.json", "w") as f:
        json.dump(prompt, f)

    # set up names filter
    names_filter_fn: Callable[[str], bool]
    if isinstance(names_filter, re.Pattern):
        names_filter_fn = lambda key: names_filter.match(key) is not None  # noqa: E731
    else:
        names_filter_fn = names_filter

    # compute activations
    with torch.no_grad():
        # TODO: batching?
        _, cache = model.run_with_cache(
            prompt_str,
            names_filter=names_filter_fn,
            return_type=None,
        )

    cache_np: ActivationCacheNp = {
        k: v.detach().cpu().numpy() for k, v in cache.items()
    }

    # save activations
    activations_path: Path = prompt_dir / "activations.npz"
    np.savez_compressed(
        activations_path,
        **cache_np,
    )

    # return path and cache
    if return_cache:
        return activations_path, cache_np
    else:
        return activations_path, None


@overload
def get_activations(
    prompt: dict,
    model: HookedTransformer | str,
    save_path: Path = Path(DATA_DIR),
    allow_disk_cache: bool = True,
    return_cache: Literal[False] = False,
) -> tuple[Path, None]: ...
@overload
def get_activations(
    prompt: dict,
    model: HookedTransformer | str,
    save_path: Path = Path(DATA_DIR),
    allow_disk_cache: bool = True,
    return_cache: Literal[True] = True,
) -> tuple[Path, ActivationCacheNp]: ...
def get_activations(
    prompt: dict,
    model: HookedTransformer | str,
    save_path: Path = Path(DATA_DIR),
    allow_disk_cache: bool = True,
    return_cache: bool = True,
) -> tuple[Path, ActivationCacheNp | None]:
    """given a prompt and a model, save or load activations

    # Parameters:
     - `prompt : dict`
        expected to contain the 'text' key
     - `model : HookedTransformer | str`
        either a `HookedTransformer` or a string model name, to be loaded with `HookedTransformer.from_pretrained`
     - `save_path : Path`
        path to save the activations to (and load from)
       (defaults to `Path(DATA_DIR)`)
     - `allow_disk_cache : bool`
        whether to allow loading from disk cache
       (defaults to `True`)
     - `return_cache : bool`
        whether to return the cache. if `False`, will return `None` as the second element
       (defaults to `True`)

    # Returns:
     - `tuple[Path, ActivationCacheNp | None]`
         the path to the activations and the cache if `return_cache` is `True`

    """
    # add hash to prompt
    augment_prompt_with_hash(prompt)

    # get the model
    model_name: str = (
        model.model_name if isinstance(model, HookedTransformer) else model
    )

    # from cache
    if allow_disk_cache:
        try:
            path, cache = load_activations(
                model_name=model_name,
                prompt=prompt,
                save_path=save_path,
            )
            if return_cache:
                return path, cache
            else:
                return path, None
        except ActivationsMissingError:
            pass

    # compute them
    if isinstance(model, str):
        model = HookedTransformer.from_pretrained(model_name)

    return compute_activations(
        prompt=prompt,
        model=model,
        save_path=save_path,
        return_cache=True,
    )


def activations_main(
    model_name: str,
    save_path: str,
    prompts_path: str,
    raw_prompts: bool,
    min_chars: int,
    max_chars: int,
    force: bool,
    n_samples: int,
    no_index_html: bool,
    shuffle: bool = False,
) -> None:
    """main function for computing activations

    # Parameters:
     - `model_name : str`
        name of a model to load with `HookedTransformer.from_pretrained`
     - `save_path : str`
        path to save the activations to
     - `prompts_path : str`
        path to the prompts file
     - `raw_prompts : bool`
        whether the prompts are raw, not filtered by length. `load_text_data` will be called if `True`, otherwise just load the "text" field from each line in `prompts_path`
     - `min_chars : int`
        minimum number of characters for a prompt
     - `max_chars : int`
        maximum number of characters for a prompt
     - `force : bool`
        whether to overwrite existing files
     - `n_samples : int`
        maximum number of samples to process
     - `no_index_html : bool`
        whether to write an index.html file
     - `shuffle : bool`
        whether to shuffle the prompts
       (defaults to `False`)
    """

    with SpinnerContext(message="loading model", **SPINNER_KWARGS):
        model: HookedTransformer = HookedTransformer.from_pretrained(model_name)
        model.model_name = model_name
        model.cfg.model_name = model_name
        n_params: int = sum(p.numel() for p in model.parameters())
    print(
        f"loaded {model_name} with {shorten_numerical_to_str(n_params)} ({n_params}) parameters"
    )

    save_path_p: Path = Path(save_path)
    save_path_p.mkdir(parents=True, exist_ok=True)
    model_path: Path = save_path_p / model_name
    with SpinnerContext(
        message=f"saving model info to {model_path.as_posix()}", **SPINNER_KWARGS
    ):
        model_cfg: HookedTransformerConfig
        model_cfg = model.cfg
        model_path.mkdir(parents=True, exist_ok=True)
        with open(model_path / "model_cfg.json", "w") as f:
            json.dump(json_serialize(asdict(model_cfg)), f)

    # load prompts
    with SpinnerContext(
        message=f"loading prompts from {prompts_path = }", **SPINNER_KWARGS
    ):
        prompts: list[dict]
        if raw_prompts:
            prompts = load_text_data(
                Path(prompts_path),
                min_chars=min_chars,
                max_chars=max_chars,
                shuffle=shuffle,
            )
        else:
            with open(model_path / "prompts.jsonl", "r") as f:
                prompts = [json.loads(line) for line in f.readlines()]
        # truncate to n_samples
        prompts = prompts[:n_samples]

    print(f"{len(prompts)} prompts loaded")

    # write index.html
    with SpinnerContext(message="writing index.html", **SPINNER_KWARGS):
        if not no_index_html:
            write_html_index(save_path_p)

    # get activations
    list(
        tqdm.tqdm(
            map(
                functools.partial(
                    get_activations,
                    model=model,
                    save_path=save_path_p,
                    allow_disk_cache=not force,
                    return_cache=False,
                ),
                prompts,
            ),
            total=len(prompts),
            desc="Computing activations",
            unit="prompt",
        )
    )

    with SpinnerContext(
        message="updating jsonl metadata for models and prompts", **SPINNER_KWARGS
    ):
        generate_models_jsonl(save_path_p)
        generate_prompts_jsonl(save_path_p / model_name)


def main():
    print(DIVIDER_S1)
    with SpinnerContext(message="parsing args", **SPINNER_KWARGS):
        arg_parser: argparse.ArgumentParser = argparse.ArgumentParser()
        # input and output
        arg_parser.add_argument(
            "--model",
            "-m",
            type=str,
            required=True,
            help="The model name(s) to use. comma separated with no whitespace if multiple",
        )

        arg_parser.add_argument(
            "--prompts",
            "-p",
            type=str,
            required=False,
            help="The path to the prompts file (jsonl with 'text' key on each line). If `None`, expects that `--figures` is passed and will generate figures for all prompts in the model directory",
            default=None,
        )

        arg_parser.add_argument(
            "--save-path",
            "-s",
            type=str,
            required=False,
            help="The path to save the attention patterns",
            default=DATA_DIR,
        )

        # min and max prompt lengths
        arg_parser.add_argument(
            "--min-chars",
            type=int,
            required=False,
            help="The minimum number of characters for a prompt",
            default=100,
        )
        arg_parser.add_argument(
            "--max-chars",
            type=int,
            required=False,
            help="The maximum number of characters for a prompt",
            default=1000,
        )

        # number of samples
        arg_parser.add_argument(
            "--n-samples",
            "-n",
            type=int,
            required=False,
            help="The max number of samples to process, do all in the file if None",
            default=None,
        )

        # force overwrite
        arg_parser.add_argument(
            "--force",
            "-f",
            action="store_true",
            help="If passed, will overwrite existing files",
        )

        # no index html
        arg_parser.add_argument(
            "--no-index-html",
            action="store_true",
            help="If passed, will not write an index.html file for the model",
        )

        # raw prompts
        arg_parser.add_argument(
            "--raw-prompts",
            "-r",
            action="store_true",
            help="pass if the prompts have not been split and tokenized (still needs keys 'text' and 'meta' for each item)",
        )

        # shuffle
        arg_parser.add_argument(
            "--shuffle",
            action="store_true",
            help="If passed, will shuffle the prompts",
        )

        args: argparse.Namespace = arg_parser.parse_args()

    print(f"args parsed: {args}")

    models: list[str]
    if "," in args.model:
        models = args.model.split(",")
    else:
        models = [args.model]

    n_models: int = len(models)
    for idx, model in enumerate(models):
        print(DIVIDER_S2)
        print(f"processing model {idx+1} / {n_models}: {model}")
        print(DIVIDER_S2)

        activations_main(
            model_name=model,
            save_path=args.save_path,
            prompts_path=args.prompts,
            raw_prompts=args.raw_prompts,
            min_chars=args.min_chars,
            max_chars=args.max_chars,
            force=args.force,
            n_samples=args.n_samples,
            no_index_html=args.no_index_html,
            shuffle=args.shuffle,
        )

    print(DIVIDER_S1)


if __name__ == "__main__":
    main()

``````{ end_of_file: "pattern_lens/activations.py" }

``````{ path: "pattern_lens/attn_figure_funcs.py" }
"""default figure functions

- If you are making a PR, add your new figure function here.
- if you are using this as a library, then you can see examples here


note that for `pattern_lens.figures` to recognize your function, you need to use the `register_attn_figure_func` decorator
which adds your function to `ATTENTION_MATRIX_FIGURE_FUNCS`

"""

from pattern_lens.consts import AttentionMatrix
from pattern_lens.figure_util import (
    AttentionMatrixFigureFunc,
    save_matrix_wrapper,
    Matrix2D,
)


ATTENTION_MATRIX_FIGURE_FUNCS: list[AttentionMatrixFigureFunc] = list()


def register_attn_figure_func(
    func: AttentionMatrixFigureFunc,
) -> AttentionMatrixFigureFunc:
    """decorator for registering attention matrix figure function

    if you want to add a new figure function, you should use this decorator

        # Parameters:
         - `func : AttentionMatrixFigureFunc`
           your function, which should take an attention matrix and path

        # Returns:
         - `AttentionMatrixFigureFunc`
           your function, after we add it to `ATTENTION_MATRIX_FIGURE_FUNCS`

    # Usage:
    ```python
    @register_attn_figure_func
    def my_new_figure_func(attn_matrix: AttentionMatrix, path: Path) -> None:
        fig, ax = plt.subplots(figsize=(10, 10))
        ax.matshow(attn_matrix, cmap="viridis")
        ax.set_title("My New Figure Function")
        ax.axis("off")
        plt.savefig(path / "my_new_figure_func", format="svgz")
        plt.close(fig)
    ```

    """
    global ATTENTION_MATRIX_FIGURE_FUNCS

    ATTENTION_MATRIX_FIGURE_FUNCS.append(func)

    return func


@register_attn_figure_func
@save_matrix_wrapper(fmt="png")
def raw(attn_matrix: AttentionMatrix) -> Matrix2D:
    return attn_matrix


# some more examples:

# @register_attn_figure_func
# @matplotlib_figure_saver
# def raw(attn_matrix: AttentionMatrix, ax: plt.Axes) -> None:
#     ax.matshow(attn_matrix, cmap="viridis")
#     ax.set_title("Raw Attention Pattern")
#     ax.axis("off")

# @register_attn_figure_func
# @save_matrix_wrapper(fmt="svg")
# def raw_svg(attn_matrix: AttentionMatrix) -> Matrix2D:
#     return attn_matrix

# @register_attn_figure_func
# @save_matrix_wrapper(fmt="svgz")
# def raw_svgz(attn_matrix: AttentionMatrix) -> Matrix2D:
#     return attn_matrix

``````{ end_of_file: "pattern_lens/attn_figure_funcs.py" }

``````{ path: "pattern_lens/consts.py" }
"""implements some constants and types"""

import re

import numpy as np
from jaxtyping import Float

AttentionMatrix = Float[np.ndarray, "n_ctx n_ctx"]
"type alias for attention matrix"

ActivationCacheNp = dict[str, np.ndarray]
"type alias for a cache of attention matrices, subset of ActivationCache"

DATA_DIR: str = "attn_data"
"default directory for attention data"

ATTN_PATTERN_REGEX: re.Pattern = re.compile(r"blocks\.(\d+)\.attn\.hook_pattern")
"regex for finding attention patterns in model state dicts"

SPINNER_KWARGS: dict = dict(
    config=dict(success="✔️ "),
)
"default kwargs for `muutils.spinner.Spinner`"

DIVIDER_S1: str = "=" * 70
"divider string for separating sections"

DIVIDER_S2: str = "-" * 50
"divider string for separating subsections"

``````{ end_of_file: "pattern_lens/consts.py" }

``````{ path: "pattern_lens/figure_util.py" }
"""implements a bunch of types, default values, and templates which are useful for figure functions

notably, you can use the decorators `matplotlib_figure_saver`, `save_matrix_wrapper` to make your functions save figures
"""

from pathlib import Path
from typing import Callable, Literal, overload, Union
import functools
import base64
import gzip
import io

from PIL import Image
import numpy as np
from jaxtyping import Float, UInt8
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.colors import Colormap

from pattern_lens.consts import AttentionMatrix

AttentionMatrixFigureFunc = Callable[[AttentionMatrix, Path], None]
"Type alias for a function that, given an attention matrix, saves a figure"

Matrix2D = Float[np.ndarray, "n m"]
"Type alias for a 2D matrix (plottable)"

Matrix2Drgb = UInt8[np.ndarray, "n m rgb=3"]
"Type alias for a 2D matrix with 3 channels (RGB)"

AttentionMatrixToMatrixFunc = Callable[[AttentionMatrix], Matrix2D]
"Type alias for a function that, given an attention matrix, returns a 2D matrix"

MATPLOTLIB_FIGURE_FMT: str = "svgz"
"format for saving matplotlib figures"

MatrixSaveFormat = Literal["png", "svg", "svgz"]
"Type alias for the format to save a matrix as when saving raw matrix, not matplotlib figure"

MATRIX_SAVE_NORMALIZE: bool = False
"default for whether to normalize the matrix to range [0, 1]"

MATRIX_SAVE_CMAP: str = "viridis"
"default colormap for saving matrices"

MATRIX_SAVE_FMT: MatrixSaveFormat = "svgz"
"default format for saving matrices"

MATRIX_SAVE_SVG_TEMPLATE: str = """<svg xmlns="http://www.w3.org/2000/svg" width="{m}" height="{n}" viewBox="0 0 {m} {n}" image-rendering="pixelated"> <image href="data:image/png;base64,{png_base64}" width="{m}" height="{n}" /> </svg>"""
"template for saving an `n` by `m` matrix as an svg/svgz"


@overload  # without keyword arguments, returns decorated function
def matplotlib_figure_saver(
    func: Callable[[AttentionMatrix, plt.Axes], None],
    *args,
    fmt: str = MATPLOTLIB_FIGURE_FMT,
) -> AttentionMatrixFigureFunc: ...
@overload  # with keyword arguments, returns decorator
def matplotlib_figure_saver(
    func: None = None,
    *args,
    fmt: str = MATPLOTLIB_FIGURE_FMT,
) -> Callable[
    [Callable[[AttentionMatrix, plt.Axes], None], str], AttentionMatrixFigureFunc
]: ...
def matplotlib_figure_saver(
    func: Callable[[AttentionMatrix, plt.Axes], None] | None = None,
    *args,
    fmt: str = MATPLOTLIB_FIGURE_FMT,
) -> Union[
    AttentionMatrixFigureFunc,
    Callable[
        [Callable[[AttentionMatrix, plt.Axes], None], str], AttentionMatrixFigureFunc
    ],
]:
    """decorator for functions which take an attention matrix and predefined `ax` object, making it save a figure

    # Parameters:
     - `func : Callable[[AttentionMatrix, plt.Axes], None]`
       your function, which should take an attention matrix and predefined `ax` object
     - `fmt : str`
       format for saving matplotlib figures
       (defaults to `MATPLOTLIB_FIGURE_FMT`)

    # Returns:
     - `AttentionMatrixFigureFunc`
       your function, after we wrap it to save a figure

    # Usage:
    ```python
    @register_attn_figure_func
    @matplotlib_figure_saver
    def raw(attn_matrix: AttentionMatrix, ax: plt.Axes) -> None:
        ax.matshow(attn_matrix, cmap="viridis")
        ax.set_title("Raw Attention Pattern")
        ax.axis("off")
    ```

    """

    assert len(args) == 0, "This decorator only supports keyword arguments"

    def decorator(
        func: Callable[[AttentionMatrix, plt.Axes], None],
        fmt: str = fmt,
    ) -> AttentionMatrixFigureFunc:
        @functools.wraps(func)
        def wrapped(attn_matrix: AttentionMatrix, save_dir: Path) -> None:
            fig_path: Path = save_dir / f"{func.__name__}.{fmt}"

            fig, ax = plt.subplots(figsize=(10, 10))
            func(attn_matrix, ax)
            plt.tight_layout()
            plt.savefig(fig_path)
            plt.close(fig)

        wrapped.figure_save_fmt = fmt  # type: ignore[attr-defined]

        return wrapped

    if callable(func):
        # Handle no-arguments case
        return decorator(func)
    else:
        # Handle arguments case
        return decorator


def matrix_to_image_preprocess(
    matrix: Matrix2D,
    normalize: bool = MATRIX_SAVE_NORMALIZE,
    cmap: str | Colormap = MATRIX_SAVE_CMAP,
) -> Matrix2Drgb:
    """preprocess a 2D matrix into a plottable heatmap image

    # Parameters:
     - `matrix : Matrix2D`
        input matrix
     - `normalize : bool`
        whether to normalize the matrix to range [0, 1]
       (defaults to `MATRIX_SAVE_NORMALIZE`)
     - `cmap : str|Colormap`
        the colormap to use for the matrix
       (defaults to `MATRIX_SAVE_CMAP`)

    # Returns:
     - `Matrix2Drgb`
    """
    # check dims
    assert matrix.ndim == 2, f"Matrix must be 2D, got {matrix.ndim = }"

    # check matrix is not empty
    assert matrix.size > 0, "Matrix cannot be empty"

    # Normalize the matrix to range [0, 1]
    normalized_matrix: Matrix2D
    if normalize:
        max_val, min_val = matrix.max(), matrix.min()
        normalized_matrix = (matrix - min_val) / (max_val - min_val)
    else:
        assert (
            matrix.min() >= 0 and matrix.max() <= 1
        ), "Matrix values must be in range [0, 1], or normalize must be True. got: min: {matrix.min() = }, max: {matrix.max() = }"
        normalized_matrix = matrix

    # get the colormap
    cmap_: Colormap
    if isinstance(cmap, str):
        cmap_ = matplotlib.colormaps[cmap]
    elif isinstance(cmap, Colormap):
        cmap_ = cmap
    else:
        raise TypeError(
            f"Invalid type for {cmap = }, {type(cmap) = }, must be str or Colormap"
        )

    # Apply the viridis colormap
    rgb_matrix: Float[np.ndarray, "n m channels=3"] = (  # noqa: F722
        cmap_(normalized_matrix)[:, :, :3] * 255
    ).astype(np.uint8)  # Drop alpha channel

    assert rgb_matrix.shape == (
        matrix.shape[0],
        matrix.shape[1],
        3,
    ), f"Matrix after colormap must have 3 channels, got {rgb_matrix.shape = }"

    return rgb_matrix


@overload
def matrix2drgb_to_png_bytes(matrix: Matrix2Drgb, buffer: None = None) -> bytes: ...
@overload
def matrix2drgb_to_png_bytes(matrix: Matrix2Drgb, buffer: io.BytesIO) -> None: ...
def matrix2drgb_to_png_bytes(
    matrix: Matrix2Drgb, buffer: io.BytesIO | None = None
) -> bytes | None:
    """Convert a `Matrix2Drgb` to valid PNG bytes via PIL

    - if `buffer` is provided, it will write the PNG bytes to the buffer and return `None`
    - if `buffer` is not provided, it will return the PNG bytes

    # Parameters:
     - `matrix : Matrix2Drgb`
     - `buffer : io.BytesIO | None`
       (defaults to `None`, in which case it will return the PNG bytes)

    # Returns:
     - `bytes|None`
       `bytes` if `buffer` is `None`, otherwise `None`
    """

    pil_img: Image.Image = Image.fromarray(matrix, mode="RGB")
    if buffer is None:
        buffer = io.BytesIO()
        pil_img.save(buffer, format="PNG")
        buffer.seek(0)
        return buffer.read()
    else:
        pil_img.save(buffer, format="PNG")
        return None


def matrix_as_svg(
    matrix: Matrix2D,
    normalize: bool = MATRIX_SAVE_NORMALIZE,
    cmap=MATRIX_SAVE_CMAP,
) -> str:
    """quickly convert a 2D matrix to an SVG image, without matplotlib

    # Parameters:
     - `matrix : Float[np.ndarray, 'n m']`
       a 2D matrix to convert to an SVG image
     - `normalize : bool`
       whether to normalize the matrix to range [0, 1]. if it's not in the range [0, 1], this must be `True` or it will raise an `AssertionError`
       (defaults to `False`)
     - `cmap : str`
       the colormap to use for the matrix -- will look up in `matplotlib.colormaps` if it's a string
       (defaults to `"viridis"`)

    # Returns:
     - `str`
       the SVG content for the matrix
    """
    # Get the dimensions of the matrix
    m, n = matrix.shape

    # Preprocess the matrix into an RGB image
    matrix_rgb: Matrix2Drgb = matrix_to_image_preprocess(
        matrix, normalize=normalize, cmap=cmap
    )

    # Convert the RGB image to PNG bytes
    image_data: bytes = matrix2drgb_to_png_bytes(matrix_rgb)

    # Encode the PNG bytes as base64
    png_base64: str = base64.b64encode(image_data).decode("utf-8")

    # Generate the SVG content
    svg_content: str = MATRIX_SAVE_SVG_TEMPLATE.format(m=m, n=n, png_base64=png_base64)

    return svg_content


@overload  # with keyword arguments, returns decorator
def save_matrix_wrapper(
    func: None = None,
    *args,
    fmt: MatrixSaveFormat = MATRIX_SAVE_FMT,
    normalize: bool = MATRIX_SAVE_NORMALIZE,
    cmap: str = MATRIX_SAVE_CMAP,
) -> Callable[[AttentionMatrixToMatrixFunc], AttentionMatrixFigureFunc]: ...
@overload  # without keyword arguments, returns decorated function
def save_matrix_wrapper(
    func: AttentionMatrixToMatrixFunc,
    *args,
    fmt: MatrixSaveFormat = MATRIX_SAVE_FMT,
    normalize: bool = MATRIX_SAVE_NORMALIZE,
    cmap: str = MATRIX_SAVE_CMAP,
) -> AttentionMatrixFigureFunc: ...
def save_matrix_wrapper(
    func: AttentionMatrixToMatrixFunc | None = None,
    *args,
    fmt: MatrixSaveFormat = MATRIX_SAVE_FMT,
    normalize: bool = MATRIX_SAVE_NORMALIZE,
    cmap=MATRIX_SAVE_CMAP,
) -> (
    AttentionMatrixFigureFunc
    | Callable[[AttentionMatrixToMatrixFunc], AttentionMatrixFigureFunc]
):
    """
    Decorator for functions that process an attention matrix and save it as an SVGZ image.
    Can handle both argumentless usage and with arguments.

    # Parameters:

     - `func : AttentionMatrixToMatrixFunc|None`
        Either the function to decorate (in the no-arguments case) or `None` when used with arguments.
     - `fmt : MatrixSaveFormat, keyword-only`
        The format to save the matrix as. Defaults to `MATRIX_SAVE_FMT`.
     - `normalize : bool, keyword-only`
        Whether to normalize the matrix to range [0, 1]. Defaults to `False`.
     - `cmap : str, keyword-only`
        The colormap to use for the matrix. Defaults to `MATRIX_SVG_CMAP`.

    # Returns:

    `AttentionMatrixFigureFunc|Callable[[AttentionMatrixToMatrixFunc], AttentionMatrixFigureFunc]`

    - `AttentionMatrixFigureFunc` if `func` is `AttentionMatrixToMatrixFunc` (no arguments case)
    - `Callable[[AttentionMatrixToMatrixFunc], AttentionMatrixFigureFunc]` if `func` is `None` -- returns the decorator which will then be applied to the  (with arguments case)

    # Usage:

    ```python
    @save_matrix_wrapper
    def identity_matrix(matrix):
        return matrix

    @save_matrix_wrapper(normalize=True, fmt="png")
    def scale_matrix(matrix):
        return matrix * 2

    @save_matrix_wrapper(normalize=True, cmap="plasma")
    def scale_matrix(matrix):
        return matrix * 2

    ```
    """

    assert len(args) == 0, "This decorator only supports keyword arguments"

    assert (
        fmt in MatrixSaveFormat.__args__  # type: ignore[attr-defined]
    ), f"Invalid format {fmt = }, must be one of {MatrixSaveFormat.__args__}"  # type: ignore[attr-defined]

    def decorator(
        func: Callable[[AttentionMatrix], Matrix2D],
    ) -> AttentionMatrixFigureFunc:
        @functools.wraps(func)
        def wrapped(attn_matrix: AttentionMatrix, save_dir: Path) -> None:
            fig_path: Path = save_dir / f"{func.__name__}.{fmt}"
            processed_matrix: Matrix2D = func(attn_matrix)

            if fmt == "png":
                processed_matrix_rgb: Matrix2Drgb = matrix_to_image_preprocess(
                    processed_matrix,
                    normalize=normalize,
                    cmap=cmap,
                )
                image_data: bytes = matrix2drgb_to_png_bytes(processed_matrix_rgb)
                fig_path.write_bytes(image_data)

            else:
                svg_content: str = matrix_as_svg(
                    processed_matrix, normalize=normalize, cmap=cmap
                )

                if fmt == "svgz":
                    with gzip.open(fig_path, "wt") as f:
                        f.write(svg_content)

                else:
                    fig_path.write_text(svg_content, encoding="utf-8")

        wrapped.figure_save_fmt = fmt  # type: ignore[attr-defined]

        return wrapped

    if callable(func):
        # Handle no-arguments case
        return decorator(func)
    else:
        # Handle arguments case
        return decorator

``````{ end_of_file: "pattern_lens/figure_util.py" }

``````{ path: "pattern_lens/figures.py" }
"""code for generating figures from attention patterns, using the functions decorated with `register_attn_figure_func`"""

import argparse
from collections import defaultdict
import functools
import itertools
import json
import warnings
from pathlib import Path

from muutils.json_serialize import json_serialize
from muutils.spinner import SpinnerContext
from muutils.parallel import run_maybe_parallel

from pattern_lens.attn_figure_funcs import ATTENTION_MATRIX_FIGURE_FUNCS
from pattern_lens.consts import (
    DATA_DIR,
    AttentionMatrix,
    SPINNER_KWARGS,
    ActivationCacheNp,
    DIVIDER_S1,
    DIVIDER_S2,
)
from pattern_lens.indexes import (
    generate_functions_jsonl,
    generate_models_jsonl,
    generate_prompts_jsonl,
)
from pattern_lens.load_activations import load_activations


class HTConfigMock:
    """Mock of `transformer_lens.HookedTransformerConfig` for type hinting and loading config json

    can be initialized with any kwargs, and will update its `__dict__` with them. does, however, require the following attributes:
    - `n_layers: int`
    - `n_heads: int`
    - `model_name: str`
    """

    def __init__(self, **kwargs):
        self.n_layers: int
        self.n_heads: int
        self.model_name: str
        self.__dict__.update(kwargs)

    def serialize(self):
        """serialize the config to json. values which aren't serializable will be converted via `muutils.json_serialize.json_serialize`"""
        return json_serialize(self.__dict__)

    @classmethod
    def load(cls, data: dict):
        "try to load a config from a dict, using the `__init__` method"
        return cls(**data)


def process_single_head(
    layer_idx: int,
    head_idx: int,
    attn_pattern: AttentionMatrix,
    save_dir: Path,
    force_overwrite: bool = False,
) -> dict[str, bool | Exception]:
    """process a single head's attention pattern, running all the functions in `ATTENTION_MATRIX_FIGURE_FUNCS` on the attention pattern

    # Parameters:
     - `layer_idx : int`
     - `head_idx : int`
     - `attn_pattern : AttentionMatrix`
        attention pattern for the head
     - `save_dir : Path`
        directory to save the figures to
     - `force_overwrite : bool`
        whether to overwrite existing figures. if `False`, will skip any functions which have already saved a figure
       (defaults to `False`)

    # Returns:
     - `dict[str, bool | Exception]`
        a dictionary of the status of each function, with the function name as the key and the status as the value
    """
    funcs_status: dict[str, bool | Exception] = dict()

    for func in ATTENTION_MATRIX_FIGURE_FUNCS:
        func_name: str = func.__name__
        fig_path: list[Path] = list(save_dir.glob(f"{func_name}.*"))

        if not force_overwrite and len(fig_path) > 0:
            funcs_status[func_name] = True
            continue

        try:
            func(attn_pattern, save_dir)
            funcs_status[func_name] = True

        except Exception as e:
            error_file = save_dir / f"{func.__name__}.error.txt"
            error_file.write_text(str(e))
            warnings.warn(
                f"Error in {func.__name__} for L{layer_idx}H{head_idx}: {str(e)}"
            )
            funcs_status[func_name] = e

    return funcs_status


def compute_and_save_figures(
    model_cfg: "HookedTransformerConfig|HTConfigMock",  # type: ignore[name-defined] # noqa: F821
    activations_path: Path,
    cache: ActivationCacheNp,
    save_path: Path = Path(DATA_DIR),
    force_overwrite: bool = False,
    track_results: bool = False,
) -> None:
    """compute and save figures for all heads in the model, using the functions in `ATTENTION_MATRIX_FIGURE_FUNCS`

    # Parameters:
     - `model_cfg : HookedTransformerConfig|HTConfigMock`
     - `cache : ActivationCacheNp`
     - `save_path : Path`
       (defaults to `Path(DATA_DIR)`)
     - `force_overwrite : bool`
        force overwrite of existing figures. if `False`, will skip any functions which have already saved a figure
       (defaults to `False`)
     - `track_results : bool`
        whether to track the results of each function for each head. Isn't used for anything yet, but this is a TODO
       (defaults to `False`)
    """
    prompt_dir: Path = activations_path.parent

    if track_results:
        results: defaultdict[
            str,  # func name
            dict[
                tuple[int, int],  # layer, head
                bool | Exception,  # success or exception
            ],
        ] = defaultdict(dict)

    for layer_idx, head_idx in itertools.product(
        range(model_cfg.n_layers),
        range(model_cfg.n_heads),
    ):
        attn_pattern: AttentionMatrix = cache[f"blocks.{layer_idx}.attn.hook_pattern"][
            0, head_idx
        ]
        save_dir: Path = prompt_dir / f"L{layer_idx}" / f"H{head_idx}"
        save_dir.mkdir(parents=True, exist_ok=True)
        head_res: dict[str, bool | Exception] = process_single_head(
            layer_idx=layer_idx,
            head_idx=head_idx,
            attn_pattern=attn_pattern,
            save_dir=save_dir,
            force_overwrite=force_overwrite,
        )

        if track_results:
            for func_name, status in head_res.items():
                results[func_name][(layer_idx, head_idx)] = status

    # TODO: do something with results

    generate_prompts_jsonl(save_path / model_cfg.model_name)


def process_prompt(
    prompt: dict,
    model_cfg: "HookedTransformerConfig|HTConfigMock",  # type: ignore[name-defined] # noqa: F821
    save_path: Path,
    force_overwrite: bool = False,
) -> None:
    """process a single prompt, loading the activations and computing and saving the figures

    basically just calls `load_activations` and then `compute_and_save_figures`

    # Parameters:
     - `prompt : dict`
     - `model_cfg : HookedTransformerConfig|HTConfigMock`
     - `force_overwrite : bool`
       (defaults to `False`)
    """
    activations_path: Path
    cache: ActivationCacheNp
    activations_path, cache = load_activations(
        model_name=model_cfg.model_name,
        prompt=prompt,
        save_path=save_path,
        return_fmt="numpy",
    )

    compute_and_save_figures(
        model_cfg=model_cfg,
        activations_path=activations_path,
        cache=cache,
        save_path=save_path,
        force_overwrite=force_overwrite,
    )


def figures_main(
    model_name: str,
    save_path: str,
    n_samples: int,
    force: bool,
    parallel: bool | int = True,
) -> None:
    """main function for generating figures from attention patterns, using the functions in `ATTENTION_MATRIX_FIGURE_FUNCS`

    # Parameters:
     - `model_name : str`
        model name to use, used for loading the model config, prompts, activations, and saving the figures
     - `save_path : str`
        base path to look in
     - `n_samples : int`
        max number of samples to process
     - `force : bool`
        force overwrite of existing figures. if `False`, will skip any functions which have already saved a figure
     - `parallel : bool | int`
        whether to run in parallel. if `True`, will use all available cores. if `False`, will run in serial. if an int, will try to use that many cores
       (defaults to `True`)
    """
    with SpinnerContext(message="setting up paths", **SPINNER_KWARGS):
        # save model info or check if it exists
        save_path_p: Path = Path(save_path)
        model_path: Path = save_path_p / model_name
        with open(model_path / "model_cfg.json", "r") as f:
            model_cfg = HTConfigMock.load(json.load(f))

    with SpinnerContext(message="loading prompts", **SPINNER_KWARGS):
        # load prompts
        with open(model_path / "prompts.jsonl", "r") as f:
            prompts: list[dict] = [json.loads(line) for line in f.readlines()]
        # truncate to n_samples
        prompts = prompts[:n_samples]

    print(f"{len(prompts)} prompts loaded")

    list(
        run_maybe_parallel(
            func=functools.partial(
                process_prompt,
                model_cfg=model_cfg,
                save_path=save_path_p,
                force_overwrite=force,
            ),
            iterable=prompts,
            parallel=parallel,
            pbar="tqdm",
            pbar_kwargs=dict(
                desc="Making figures",
                unit="prompt",
            ),
        )
    )

    with SpinnerContext(
        message="updating jsonl metadata for models and functions", **SPINNER_KWARGS
    ):
        generate_models_jsonl(save_path_p)
        generate_functions_jsonl(save_path_p)


def main():
    print(DIVIDER_S1)
    with SpinnerContext(message="parsing args", **SPINNER_KWARGS):
        arg_parser: argparse.ArgumentParser = argparse.ArgumentParser()
        # input and output
        arg_parser.add_argument(
            "--model",
            "-m",
            type=str,
            required=True,
            help="The model name(s) to use. comma separated with no whitespace if multiple",
        )
        arg_parser.add_argument(
            "--save-path",
            "-s",
            type=str,
            required=False,
            help="The path to save the attention patterns",
            default=DATA_DIR,
        )
        # number of samples
        arg_parser.add_argument(
            "--n-samples",
            "-n",
            type=int,
            required=False,
            help="The max number of samples to process, do all in the file if None",
            default=None,
        )
        # force overwrite of existing figures
        arg_parser.add_argument(
            "--force",
            "-f",
            type=bool,
            required=False,
            help="Force overwrite of existing figures",
            default=False,
        )

        args: argparse.Namespace = arg_parser.parse_args()

    print(f"args parsed: {args}")

    models: list[str]
    if "," in args.model:
        models = args.model.split(",")
    else:
        models = [args.model]

    n_models: int = len(models)
    for idx, model in enumerate(models):
        print(DIVIDER_S2)
        print(f"processing model {idx+1} / {n_models}: {model}")
        print(DIVIDER_S2)
        figures_main(
            model_name=model,
            save_path=args.save_path,
            n_samples=args.n_samples,
            force=args.force,
        )

    print(DIVIDER_S1)


if __name__ == "__main__":
    main()

``````{ end_of_file: "pattern_lens/figures.py" }

``````{ path: "pattern_lens/indexes.py" }
"""writes indexes to the model directory for the frontend to use or for record keeping"""

import inspect
import json
from pathlib import Path
import importlib.resources
from typing import Callable

import pattern_lens
from pattern_lens.attn_figure_funcs import ATTENTION_MATRIX_FIGURE_FUNCS


def generate_prompts_jsonl(model_dir: Path):
    """creates a `prompts.jsonl` file with all the prompts in the model directory

    looks in all directories in `{model_dir}/prompts` for a `prompt.json` file
    """
    prompts: list[dict] = list()
    for prompt_dir in (model_dir / "prompts").iterdir():
        prompt_file: Path = prompt_dir / "prompt.json"
        if prompt_file.exists():
            with open(prompt_file, "r") as f:
                prompt_data: dict = json.load(f)
                prompts.append(prompt_data)

    with open(model_dir / "prompts.jsonl", "w") as f:
        for prompt in prompts:
            f.write(json.dumps(prompt))
            f.write("\n")


def generate_models_jsonl(path: Path):
    """creates a `models.jsonl` file with all the models"""
    models: list[dict] = list()
    for model_dir in (path).iterdir():
        model_cfg_path: Path = model_dir / "model_cfg.json"
        if model_cfg_path.exists():
            with open(model_cfg_path, "r") as f:
                model_cfg: dict = json.load(f)
                models.append(model_cfg)

    with open(path / "models.jsonl", "w") as f:
        for model in models:
            f.write(json.dumps(model))
            f.write("\n")


def get_func_metadata(func: Callable) -> dict[str, str | None]:
    """get metadata for a function

    # Parameters:
     - `func : Callable`

    # Returns:

    `dict[str, str | None]`
    dictionary:

    - `name : str` : the name of the function
    - `doc : str` : the docstring of the function
    - `figure_save_fmt : str | None` : the format of the figure that the function saves, using the `figure_save_fmt` attribute of the function. `None` if the attribute does not exist
    - `source : str | None` : the source file of the function
    - `code : str | None` : the source code of the function, split by line. `None` if the source file cannot be read

    """
    source_file: str | None = inspect.getsourcefile(func)
    output: dict[str, str | None] = dict(
        name=func.__name__,
        doc=func.__doc__,
        figure_save_fmt=getattr(func, "figure_save_fmt", None),
        source=Path(source_file).as_posix() if source_file else None,
    )

    try:
        output["code"] = inspect.getsource(func)
    except OSError:
        output["code"] = None

    return output


def generate_functions_jsonl(path: Path):
    "unions all functions from file and current `ATTENTION_MATRIX_FIGURE_FUNCS` into a `functions.jsonl` file"
    functions_file: Path = path / "functions.jsonl"
    existing_functions: dict[str, dict] = dict()

    if functions_file.exists():
        with open(functions_file, "r") as f:
            for line in f:
                func_data: dict = json.loads(line)
                existing_functions[func_data["name"]] = func_data

    # Add any new functions from ALL_FUNCTIONS
    new_functions: dict[str, dict] = {
        func.__name__: get_func_metadata(func) for func in ATTENTION_MATRIX_FIGURE_FUNCS
    }

    all_functions: list[dict] = list(
        {
            **existing_functions,
            **new_functions,
        }.values()
    )

    with open(functions_file, "w") as f:
        for func_meta in sorted(all_functions, key=lambda x: x["name"]):
            json.dump(func_meta, f)
            f.write("\n")


def write_html_index(path: Path):
    """writes an index.html file to the path"""
    html_index: str = (
        importlib.resources.files(pattern_lens)
        .joinpath("frontend/index.html")
        .read_text(encoding="utf-8")
    )
    with open(path / "index.html", "w", encoding="utf-8") as f:
        f.write(html_index)

``````{ end_of_file: "pattern_lens/indexes.py" }

``````{ path: "pattern_lens/load_activations.py" }
"loading activations from .npz on disk. implements some custom Exception classes"

import base64
import hashlib
import json
from pathlib import Path
from typing import Literal, overload

import numpy as np


class GetActivationsError(ValueError):
    """base class for errors in getting activations"""

    pass


class ActivationsMissingError(GetActivationsError, FileNotFoundError):
    """error for missing activations -- can't find the activations file"""

    pass


class ActivationsMismatchError(GetActivationsError):
    """error for mismatched activations -- the prompt text or hash do not match

    raised by `compare_prompt_to_loaded`
    """

    pass


def compare_prompt_to_loaded(prompt: dict, prompt_loaded: dict) -> None:
    """compare a prompt to a loaded prompt, raise an error if they do not match

    # Parameters:
     - `prompt : dict`
     - `prompt_loaded : dict`

    # Returns:
     - `None`

    # Raises:
     - `ActivationsMismatchError` : if the prompt text or hash do not match
    """
    for key in ("text", "hash"):
        if prompt[key] != prompt_loaded[key]:
            raise ActivationsMismatchError(
                f"Prompt file does not match prompt at key {key}:\n{prompt}\n{prompt_loaded}"
            )


def augment_prompt_with_hash(prompt: dict) -> dict:
    """if a prompt does not have a hash, add one

    # Parameters:
     - `prompt : dict`

    # Returns:
     - `dict`

    # Modifies:
    the input `prompt` dictionary, if it does not have a `"hash"` key
    """
    if "hash" not in prompt:
        prompt_str: str = prompt["text"]
        prompt_hash: str = (
            base64.urlsafe_b64encode(hashlib.md5(prompt_str.encode()).digest())
            .decode()
            .rstrip("=")
        )
        prompt.update(hash=prompt_hash)
    return prompt


@overload
def load_activations(
    model_name: str,
    prompt: dict,
    save_path: Path,
    return_fmt: Literal["torch"] = "torch",
) -> "tuple[Path, dict[str, torch.Tensor]]":  # type: ignore[name-defined] # noqa: F821
    ...
@overload
def load_activations(
    model_name: str,
    prompt: dict,
    save_path: Path,
    return_fmt: Literal["numpy"] = "numpy",
) -> "tuple[Path, dict[str, np.ndarray]]": ...
def load_activations(
    model_name: str,
    prompt: dict,
    save_path: Path,
    return_fmt: Literal["torch", "numpy"] = "torch",
) -> "tuple[Path, dict[str, torch.Tensor]|dict[str, np.ndarray]]":  # type: ignore[name-defined] # noqa: F821
    """load activations for a prompt and model, from an npz file

    # Parameters:
     - `model_name : str`
     - `prompt : dict`
     - `save_path : Path`
     - `return_fmt : Literal["torch", "numpy"]`
       (defaults to `"torch"`)

    # Returns:
     - `tuple[Path, dict[str, torch.Tensor]|dict[str, np.ndarray]]`
         the path to the activations file and the activations as a dictionary of numpy arrays or torch tensors, depending on `return_fmt`

    # Raises:
     - `ActivationsMissingError` : if the activations file is missing
     - `ValueError` : if `return_fmt` is not `"torch"` or `"numpy"`
    """

    if return_fmt not in ("torch", "numpy"):
        raise ValueError(
            f"Invalid return_fmt: {return_fmt}, expected 'torch' or 'numpy'"
        )
    if return_fmt == "torch":
        import torch

    augment_prompt_with_hash(prompt)

    prompt_dir: Path = save_path / model_name / "prompts" / prompt["hash"]
    prompt_file: Path = prompt_dir / "prompt.json"
    if not prompt_file.exists():
        raise ActivationsMissingError(f"Prompt file {prompt_file} does not exist")
    with open(prompt_dir / "prompt.json", "r") as f:
        prompt_loaded: dict = json.load(f)
        compare_prompt_to_loaded(prompt, prompt_loaded)

    activations_path: Path = prompt_dir / "activations.npz"

    cache: dict

    with np.load(activations_path) as npz_data:
        if return_fmt == "numpy":
            cache = {k: v for k, v in npz_data.items()}
        elif return_fmt == "torch":
            cache = {k: torch.from_numpy(v) for k, v in npz_data.items()}

    return activations_path, cache

``````{ end_of_file: "pattern_lens/load_activations.py" }

``````{ path: "pattern_lens/prompts.py" }
"implements `load_text_data` for loading prompts"

import json
import random
from pathlib import Path


def load_text_data(
    fname: Path,
    min_chars: int | None = None,
    max_chars: int | None = None,
    shuffle: bool = False,
) -> list[dict]:
    """given `fname`, the path to a jsonl file, split prompts up into more reasonable sizes

    # Parameters:
     - `fname : Path`
        jsonl file with prompts. Expects a list of dicts with a "text" key
     - `min_chars : int | None`
       (defaults to `None`)
     - `max_chars : int | None`
       (defaults to `None`)
     - `shuffle : bool`
       (defaults to `False`)

    # Returns:
     - `list[dict]`
       new, processed list of prompts. Each prompt has a "text" key with a string value, and some metadata. this is not guaranteed to be the same length as the input list!
    """
    # read raw data
    with open(fname, "r") as f:
        data_raw: list[dict] = [json.loads(d) for d in f.readlines()]

    # add fname metadata
    for d in data_raw:
        d["source_fname"] = fname.as_posix()

    # trim too-short samples
    if min_chars is not None:
        data_raw = list(
            filter(
                lambda x: len(x["text"]) >= min_chars,
                data_raw,
            )
        )

    # split up too-long samples
    if max_chars is not None:
        data_new: list[dict] = []
        for d in data_raw:
            d_text: str = d["text"]
            while len(d_text) > max_chars:
                data_new.append(
                    {
                        **d,
                        "text": d_text[:max_chars],
                    }
                )
                d_text = d_text[max_chars:]
            data_new.append(
                {
                    **d,
                    "text": d_text,
                }
            )
        data_raw = data_new

    # trim too-short samples again
    if min_chars is not None:
        data_raw = list(
            filter(
                lambda x: len(x["text"]) >= min_chars,
                data_raw,
            )
        )

    # shuffle
    if shuffle:
        random.shuffle(data_raw)

    return data_raw

``````{ end_of_file: "pattern_lens/prompts.py" }

``````{ path: "pattern_lens/server.py" }
"""cli for starting the server to show the web ui.

can also run with --rewrite-index to update the index.html file. this is useful for working on the ui.
"""

from pathlib import Path
import sys
import os
import argparse
import http.server
import socketserver

from pattern_lens.indexes import write_html_index


def main(path: str, port: int = 8000):
    os.chdir(path)
    try:
        with socketserver.TCPServer(
            ("", port), http.server.SimpleHTTPRequestHandler
        ) as httpd:
            print(f"Serving at http://localhost:{port}")
            httpd.serve_forever()
    except KeyboardInterrupt:
        print("Server stopped")
        sys.exit(0)


if __name__ == "__main__":
    arg_parser: argparse.ArgumentParser = argparse.ArgumentParser()
    arg_parser.add_argument(
        "--path",
        type=str,
        required=False,
        help="The path to serve, defaults to the current directory",
        default=".",
    )
    arg_parser.add_argument(
        "--port",
        type=int,
        required=False,
        help="The port to serve on, defaults to 8000",
        default=8000,
    )
    arg_parser.add_argument(
        "--rewrite-index",
        action="store_true",
        help="Whether to write the latest index.html file",
    )
    args: argparse.Namespace = arg_parser.parse_args()

    if args.rewrite_index:
        write_html_index(path=Path(args.path))

    main(path=args.path, port=args.port)

``````{ end_of_file: "pattern_lens/server.py" }

``````{ path: "tests/integration/test_pipeline.py" }
import pytest

from pattern_lens.activations import activations_main
from pattern_lens.figures import figures_main

SAVE_PATH_BASE: str = "tests/_temp/pipeline"
PROMPTS_PATH: str = "data/pile_100.jsonl"
N_SAMPLES: int = 3
MIN_CHARS: int = 32
MAX_CHARS: int = 128
FORCE: bool = True
NO_INDEX_HTML: bool = False
FIGURES_PARALLEL: bool = False


@pytest.mark.parametrize(
    "model_name",
    ["pythia-14m", "tiny-stories-1M"],
)
def test_pipeline(model_name: str):
    activations_main(
        model_name=model_name,
        save_path=SAVE_PATH_BASE,
        prompts_path=PROMPTS_PATH,
        raw_prompts=True,
        min_chars=MIN_CHARS,
        max_chars=MAX_CHARS,
        force=FORCE,
        n_samples=N_SAMPLES,
        no_index_html=NO_INDEX_HTML,
    )
    figures_main(
        model_name=model_name,
        save_path=SAVE_PATH_BASE,
        n_samples=N_SAMPLES,
        force=FORCE,
        parallel=FIGURES_PARALLEL,
    )

``````{ end_of_file: "tests/integration/test_pipeline.py" }

``````{ path: "tests/unit/test_figure_util.py" }
import jaxtyping
import pytest
import numpy as np
from pathlib import Path
import gzip
import re
import base64
import io

from PIL import Image
import matplotlib.pyplot as plt


from pattern_lens.figure_util import (
    MATPLOTLIB_FIGURE_FMT,
    matplotlib_figure_saver,
    matrix_as_svg,
    save_matrix_wrapper,
)


TEMP_DIR: Path = Path("tests/_temp")


def test_matplotlib_figure_saver():
    TEMP_DIR.mkdir(parents=True, exist_ok=True)

    @matplotlib_figure_saver
    def plot_matrix(attn_matrix, ax):
        ax.matshow(attn_matrix, cmap="viridis")
        ax.axis("off")

    attn_matrix = np.random.rand(10, 10).astype(np.float32)
    plot_matrix(attn_matrix, TEMP_DIR)

    saved_file = TEMP_DIR / f"plot_matrix.{MATPLOTLIB_FIGURE_FMT}"
    assert saved_file.exists(), "Matplotlib figure file was not saved"


def test_matplotlib_figure_saver_exception():
    TEMP_DIR.mkdir(parents=True, exist_ok=True)

    @matplotlib_figure_saver
    def faulty_plot(attn_matrix, ax):
        raise ValueError("Intentional failure for testing")

    attn_matrix = np.random.rand(10, 10).astype(np.float32)
    with pytest.raises(ValueError, match="Intentional failure for testing"):
        faulty_plot(attn_matrix, TEMP_DIR)


def test_matrix_as_svg_normalization():
    matrix = np.array([[2, 4], [6, 8]], dtype=np.float32)
    svg_content = matrix_as_svg(matrix, normalize=True)
    assert "image href=" in svg_content, "SVG content is malformed"
    assert "data:image/png;base64," in svg_content, "Base64 encoding is missing"


def test_matrix_as_svg_no_normalization():
    matrix = np.array([[0.1, 0.4], [0.6, 0.9]], dtype=np.float32)
    svg_content = matrix_as_svg(matrix, normalize=False)
    assert "image href=" in svg_content, "SVG content is malformed"
    assert "data:image/png;base64," in svg_content, "Base64 encoding is missing"


def test_matrix_as_svg_invalid_range():
    matrix = np.array([[-1, 2], [3, 4]], dtype=np.float32)
    with pytest.raises(
        AssertionError,
        match="Matrix values must be in range \\[0, 1\\], or normalize must be True",
    ):
        matrix_as_svg(matrix, normalize=False)


def test_matrix_as_svg_invalid_dims():
    matrix = np.random.rand(5, 5, 5).astype(np.float32)
    with pytest.raises((AssertionError, jaxtyping.TypeCheckError)):
        matrix_as_svg(matrix, normalize=True)


def test_matrix_as_svg_invalid_cmap_fixed():
    matrix = np.array([[0.1, 0.4], [0.6, 0.9]], dtype=np.float32)
    with pytest.raises(KeyError, match="'invalid_cmap' is not a known colormap name"):
        matrix_as_svg(matrix, cmap="invalid_cmap")


# Test with no arguments
def test_save_matrix_as_svgz_wrapper_no_args():
    TEMP_DIR.mkdir(parents=True, exist_ok=True)

    @save_matrix_wrapper(fmt="svgz")
    def no_op(matrix):
        return matrix

    test_matrix = np.array([[0.1, 0.2], [0.3, 0.4]], dtype=np.float32)
    no_op(test_matrix, TEMP_DIR)

    saved_file = TEMP_DIR / "no_op.svgz"
    assert saved_file.exists(), "SVGZ file was not saved in no-args case"


# Test with keyword-only arguments
def test_save_matrix_as_svgz_wrapper_with_args():
    TEMP_DIR.mkdir(parents=True, exist_ok=True)

    @save_matrix_wrapper(normalize=True, cmap="plasma")
    def scale_matrix(matrix):
        return matrix * 2

    test_matrix = np.array([[0.5, 0.6], [0.7, 0.8]], dtype=np.float32)
    scale_matrix(test_matrix, TEMP_DIR)

    saved_file = TEMP_DIR / "scale_matrix.svgz"
    assert saved_file.exists(), "SVGZ file was not saved with keyword-only arguments"


# Test exception handling
def test_save_matrix_as_svgz_wrapper_exceptions():
    TEMP_DIR.mkdir(parents=True, exist_ok=True)

    @save_matrix_wrapper(normalize=False)
    def invalid_range(matrix):
        return matrix * 2

    test_matrix = np.array([[2, 3], [4, 5]], dtype=np.float32)
    with pytest.raises(
        AssertionError,
        match=r"Matrix values must be in range \[0, 1\], or normalize must be True\. got: min: .*?, max: .*?",
    ):
        invalid_range(test_matrix, TEMP_DIR)


# Test keyword-only arguments enforced
def test_save_matrix_as_svgz_wrapper_keyword_only():
    TEMP_DIR.mkdir(parents=True, exist_ok=True)

    @save_matrix_wrapper(normalize=True, cmap="plasma")
    def scale_matrix(matrix):
        return matrix * 2

    test_matrix = np.array([[0.5, 0.6], [0.7, 0.8]], dtype=np.float32)
    scale_matrix(test_matrix, TEMP_DIR)

    saved_file = TEMP_DIR / "scale_matrix.svgz"
    assert saved_file.exists(), "SVGZ file was not saved with keyword-only arguments"


# Test multiple calls to the decorator
def test_save_matrix_as_svgz_wrapper_multiple():
    TEMP_DIR.mkdir(parents=True, exist_ok=True)

    @save_matrix_wrapper(normalize=True)
    def scale_by_factor(matrix):
        return matrix * 3

    matrix_1 = np.array([[0.1, 0.5], [0.7, 0.9]], dtype=np.float32)
    matrix_2 = np.array([[0.2, 0.6], [0.8, 1.0]], dtype=np.float32)

    scale_by_factor(matrix_1, TEMP_DIR)
    scale_by_factor(matrix_2, TEMP_DIR)

    # Check the saved files
    saved_file = TEMP_DIR / "scale_by_factor.svgz"
    assert saved_file.exists(), "SVGZ file was not saved for multiple calls"


# Validate behavior when normalize is False and values are in range
def test_save_matrix_as_svgz_wrapper_no_normalization():
    TEMP_DIR.mkdir(parents=True, exist_ok=True)

    @save_matrix_wrapper(normalize=False)
    def pass_through(matrix):
        return matrix

    test_matrix = np.array([[0.1, 0.2], [0.3, 0.4]], dtype=np.float32)
    pass_through(test_matrix, TEMP_DIR)

    saved_file = TEMP_DIR / "pass_through.svgz"
    assert (
        saved_file.exists()
    ), "SVGZ file was not saved when normalization was not applied"


# Test with a complex matrix
def test_save_matrix_as_svgz_wrapper_complex_matrix():
    TEMP_DIR.mkdir(parents=True, exist_ok=True)

    @save_matrix_wrapper(normalize=True, cmap="viridis")
    def complex_processing(matrix):
        return np.sin(matrix)

    test_matrix = np.linspace(0, np.pi, 16).reshape(4, 4).astype(np.float32)
    complex_processing(test_matrix, TEMP_DIR)

    saved_file = TEMP_DIR / "complex_processing.svgz"
    assert saved_file.exists(), "SVGZ file was not saved for complex matrix processing"


def test_matrix_as_svg_dimensions():
    # Test different matrix shapes
    matrices = [
        np.random.rand(5, 10),  # Non-square
        np.random.rand(3, 3),  # Small square
        np.random.rand(100, 50),  # Large non-square
    ]

    for matrix in matrices:
        m, n = matrix.shape
        svg_content = matrix_as_svg(matrix, normalize=True)
        assert f'width="{m}"' in svg_content
        assert f'height="{n}"' in svg_content
        assert f'viewBox="0 0 {m} {n}"' in svg_content


def test_save_matrix_as_svgz_wrapper_content():
    TEMP_DIR.mkdir(parents=True, exist_ok=True)

    @save_matrix_wrapper(normalize=True)
    def identity(matrix):
        return matrix

    test_matrix = np.array([[0.1, 0.2], [0.3, 0.4]], dtype=np.float32)
    identity(test_matrix, TEMP_DIR)

    saved_file = TEMP_DIR / "identity.svgz"
    with gzip.open(saved_file, "rt") as f:
        content = f.read()
        assert "svg" in content
        assert "image href=" in content
        assert "base64" in content


def test_matplotlib_figure_saver_formats():
    TEMP_DIR.mkdir(parents=True, exist_ok=True)
    formats = ["png", "pdf", "svg"]

    for fmt in formats:

        @matplotlib_figure_saver(fmt=fmt)
        def plot_matrix(attn_matrix, ax):
            ax.matshow(attn_matrix)
            ax.axis("off")

        matrix = np.random.rand(5, 5)
        plot_matrix(matrix, TEMP_DIR)
        saved_file = TEMP_DIR / f"plot_matrix.{fmt}"
        assert saved_file.exists(), f"File not saved for format {fmt}"


def test_matrix_as_svg_empty():
    empty_matrix = np.array([[]], dtype=np.float32).reshape(0, 0)
    with pytest.raises(AssertionError, match="Matrix cannot be empty"):
        matrix_as_svg(empty_matrix)


def test_matplotlib_figure_saver_cleanup():
    TEMP_DIR.mkdir(parents=True, exist_ok=True)
    initial_figures = len(plt.get_fignums())

    @matplotlib_figure_saver
    def plot_matrix(attn_matrix, ax):
        ax.matshow(attn_matrix)

    matrix = np.random.rand(5, 5)
    plot_matrix(matrix, TEMP_DIR)

    # Check that no figure objects remain
    assert len(plt.get_fignums()) == initial_figures, "Figure not properly cleaned up"


def test_matrix_as_svg_non_numeric():
    matrix = np.array([["a", "b"], ["c", "d"]])
    with pytest.raises(TypeError):
        matrix_as_svg(matrix)


def test_matrix_as_svg_format():
    # create a small 2x2 matrix
    matrix = np.array([[0.0, 0.5], [1.0, 0.75]], dtype=float)

    svg_str = matrix_as_svg(matrix)

    # ensure it's got the correct SVG wrapper
    assert svg_str.startswith("<svg"), "SVG should start with <svg>"
    assert svg_str.endswith("</svg>"), "SVG should end with </svg>"

    # find the embedded base64 image data
    match = re.search(r'data:image/png;base64,([^"]+)', svg_str)
    assert match, "Expected an embedded PNG in data URI format"

    embedded_data = match.group(1)
    png_data = base64.b64decode(embedded_data)

    Image.open(io.BytesIO(png_data))

``````{ end_of_file: "tests/unit/test_figure_util.py" }

``````{ path: "LICENSE" }
                    GNU GENERAL PUBLIC LICENSE
                       Version 3, 29 June 2007

 Copyright (C) 2007 Free Software Foundation, Inc. <https://fsf.org/>
 Everyone is permitted to copy and distribute verbatim copies
 of this license document, but changing it is not allowed.

                            Preamble

  The GNU General Public License is a free, copyleft license for
software and other kinds of works.

  The licenses for most software and other practical works are designed
to take away your freedom to share and change the works.  By contrast,
the GNU General Public License is intended to guarantee your freedom to
share and change all versions of a program--to make sure it remains free
software for all its users.  We, the Free Software Foundation, use the
GNU General Public License for most of our software; it applies also to
any other work released this way by its authors.  You can apply it to
your programs, too.

  When we speak of free software, we are referring to freedom, not
price.  Our General Public Licenses are designed to make sure that you
have the freedom to distribute copies of free software (and charge for
them if you wish), that you receive source code or can get it if you
want it, that you can change the software or use pieces of it in new
free programs, and that you know you can do these things.

  To protect your rights, we need to prevent others from denying you
these rights or asking you to surrender the rights.  Therefore, you have
certain responsibilities if you distribute copies of the software, or if
you modify it: responsibilities to respect the freedom of others.

  For example, if you distribute copies of such a program, whether
gratis or for a fee, you must pass on to the recipients the same
freedoms that you received.  You must make sure that they, too, receive
or can get the source code.  And you must show them these terms so they
know their rights.

  Developers that use the GNU GPL protect your rights with two steps:
(1) assert copyright on the software, and (2) offer you this License
giving you legal permission to copy, distribute and/or modify it.

  For the developers' and authors' protection, the GPL clearly explains
that there is no warranty for this free software.  For both users' and
authors' sake, the GPL requires that modified versions be marked as
changed, so that their problems will not be attributed erroneously to
authors of previous versions.

  Some devices are designed to deny users access to install or run
modified versions of the software inside them, although the manufacturer
can do so.  This is fundamentally incompatible with the aim of
protecting users' freedom to change the software.  The systematic
pattern of such abuse occurs in the area of products for individuals to
use, which is precisely where it is most unacceptable.  Therefore, we
have designed this version of the GPL to prohibit the practice for those
products.  If such problems arise substantially in other domains, we
stand ready to extend this provision to those domains in future versions
of the GPL, as needed to protect the freedom of users.

  Finally, every program is threatened constantly by software patents.
States should not allow patents to restrict development and use of
software on general-purpose computers, but in those that do, we wish to
avoid the special danger that patents applied to a free program could
make it effectively proprietary.  To prevent this, the GPL assures that
patents cannot be used to render the program non-free.

  The precise terms and conditions for copying, distribution and
modification follow.

                       TERMS AND CONDITIONS

  0. Definitions.

  "This License" refers to version 3 of the GNU General Public License.

  "Copyright" also means copyright-like laws that apply to other kinds of
works, such as semiconductor masks.

  "The Program" refers to any copyrightable work licensed under this
License.  Each licensee is addressed as "you".  "Licensees" and
"recipients" may be individuals or organizations.

  To "modify" a work means to copy from or adapt all or part of the work
in a fashion requiring copyright permission, other than the making of an
exact copy.  The resulting work is called a "modified version" of the
earlier work or a work "based on" the earlier work.

  A "covered work" means either the unmodified Program or a work based
on the Program.

  To "propagate" a work means to do anything with it that, without
permission, would make you directly or secondarily liable for
infringement under applicable copyright law, except executing it on a
computer or modifying a private copy.  Propagation includes copying,
distribution (with or without modification), making available to the
public, and in some countries other activities as well.

  To "convey" a work means any kind of propagation that enables other
parties to make or receive copies.  Mere interaction with a user through
a computer network, with no transfer of a copy, is not conveying.

  An interactive user interface displays "Appropriate Legal Notices"
to the extent that it includes a convenient and prominently visible
feature that (1) displays an appropriate copyright notice, and (2)
tells the user that there is no warranty for the work (except to the
extent that warranties are provided), that licensees may convey the
work under this License, and how to view a copy of this License.  If
the interface presents a list of user commands or options, such as a
menu, a prominent item in the list meets this criterion.

  1. Source Code.

  The "source code" for a work means the preferred form of the work
for making modifications to it.  "Object code" means any non-source
form of a work.

  A "Standard Interface" means an interface that either is an official
standard defined by a recognized standards body, or, in the case of
interfaces specified for a particular programming language, one that
is widely used among developers working in that language.

  The "System Libraries" of an executable work include anything, other
than the work as a whole, that (a) is included in the normal form of
packaging a Major Component, but which is not part of that Major
Component, and (b) serves only to enable use of the work with that
Major Component, or to implement a Standard Interface for which an
implementation is available to the public in source code form.  A
"Major Component", in this context, means a major essential component
(kernel, window system, and so on) of the specific operating system
(if any) on which the executable work runs, or a compiler used to
produce the work, or an object code interpreter used to run it.

  The "Corresponding Source" for a work in object code form means all
the source code needed to generate, install, and (for an executable
work) run the object code and to modify the work, including scripts to
control those activities.  However, it does not include the work's
System Libraries, or general-purpose tools or generally available free
programs which are used unmodified in performing those activities but
which are not part of the work.  For example, Corresponding Source
includes interface definition files associated with source files for
the work, and the source code for shared libraries and dynamically
linked subprograms that the work is specifically designed to require,
such as by intimate data communication or control flow between those
subprograms and other parts of the work.

  The Corresponding Source need not include anything that users
can regenerate automatically from other parts of the Corresponding
Source.

  The Corresponding Source for a work in source code form is that
same work.

  2. Basic Permissions.

  All rights granted under this License are granted for the term of
copyright on the Program, and are irrevocable provided the stated
conditions are met.  This License explicitly affirms your unlimited
permission to run the unmodified Program.  The output from running a
covered work is covered by this License only if the output, given its
content, constitutes a covered work.  This License acknowledges your
rights of fair use or other equivalent, as provided by copyright law.

  You may make, run and propagate covered works that you do not
convey, without conditions so long as your license otherwise remains
in force.  You may convey covered works to others for the sole purpose
of having them make modifications exclusively for you, or provide you
with facilities for running those works, provided that you comply with
the terms of this License in conveying all material for which you do
not control copyright.  Those thus making or running the covered works
for you must do so exclusively on your behalf, under your direction
and control, on terms that prohibit them from making any copies of
your copyrighted material outside their relationship with you.

  Conveying under any other circumstances is permitted solely under
the conditions stated below.  Sublicensing is not allowed; section 10
makes it unnecessary.

  3. Protecting Users' Legal Rights From Anti-Circumvention Law.

  No covered work shall be deemed part of an effective technological
measure under any applicable law fulfilling obligations under article
11 of the WIPO copyright treaty adopted on 20 December 1996, or
similar laws prohibiting or restricting circumvention of such
measures.

  When you convey a covered work, you waive any legal power to forbid
circumvention of technological measures to the extent such circumvention
is effected by exercising rights under this License with respect to
the covered work, and you disclaim any intention to limit operation or
modification of the work as a means of enforcing, against the work's
users, your or third parties' legal rights to forbid circumvention of
technological measures.

  4. Conveying Verbatim Copies.

  You may convey verbatim copies of the Program's source code as you
receive it, in any medium, provided that you conspicuously and
appropriately publish on each copy an appropriate copyright notice;
keep intact all notices stating that this License and any
non-permissive terms added in accord with section 7 apply to the code;
keep intact all notices of the absence of any warranty; and give all
recipients a copy of this License along with the Program.

  You may charge any price or no price for each copy that you convey,
and you may offer support or warranty protection for a fee.

  5. Conveying Modified Source Versions.

  You may convey a work based on the Program, or the modifications to
produce it from the Program, in the form of source code under the
terms of section 4, provided that you also meet all of these conditions:

    a) The work must carry prominent notices stating that you modified
    it, and giving a relevant date.

    b) The work must carry prominent notices stating that it is
    released under this License and any conditions added under section
    7.  This requirement modifies the requirement in section 4 to
    "keep intact all notices".

    c) You must license the entire work, as a whole, under this
    License to anyone who comes into possession of a copy.  This
    License will therefore apply, along with any applicable section 7
    additional terms, to the whole of the work, and all its parts,
    regardless of how they are packaged.  This License gives no
    permission to license the work in any other way, but it does not
    invalidate such permission if you have separately received it.

    d) If the work has interactive user interfaces, each must display
    Appropriate Legal Notices; however, if the Program has interactive
    interfaces that do not display Appropriate Legal Notices, your
    work need not make them do so.

  A compilation of a covered work with other separate and independent
works, which are not by their nature extensions of the covered work,
and which are not combined with it such as to form a larger program,
in or on a volume of a storage or distribution medium, is called an
"aggregate" if the compilation and its resulting copyright are not
used to limit the access or legal rights of the compilation's users
beyond what the individual works permit.  Inclusion of a covered work
in an aggregate does not cause this License to apply to the other
parts of the aggregate.

  6. Conveying Non-Source Forms.

  You may convey a covered work in object code form under the terms
of sections 4 and 5, provided that you also convey the
machine-readable Corresponding Source under the terms of this License,
in one of these ways:

    a) Convey the object code in, or embodied in, a physical product
    (including a physical distribution medium), accompanied by the
    Corresponding Source fixed on a durable physical medium
    customarily used for software interchange.

    b) Convey the object code in, or embodied in, a physical product
    (including a physical distribution medium), accompanied by a
    written offer, valid for at least three years and valid for as
    long as you offer spare parts or customer support for that product
    model, to give anyone who possesses the object code either (1) a
    copy of the Corresponding Source for all the software in the
    product that is covered by this License, on a durable physical
    medium customarily used for software interchange, for a price no
    more than your reasonable cost of physically performing this
    conveying of source, or (2) access to copy the
    Corresponding Source from a network server at no charge.

    c) Convey individual copies of the object code with a copy of the
    written offer to provide the Corresponding Source.  This
    alternative is allowed only occasionally and noncommercially, and
    only if you received the object code with such an offer, in accord
    with subsection 6b.

    d) Convey the object code by offering access from a designated
    place (gratis or for a charge), and offer equivalent access to the
    Corresponding Source in the same way through the same place at no
    further charge.  You need not require recipients to copy the
    Corresponding Source along with the object code.  If the place to
    copy the object code is a network server, the Corresponding Source
    may be on a different server (operated by you or a third party)
    that supports equivalent copying facilities, provided you maintain
    clear directions next to the object code saying where to find the
    Corresponding Source.  Regardless of what server hosts the
    Corresponding Source, you remain obligated to ensure that it is
    available for as long as needed to satisfy these requirements.

    e) Convey the object code using peer-to-peer transmission, provided
    you inform other peers where the object code and Corresponding
    Source of the work are being offered to the general public at no
    charge under subsection 6d.

  A separable portion of the object code, whose source code is excluded
from the Corresponding Source as a System Library, need not be
included in conveying the object code work.

  A "User Product" is either (1) a "consumer product", which means any
tangible personal property which is normally used for personal, family,
or household purposes, or (2) anything designed or sold for incorporation
into a dwelling.  In determining whether a product is a consumer product,
doubtful cases shall be resolved in favor of coverage.  For a particular
product received by a particular user, "normally used" refers to a
typical or common use of that class of product, regardless of the status
of the particular user or of the way in which the particular user
actually uses, or expects or is expected to use, the product.  A product
is a consumer product regardless of whether the product has substantial
commercial, industrial or non-consumer uses, unless such uses represent
the only significant mode of use of the product.

  "Installation Information" for a User Product means any methods,
procedures, authorization keys, or other information required to install
and execute modified versions of a covered work in that User Product from
a modified version of its Corresponding Source.  The information must
suffice to ensure that the continued functioning of the modified object
code is in no case prevented or interfered with solely because
modification has been made.

  If you convey an object code work under this section in, or with, or
specifically for use in, a User Product, and the conveying occurs as
part of a transaction in which the right of possession and use of the
User Product is transferred to the recipient in perpetuity or for a
fixed term (regardless of how the transaction is characterized), the
Corresponding Source conveyed under this section must be accompanied
by the Installation Information.  But this requirement does not apply
if neither you nor any third party retains the ability to install
modified object code on the User Product (for example, the work has
been installed in ROM).

  The requirement to provide Installation Information does not include a
requirement to continue to provide support service, warranty, or updates
for a work that has been modified or installed by the recipient, or for
the User Product in which it has been modified or installed.  Access to a
network may be denied when the modification itself materially and
adversely affects the operation of the network or violates the rules and
protocols for communication across the network.

  Corresponding Source conveyed, and Installation Information provided,
in accord with this section must be in a format that is publicly
documented (and with an implementation available to the public in
source code form), and must require no special password or key for
unpacking, reading or copying.

  7. Additional Terms.

  "Additional permissions" are terms that supplement the terms of this
License by making exceptions from one or more of its conditions.
Additional permissions that are applicable to the entire Program shall
be treated as though they were included in this License, to the extent
that they are valid under applicable law.  If additional permissions
apply only to part of the Program, that part may be used separately
under those permissions, but the entire Program remains governed by
this License without regard to the additional permissions.

  When you convey a copy of a covered work, you may at your option
remove any additional permissions from that copy, or from any part of
it.  (Additional permissions may be written to require their own
removal in certain cases when you modify the work.)  You may place
additional permissions on material, added by you to a covered work,
for which you have or can give appropriate copyright permission.

  Notwithstanding any other provision of this License, for material you
add to a covered work, you may (if authorized by the copyright holders of
that material) supplement the terms of this License with terms:

    a) Disclaiming warranty or limiting liability differently from the
    terms of sections 15 and 16 of this License; or

    b) Requiring preservation of specified reasonable legal notices or
    author attributions in that material or in the Appropriate Legal
    Notices displayed by works containing it; or

    c) Prohibiting misrepresentation of the origin of that material, or
    requiring that modified versions of such material be marked in
    reasonable ways as different from the original version; or

    d) Limiting the use for publicity purposes of names of licensors or
    authors of the material; or

    e) Declining to grant rights under trademark law for use of some
    trade names, trademarks, or service marks; or

    f) Requiring indemnification of licensors and authors of that
    material by anyone who conveys the material (or modified versions of
    it) with contractual assumptions of liability to the recipient, for
    any liability that these contractual assumptions directly impose on
    those licensors and authors.

  All other non-permissive additional terms are considered "further
restrictions" within the meaning of section 10.  If the Program as you
received it, or any part of it, contains a notice stating that it is
governed by this License along with a term that is a further
restriction, you may remove that term.  If a license document contains
a further restriction but permits relicensing or conveying under this
License, you may add to a covered work material governed by the terms
of that license document, provided that the further restriction does
not survive such relicensing or conveying.

  If you add terms to a covered work in accord with this section, you
must place, in the relevant source files, a statement of the
additional terms that apply to those files, or a notice indicating
where to find the applicable terms.

  Additional terms, permissive or non-permissive, may be stated in the
form of a separately written license, or stated as exceptions;
the above requirements apply either way.

  8. Termination.

  You may not propagate or modify a covered work except as expressly
provided under this License.  Any attempt otherwise to propagate or
modify it is void, and will automatically terminate your rights under
this License (including any patent licenses granted under the third
paragraph of section 11).

  However, if you cease all violation of this License, then your
license from a particular copyright holder is reinstated (a)
provisionally, unless and until the copyright holder explicitly and
finally terminates your license, and (b) permanently, if the copyright
holder fails to notify you of the violation by some reasonable means
prior to 60 days after the cessation.

  Moreover, your license from a particular copyright holder is
reinstated permanently if the copyright holder notifies you of the
violation by some reasonable means, this is the first time you have
received notice of violation of this License (for any work) from that
copyright holder, and you cure the violation prior to 30 days after
your receipt of the notice.

  Termination of your rights under this section does not terminate the
licenses of parties who have received copies or rights from you under
this License.  If your rights have been terminated and not permanently
reinstated, you do not qualify to receive new licenses for the same
material under section 10.

  9. Acceptance Not Required for Having Copies.

  You are not required to accept this License in order to receive or
run a copy of the Program.  Ancillary propagation of a covered work
occurring solely as a consequence of using peer-to-peer transmission
to receive a copy likewise does not require acceptance.  However,
nothing other than this License grants you permission to propagate or
modify any covered work.  These actions infringe copyright if you do
not accept this License.  Therefore, by modifying or propagating a
covered work, you indicate your acceptance of this License to do so.

  10. Automatic Licensing of Downstream Recipients.

  Each time you convey a covered work, the recipient automatically
receives a license from the original licensors, to run, modify and
propagate that work, subject to this License.  You are not responsible
for enforcing compliance by third parties with this License.

  An "entity transaction" is a transaction transferring control of an
organization, or substantially all assets of one, or subdividing an
organization, or merging organizations.  If propagation of a covered
work results from an entity transaction, each party to that
transaction who receives a copy of the work also receives whatever
licenses to the work the party's predecessor in interest had or could
give under the previous paragraph, plus a right to possession of the
Corresponding Source of the work from the predecessor in interest, if
the predecessor has it or can get it with reasonable efforts.

  You may not impose any further restrictions on the exercise of the
rights granted or affirmed under this License.  For example, you may
not impose a license fee, royalty, or other charge for exercise of
rights granted under this License, and you may not initiate litigation
(including a cross-claim or counterclaim in a lawsuit) alleging that
any patent claim is infringed by making, using, selling, offering for
sale, or importing the Program or any portion of it.

  11. Patents.

  A "contributor" is a copyright holder who authorizes use under this
License of the Program or a work on which the Program is based.  The
work thus licensed is called the contributor's "contributor version".

  A contributor's "essential patent claims" are all patent claims
owned or controlled by the contributor, whether already acquired or
hereafter acquired, that would be infringed by some manner, permitted
by this License, of making, using, or selling its contributor version,
but do not include claims that would be infringed only as a
consequence of further modification of the contributor version.  For
purposes of this definition, "control" includes the right to grant
patent sublicenses in a manner consistent with the requirements of
this License.

  Each contributor grants you a non-exclusive, worldwide, royalty-free
patent license under the contributor's essential patent claims, to
make, use, sell, offer for sale, import and otherwise run, modify and
propagate the contents of its contributor version.

  In the following three paragraphs, a "patent license" is any express
agreement or commitment, however denominated, not to enforce a patent
(such as an express permission to practice a patent or covenant not to
sue for patent infringement).  To "grant" such a patent license to a
party means to make such an agreement or commitment not to enforce a
patent against the party.

  If you convey a covered work, knowingly relying on a patent license,
and the Corresponding Source of the work is not available for anyone
to copy, free of charge and under the terms of this License, through a
publicly available network server or other readily accessible means,
then you must either (1) cause the Corresponding Source to be so
available, or (2) arrange to deprive yourself of the benefit of the
patent license for this particular work, or (3) arrange, in a manner
consistent with the requirements of this License, to extend the patent
license to downstream recipients.  "Knowingly relying" means you have
actual knowledge that, but for the patent license, your conveying the
covered work in a country, or your recipient's use of the covered work
in a country, would infringe one or more identifiable patents in that
country that you have reason to believe are valid.

  If, pursuant to or in connection with a single transaction or
arrangement, you convey, or propagate by procuring conveyance of, a
covered work, and grant a patent license to some of the parties
receiving the covered work authorizing them to use, propagate, modify
or convey a specific copy of the covered work, then the patent license
you grant is automatically extended to all recipients of the covered
work and works based on it.

  A patent license is "discriminatory" if it does not include within
the scope of its coverage, prohibits the exercise of, or is
conditioned on the non-exercise of one or more of the rights that are
specifically granted under this License.  You may not convey a covered
work if you are a party to an arrangement with a third party that is
in the business of distributing software, under which you make payment
to the third party based on the extent of your activity of conveying
the work, and under which the third party grants, to any of the
parties who would receive the covered work from you, a discriminatory
patent license (a) in connection with copies of the covered work
conveyed by you (or copies made from those copies), or (b) primarily
for and in connection with specific products or compilations that
contain the covered work, unless you entered into that arrangement,
or that patent license was granted, prior to 28 March 2007.

  Nothing in this License shall be construed as excluding or limiting
any implied license or other defenses to infringement that may
otherwise be available to you under applicable patent law.

  12. No Surrender of Others' Freedom.

  If conditions are imposed on you (whether by court order, agreement or
otherwise) that contradict the conditions of this License, they do not
excuse you from the conditions of this License.  If you cannot convey a
covered work so as to satisfy simultaneously your obligations under this
License and any other pertinent obligations, then as a consequence you may
not convey it at all.  For example, if you agree to terms that obligate you
to collect a royalty for further conveying from those to whom you convey
the Program, the only way you could satisfy both those terms and this
License would be to refrain entirely from conveying the Program.

  13. Use with the GNU Affero General Public License.

  Notwithstanding any other provision of this License, you have
permission to link or combine any covered work with a work licensed
under version 3 of the GNU Affero General Public License into a single
combined work, and to convey the resulting work.  The terms of this
License will continue to apply to the part which is the covered work,
but the special requirements of the GNU Affero General Public License,
section 13, concerning interaction through a network will apply to the
combination as such.

  14. Revised Versions of this License.

  The Free Software Foundation may publish revised and/or new versions of
the GNU General Public License from time to time.  Such new versions will
be similar in spirit to the present version, but may differ in detail to
address new problems or concerns.

  Each version is given a distinguishing version number.  If the
Program specifies that a certain numbered version of the GNU General
Public License "or any later version" applies to it, you have the
option of following the terms and conditions either of that numbered
version or of any later version published by the Free Software
Foundation.  If the Program does not specify a version number of the
GNU General Public License, you may choose any version ever published
by the Free Software Foundation.

  If the Program specifies that a proxy can decide which future
versions of the GNU General Public License can be used, that proxy's
public statement of acceptance of a version permanently authorizes you
to choose that version for the Program.

  Later license versions may give you additional or different
permissions.  However, no additional obligations are imposed on any
author or copyright holder as a result of your choosing to follow a
later version.

  15. Disclaimer of Warranty.

  THERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY
APPLICABLE LAW.  EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT
HOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM "AS IS" WITHOUT WARRANTY
OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO,
THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
PURPOSE.  THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE PROGRAM
IS WITH YOU.  SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF
ALL NECESSARY SERVICING, REPAIR OR CORRECTION.

  16. Limitation of Liability.

  IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING
WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MODIFIES AND/OR CONVEYS
THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY
GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE
USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED TO LOSS OF
DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD
PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER PROGRAMS),
EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF
SUCH DAMAGES.

  17. Interpretation of Sections 15 and 16.

  If the disclaimer of warranty and limitation of liability provided
above cannot be given local legal effect according to their terms,
reviewing courts shall apply local law that most closely approximates
an absolute waiver of all civil liability in connection with the
Program, unless a warranty or assumption of liability accompanies a
copy of the Program in return for a fee.

                     END OF TERMS AND CONDITIONS

            How to Apply These Terms to Your New Programs

  If you develop a new program, and you want it to be of the greatest
possible use to the public, the best way to achieve this is to make it
free software which everyone can redistribute and change under these terms.

  To do so, attach the following notices to the program.  It is safest
to attach them to the start of each source file to most effectively
state the exclusion of warranty; and each file should have at least
the "copyright" line and a pointer to where the full notice is found.

    <one line to give the program's name and a brief idea of what it does.>
    Copyright (C) <year>  <name of author>

    This program is free software: you can redistribute it and/or modify
    it under the terms of the GNU General Public License as published by
    the Free Software Foundation, either version 3 of the License, or
    (at your option) any later version.

    This program is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU General Public License for more details.

    You should have received a copy of the GNU General Public License
    along with this program.  If not, see <https://www.gnu.org/licenses/>.

Also add information on how to contact you by electronic and paper mail.

  If the program does terminal interaction, make it output a short
notice like this when it starts in an interactive mode:

    <program>  Copyright (C) <year>  <name of author>
    This program comes with ABSOLUTELY NO WARRANTY; for details type `show w'.
    This is free software, and you are welcome to redistribute it
    under certain conditions; type `show c' for details.

The hypothetical commands `show w' and `show c' should show the appropriate
parts of the General Public License.  Of course, your program's commands
might be different; for a GUI interface, you would use an "about box".

  You should also get your employer (if you work as a programmer) or school,
if any, to sign a "copyright disclaimer" for the program, if necessary.
For more information on this, and how to apply and follow the GNU GPL, see
<https://www.gnu.org/licenses/>.

  The GNU General Public License does not permit incorporating your program
into proprietary programs.  If your program is a subroutine library, you
may consider it more useful to permit linking proprietary applications with
the library.  If this is what you want to do, use the GNU Lesser General
Public License instead of this License.  But first, please read
<https://www.gnu.org/licenses/why-not-lgpl.html>.

``````{ end_of_file: "LICENSE" }

``````{ path: "README.md" }
# pattern-lens
visualization of LLM attention patterns and things computed about them

`pattern-lens` makes it easy to:

- Generate visualizations of attention patterns, or figures computed from attention patterns, from models supported by [TransformerLens](https://github.com/TransformerLensOrg/TransformerLens)
- Compare generated figures across models, layers, and heads in an [interactive web interface](https://miv.name/pattern-lens/demo/)

# Installation

```bash
pip install pattern-lens
```


# Usage

The pipeline is as follows:

- Generate attention patterns using `pattern_lens.activations.acitvations_main()`, saving them in `npz` files
- Generate visualizations using `pattern_lens.figures.figures_main()` -- read the `npz` files, pass each attention pattern to each visualization function, and save the resulting figures
- Serve the web interface using `pattern_lens.server` -- web interface reads metadata in json/jsonl files, then lets the user select figures to show


## Basic CLI

Generate attention patterns and default visualizations:

```bash
# generate activations
python -m pattern_lens.activations --model gpt2 --prompts data/pile_1k.jsonl --save-path attn_data
# create visualizations
python -m pattern_lens.figures --model gpt2 --save-path attn_data
```

serve the web UI:

```bash
python -m pattern_lens.server --path attn_data
```


## Web UI

View a demo of the web UI at [miv.name/pattern-lens/demo](https://miv.name/pattern-lens/demo/).

## Custom Visualizations

Add custom visualization functions by decorating them with `@register_attn_figure_func`. You should generate the activations first:
```
python -m pattern_lens.activations --model gpt2 --prompts data/pile_1k.jsonl --save-path attn_data
```


and then write+run a script/notebook that looks something like this:
```python
# imports
import matplotlib.pyplot as plt
from pattern_lens.figure_util import save_matrix_wrapper, matplotlib_figure_saver
from pattern_lens.attn_figure_funcs import register_attn_figure_func
from pattern_lens.figures import figures_main

# define your own functions


# run the figures pipelne


```
``````{ end_of_file: "README.md" }

``````{ path: "demo.ipynb" }
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pattern_lens.figure_util import save_matrix_wrapper, matplotlib_figure_saver\n",
    "from pattern_lens.attn_figure_funcs import register_attn_figure_func\n",
    "from pattern_lens.figures import figures_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

``````{ end_of_file: "demo.ipynb" }

``````{ path: "makefile" }
# ==================================================
# configuration & variables
# ==================================================

PACKAGE_NAME := pattern_lens

# for checking you are on the right branch when publishing
PUBLISH_BRANCH := main

# where to put docs
DOCS_DIR := docs

# where to put the coverage reports
# note that this will be published with the docs!
# modify the `docs` targets and `.gitignore` if you don't want that
COVERAGE_REPORTS_DIR := docs/coverage

# where the tests are, for pytest
TESTS_DIR := tests

# tests temp directory to clean up. will remove this in `make clean`
TESTS_TEMP_DIR := $(TESTS_DIR)/_temp/

# probably don't change these:
# --------------------------------------------------

# where the pyproject.toml file is. no idea why you would change this but just in case
PYPROJECT := pyproject.toml

# requirements.txt files for base package, all extras, dev, and all
REQ_LOCATION := .github/requirements

# local files (don't push this to git)
LOCAL_DIR := .github/local

# will print this token when publishing. make sure not to commit this file!!!
PYPI_TOKEN_FILE := $(LOCAL_DIR)/.pypi-token

# version files
VERSIONS_DIR := .github/versions

# the last version that was auto-uploaded. will use this to create a commit log for version tag
# see `gen-commit-log` target
LAST_VERSION_FILE := $(VERSIONS_DIR)/.lastversion

# current version (writing to file needed due to shell escaping issues)
VERSION_FILE := $(VERSIONS_DIR)/.version

# base python to use. Will add `uv run` in front of this if `RUN_GLOBAL` is not set to 1
PYTHON_BASE := python

# where the commit log will be stored
COMMIT_LOG_FILE := $(LOCAL_DIR)/.commit_log

# pandoc commands (for docs)
PANDOC ?= pandoc

# version vars - extracted automatically from `pyproject.toml`, `$(LAST_VERSION_FILE)`, and $(PYTHON)
# --------------------------------------------------

# assuming your `pyproject.toml` has a line that looks like `version = "0.0.1"`, `gen-version-info` will extract this
VERSION := NULL
# `gen-version-info` will read the last version from `$(LAST_VERSION_FILE)`, or `NULL` if it doesn't exist
LAST_VERSION := NULL
# get the python version, now that we have picked the python command
PYTHON_VERSION := NULL

# cuda version
# --------------------------------------------------
# 0 or 1
CUDA_PRESENT :=
# a version like "12.4" or "NULL"
CUDA_VERSION := NULL
# a version like "124" or "NULL"
CUDA_VERSION_SHORT := NULL


# python scripts we want to use inside the makefile
# --------------------------------------------------

# create commands for exporting requirements as specified in `pyproject.toml:tool.uv-exports.exports`
define EXPORT_SCRIPT
import sys
if sys.version_info >= (3, 11):
    import tomllib
else:
    import tomli as tomllib
from pathlib import Path
from typing import Union, List, Optional

pyproject_path: Path = Path(sys.argv[1])
output_dir: Path = Path(sys.argv[2])

with open(pyproject_path, 'rb') as f:
	pyproject_data: dict = tomllib.load(f)

# all available groups
all_groups: List[str] = list(pyproject_data.get('dependency-groups', {}).keys())
all_extras: List[str] = list(pyproject_data.get('project', {}).get('optional-dependencies', {}).keys())

# options for exporting
export_opts: dict = pyproject_data.get('tool', {}).get('uv-exports', {})

# what are we exporting?
exports: List[str] = export_opts.get('exports', [])
if not exports:
	exports = [{'name': 'all', 'groups': [], 'extras': [], 'options': []}]

# export each configuration
for export in exports:
	# get name and validate
	name = export.get('name')
	if not name or not name.isalnum():
		print(f"Export configuration missing valid 'name' field {export}", file=sys.stderr)
		continue

	# get other options with default fallbacks
	filename: str = export.get('filename') or f"requirements-{name}.txt"
	groups: Union[List[str], bool, None] = export.get('groups', None)
	extras: Union[List[str], bool] = export.get('extras', [])
	options: List[str] = export.get('options', [])

	# init command
	cmd: List[str] = ['uv', 'export'] + export_opts.get('args', [])

	# handle groups
	if groups is not None:
		groups_list: List[str] = []
		if isinstance(groups, bool):
			if groups:
				groups_list = all_groups.copy()
		else:
			groups_list = groups
		
		for group in all_groups:
			if group in groups_list:
				cmd.extend(['--group', group])
			else:
				cmd.extend(['--no-group', group])

	# handle extras
	extras_list: List[str] = []
	if isinstance(extras, bool):
		if extras:
			extras_list = all_extras.copy()
	else:
		extras_list = extras

	for extra in extras_list:
		cmd.extend(['--extra', extra])

	cmd.extend(options)

	output_path = output_dir / filename
	print(f"{' '.join(cmd)} > {output_path.as_posix()}")
endef

export EXPORT_SCRIPT

# get the version from `pyproject.toml:project.version`
define GET_VERSION_SCRIPT
import sys

try:
	if sys.version_info >= (3, 11):
		import tomllib
	else:
		import tomli as tomllib

	pyproject_path = '$(PYPROJECT)'

	with open(pyproject_path, 'rb') as f:
		pyproject_data = tomllib.load(f)

	print('v' + pyproject_data['project']['version'], end='')
except Exception as e:
	print('NULL', end='')
	sys.exit(1)
endef

export GET_VERSION_SCRIPT


# get the commit log since the last version from `$(LAST_VERSION_FILE)`
define GET_COMMIT_LOG_SCRIPT
import subprocess
import sys

last_version = sys.argv[1].strip()
commit_log_file = '$(COMMIT_LOG_FILE)'

if last_version == 'NULL':
    print('!!! ERROR !!!', file=sys.stderr)
    print('LAST_VERSION is NULL, can\'t get commit log!', file=sys.stderr)
    sys.exit(1)

try:
    log_cmd = ['git', 'log', f'{last_version}..HEAD', '--pretty=format:- %s (%h)']
    commits = subprocess.check_output(log_cmd).decode('utf-8').strip().split('\n')
    with open(commit_log_file, 'w') as f:
        f.write('\n'.join(reversed(commits)))
except subprocess.CalledProcessError as e:
    print(f'Error: {e}', file=sys.stderr)
    sys.exit(1)
endef

export GET_COMMIT_LOG_SCRIPT

# get cuda information and whether torch sees it
define CHECK_TORCH_SCRIPT
import os
import sys
print(f'python version: {sys.version}')
print(f"\tpython executable path: {str(sys.executable)}")
print(f"\tsys_platform: {sys.platform}")
print(f'\tcurrent working directory: {os.getcwd()}')
print(f'\tHost name: {os.name}')
print(f'\tCPU count: {os.cpu_count()}')
print()

try:
	import torch
except Exception as e:
	print('ERROR: error importing torch, terminating        ')
	print('-'*50)
	raise e
	sys.exit(1)

print(f'torch version: {torch.__version__}')

print(f'\t{torch.cuda.is_available() = }')

if torch.cuda.is_available():
	# print('\tCUDA is available on torch')
	print(f'\tCUDA version via torch: {torch.version.cuda}')

	if torch.cuda.device_count() > 0:
		print(f"\tcurrent device: {torch.cuda.current_device() = }\n")
		n_devices: int = torch.cuda.device_count()
		print(f"detected {n_devices = }")
		for current_device in range(n_devices):
			try:
				# print(f'checking current device {current_device} of {torch.cuda.device_count()} devices')
				print(f'\tdevice {current_device}')
				dev_prop = torch.cuda.get_device_properties(torch.device(0))
				print(f'\t    name:                   {dev_prop.name}')
				print(f'\t    version:                {dev_prop.major}.{dev_prop.minor}')
				print(f'\t    total_memory:           {dev_prop.total_memory} ({dev_prop.total_memory:.1e})')
				print(f'\t    multi_processor_count:  {dev_prop.multi_processor_count}')
				print(f'\t    is_integrated:          {dev_prop.is_integrated}')
				print(f'\t    is_multi_gpu_board:     {dev_prop.is_multi_gpu_board}')
				print(f'\t')
			except Exception as e:
				print(f'Exception when trying to get properties of device {current_device}')
				raise e
		sys.exit(0)
	else:
		print(f'ERROR: {torch.cuda.device_count()} devices detected, invalid')
		print('-'*50)
		sys.exit(1)

else:
	print('ERROR: CUDA is NOT available, terminating')
	print('-'*50)
	sys.exit(1)
endef

export CHECK_TORCH_SCRIPT


# ==================================================
# reading command line options
# ==================================================

# for formatting or something, we might want to run python without uv
# RUN_GLOBAL=1 to use global `PYTHON_BASE` instead of `uv run $(PYTHON_BASE)`
RUN_GLOBAL ?= 0

ifeq ($(RUN_GLOBAL),0)
	PYTHON = uv run $(PYTHON_BASE)
else
	PYTHON = $(PYTHON_BASE)
endif

# if you want different behavior for different python versions
# --------------------------------------------------
# COMPATIBILITY_MODE := $(shell $(PYTHON) -c "import sys; print(1 if sys.version_info < (3, 10) else 0)")

# options we might want to pass to pytest
# --------------------------------------------------

# base options for pytest, will be appended to if `COV` or `VERBOSE` are 1.
# user can also set this when running make to add more options
PYTEST_OPTIONS ?= --durations 10 -vvv

# set to `1` to run pytest with `--cov=.` to get coverage reports in a `.coverage` file
COV ?= 1
# set to `1` to run pytest with `--verbose`
VERBOSE ?= 0

ifeq ($(VERBOSE),1)
	PYTEST_OPTIONS += --verbose
endif

ifeq ($(COV),1)
	PYTEST_OPTIONS += --cov=.
endif

# ==================================================
# default target (help)
# ==================================================

# first/default target is help
.PHONY: default
default: help

# ==================================================
# getting version info
# we do this in a separate target because it takes a bit of time
# ==================================================

# this recipe is weird. we need it because:
# - a one liner for getting the version with toml is unwieldy, and using regex is fragile
# - using $$GET_VERSION_SCRIPT within $(shell ...) doesn't work because of escaping issues
# - trying to write to the file inside the `gen-version-info` recipe doesn't work, 
# 	shell eval happens before our `python -c ...` gets run and `cat` doesn't see the new file
.PHONY: write-proj-version
write-proj-version:
	@mkdir -p $(VERSIONS_DIR)
	@$(PYTHON) -c "$$GET_VERSION_SCRIPT" > $(VERSION_FILE)

# gets version info from $(PYPROJECT), last version from $(LAST_VERSION_FILE), and python version
# uses just `python` for everything except getting the python version. no echo here, because this is "private"
.PHONY: gen-version-info
gen-version-info: write-proj-version
	@mkdir -p $(LOCAL_DIR)
	$(eval VERSION := $(shell cat $(VERSION_FILE)) )
	$(eval LAST_VERSION := $(shell [ -f $(LAST_VERSION_FILE) ] && cat $(LAST_VERSION_FILE) || echo NULL) )
	$(eval PYTHON_VERSION := $(shell $(PYTHON) -c "import sys; print(f'{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}')") )

# getting commit log since the tag specified in $(LAST_VERSION_FILE)
# will write to $(COMMIT_LOG_FILE)
# when publishing, the contents of $(COMMIT_LOG_FILE) will be used as the tag description (but can be edited during the process)
# no echo here, because this is "private"
.PHONY: gen-commit-log
gen-commit-log: gen-version-info
	@if [ "$(LAST_VERSION)" = "NULL" ]; then \
		echo "!!! ERROR !!!"; \
		echo "LAST_VERSION is NULL, cant get commit log!"; \
		exit 1; \
	fi
	@mkdir -p $(LOCAL_DIR)
	@$(PYTHON) -c "$$GET_COMMIT_LOG_SCRIPT" "$(LAST_VERSION)"


# force the version info to be read, printing it out
# also force the commit log to be generated, and cat it out
.PHONY: version
version: gen-commit-log
	@echo "Current version is $(VERSION), last auto-uploaded version is $(LAST_VERSION)"
	@echo "Commit log since last version from '$(COMMIT_LOG_FILE)':"
	@cat $(COMMIT_LOG_FILE)
	@echo ""
	@if [ "$(VERSION)" = "$(LAST_VERSION)" ]; then \
		echo "!!! ERROR !!!"; \
		echo "Python package $(VERSION) is the same as last published version $(LAST_VERSION), exiting!"; \
		exit 1; \
	fi


# ==================================================
# dependencies and setup
# ==================================================

.PHONY: setup
setup: dep-check
	@echo "install and update via uv"
	@echo "To activate the virtual environment, run one of:"
	@echo "  source .venv/bin/activate"
	@echo "  source .venv/Scripts/activate"

.PHONY: get-cuda-info
get-cuda-info:
	$(eval CUDA_PRESENT := $(shell if command -v nvcc > /dev/null 2>&1; then echo 1; else echo 0; fi))
	$(eval CUDA_VERSION := $(if $(filter $(CUDA_PRESENT),1),$(shell nvcc --version 2>/dev/null | grep "release" | awk '{print $$5}' | sed 's/,//'),NULL))
	$(eval CUDA_VERSION_SHORT := $(if $(filter $(CUDA_PRESENT),1),$(shell echo $(CUDA_VERSION) | sed 's/\.//'),NULL))

.PHONY: dep-check-torch
dep-check-torch:
	@echo "see if torch is installed, and which CUDA version and devices it sees"
	$(PYTHON) -c "$$CHECK_TORCH_SCRIPT"

.PHONY: dep
dep: get-cuda-info
	@echo "Exporting dependencies as per $(PYPROJECT) section 'tool.uv-exports.exports'"
	uv sync --all-extras --all-groups
	mkdir -p $(REQ_LOCATION)
	$(PYTHON) -c "$$EXPORT_SCRIPT" $(PYPROJECT) $(REQ_LOCATION) | sh -x
	
	@if [ "$(CUDA_PRESENT)" = "1" ]; then \
		echo "CUDA is present, installing torch with CUDA $(CUDA_VERSION)"; \
		uv pip install torch --upgrade --index https://download.pytorch.org/whl/cu$(CUDA_VERSION_SHORT); \
	fi
	

.PHONY: dep-check
dep-check:
	@echo "Checking that exported requirements are up to date"
	uv sync --all-extras --all-groups
	mkdir -p $(REQ_LOCATION)-TEMP
	$(PYTHON) -c "$$EXPORT_SCRIPT" $(PYPROJECT) $(REQ_LOCATION)-TEMP | sh -x
	diff -r $(REQ_LOCATION)-TEMP $(REQ_LOCATION)
	rm -rf $(REQ_LOCATION)-TEMP


.PHONY: dep-clean
dep-clean:
	@echo "clean up lock files, .venv, and requirements files"
	rm -rf .venv
	rm -rf uv.lock
	rm -rf $(REQ_LOCATION)/*.txt

# ==================================================
# checks (formatting/linting, typing, tests)
# ==================================================

# runs ruff and pycln to format the code
.PHONY: format
format:
	@echo "format the source code"
	$(PYTHON) -m ruff format --config $(PYPROJECT) .
	$(PYTHON) -m ruff check --fix --config $(PYPROJECT) .
	$(PYTHON) -m pycln --config $(PYPROJECT) --all .

# runs ruff and pycln to check if the code is formatted correctly
.PHONY: format-check
format-check:
	@echo "check if the source code is formatted correctly"
	$(PYTHON) -m ruff check --config $(PYPROJECT) .
	$(PYTHON) -m pycln --check --config $(PYPROJECT) .

# runs type checks with mypy
# at some point, need to add back --check-untyped-defs to mypy call
# but it complains when we specify arguments by keyword where positional is fine
# not sure how to fix this
.PHONY: typing
typing: clean
	@echo "running type checks"
	$(PYTHON) -m mypy --config-file $(PYPROJECT) $(TYPECHECK_ARGS) $(PACKAGE_NAME)/
	$(PYTHON) -m mypy --config-file $(PYPROJECT) $(TYPECHECK_ARGS) $(TESTS_DIR)

.PHONY: test
test: clean
	@echo "running tests"
	$(PYTHON) -m pytest $(PYTEST_OPTIONS) $(TESTS_DIR)

.PHONY: test-unit
test-unit:
	@echo "running unit tests"
	$(PYTHON) -m pytest $(PYTEST_OPTIONS) $(TESTS_DIR)/unit

.PHONY: test-integration
test-integration:
	@echo "running integration tests"
	$(PYTHON) -m pytest $(PYTEST_OPTIONS) $(TESTS_DIR)/integration

.PHONY: check
check: clean format-check test typing
	@echo "run format checks, tests, and typing checks"

# ==================================================
# coverage & docs
# ==================================================

# generates a whole tree of documentation in html format.
# see `docs/make_docs.py` and the templates in `docs/templates/html/` for more info
.PHONY: docs-html
docs-html:
	@echo "generate html docs"
	$(PYTHON) docs/make_docs.py

# instead of a whole website, generates a single markdown file with all docs using the templates in `docs/templates/markdown/`.
# this is useful if you want to have a copy that you can grep/search, but those docs are much messier.
# docs-combined will use pandoc to convert them to other formats.
.PHONY: docs-md
docs-md:
	@echo "generate combined (single-file) docs in markdown"
	mkdir $(DOCS_DIR)/combined -p
	$(PYTHON) docs/make_docs.py --combined

# after running docs-md, this will convert the combined markdown file to other formats:
# gfm (github-flavored markdown), plain text, and html
# requires pandoc in path, pointed to by $(PANDOC)
# pdf output would be nice but requires other deps
.PHONY: docs-combined
docs-combined: docs-md
	@echo "generate combined (single-file) docs in markdown and convert to other formats"
	@echo "requires pandoc in path"
	$(PANDOC) -f markdown -t gfm $(DOCS_DIR)/combined/$(PACKAGE_NAME).md -o $(DOCS_DIR)/combined/$(PACKAGE_NAME)_gfm.md
	$(PANDOC) -f markdown -t plain $(DOCS_DIR)/combined/$(PACKAGE_NAME).md -o $(DOCS_DIR)/combined/$(PACKAGE_NAME).txt
	$(PANDOC) -f markdown -t html $(DOCS_DIR)/combined/$(PACKAGE_NAME).md -o $(DOCS_DIR)/combined/$(PACKAGE_NAME).html

# generates coverage reports as html and text with `pytest-cov`, and a badge with `coverage-badge`
# if `.coverage` is not found, will run tests first
# also removes the `.gitignore` file that `coverage html` creates, since we count that as part of the docs
.PHONY: cov
cov:
	@echo "generate coverage reports"
	@if [ ! -f .coverage ]; then \
		echo ".coverage not found, running tests first..."; \
		$(MAKE) test; \
	fi
	mkdir $(COVERAGE_REPORTS_DIR) -p
	$(PYTHON) -m coverage report -m > $(COVERAGE_REPORTS_DIR)/coverage.txt
	$(PYTHON) -m coverage_badge -f -o $(COVERAGE_REPORTS_DIR)/coverage.svg
	$(PYTHON) -m coverage html --directory=$(COVERAGE_REPORTS_DIR)/html/
	rm -rf $(COVERAGE_REPORTS_DIR)/html/.gitignore

# runs the coverage report, then the docs, then the combined docs
.PHONY: docs
docs: demo-docs cov docs-html docs-combined
	@echo "generate all documentation and coverage reports"

# removed all generated documentation files, but leaves the templates and the `docs/make_docs.py` script
# distinct from `make clean`
.PHONY: docs-clean
docs-clean:
	@echo "remove generated docs"
	rm -rf $(DOCS_DIR)/combined/
	rm -rf $(DOCS_DIR)/$(PACKAGE_NAME)/
	rm -rf $(COVERAGE_REPORTS_DIR)/
	rm $(DOCS_DIR)/$(PACKAGE_NAME).html
	rm $(DOCS_DIR)/index.html
	rm $(DOCS_DIR)/search.js
	rm $(DOCS_DIR)/package_map.dot
	rm $(DOCS_DIR)/package_map.html


# ==================================================
# build and publish
# ==================================================

# verifies that the current branch is $(PUBLISH_BRANCH) and that git is clean
# used before publishing
.PHONY: verify-git
verify-git: 
	@echo "checking git status"
	if [ "$(shell git branch --show-current)" != $(PUBLISH_BRANCH) ]; then \
		echo "!!! ERROR !!!"; \
		echo "Git is not on the $(PUBLISH_BRANCH) branch, exiting!"; \
		exit 1; \
	fi; \
	if [ -n "$(shell git status --porcelain)" ]; then \
		echo "!!! ERROR !!!"; \
		echo "Git is not clean, exiting!"; \
		exit 1; \
	fi; \


.PHONY: build
build: 
	@echo "build the package"
	uv build

# gets the commit log, checks everything, builds, and then publishes with twine
# will ask the user to confirm the new version number (and this allows for editing the tag info)
# will also print the contents of $(PYPI_TOKEN_FILE) to the console for the user to copy and paste in when prompted by twine
.PHONY: publish
publish: gen-commit-log check build verify-git version gen-version-info
	@echo "run all checks, build, and then publish"

	@echo "Enter the new version number if you want to upload to pypi and create a new tag"
	@echo "Now would also be the time to edit $(COMMIT_LOG_FILE), as that will be used as the tag description"
	@read -p "Confirm: " NEW_VERSION; \
	if [ "$$NEW_VERSION" = $(VERSION) ]; then \
		echo "!!! ERROR !!!"; \
		echo "Version confirmed. Proceeding with publish."; \
	else \
		echo "Version mismatch, exiting: you gave $$NEW_VERSION but expected $(VERSION)"; \
		exit 1; \
	fi;

	@echo "pypi username: __token__"
	@echo "pypi token from '$(PYPI_TOKEN_FILE)' :"
	echo $$(cat $(PYPI_TOKEN_FILE))

	echo "Uploading!"; \
	echo $(VERSION) > $(LAST_VERSION_FILE); \
	git add $(LAST_VERSION_FILE); \
	git commit -m "Auto update to $(VERSION)"; \
	git tag -a $(VERSION) -F $(COMMIT_LOG_FILE); \
	git push origin $(VERSION); \
	twine upload dist/* --verbose

# ==================================================
# cleanup of temp files
# ==================================================

# cleans up temp files from formatter, type checking, tests, coverage
# removes all built files
# removes $(TESTS_TEMP_DIR) to remove temporary test files
# recursively removes all `__pycache__` directories and `*.pyc` or `*.pyo` files
# distinct from `make docs-clean`, which only removes generated documentation files
.PHONY: clean
clean:
	@echo "clean up temporary files"
	rm -rf .mypy_cache
	rm -rf .ruff_cache
	rm -rf .pytest_cache
	rm -rf .coverage
	rm -rf dist
	rm -rf build
	rm -rf $(PACKAGE_NAME).egg-info
	rm -rf $(TESTS_TEMP_DIR)
	$(PYTHON_BASE) -Bc "import pathlib; [p.unlink() for path in ['$(PACKAGE_NAME)', '$(TESTS_DIR)', '$(DOCS_DIR)'] for pattern in ['*.py[co]', '__pycache__/*'] for p in pathlib.Path(path).rglob(pattern)]"

.PHONY: clean-all
clean-all: clean dep-clean docs-clean
	@echo "clean up all temporary files, dep files, venv, and generated docs"


# ==================================================
# smart help command
# ==================================================

# listing targets is from stackoverflow
# https://stackoverflow.com/questions/4219255/how-do-you-get-the-list-of-targets-in-a-makefile
# no .PHONY because this will only be run before `make help`
# it's a separate command because getting the versions takes a bit of time
help-targets:
	@echo -n "# make targets"
	@echo ":"
	@cat Makefile | sed -n '/^\.PHONY: / h; /\(^\t@*echo\|^\t:\)/ {H; x; /PHONY/ s/.PHONY: \(.*\)\n.*"\(.*\)"/    make \1\t\2/p; d; x}'| sort -k2,2 |expand -t 30


.PHONY: info
info: gen-version-info get-cuda-info
	@echo "# makefile variables"
	@echo "    PYTHON = $(PYTHON)"
	@echo "    PYTHON_VERSION = $(PYTHON_VERSION)"
	@echo "    PACKAGE_NAME = $(PACKAGE_NAME)"
	@echo "    VERSION = $(VERSION)"
	@echo "    LAST_VERSION = $(LAST_VERSION)"
	@echo "    PYTEST_OPTIONS = $(PYTEST_OPTIONS)"
	@echo "    CUDA_PRESENT = $(CUDA_PRESENT)"
	@if [ "$(CUDA_PRESENT)" = "1" ]; then \
		echo "    CUDA_VERSION = $(CUDA_VERSION)"; \
		echo "    CUDA_VERSION_SHORT = $(CUDA_VERSION_SHORT)"; \
	fi

.PHONY: info-long
info-long: info
	@echo "# other variables"
	@echo "    PUBLISH_BRANCH = $(PUBLISH_BRANCH)"
	@echo "    DOCS_DIR = $(DOCS_DIR)"
	@echo "    COVERAGE_REPORTS_DIR = $(COVERAGE_REPORTS_DIR)"
	@echo "    TESTS_DIR = $(TESTS_DIR)"
	@echo "    TESTS_TEMP_DIR = $(TESTS_TEMP_DIR)"
	@echo "    PYPROJECT = $(PYPROJECT)"
	@echo "    REQ_LOCATION = $(REQ_LOCATION)"
	@echo "    REQ_BASE = $(REQ_BASE)"
	@echo "    REQ_EXTRAS = $(REQ_EXTRAS)"
	@echo "    REQ_DEV = $(REQ_DEV)"
	@echo "    REQ_ALL = $(REQ_ALL)"
	@echo "    LOCAL_DIR = $(LOCAL_DIR)"
	@echo "    PYPI_TOKEN_FILE = $(PYPI_TOKEN_FILE)"
	@echo "    LAST_VERSION_FILE = $(LAST_VERSION_FILE)"
	@echo "    PYTHON_BASE = $(PYTHON_BASE)"
	@echo "    COMMIT_LOG_FILE = $(COMMIT_LOG_FILE)"
	@echo "    PANDOC = $(PANDOC)"
	@echo "    COV = $(COV)"
	@echo "    VERBOSE = $(VERBOSE)"
	@echo "    RUN_GLOBAL = $(RUN_GLOBAL)"
	@echo "    TYPECHECK_ARGS = $(TYPECHECK_ARGS)"

# immediately print out the help targets, and then local variables (but those take a bit longer)
.PHONY: help
help: help-targets info
	@echo -n ""

# ==================================================
# custom targets
# ==================================================
# (put them down here, or delimit with ~~~~~)


DEMO_MODEL ?= pythia-14m,tiny-stories-1M
DEMO_PROMPTS ?= data/pile_100.jsonl
DEMO_N_SAMPLES ?= 10
DEMO_ARGS ?= --min-chars 128 --max-chars 256
DEMO_DATA ?= docs/demo


.PHONY: demo-clean
demo-clean:
	rm -rf $(DEMO_DATA)

.PHONY: demo-activations
demo-activations:
	$(PYTHON) -m pattern_lens.activations --model $(DEMO_MODEL) --prompts $(DEMO_PROMPTS) --raw-prompts --save-path $(DEMO_DATA) --n-samples $(DEMO_N_SAMPLES) $(DEMO_ARGS)

.PHONY: demo-figures
demo-figures:
	$(PYTHON) -m pattern_lens.figures --model $(DEMO_MODEL) --save-path $(DEMO_DATA)

.PHONY: demo-server
demo-server:
	$(PYTHON) -m pattern_lens.server --path $(DEMO_DATA)

.PHONY: demo
demo: demo-clean demo-activations demo-figures demo-server
	@echo "generate demo"

.PHONY: demo-docs
demo-docs: demo-clean demo-activations demo-figures
	@echo "generate demo for docs (no server)"


.PHONY: summary
summary:
	@echo "write docs/summary.md using lmcat"
	py -m lmcat -o docs/summary.md
``````{ end_of_file: "makefile" }

``````{ path: "pyproject.toml" }
[project]
name = "pattern_lens"
version = "0.1.0"
description = ""
readme = "README.md"
requires-python = ">=3.12"
dependencies = [
    # standard
    "numpy>=1.26.1,<2.0.0",
    "torch>=2.5.1",
    "jaxtyping>=0.2.33",
    "tqdm>=4.66.5",
    "pandas>=2.2.2",
    "scipy>=1.14.1",
    # "scikit-learn>=1.3",
    "matplotlib>=3.8.0",
    "pillow>=11.0.0",
    # jupyter
    "ipykernel>=6.29.5",
    "ipywidgets>=8.1.5",
    # typing
    "beartype>=0.14.1",
    # custom utils
    "muutils>=0.6.19",
	"zanj>=0.3.1",
    # TL
    "transformer-lens>=2.10.0",
    # this TL dep not listed? is this in an extra?
    "typeguard>=4.4.1",
]

[dependency-groups]
dev = [
    # lmcat
    "lmcat>=0.0.1",
	# test
	"pytest>=8.2.2",
	# coverage
	"pytest-cov>=4.1.0",
	"coverage-badge>=1.1.0",
	# type checking
	"mypy>=1.0.1",
    "types-tqdm",
	# docs
	'pdoc>=14.6.0',
	# tomli since no tomlib in python < 3.11
	"tomli>=2.1.0; python_version < '3.11'",
	# lint
	"pycln>=2.1.3",
	"ruff>=0.4.8",
]

[tool.uv]
package = true
compile-bytecode = true

[project.urls]
Homepage = "https://miv.name/pattern-lens"
Documentation = "https://miv.name/pattern-lens"
Repository = "https://github.com/mivanit/pattern-lens"
Issues = "https://github.com/mivanit/pattern-lens/issues"

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.hatch.build.targets.wheel]
packages = ["pattern_lens"]

# Custom export configurations
[tool.uv-exports]
args = [
	"--no-hashes"
]
exports = [
	# no groups, no extras, just the base dependencies
    { name = "base", groups = false, extras = false },
	# all groups and extras
    { name = "all", filename="requirements.txt", groups = true, extras=true },
	{ name = "all", groups = true, options = ["--all-extras"] },
]

[tool.pytest.ini_options]
addopts = "--jaxtyping-packages=pattern_lens,beartype.beartype"
filterwarnings = [
    "ignore: PEP 484 type hint*:beartype.roar._roarwarn.BeartypeDecorHintPep585DeprecationWarning",
]
``````{ end_of_file: "pyproject.toml" }